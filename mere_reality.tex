\part{Mere Reality}


\mysectiontwo{The World: An Introduction}{The World: An Introduction\newline
by Rob Bensinger}


 Previous essays have discussed human reasoning, language, goals,
and social dynamics. Mathematics, physics, and biology were cited to
explain patterns in human behavior, but little has been said about
humanity's place in nature, or about the natural world
in its own right.


 Just as it was useful to contrast humans \textit{as goal-oriented
systems} with inhuman processes in evolutionary biology and artificial
intelligence, it will be useful in the coming sequences of essays to
contrast humans \textit{as physical systems} with inhuman processes
that \textit{aren't} mind-like.

{
 We humans are, after all, built out of inhuman parts. The world of
atoms looks nothing like the world as we ordinarily think of it, and
certainly looks nothing like the world's conscious
denizens as we ordinarily think of them. As Giulio Giorello put the
point in an interview with Daniel Dennett: ``Yes, we
have a soul. But it's made of lots of tiny
robots.''\footnote{Daniel C. Dennett, \textit{Freedom Evolves} (Viking Books,
2003).\comment{1}}}


 \textit{Mere Reality} collects seven sequences of essays on this
topic. The first three introduce the question of how the human world
relates to the world revealed by physics: ``Lawful
Truth'' (on the basic links between physics and human
cognition), ``Reductionism 101'' (on
the project of scientifically explaining phenomena), and
``Joy in the Merely Real'' (on the
emotional, personal significance of the scientific world-view). This is
followed by two sequences that go into more depth on specific academic
debates: ``Physicalism 201'' (on the
hard problem of consciousness) and ``Quantum Physics
and Many Worlds'' (on the measurement problem in
physics). Finally, the sequence ``Science and
Rationality'' and the essay A Technical Explanation
of Technical Explanation tie these ideas together and relate them to
scientific practice.


 The discussions of consciousness and quantum physics illustrate
the relevance of reductionism to present-day controversies in science
and philosophy. For those interested in a bit of extra context,
I'll say a few more words about those two topics here.
For those eager to skip ahead: skip ahead!

\subsection{Minds in the World}


 Can we ever know what it's like to be a bat?

{
 We can certainly develop better cognitive models for predicting
bat behavior, or more fine-grained models of bat neurology---but it
isn't obvious that this would tell us what echolocation
subjectively feels like, or what flying feels like, \textit{from the
bat's point of view}.}


 Indeed, it seems as though we could never even be certain that
there \textit{is} anything it's like to be a bat. Why
couldn't an unconscious automaton replicate all the
overt behaviors of a conscious agent to arbitrary precision?
(Philosophers call such automata
``zombies,'' though they have little
in common with the zombies of folklore---who are \textit{quite visibly}
different from conscious agents!)


 A race of alien psychologists would run into the same problem in
trying to model \textit{human} consciousness. They might arrive at a
perfect predictive model of what we say and do when we see a red rose,
but that wouldn't mean that the aliens fully understand
what redness feels like ``from the
inside.''


 Running with examples like these, philosophers like Thomas Nagel
and David Chalmers have argued that third-person cognitive and neural
models can never fully capture first-person
consciousness.\footnote{David J. Chalmers, \textit{The Conscious Mind: In Search of a
Fundamental Theory} (New York: Oxford University Press, 1996).\comment{2}}\supercomma\footnote{Thomas Nagel, ``What Is It Like to Be a
Bat?,'' \textit{Philosophical Review} 83, no. 4
(1974): 435--450, \url{http://www.jstor.org/stable/2183914}.\comment{3}} No matter how much we know about a
physical system, it is always logically possible, on this view, that
the system has no first-person experiences. Traditional dualism, with
its immaterial souls freely floating around violating physical laws,
may be false; but Chalmers insists on a weaker thesis, that
consciousness is a ``further fact''
not fully explainable by the physical facts.


 A number of philosophers and scientists have found this line of
reasoning persuasive.\footnote{In a survey of Anglophone professional philosophers, 56.5\%
endorsed physicalism, 27.1\% endorsed anti-physicalism, and 16.4\%
endorsed other views (e.g., ``I don't
know'').\footnotemark Most philosophers reject
the metaphysical possibility of Chalmers's
``zombies,'' but there is no
consensus about \textit{why}, exactly, Chalmers's
zombie argument fails. Kirk summarizes contemporary positions on
phenomenal consciousness, giving arguments that resemble
Yudkowsky's against the possibility of knowing or
referring to irreducible qualia.\footnotemark\comment{4}}
\footback{2}\footnext\footnotetext{David Bourget and David J. Chalmers, ``What
Do Philosophers Believe?,'' \textit{Philosophical
  Studies} (2013): 1--36.\comment{11}}\footnext\footnotetext{Robert Kirk, \textit{Mind and Body}
  (McGill-Queen's University Press, 2003).\comment{12}}If we feel this
argument's intuitive force, should we grant its
conclusion and ditch physicalism?


 We certainly shouldn't reject it just because it
\textit{sounds strange} or feels vaguely unscientific. But how does the
argument stand up to a \textit{technical} understanding of how
explanation and belief work? Are there any hints we can take from the
history of science, or from our understanding of the physical
mechanisms underlying evidence? ``Physicalism
201'' will return to this question.


\subsection{Worlds in the World}


 Quantum mechanics is our best mathematical model of the universe
to date, powerfully confirmed by a century of tests. The theory posits
a complex-numbered ``probability
amplitude,'' so called because a specific operation
(squaring the number's absolute value---the Born rule)
lets us probabilistically predict phenomena at small scales and extreme
energy levels. This amplitude changes deterministically in accord with
the Schrödinger equation. In the process, it often enters odd states
called ``superpositions.''


 Yet when we perform experiments, the superpositions seem to vanish
without a trace. When we aren't looking, the
Schrödinger equation appears to capture everything there is to know
about the dynamics of physical systems. When we \textit{are} looking,
though, this clean determinism is replaced by Born's
probabilistic rule. It's as though the ordinary laws of
physics are suddenly suspended whenever we make
``observations.'' As John Stewart
Bell put the point:

\begin{quote}
{
 It would seem that the theory is exclusively concerned about
``results of measurements'' and has
nothing to say about anything else. What exactly qualifies some
physical systems to play the role of the
``measurer''? Was the wavefunction
of the world waiting to jump for thousands of millions of years until a
single-celled living creature appeared? Or did it have to wait a little
longer, for some better qualified system\,\ldots with a PhD?}
\end{quote}


 Everyone agrees that this strange mix of Schrödinger and
Born's rules has proved empirically adequate. However,
the question of exactly \textit{when} Born's rule
enters the mix, and what it all \textit{means}, has produced a chaos of
different views on the nature of quantum mechanics.


 Early on, the Copenhagen school---Niels Bohr and other originators
of quantum theory---splintered into several standard ways of talking
about the experimental results and the odd formalism used to predict
them. Some, taking the theory's focus on
``measurements'' and
``observations'' quite literally,
proposed that consciousness plays a fundamental role in physical law,
intervening to cause complex amplitudes to
``collapse'' into observables.
Others, led by Werner Heisenberg, advocated a non-realistic view
according to which physics is about our states of knowledge rather than
about any objective reality. Yet another Copenhagen tradition, summed
up in the slogan ``shut up and
calculate,'' warned against metaphysical speculation
of all kinds.


 Yudkowsky uses this scientific controversy as a proving ground for
some central ideas from previous sequences: map-territory distinctions,
mysterious answers, Bayesianism, and Occam's Razor.
Since he is not a physicist---and neither am I---I'll
provide some outside sources here for readers who want to vet his
arguments or learn more about his physics examples.


 Tegmark's \textit{Our Mathematical Universe}
discusses a number of relevant ideas in philosophy and
physics.\footnote{Max Tegmark, \textit{Our Mathematical Universe: My Quest for
the Ultimate Nature }\textit{of Reality} (Random House LLC, 2014).\comment{5}} Among Tegmark's more novel
ideas is his argument that all consistent mathematical structures
exist, including worlds with physical laws and boundary conditions
entirely unlike our own. He distinguishes these Tegmark worlds from
multiverses in more scientifically mainstream hypotheses---e.g., worlds
in stochastic eternal inflationary models of the Big Bang and in Hugh
Everett's many-worlds interpretation of quantum
physics.

{
 Yudkowsky discusses many-worlds interpretations at greater length,
as a response to the Copenhagen interpretations of quantum mechanics.
Many-worlds has become very popular in recent decades among physicists,
especially cosmologists. However, a number of physicists continue to
reject it or maintain agnosticism. For a (mostly) philosophically
mainstream introduction to this debate, see Albert's
\textit{Quantum Mechanics and Experience}.\footnote{David Z. Albert, \textit{Quantum Mechanics and Experience}
(Harvard University Press, 1994).\comment{6}} See also
the \textit{Stanford Encyclopedia of Philosophy}'s
introduction to ``Measurement in Quantum
Theory,''\footnote{Henry Krips, ``Measurement in Quantum
Theory,'' in \textit{The Stanford Encyclopedia of
Philosophy}, Fall 2013, ed. Edward N. Zalta.\comment{7}} and their introduction
to several of the views associated with ``many
worlds'' in
``Everett's Relative-State
Formulation''\footnote{Jeffrey Barrett, \textit{Everett's
Relative-State Formulation of Quantum Mechanics}, ed. Edward N. Zalta,
\url{http://plato.stanford.edu/archives/fall2008/entries/qm-everett/}.\comment{8}} and
``Many-Worlds
Interpretation.''\footnote{Lev Vaidman, ``Many-Worlds Interpretation of
Quantum Mechanics,'' in \textit{The Stanford
Encyclopedia of Philosophy}, Fall 2008, ed. Edward N. Zalta.\comment{9}}}


 On the less theoretical side, Epstein's
\textit{Thinking Physics} is a great text for training physical
intuitions.\footnote{Lewis Carroll Epstein, \textit{Thinking Physics:
Understandable Practical Reality, 3rd Edition} (Insight Press, 2009).\comment{10}} It's worth keeping in
mind that just as one can understand most of cognitive science without
understanding the nature of subjective awareness, one can understand
most of physics without having a settled view of the ultimate nature
(and size!) of the physical world.


\chapter{Lawful Truth}

\mysection{Universal Fire}


 In L. Sprague de Camp's fantasy story \textit{The
Incomplete Enchanter} (which set the mold for the many imitations that
followed), the hero, Harold Shea, is transported from our own universe
into the universe of Norse mythology.\footnote{Lyon Sprague de Camp and Fletcher Pratt, \textit{The Incomplete
Enchanter} (New York: Henry Holt \& Company, 1941).\comment{1}} This world is
based on magic rather than technology; so naturally, when Our Hero
tries to light a fire with a match brought along from Earth, the match
fails to strike. 


 I realize it was only a fantasy story, but\,\ldots how do I put this\,\ldots


 \textit{No.}


 In the late eighteenth century, Antoine-Laurent de Lavoisier
discovered fire. ``What?'' you say.
``Hasn't the use of fire been dated
back for hundreds of thousands of years?'' Well, yes,
people \textit{used} fire; it was hot, bright, sort of orangey-colored,
and you could use it to cook things. But nobody knew how it worked.
Greek and medieval alchemists thought that Fire was a basic thing, one
of the Four Elements. In Lavoisier's time the
alchemical paradigm had been gradually amended and greatly complicated,
but fire was still held to be basic---in the form of
``phlogiston,'' a rather mysterious
substance which was said to explain fire, and also every other
phenomenon in alchemy.


 Lavoisier's great innovation was to weigh
\textit{all} the pieces of the chemical puzzle, both before and after
the chemical reaction. It had previously been thought that some
chemical transmutations changed the weight of the total material: If
you subjected finely ground antimony to the focused sunlight of a
burning glass, the antimony would be reduced to ashes after one hour,
and the ashes would weigh one-tenth more than the original
antimony---even though the burning had been accompanied by the loss of
a thick white smoke. Lavoisier weighed \textit{all} the components of
such reactions, including the air in which the reaction took place, and
discovered that matter was neither created nor destroyed. If the burnt
ashes increased in weight, there was a corresponding decrease in the
weight of the air.

{
 Lavoisier also knew how to separate gases, and discovered that a
burning candle diminished the amount of one kind of gas, \textit{vital
air}, and produced another gas, \textit{fixed air}. Today we would call
them \textit{oxygen} and \textit{carbon dioxide}. When the
\textit{vital air} was exhausted, the fire went out. One might guess,
perhaps, that combustion transformed \textit{vital air} into
\textit{fixed air} and fuel to ash, and that the ability of this
transformation to continue was limited by the amount of \textit{vital
air} available.}


 Lavoisier's proposal directly contradicted the
then-current phlogiston theory. That alone would have been shocking
enough, but it also turned out\,\ldots


 To appreciate what comes next, you must put yourself into an
eighteenth-century frame of mind. Forget the discovery of DNA, which
occurred only in 1953. Unlearn the cell theory of biology, which was
formulated in 1839. Imagine looking at your hand, flexing your fingers\,\ldots and having absolutely no idea how it worked. The anatomy of
muscle and bone was known, but no one had any notion of
``what makes it go''---why a muscle
moves and flexes, while clay molded into a similar shape just sits
there. Imagine \textit{your own body} being composed of mysterious,
incomprehensible gloop. And then, imagine discovering\,\ldots


 \ldots that humans, in the course of breathing, consumed
\textit{vital air} and breathed out \textit{fixed air}. People also ran
on combustion! Lavoisier measured the amount of heat that animals (and
Lavoisier's assistant, Seguin) produced when
exercising, the amount of \textit{vital air} consumed, and the
\textit{fixed air} breathed out. When animals produced more heat, they
consumed more \textit{vital air} and exhaled more \textit{fixed air}.
People, like fire, consumed fuel and oxygen; people, like fire,
produced heat and carbon dioxide. Deprive people of oxygen, or fuel,
and the light goes out.


 Matches catch fire because of
phosphorus---``safety matches'' have
phosphorus on the ignition strip; strike-anywhere matches have
phosphorus in the match heads. Phosphorus is highly reactive; pure
phosphorus glows in the dark and may spontaneously combust. (Henning
Brand, who purified phosphorus in 1669, announced that he had
discovered Elemental Fire.) Phosphorus is thus also well-suited to its
role in \textit{adenosine triphosphate}, ATP, your
body's chief method of storing chemical energy. ATP is
sometimes called the ``molecular
currency.'' It invigorates your muscles and charges
up your neurons. Almost every metabolic reaction in biology relies on
ATP, and therefore on the chemical properties of phosphorus.


 If a match stops working, so do you. You can't
change just one thing.


 The surface-level rules, ``Matches catch fire
when struck,'' and ``Humans need air
to breathe,'' are not obviously connected. It took
centuries to discover the connection, and even then, it still seems
like some distant fact learned in school, relevant only to a few
specialists. It is all too easy to imagine a world where one surface
rule holds, and the other doesn't; to suppress our
credence in one belief, but not the other. But that is
\textit{imagination}, not reality. If your map breaks into four pieces
for easy storage, it doesn't mean the territory is also
broken into disconnected parts. Our minds store different surface-level
rules in different compartments, but this does not reflect any division
in the laws that govern Nature.


 We can take the lesson further. Phosphorus derives its behavior
from even deeper laws, electrodynamics and chromodynamics.
``Phosphorus'' is merely our
\textit{word} for electrons and quarks arranged a certain way. You
cannot change the chemical properties of phosphorus without changing
the laws governing electrons and quarks.


 If you stepped into a world where matches failed to strike, you
would cease to exist as organized matter.


 Reality is laced together a lot more tightly than humans might
like to believe.

\myendsectiontext


\bigskip

\mysection{Universal Law}


 Antoine-Laurent de Lavoisier discovered that breathing
(respiration) and fire (combustion) operated on the same principle. It
was one of the most startling unifications in the history of science,
for it brought together the mundane realm of matter and the sacred
realm of life, which humans had divided into separate magisteria. 


 The first great simplification was that of Isaac Newton, who
unified the course of the planets with the trajectory of a falling
apple. The shock of this discovery was greater by far than
Lavoisier's. It wasn't just that Newton
had dared to unify the Earthly realm of base matter with the obviously
different and sacred celestial realm, once thought to be the abode of
the gods. Newton's discovery gave rise to the notion of
a \textit{universal law}, one that is the same everywhere and
everywhen, with literally \textit{zero} exceptions.


 Human beings live in a world of surface phenomena, and surface
phenomena are divided into leaky categories with plenty of exceptions.
A tiger does not behave like a buffalo. Most buffalo have four legs,
but perhaps this one has three. Why would anyone think there would be
laws that hold everywhere? It's just so obviously
untrue.


 The only time when it seems like we would \textit{want} a law to
hold everywhere is when we are talking about moral laws---tribal rules
of behavior. Some tribe members may try to take more than their fair
share of the buffalo meat---perhaps coming up with some clever
excuse---so in the case of moral laws we do seem to have an instinct to
universality. Yes, the rule about dividing the meat evenly applies to
\textit{you}, right now, whether you like it or not. But even here
there are exceptions. If---for some bizarre reason---a more powerful
tribe threatened to spear all of you unless Bob received twice as much
meat on just this one occasion, you'd give Bob twice as
much meat. The idea of a rule with literally \textit{no} exceptions
seems insanely rigid, the product of closed-minded thinking by fanatics
so in the grip of their one big idea that they can't
see the richness and complexity of the real universe.


 This is the customary accusation made against scientists---the
professional students of the richness and complexity of the real
universe. Because \textit{when you actually look at the universe}, it
turns out to be, by human standards, insanely rigid in applying its
rules. As far as we know, there has been \textit{not one single}
violation of Conservation of Momentum from the uttermost dawn of time
up until now.


 Sometimes---very rarely---we observe an apparent violation of our
\textit{models} of the fundamental laws. Though our scientific models
may last for a generation or two, they are not stable over the course
of centuries\,\ldots but do not fancy that this makes the universe itself
whimsical. That is mixing up the map with the territory. For when the
dust subsides and the old theory is overthrown, it turns out that the
universe \textit{always was} acting according to the new generalization
we have discovered, which once again is absolutely universal as far as
humanity's knowledge extends. When it was discovered
that Newtonian gravitation was a special case of General Relativity, it
was seen that General Relativity had been governing the orbit of
Mercury for decades before any human being knew about it; and it would
later become apparent that General Relativity had been governing the
collapse of stars for billions of years before humanity. It is only our
model that was mistaken---the Law itself was always absolutely
constant---or so our new model tells us.

{
 I may repose only 80\% confidence that the lightspeed limit will
last out the next hundred thousand years, but this does not mean that I
think the lightspeed limit holds only 80\% of the time, with occasional
exceptions. The proposition to which I assign 80\% probability is that
the lightspeed law is \textit{absolutely inviolable throughout the
entirety of space and time}.}


 One of the reasons the ancient Greeks didn't
discover science is that they didn't realize you could
generalize from experiments. The Greek philosophers were interested in
``normal'' phenomena. If you set up
a contrived experiment, you would probably get a
``monstrous'' result, one that had
no implications for how things really worked.


 So that is how humans tend to dream, before they learn better; but
what of the universe's own quiet dreams that it dreamed
to itself before ever it dreamed of humans? If you would learn to think
like reality, then here is the Tao:

\begin{quote}
{
 \textit{Since the beginning}\newline
\textit{ not one unusual thing}\newline
\textit{ has ever happened.}}
\end{quote}

\myendsectiontext

\mysection{Is Reality Ugly?}


 Consider the cubes, \{1, 8, 27,
64, 125,\,\ldots~\}. Their first
differences \{7, 19, 37, 61,\,\ldots~\} might at first seem to lack
an obvious pattern, but taking the second differences
\{12, 18, 24,\,\ldots~\} takes you down to the simply
related level. Taking the third differences
\{6, 6,\,\ldots~\} brings us to the perfectly
stable level, where chaos dissolves into order. 


 But this is a handpicked example. Perhaps the
``messy real world'' lacks the
beauty of these abstract mathematical objects? Perhaps it would be more
appropriate to talk about neuroscience or gene expression networks?


 Abstract math, being constructed solely in imagination, arises
from simple foundations---a small set of initial axioms---and is a
closed system; conditions that might seem \textit{unnaturally}
conducive to neatness.


 Which is to say: In pure math, you don't have to
worry about a tiger leaping out of the bushes and eating
Pascal's Triangle.


 So is the real world uglier than mathematics?


 Strange that people ask this. I mean, the question might have been
sensible two and a half millennia ago\,\ldots Back when the Greek
philosophers were debating what this ``real
world'' thingy might be made of, there were many
positions. Heraclitus said, ``All is
fire.'' Thales said, ``All is
water.'' Pythagoras said, ``All is
number.''


 Score:

\begin{center}
\begin{tabular}{|l|l|}
  \hline
  Heraclitus: & 0\\
  \hline
  Thales: & 0\\
  \hline
  Pythagoras: & 1\\
  \hline
\end{tabular}
\end{center}


 Beneath the complex forms and shapes of the surface world, there
is a simple level, an exact and stable level, whose laws we name
``physics.'' This discovery, the
Great Surprise, has already taken place at our point in human
history---but it does not do to forget that it was surprising. Once
upon a time, people went in search of underlying beauty, with no
guarantee of finding it; and once upon a time, they found it; and now
it is a known thing, and taken for granted.


 Then why can't we predict the location of every
tiger in the bushes as easily as we predict the sixth cube?


 I count three sources of uncertainty even within worlds of pure
math---two obvious sources, and one not so obvious.


 The first source of uncertainty is that even a creature of pure
math, living embedded in a world of pure math, may not know the math.
Humans walked the Earth long before Galileo/Newton/Einstein discovered
the law of gravity that prevents us from being flung off into space.
You can be governed by stable fundamental rules without knowing them.
There is no law of physics which says that laws of physics must be
explicitly represented, as knowledge, in brains that run under them.


 We do not yet have the Theory of Everything. Our best current
theories are things of math, but they are not perfectly integrated with
each other. The most probable explanation is that---as has previously
proved to be the case---we are seeing surface manifestations of deeper
math. So by far the best guess is that reality is made of math; but we
do not fully know which math, yet.


 But physicists have to construct huge particle accelerators to
distinguish between theories---to manifest their remaining uncertainty
in any visible fashion. That physicists must go to such lengths to be
unsure, suggests that this is not the source of our uncertainty about
stock prices.


 The second obvious source of uncertainty is that even when you
know all the relevant laws of physics, you may not have enough
computing power to extrapolate them. We know every fundamental physical
law that is relevant to a chain of amino acids folding itself into a
protein. But we still can't predict the shape of the
protein from the amino acids. Some tiny little 5-nanometer molecule
that folds in a microsecond is \textit{too much information} for
current computers to handle (never mind tigers and stock prices). Our
frontier efforts in protein folding use clever approximations, rather
than the underlying Schrödinger equation. When it comes to describing a
5-nanometer object using \textit{really} basic physics, over
quarks---well, you don't even bother trying.


 We have to use instruments like X-ray crystallography and NMR to
discover the shapes of proteins that are fully determined by physics we
know and a DNA sequence we know. We are not logically omniscient; we
cannot see all the implications of our thoughts; we do not know what we
believe.


 The third source of uncertainty is the most difficult to
understand, and Nick Bostrom has written a book about it. Suppose that
the sequence \{1, 8, 27, 64, 125,\,\ldots~\} exists; suppose that this is
a fact. And suppose that atop each cube is a little person---one person
per cube---and suppose that this is also a fact.


 If you stand on the outside and take a global
perspective---looking down from above at the sequence of cubes and the
little people perched on top---then these two facts say everything
there is to know about the sequence and the people.


 But if you are one of the little people perched atop a cube, and
you know these two facts, there is still a third piece of information
you need to make predictions: ``Which cube am
\textit{I} standing on?''


 You expect to find yourself standing on a cube; you do not expect
to find yourself standing on the number 7. Your anticipations are
definitely constrained by your knowledge of the basic physics; your
beliefs are falsifiable. But you still have to look down to find out
whether you're standing on 1,728 or 5,177,717. If you
can do fast mental arithmetic, then seeing that the first two digits of
a four-digit cube are 17\_\_ will be sufficient to guess that the last
digits are 2 and 8. Otherwise you may have to look to discover the 2
and 8 as well.


 To figure out what the night sky should look like,
it's not enough to know the laws of physics.
It's not even enough to have logical omniscience over
their consequences. You have to know \textit{where} you are in the
universe. You have to know that you're looking up at
the night sky \textit{from Earth.} The information required is not just
the information to locate Earth in the \textit{visible} universe, but
in the entire universe, including all the parts that our telescopes
can't see because they are too distant, and different
inflationary universes, and alternate Everett branches.


 It's a good bet that
``uncertainty about initial conditions at the
boundary'' is really indexical uncertainty. But if
not, it's empirical uncertainty, uncertainty about how
the universe \textit{is} from a global perspective, which puts it in
the same class as uncertainty about fundamental laws.


 Wherever our best guess is that the ``real
world'' has an \textit{irretrievably} messy
component, it is because of the second and third sources of
uncertainty---logical uncertainty and indexical uncertainty.


 Ignorance of fundamental laws does not tell you that a
messy-looking pattern really is messy. It might just be that you
haven't figured out the order yet.


 But when it comes to messy gene expression networks,
we've \textit{already found} the hidden beauty---the
stable level of underlying physics. \textit{Because}
we've already found the master order, we can guess that
we won't find any \textit{additional} secret patterns
that will make biology as easy as a sequence of cubes. Knowing the
rules of the game, we know that the game is hard. We
don't have enough computing power to do protein
chemistry from physics (the second source of uncertainty) and
evolutionary pathways may have gone different ways on different planets
(the third source of uncertainty). New discoveries in basic physics
won't help us here.


 If you were an ancient Greek staring at the raw data from a
biology experiment, you would be much wiser to look for some hidden
structure of Pythagorean elegance, all the proteins lining up in a
perfect icosahedron. But in biology we already know where the
Pythagorean elegance is, and we know it's too far down
to help us overcome our indexical and logical uncertainty.


 Similarly, we can be confident that no one will ever be able to
predict the results of certain quantum experiments, only because our
fundamental theory tells us quite definitely that different versions of
us will see different results. If your knowledge of fundamental laws
tells you that there's a sequence of cubes, and that
there's one little person standing on top of each cube,
and that the little people are all alike except for being on different
cubes, and that you are one of these little people, then you
\textit{know} that you have no way of deducing which cube
you're on except by looking.


 The best current knowledge says that the ``real
world'' is a perfectly regular, deterministic, and
\textit{very large} mathematical object which is highly expensive to
simulate. So ``real life'' is less
like predicting the next cube in a sequence of cubes, and more like
knowing that lots of little people are standing on top of cubes, but
not knowing who \textit{you personally} are, and also not being very
good at mental arithmetic. Our knowledge of the rules does constrain
our anticipations, quite a bit, but not perfectly.


 There, now doesn't \textit{that} sound like real
life?


 But uncertainty exists in the map, not in the territory. If we are
ignorant of a phenomenon, that is a fact about our state of mind, not a
fact about the phenomenon itself. Empirical uncertainty, logical
uncertainty, and indexical uncertainty are just names for our own
bewilderment. The best current guess is that the world is math and the
math is perfectly regular. The messiness is only in the eye of the
beholder.


 Even the huge morass of the blogosphere is embedded in this
perfect physics, which is ultimately as orderly as
\{1, 8, 27, 64, 125,\,\ldots~\}.


 So the Internet is not a big muck\,\ldots it's a
series of cubes.

\myendsectiontext

\mysection{Beautiful Probability}


 Should we expect rationality to be, \textit{on some level},
simple? Should we search and hope for \textit{underlying} beauty in the
arts of belief and choice? 

{
 Let me introduce this issue by borrowing a complaint of the late
great Bayesian Master, E. T. Jaynes:\footnote{Edwin T. Jaynes, ``Probability Theory as
Logic,'' in \textit{Maximum Entropy and Bayesian
Methods}, ed. Paul F. Fougère (Springer Netherlands, 1990).\comment{1}}}

\begin{quote}
{
 Two medical researchers use the same treatment independently, in
different hospitals. Neither would stoop to falsifying the data, but
one had decided beforehand that because of finite resources he would
stop after treating n = 100 patients, however many cures were observed
by then. The other had staked his reputation on the efficacy of the
treatment, and decided he would not stop until he had data indicating a
rate of cures definitely greater than 60\%, however many patients that
might require. But in fact, both stopped with exactly the same data: n
= 100 [patients], r = 70 [cures]. Should we then draw different
conclusions from their experiments?'' [Presumably the
  two control groups also had equal results.]}
\end{quote}

{
 Cyan\footnote{\url{http://lesswrong.com/lw/mt/beautiful_probability/hnz}} directs us to chapter 37\footnote{\url{http://www.inference.phy.cam.ac.uk/mackay/itprnn/ps/457.466.pdf}} of MacKay's
excellent statistics book, free online, for a more thorough explanation
of this problem.\footnote{David J. C. MacKay, \textit{Information Theory, Inference, and
Learning Algorithms} (New York: Cambridge University Press, 2003). \url{http://www.inference.phy.cam.ac.uk/mackay/itila/book.html}\comment{2}}}


 According to old-fashioned statistical procedure---which I believe
is still being taught today---the two researchers have performed
different experiments with different stopping conditions. The two
experiments \textit{could} have terminated with different data, and
therefore represent different tests of the hypothesis, requiring
different statistical analyses. It's quite possible
that the first experiment will be ``statistically
significant,'' the second not.


 Whether or not you are disturbed by this says a good deal about
your attitude toward probability theory, and indeed, rationality
itself.


 Non-Bayesian statisticians might shrug, saying,
``Well, not all statistical tools have the same
strengths and weaknesses, y'know---a hammer
isn't like a screwdriver---and if you apply different
statistical tools you may get different results, just like using the
same data to compute a linear regression or train a regularized neural
network. You've got to use the right tool for the
occasion. Life is messy---''


 And then there's the Bayesian reply:
``Excuse \textit{you}? The evidential impact of a
fixed experimental method, producing the same data, depends on the
researcher's private thoughts? And you have the nerve
to accuse \textit{us} of being `too
subjective'?''


 If Nature is one way, the likelihood of the data coming out the
way we have seen will be one thing. If Nature is another way, the
likelihood of the data coming out that way will be something else. But
the likelihood of a given state of Nature producing the data we have
seen, has nothing to do with the researcher's private
intentions. So whatever our hypotheses about Nature, the likelihood
ratio is the same, and the evidential impact is the same, and the
posterior belief should be the same, between the two experiments. At
least one of the two Old Style methods must discard relevant
information---or simply do the wrong calculation---for the two methods
to arrive at different answers.


 The ancient war between the Bayesians and the accursèd
frequentists stretches back through decades, and I'm
not going to try to recount that elder history in this essay.


 But one of the central conflicts is that Bayesians expect
probability theory to be\,\ldots what's the word
I'm looking for?
``Neat?''
``Clean?''
``Self-consistent?''


 As Jaynes says, the theorems of Bayesian probability are just
that, \textit{theorems} in a coherent proof system. No matter what
derivations you use, in what order, the results of Bayesian probability
theory should always be consistent---every theorem compatible with
every other theorem.


 If you want to know the sum 10 + 10, you can redefine it as (2
{\texttimes} 5) + (7 + 3) or as (2 {\texttimes} (4 + 6)) or use
whatever other \textit{legal} tricks you like, but the result always
has to come out to be the same, in this case, 20. If it comes out as 20
one way and 19 the other way, then you may conclude you did something
illegal on at least one of the two occasions. (In arithmetic, the
illegal operation is usually division by zero; in probability theory,
it is usually an infinity that was not taken as a the limit of a finite
process.)


 If you get the result 19 = 20, look hard for that error you just
made, because it's unlikely that you've
sent arithmetic itself up in smoke. If anyone should ever succeed in
deriving a \textit{real} contradiction from Bayesian probability
theory---like, say, two different evidential impacts from the same
experimental method yielding the same results---then the whole edifice
goes up in smoke. Along with set theory, 'cause
I'm pretty sure \textsf{ZF} provides a model for probability
theory.


 Math! That's the word I was looking for. Bayes\-ians
expect probability theory to be \textit{math.} That's
why we're interested in Cox's Theorem
and its many extensions, showing that any representation of uncertainty
which obeys certain constraints has to map onto probability theory.
Coherent math is great, but unique math is even better.


 And yet\,\ldots \textit{should} rationality be math? It is by no
means a foregone conclusion that probability should be pretty. The real
world is messy---so shouldn't you need messy reasoning
to handle it? Maybe the non-Bayesian statisticians, with their vast
collection of ad-hoc methods and ad-hoc justifications, are strictly
more competent because they have a strictly larger toolbox.
It's nice when problems are clean, but they usually
aren't, and you have to live with that.


 After all, it's a well-known fact that you
can't use Bayesian methods on many problems because the
Bayesian calculation is computationally intractable. So why not let
many flowers bloom? Why not have more than one tool in your toolbox?


 \textit{That's} the fundamental difference in
mindset. Old School statisticians thought in terms of \textit{tools},
tricks to throw at particular problems. Bayesians---at least this
Bayesian, though I don't think I'm
speaking only for myself---we think in terms of \textit{laws.}


 Looking for laws isn't the same as looking for
especially neat and pretty tools. The Second Law of Thermodynamics
isn't an especially neat and pretty refrigerator.


 The Carnot cycle is an ideal engine---in fact, \textit{the} ideal
engine. No engine powered by two heat reservoirs can be more efficient
than a Carnot engine. As a corollary, all thermodynamically reversible
engines operating between the same heat reservoirs are equally
efficient.


 But, of course, you can't use a Carnot engine to
power a real car. A real car's engine bears the same
resemblance to a Carnot engine that the car's tires
bear to perfect rolling cylinders.


 Clearly, then, a Carnot engine is a useless \textit{tool} for
building a real-world car. The Second Law of Thermodynamics, obviously,
is not applicable here. It's too hard to make an engine
that obeys it, in the real world. Just ignore thermodynamics---use
whatever works.


 This is the sort of confusion that I think reigns over they who
still cling to the Old Ways.


 No, you can't always do the exact Bayesian
calculation for a problem. Sometimes you must seek an approximation;
often, indeed. This doesn't mean that probability
theory has ceased to apply, any more than your inability to calculate
the aerodynamics of a 747 on an atom-by-atom basis implies that the 747
is not made out of atoms. Whatever approximation you use, it works to
the extent that it approximates the ideal Bayesian calculation---and
fails to the extent that it departs.


 Bayesianism's coherence and uniqueness proofs cut
both ways. Just as any calculation that obeys Cox's
coherency axioms (or any of the many reformulations and
generalizations) must map onto probabilities, so too, anything that is
not Bayesian must fail one of the coherency tests. This, in turn, opens
you to punishments like Dutch-booking (accepting combinations of bets
that are sure losses, or rejecting combinations of bets that are sure
gains).


 You may not be able to compute the optimal answer. But whatever
approximation you use, both its failures and successes will be
\textit{explainable} in terms of Bayesian probability theory. You may
not know the explanation; that does not mean no explanation exists.


 So you want to use a linear regression, instead of doing Bayesian
updates? But look to the underlying structure of the linear regression,
and you see that it corresponds to picking the best point estimate
given a Gaussian likelihood function and a uniform prior over the
parameters.


 You want to use a regularized linear regression, because that
works better in practice? Well, that corresponds (says the Bayesian) to
having a Gaussian prior over the weights.


 Sometimes you can't use Bayesian methods
\textit{literally}; often, indeed. But when you \textit{can} use the
exact Bayesian calculation that uses every scrap of available
knowledge, you are done. You will never find a statistical method that
yields a \textit{better} answer. You may find a cheap approximation
that works excellently nearly all the time, and it will be cheaper, but
it will not be more accurate. Not unless the other method uses
knowledge, perhaps in the form of disguised prior information, that you
are not allowing into the Bayesian calculation; and then when you feed
the prior information into the Bayesian calculation, the Bayesian
calculation will again be equal or superior.


 When you use an Old Style ad-hoc statistical tool with an ad-hoc
(but often quite interesting) justification, you never know if someone
else will come up with an even more clever tool tomorrow. But when you
\textit{can} directly use a calculation that mirrors the Bayesian law,
you're \textit{done}{}---like managing to put a Carnot
heat engine into your car. It is, as the saying goes,
``Bayes-optimal.''


 It seems to me that the toolboxers are looking at the sequence of
cubes \{1, 8, 27, 64, 125,\,\ldots~\} and pointing to the first
differences \{7, 19, 37, 61,\,\ldots~\} and saying
``Look, life isn't always so
neat---you've got to adapt to
circumstances.'' And the Bayesians are pointing to
the third differences, the underlying stable level
\{6, 6, 6, 6, 6,\,\ldots~\}. And the critics are saying,
``What the heck are you talking about?
It's 7, 19, 37 not 6, 6, 6. You are oversimplifying
this messy problem; you are too attached to
simplicity.''


 It's not necessarily simple on a \textit{surface}
level. You have to dive deeper than that to find stability.


 Think laws, not tools. Needing to calculate approximations to a
law doesn't change the law. Planes are still atoms,
they aren't governed by special exceptions in Nature
for aerodynamic calculations. The approximation exists in the map, not
in the territory. You can know the Second Law of Thermodynamics, and
yet apply yourself as an engineer to build an imperfect car engine. The
Second Law does not cease to be applicable; your knowledge of that law,
and of Carnot cycles, helps you get as close to the ideal efficiency as
you can.


 We aren't enchanted by Bayesian methods merely
because they're beautiful. The beauty is a side effect.
Bayesian \textit{theorems} are elegant, coherent, optimal, and provably
unique because they are \textit{laws}.

\myendsectiontext


\bigskip

\mysection{Outside the Laboratory}


 ``Outside the laboratory, scientists are no wiser
than anyone else.'' Sometimes this proverb is spoken
by scientists, humbly, sadly, to remind themselves of their own
fallibility. Sometimes this proverb is said for rather less
praiseworthy reasons, to devalue unwanted expert advice. Is the proverb
true? Probably not in an absolute sense. It seems much too pessimistic
to say that scientists are literally \textit{no} wiser than average,
that there is literally \textit{zero} correlation. 


 But the proverb does appear true to some degree, and I propose
that we should be very disturbed by this fact. We should not sigh, and
shake our heads sadly. Rather we should sit bolt upright in alarm. Why?
Well, suppose that an apprentice shepherd is laboriously trained to
count sheep, as they pass in and out of a fold. Thus the shepherd knows
when all the sheep have left, and when all the sheep have returned.
Then you give the shepherd a few apples, and say:
``How many apples?'' But the
shepherd stares at you blankly, because they weren't
trained to count apples---just sheep. You would probably suspect that
the shepherd didn't understand counting very well.


 Now suppose we discover that a PhD economist buys a lottery ticket
every week. We have to ask ourselves: Does this person really
\textit{understand} expected utility, on a gut level? Or have they just
been trained to perform certain algebra tricks?


 One thinks of Richard Feynman's account of a
failing physics education program:

\begin{quote}
{
 The students had memorized everything, but they
didn't know what anything meant. When they heard
``light that is reflected from a medium with an
index,'' they didn't know that it
meant a material \textit{such as water}. They didn't
know that the ``direction of the
light'' is the direction in which you \textit{see}
something when you're looking at it, and so on.
Everything was entirely memorized, yet nothing had been translated into
meaningful words. So if I asked, ``What is
Brewster's Angle?''
I'm going into the computer with the right keywords.
But if I say, ``Look at the water,''
nothing happens---they don't have anything under
``Look at the water''!}
\end{quote}


 Suppose we have an apparently competent scientist, who knows how
to design an experiment on $N$ subjects; the $N$ subjects will receive a
randomized treatment; blinded judges will classify the subject
outcomes; and then we'll run the results through a
computer and see if the results are significant at the 0.05 confidence
level. Now this is not just a ritualized tradition. This is not a point
of arbitrary etiquette like using the correct fork for salad. It is a
ritualized tradition for \textit{testing hypotheses experimentally.}
Why should you test your hypothesis experimentally? Because you know
the journal will demand so before it publishes your paper? Because you
were trained to do it in college? Because everyone else says in unison
that it's important to do the experiment, and
they'll look at you funny if you say otherwise?


 No: because, in order to map a territory, you have to go out and
look at the territory. It isn't possible to produce an
accurate map of a city while sitting in your living room with your eyes
closed, thinking pleasant thoughts about what you wish the city was
like. You have to go out, walk through the city, and write lines on
paper that correspond to what you see. It happens, in miniature, every
time you look down at your shoes to see if your shoelaces are untied.
Photons arrive from the Sun, bounce off your shoelaces, strike your
retina, are transduced into neural firing frequencies, and are
reconstructed by your visual cortex into an activation pattern that is
strongly correlated with the current shape of your shoelaces. To gain
new information about the territory, you have to interact with the
territory. There has to be some real, physical process whereby your
brain state ends up correlated to the state of the environment.
Reasoning processes aren't magic; you can give causal
descriptions of how they work. Which all goes to say that, to find
things out, you've got to go look.


 Now what are we to think of a scientist who seems competent inside
the laboratory, but who, outside the laboratory, believes in a spirit
world? We ask why, and the scientist says something along the lines of:
``Well, no one really knows, and I admit that I
don't have any evidence---it's a
religious belief, it can't be disproven one way or
another by observation.'' I cannot but conclude that
this person \textit{literally doesn't know why you have
to look at things.} They may have been taught a certain ritual of
experimentation, but they don't understand the
\textit{reason} for it---that to map a territory, you have to look at
it---that to gain information about the environment, you have to
undergo a causal process whereby you interact with the environment and
end up correlated to it. This applies just as much to a double-blind
experimental design that gathers information about the efficacy of a
new medical device, as it does to your eyes gathering information about
your shoelaces.


 Maybe our spiritual scientist says: ``But
it's not a matter for experiment. The spirits spoke to
me in my heart.'' Well, if we really suppose that
spirits are speaking in any fashion whatsoever, that is a causal
interaction and it counts as an observation. Probability theory still
applies. If you propose that some personal experience of
``spirit voices'' is evidence for
actual spirits, you must propose that there is a favorable likelihood
ratio for spirits causing ``spirit
voices,'' as compared to other explanations for
``spirit voices,'' which is
sufficient to overcome the prior improbability of a complex belief with
many parts. Failing to realize that ``the spirits
spoke to me in my heart'' is an instance of
``causal interaction,'' is analogous
to a physics student not realizing that a ``medium
with an index'' means a material such as water.


 It is easy to be fooled, perhaps, by the fact that people wearing
lab coats use the phrase ``causal
interaction'' and that people wearing gaudy jewelry
use the phrase ``spirits speaking.''
Discussants wearing different clothing, as we all know, demarcate
independent spheres of existence---``separate
magisteria,'' in Stephen J. Gould's
immortal blunder of a phrase. Actually, ``causal
interaction'' is just a fancy way of saying,
``Something that makes something else
happen,'' and probability theory
doesn't care what clothes you wear.


 In modern society there is a prevalent notion that spiritual
matters can't be settled by logic or observation, and
therefore you can have whatever religious beliefs you like. If a
scientist falls for this, and decides to live their extralaboratorial
life accordingly, then this, to me, says that they only understand the
experimental principle as a \textit{social convention}. They know when
they are \textit{expected} to do experiments and test the results for
statistical significance. But put them in a context where it is
\textit{socially conventional} to make up wacky beliefs without
looking, and they just as happily do that instead.


 The apprentice shepherd is told that if
``seven'' sheep go out, and
``eight'' sheep go out, then
``fifteen'' sheep had better come
back in. Why ``fifteen'' instead of
``fourteen'' or
``three''? Because otherwise
you'll get no dinner tonight, that's
why! So that's professional training of a kind, and it
works after a fashion---but if social convention is the only reason why
seven sheep plus eight sheep equals fifteen sheep, then maybe seven
apples plus eight apples equals three apples. Who's to
say that the rules shouldn't be different for apples?


 But if you know \textit{why} the rules work, you can see that
addition is the same for sheep and for apples. Isaac Newton is justly
revered, not for his outdated theory of gravity, but for discovering
that---amazingly, surprisingly---the celestial planets, in the glorious
heavens, obeyed just the same rules as falling apples. In the
macroscopic world---the everyday ancestral environment---different
trees bear different fruits, different customs hold for different
people at different times. A genuinely unified universe, with
stationary universal laws, is a highly counterintuitive notion to
humans! It is only scientists who really believe it, though some
religions may talk a good game about the ``unity of
all things.''


 As Richard Feynman put it:

\begin{quote}
{
 If we look at a glass closely enough we see the entire universe.
There are the things of physics: the twisting liquid which evaporates
depending on the wind and weather, the reflections in the glass, and
our imagination adds the atoms. The glass is a distillation of the
Earth's rocks, and in its composition we see the secret
of the universe's age, and the evolution of the stars.
What strange array of chemicals are there in the wine? How did they
come to be? There are the ferments, the enzymes, the substrates, and
the products. There in wine is found the great generalization: all life
is fermentation. Nobody can discover the chemistry of wine without
discovering, as did Louis Pasteur, the cause of much disease. How vivid
is the claret, pressing its existence into the consciousness that
watches it! If our small minds, for some convenience, divide this glass
of wine, this universe, into parts---physics, biology, geology,
astronomy, psychology, and so on---remember that Nature does not know
it! So let us put it all back together, not forgetting ultimately what
it is for. Let it give us one more final pleasure: drink it and forget
it all!\footnote{Richard P. Feynman, Robert B. Leighton, and Matthew L. Sands,
\textit{The Feynman Lectures on Physics}, 3 vols. (Reading, MA:
Addison-Wesley, 1963). Vol I, Chap 3, \url{http://www.feynmanlectures.caltech.edu/I_03.html}}}
\end{quote}


 A few religions, especially the ones invented or refurbished after
Isaac Newton, may profess that ``everything is
connected to everything else.'' (Since there is a
trivial isomorphism between graphs and their complements, this profound
wisdom conveys exactly the same useful information as a graph with no
edges.) But when it comes to the actual meat of the religion, prophets
and priests follow the ancient human practice of making everything up
as they go along. And they make up one rule for women under twelve,
another rule for men over thirteen; one rule for the Sabbath and
another rule for weekdays; one rule for science and another rule for
sorcery\,\ldots


 Reality, we have learned to our shock, is \textit{not} a
collection of separate magisteria, but a single unified process
governed by mathematically simple low-level rules. Different buildings
on a university campus do not belong to different universes, though it
may sometimes seem that way. The universe is not divided into mind and
matter, or life and nonlife; the atoms in our heads interact seamlessly
with the atoms of the surrounding air. Nor is Bayes's
Theorem different from one place to another.


 If, outside of their specialist field, some particular scientist
is just as susceptible as anyone else to wacky ideas, then they
probably never did understand \textit{why} the scientific rules work.
Maybe they can parrot back a bit of Popperian falsificationism; but
they don't understand on a deep level, the algebraic
level of probability theory, the causal level of
cognition-as-machinery. They've been trained to behave
a certain way in the laboratory, but they don't
\textit{like} to be constrained by evidence; when they go home, they
take off the lab coat and relax with some comfortable nonsense. And
yes, that does make me wonder if I can trust that
scientist's opinions even in their own
field---especially when it comes to any controversial issue, any open
question, anything that isn't already nailed down by
massive evidence and social convention.


 Maybe we \textit{can} beat the proverb---be rational in our
personal lives, not just our professional lives. We
shouldn't let a mere proverb stop us:
``A witty saying proves nothing,''
as Voltaire said. Maybe we can do better, if we study enough
probability theory to know \textit{why} the rules work, and enough
experimental psychology to see how they apply in real-world cases---if
we can learn to look at the water. An ambition like that lacks the
comfortable modesty of being able to confess that, outside your
specialty, you're no better than anyone else. But if
our theories of rationality don't generalize to
everyday life, we're doing something wrong.
It's not a different universe inside and outside the
laboratory.

\myendsectiontext

\mysection{The Second Law of Thermodynamics, and Engines of Cognition}
\label{engines_of_cognition}


 The First Law of Thermodynamics, better known as Conservation of
Energy, says that you can't create energy from nothing:
it prohibits perpetual motion machines of the first type, which run and
run indefinitely without consuming fuel or any other resource.
According to our modern view of physics, energy is conserved in each
\textit{individual} interaction of particles. By mathematical
induction, we see that no matter how large an assemblage of particles
may be, it cannot produce energy from nothing---not without violating
what we presently believe to be the laws of physics. 


 This is why the US Patent Office will summarily reject your
amazingly clever proposal for an assemblage of wheels and gears that
cause one spring to wind up another as the first runs down, and so
continue to do work forever, according to your calculations.
There's a \textit{fully general} proof that at least
one wheel must violate (our standard model of) the laws of physics for
this to happen. So unless you can explain how \textit{one} wheel
violates the laws of physics, the \textit{assembly} of wheels
can't do it either.


 A similar argument applies to a ``reactionless
drive,'' a propulsion system that violates
Conservation of Momentum. In standard physics, momentum is conserved
for all individual particles and their interactions; by mathematical
induction, momentum is conserved for physical systems whatever their
size. If you can visualize two particles knocking into each other and
always coming out with the same total momentum that they started with,
then you can see how scaling it up from particles to a gigantic
complicated collection of gears won't change anything.
Even if there's a trillion quadrillion atoms involved,
0 + 0 + {\dots} + 0 = 0.


 But Conservation of Energy, as such, cannot prohibit converting
heat into work. You can, in fact, build a sealed box that converts ice
cubes and stored electricity into warm water. It isn't
even difficult. Energy cannot be created or destroyed: the net change
in energy, from transforming (ice cubes + electricity) to (warm water),
must be 0. So it couldn't violate Conservation of
Energy, as such, if you did it the other way around\,\ldots


 Perpetual motion machines of the second type, which convert warm
water into electrical current and ice cubes, are prohibited by the
\textit{Second} Law of Thermodynamics.


 The second law is a bit harder to understand, as it is essentially
Bayesian in nature.


 Yes, really.

{
 The essential \textit{physical} law underlying the Second Law of
Thermodynamics is a theorem which can be proven within the standard
model of physics: \textit{In the development over time of any closed
system, phase space volume is conserved}.}


 Let's say you're holding a ball
high above the ground. We can describe this state of affairs as a point
in a multidimensional space, at least one of whose dimensions is
``height of ball above the ground.''
Then, when you drop the ball, it moves, and so does the dimensionless
point in phase space that describes the entire system that includes you
and the ball. ``Phase space,'' in
physics-speak, means that there are dimensions for the momentum of the
particles, not just their position---e.g., a system of 2 particles
would have 12 dimensions, 3 dimensions for each
particle's position, and 3 dimensions for each
particle's momentum.


 If you had a multidimensional space, each of whose dimensions
described the position of a gear in a huge assemblage of gears, then as
you turned the gears a single point would swoop and dart around in a
rather high-dimensional phase space. Which is to say, just as you can
view a great big complex machine as a single point in a
very-high-dimensional space, so too you can view the laws of physics
describing the behavior of this machine over time as describing the
trajectory of its point through the phase space.


 The Second Law of Thermodynamics is a consequence of a theorem
which can be proven in the standard model of physics: If you take a
volume of phase space, and develop it forward in time using standard
physics, the total volume of the phase space is conserved.


 For example, let there be two systems, $X$ and $Y$, where $X$ has 8
possible states, $Y$ has 4 possible states, and the joint system $(X,Y)$
has 32 possible states.


 The development of the joint system over time can be described as
a rule that maps initial points onto future points. For example, the
system could start out in $X_{7}Y_{2}$, then
develop (under some set of physical laws) into the state
$X_{3}Y_{3}$ a minute later. Which is to say:
if $X$ started in state $X_{7}$, and $Y$ started in state
$Y_{2}$, and we watched it for 1 minute, we would see $X$ go
to $X_{3}$ and $Y$ go to $Y_{3}$. Such are the laws
of physics.


 Next, let's carve out a subspace $S$ of the joint
system state. The space $S$ will be the subspace bounded by $X$ being in
state $X_{1}$ and $Y$ being in states $Y_{1}$
through $Y_{4}$. So the total volume of $S$ is 4 states.


 And let's suppose that, under the laws of physics
governing $(X,Y)$, the states initially in S behave as follows:


\begin{align*}
 X_{1}Y_{1} &\rightarrow X_{2}Y_{1} \\
 X_{1}Y_{2} &\rightarrow X_{4}Y_{1} \\
 X_{1}Y_{3} &\rightarrow X_{6}Y_{1} \\
 X_{1}Y_{4} &\rightarrow X_{8}Y_{1}.
\end{align*}


 That, in a nutshell, is how a refrigerator works.


 The $X$ subsystem began in a narrow region of state space---the
single state $X_{1}$, in fact---and $Y$ began distributed over
a wider region of space, states $Y_{1}$ through
$Y_{4}$. By interacting with each other, $Y$ went into a
narrow region, and $X$ ended up in a wide region; \textit{but the total
phase space volume was conserved.} Four initial states mapped to four
end states.


 Clearly, so long as total phase space volume is conserved by
physics over time, you can't squeeze $Y$ harder than $X$
expands, or vice versa---for every subsystem you squeeze into a
narrower region of state space, some other subsystem has to expand into
a wider region of state space.


 Now let's say that we're
\textit{uncertain} about the joint system $(X,Y)$, and our
\textit{uncertainty} is described by an equiprobable distribution over
$S$. That is, we're pretty sure $X$ is in state
$X_{1}$, but $Y$ is equally likely to be in any of the states
$Y_{1}$ through $Y_{4}$. If we shut our eyes for
a minute and then open them again, we will expect to see Y in state
$Y_{1}$, but $X$ might be in any of the states
$X_{2}$ through $X_{8}$. Actually, $X$ can only be
in \textit{some} of the states $X_{2}$ through
$X_{8}$, but it would be too costly to think out exactly
which states these might be, so we'll just say
$X_{2}$ through $X_{8}$.


 If you consider the Shannon entropy of our uncertainty about $X$ and
$Y$ as individual systems, $X$ began with 0 bits of entropy because it had
a single definite state, and $Y$ began with 2 bits of entropy because it
was equally likely to be in any of 4 possible states.
(There's no mutual information between $X$ and $Y$.) A bit
of physics occurred, and lo, the entropy of $Y$ went to 0, but the
entropy of $X$ went to $log_{2}(7) = 2.8$ bits. So entropy was
transferred from one system to another, and decreased \textit{within}
the $Y$ subsystem; but due to the cost of bookkeeping, we
didn't bother to track some information, and hence
(from our perspective) the overall entropy increased.


 Suppose there was a physical process that mapped past states onto
future states like this:

\begin{align*}
 X_{2}Y_{1} &\rightarrow X_{2}Y_{1} \\
 X_{2}Y_{2} &\rightarrow X_{2}Y_{1} \\
 X_{2}Y_{3} &\rightarrow X_{2}Y_{1} \\
 X_{2}Y_{4} &\rightarrow X_{2}Y_{1}.
\end{align*}


 Then you could have a physical process that would actually
\textit{decrease entropy}, because no matter where you started out, you
would end up at the same place. The laws of physics, developing over
time, would compress the phase space.


 But there is a theorem, Liouville's Theorem, which
can be proven true of our laws of physics, which says that this never
happens: phase space is conserved.


 The Second Law of Thermodynamics is a corollary of
Liouville's Theorem: no matter how clever your
configuration of wheels and gears, you'll never be able
to decrease entropy in one subsystem without increasing it somewhere
else. When the phase space of one subsystem narrows, the phase space of
another subsystem must widen, and the joint space keeps the same
volume.


 Except that what was initially a \textit{compact} phase space, may
develop squiggles and wiggles and convolutions; so that to draw a
simple boundary around the whole mess, you must draw a much larger
boundary than before---this is what gives the appearance of entropy
increasing. (And in quantum systems, where different universes go
different ways, entropy actually does increase in any local universe.
But omit this complication for now.)


 The Second Law of Thermodynamics is actually probabilistic in
nature---if you ask about the probability of hot water spontaneously
entering the ``cold water and
electricity'' state, the probability does exist,
it's just very small. This doesn't mean
Liouville's Theorem is violated with small probability;
a theorem's a theorem, after all. It means that if
you're in a great big phase space volume at the start,
but you \textit{don't know where}, you may assess a
tiny little \textit{probability} of ending up in some particular phase
space volume. \textit{So far as you know}, with infinitesimal
probability, this particular glass of hot water may be the kind that
spontaneously transforms itself to electrical current and ice cubes.
(Neglecting, as usual, quantum effects.)


 So the Second Law really \textit{is} inherently Bayesian. When it
comes to any real thermodynamic system, it's a strictly
lawful statement of your \textit{beliefs about} the system, but only a
probabilistic statement about the system itself.


 ``Hold on,'' you say.
``That's not what I learned in physics
class,'' you say. ``In the lectures
\textit{I} heard, thermodynamics is about, you know,
\textit{temperatures.} Uncertainty is a subjective state of mind! The
temperature of a glass of water is an objective property of the water!
What does heat have to do with probability?''


 Oh ye of little trust.


 In one direction, the connection between heat and probability is
relatively straightforward: If the only fact you know about a glass of
water is its temperature, then you are much more uncertain about a hot
glass of water than a cold glass of water.


 Heat is the zipping around of lots of tiny molecules; the hotter
they are, the faster they can go. Not all the molecules in hot water
are travelling at the same speed---the
``temperature''
isn't a uniform speed of all the molecules,
it's an average speed of the molecules, which in turn
corresponds to a predictable statistical distribution of
speeds---anyway, the point is that, the hotter the water, the faster
the water molecules \textit{could be} going, and hence, the more
uncertain you are about the velocity (not just speed) of any
\textit{individual} molecule. When you multiply together your
uncertainties about all the individual molecules, you will be
\textit{exponentially} more uncertain about the whole glass of water.


 We take the logarithm of this exponential volume of uncertainty,
and call that the entropy. So it all works out, you see.


 The connection in the other direction is less obvious. Suppose
there was a glass of water, about which, initially, you knew only that
its temperature was 72 degrees. Then, suddenly, Saint Laplace reveals
to you the exact locations and velocities of all the atoms in the
water. You now know perfectly the state of the water, so, by the
information-theoretic definition of entropy, its entropy is zero. Does
that make its \textit{thermodynamic} entropy zero? Is the water colder,
because we know more about it?


 Ignoring quantumness for the moment, the answer is: Yes! Yes it
is!


 Maxwell once asked: Why can't we take a uniformly
hot gas, and partition it into two volumes $A$ and $B$, and let only
fast-moving molecules pass from $B$ to $A$, while only slow-moving
molecules are allowed to pass from $A$ to $B$? If you could build a gate
like this, soon you would have hot gas on the $A$ side, and cold gas on
the $B$ side. That would be a cheap way to refrigerate food, right?


 The agent who inspects each gas molecule, and decides whether to
let it through, is known as
``Maxwell's Demon.''
And the reason you can't build an efficient
refrigerator this way, is that Maxwell's Demon
generates entropy in the process of inspecting the gas molecules and
deciding which ones to let through.


 But suppose you already \textit{knew} where all the gas molecules
were?


 Then you actually \textit{could} run Maxwell's
Demon and extract useful work.


 So (again ignoring quantum effects for the moment), if you
\textit{know} the states of all the molecules in a glass of hot water,
it is cold in a genuinely thermodynamic sense: you can take electricity
out of it and leave behind an ice cube.


 This doesn't violate Liouville's
Theorem, because if $Y$ is the water, and \textit{you} are
Maxwell's Demon (denoted $M$), the physical process
behaves as:

\begin{align*}
 M_{1}Y_{1} &\rightarrow M_{1}Y_{1}  \\
 M_{2}Y_{2} &\rightarrow M_{2}Y_{1} \\
 M_{3}Y_{3} &\rightarrow M_{3}Y_{1} \\
 M_{4}Y_{4} &\rightarrow M_{4}Y_{1}.
\end{align*}


 Because Maxwell's demon \textit{knows} the exact
state of $Y$, this is mutual information between $M$ and $Y$. The mutual
information decreases the joint entropy of $(M,Y)$: we have $H(M,Y) = H(M)
+ H(Y) - I(M;Y)$. The demon $M$ has 2 bits of entropy, $Y$ has two bits of
entropy, and their mutual information is 2 bits, so $(M,Y)$ has a total
of 2 + 2 - 2 = 2 bits of entropy. The physical process just transforms
the ``coldness'' (negative entropy,
or negentropy) of the mutual information to make the actual water
cold---afterward, $M$ has 2 bits of entropy, $Y$ has 0 bits of entropy, and
the mutual information is 0. Nothing wrong with that!


 And don't tell me that knowledge is
``subjective.'' Knowledge has to be
represented in a brain, and that makes it as physical as anything else.
For $M$ to physically represent an accurate picture of the state of $Y$, it
must be that $M$'s physical state correlates with the
state of $Y$. You can take thermodynamic advantage of
that---it's called a Szilárd engine.


 Or as E. T. Jaynes put it, ``The old adage
`knowledge is power' is a very cogent
truth, both in human relations and in
thermodynamics.''

{
 And conversely, \textit{one subsystem cannot increase in mutual
information with another subsystem, without (a) interacting with it and
(b) doing thermodynamic work.}}


 Otherwise you could build a Maxwell's Demon and
violate the Second Law of Thermodynamics---which in turn would violate
Liouville's Theorem---which is prohibited in the
standard model of physics.


 Which is to say: \textbf{To form accurate beliefs about something,
you }\textbf{\textit{really do}}\textbf{ have to observe it}.
It's a very physical, very real process: any rational
mind does ``work'' in the
thermodynamic sense, not just the sense of mental effort.


 (It is sometimes said that it is erasing bits in order to prepare
for the next observation that takes the thermodynamic work---but that
distinction is just a matter of words and perspective; the math is
unambiguous.)


 (Discovering logical ``truths''
is a complication which I will not, for now, consider---at least in
part because I am still thinking through the exact formalism myself. In
thermodynamics, knowledge of logical truths does not count as
negentropy; as would be expected, since a reversible computer can
compute logical truths at arbitrarily low cost. All this that I have
said is true of the logically omniscient: any lesser mind will
necessarily be less efficient.)


 ``Forming accurate beliefs requires a
corresponding amount of evidence'' is a very cogent
truth both in human relations and in thermodynamics: if blind faith
actually worked as a method of investigation, you could turn warm water
into electricity and ice cubes. Just build a Maxwell's
Demon that has blind faith in molecule velocities.


 Engines of cognition are not so different from heat engines,
though they manipulate entropy in a more subtle form than burning
gasoline. For example, to the extent that an engine of cognition is not
perfectly efficient, it must radiate waste heat, just like a car engine
or refrigerator.


 ``Cold rationality'' is true in
a sense that Hollywood scriptwriters never dreamed (and false in the
sense that they did dream).


 So unless you can tell me which \textit{specific step} in your
argument violates the laws of physics by giving you true knowledge of
the unseen, don't expect me to believe that a big,
elaborate clever argument can do it either.

\myendsectiontext

\mysection{Perpetual Motion Beliefs}


 The last essay concluded:

\begin{quote}
{
 \textbf{To form accurate beliefs about something, you
}\textbf{\textit{really do}}\textbf{ have to observe it.}
It's a very physical, very real process: any rational
mind does ``work'' in the
thermodynamic sense, not just the sense of mental effort\,\ldots So
unless you can tell me which \textit{specific step} in your argument
violates the laws of physics by giving you true knowledge of the
unseen, don't expect me to believe that a big,
elaborate clever argument can do it either.}
\end{quote}


 One of the chief morals of the mathematical analogy between
thermodynamics and cognition is that the constraints of probability are
inescapable; probability may be a ``subjective state
of belief,'' but the laws of probability are harder
than steel.


 People learn under the traditional school regimen that the teacher
tells you certain things, and you must believe them and recite them
back; but if a mere \textit{student} suggests a belief, you do not have
to obey it. They map the domain of belief onto the domain of authority,
and think that a certain belief is like an order that must be obeyed,
but a probabilistic belief is like a mere suggestion.


 They look at a lottery ticket, and say, ``But you
can't \textit{prove} I won't win,
right?'' Meaning: ``You may have
calculated a low probability of winning, but since it is a
\textit{probability}, it's just a \textit{suggestion},
and I am \textit{allowed} to believe what I want.''


 Here's a little experiment: Smash an egg on the
floor. The rule that says that the egg won't
spontaneously reform and leap back into your hand is merely
probabilistic. A suggestion, if you will. The laws of thermodynamics
are probabilistic, so they can't really be
\textit{laws}, the way that ``Thou shalt not
murder'' is a law\,\ldots right?


 So why not just ignore the suggestion? Then the egg will
unscramble itself\,\ldots right?


 It may help to think of it this way---if you still have some
lingering intuition that uncertain beliefs are not authoritative:


 In reality, there may be a very small chance that the egg
spontaneously reforms. But you cannot \textit{expect} it to reform. You
\textit{must} expect it to smash. Your mandatory belief is that the
egg's probability of spontaneous reformation is \~{}0.
Probabilities are not certainties, but the \textit{laws of} probability
are theorems.


 If you doubt this, try dropping an egg on the floor a few
decillion times, ignoring the thermodynamic suggestion and expecting it
to spontaneously reassemble, and see what happens. Probabilities may be
subjective states of belief, but the laws governing them are stronger
by far than steel. I once knew a fellow who was \textit{convinced} that
his system of wheels and gears would produce reactionless thrust, and
he had an Excel spreadsheet that would prove this---which of course he
couldn't show us because he was still developing the
system. In classical mechanics, violating Conservation of Momentum is
\textit{provably} impossible. So any Excel spreadsheet calculated
\textit{according to the rules of classical mechanics} must
\textit{necessarily} show that no reactionless thrust exists---unless
your machine is complicated enough that you have made a mistake in the
calculations.


 And similarly, when half-trained or tenth-trained rationalists
abandon their art and try to believe without evidence just this once,
they often build vast edifices of justification, confusing themselves
just enough to conceal the magical steps.


 It can be quite a pain to nail down where the magic occurs---their
structure of argument tends to morph and squirm away as you interrogate
them. But there's always some step where a tiny
probability turns into a large one---where they try to believe without
evidence---where they step into the unknown, thinking,
``No one can prove me wrong.''


 Their foot naturally lands on thin air, for there is far more thin
air than ground in the realms of Possibility. Ah, but there \textit{is}
an (exponentially tiny) amount of ground in Possibility, and you do
have an (exponentially tiny) probability of hitting it by luck, so
maybe this time, your foot \textit{will} land in the right place! It is
\textit{merely} a probability, so it must be \textit{merely} a
suggestion.


 The exact state of a glass of boiling-hot water may be unknown to
you---indeed, your ignorance of its exact state is what makes the
molecules' kinetic energy
``heat,'' rather than work waiting
to be extracted like the momentum of a spinning flywheel. So the water
\textit{might} cool down your hand instead of heating it up, with
probability \~{}0.


 Decide to ignore the laws of thermodynamics and stick your hand in
anyway, and you'll get burned.


 ``But you don't know
that!''


 I don't know it with certainty, but it is
\textit{mandatory} that I \textit{expect} it to happen. Probabilities
are not logical truths, but the \textit{laws of} probability are.


 ``But what if I guess the state of the boiling
water, and I happen to guess correctly?''


 Your chance of guessing correctly by luck, is even \textit{less}
than the chance of the boiling water cooling your hand by luck.


 ``But you can't \textit{prove} I
won't guess correctly.''


 I can (indeed, must) assign extremely low probability to it.


 ``That's not the same as
certainty, though.''


 Hey, maybe if you add enough wheels and gears to your argument,
it'll turn warm water into electricity and ice cubes!
Or, rather, you will no longer see why this
\textit{couldn't} be the case.


 ``Right! I \textit{can't} see why
couldn't be the case! So maybe it
is!''


 \textit{Another} gear? That just makes your machine even
\textit{less} efficient. It wasn't a perpetual motion
machine before, and each extra gear you add makes it even less
efficient than that.


 Each extra detail in your argument necessarily decreases the joint
probability. The probability that you've violated the
Second Law of Thermodynamics without knowing exactly how, by guessing
the exact state of boiling water without evidence, so that you can
stick your finger in without getting burned, is, necessarily, even less
than the probability of sticking in your finger into boiling water
without getting burned.


 I say all this, because people really do construct these huge
edifices of argument in the course of believing without evidence. One
must learn to see this as analogous to all the wheels and gears that
fellow added onto his reactionless drive, until he finally collected
enough complications to make a mistake in his Excel spreadsheet.

\myendsectiontext

\mysection{Searching for Bayes{}-Structure}

\begin{quote}

 \textit{Gnomish helms} should not function. Their very
construction seems to defy the nature of thaumaturgical law. In fact,
they are impossible. Like most products of gnomish minds, they include
a large number of bells and whistles, and very little substance. Those
that work usually have a \textit{minor helm} contained within, always
hidden away, disguised to appear innocuous and inessential.

{\raggedleft
 {}---Spelljammer campaign set
\par}
\end{quote}



 We have seen that knowledge implies mutual information between a
mind and its environment, and we have seen that this mutual information
is negentropy in a very physical sense: If you know where molecules are
and how fast they're moving, you can turn heat into
work via a Maxwell's Demon / Szilárd engine.


 We have seen that forming true beliefs without evidence is the
same sort of improbability as a hot glass of water spontaneously
reorganizing into ice cubes and electricity. Rationality takes
``work'' in a thermodynamic sense,
not just the sense of mental effort; minds have to radiate heat if they
are not perfectly efficient. This cognitive work is governed by
probability theory, of which thermodynamics is a special case.
(Statistical mechanics is a special case of statistics.)


 If you saw a machine continually spinning a wheel, apparently
without being plugged into a wall outlet or any other source of power,
then you would look for a hidden battery, or a nearby broadcast power
source---something to explain the work being done, without violating
the laws of physics.


 So if a mind is arriving at true beliefs, and we assume that the
Second Law of Thermodynamics has not been violated, that mind must be
doing something at least \textit{vaguely} Bayesian---at least one
process with a sort-of Bayesian structure \textit{somewhere}{}---or it
\textit{couldn't possibly work}.


 In the beginning, at time $T = 0$, a mind has no mutual information
with a subsystem $S$ in its environment. At time $T = 1$, the mind has 10
bits of mutual information with $S$. Somewhere in between, the mind must
have encountered evidence---under the Bayesian definition of evidence,
because all Bayesian evidence is mutual information and all mutual
information is Bayesian evidence, they are just different ways of
looking at it---and processed at least some of that evidence, however
inefficiently, in the right direction according to Bayes on at least
some occasions. The mind must have \textit{moved in harmony with the
Bayes} at least a little, somewhere along the line---either that or
violated the Second Law of Thermodynamics by creating mutual
information from nothingness.


 In fact, any \textit{part} of a cognitive process that
\textit{contributes usefully} to truth-finding must have at least a
little Bayesian structure---must harmonize with Bayes, at some point or
another---must partially conform with the Bayesian flow, however
noisily---despite however many disguising bells and whistles---even if
this Bayesian structure is only apparent in the context of surrounding
processes. Or it couldn't even \textit{help}.


 How philosophers pondered the nature of words! All the ink spent
on the true definitions of words, and the true meaning of definitions,
and the true meaning of meaning! What collections of gears and wheels
they built, in their explanations! And all along, it was a disguised
form of Bayesian inference!

{
 I was actually a bit disappointed that no one in the audience
jumped up and said: ``\textit{Yes! Yes,
that's it! Of course! It was really Bayes all
along!}''}


 But perhaps it is not \textit{quite} as exciting to see something
that \textit{doesn't} look Bayesian on the surface,
revealed as Bayes wearing a clever disguise, if: (a) you
don't unravel the mystery yourself, but read about
someone else doing it (Newton had more fun than most students taking
calculus), and (b) you don't realize that
\textit{searching for the hidden Bayes-structure} is this huge,
difficult, omnipresent quest, like searching for the Holy Grail.


 It's a different quest for each facet of
cognition, but the Grail always \textit{turns out} to be the same. It
has to be the \textit{right} Grail, though---and the \textit{entire}
Grail, without any parts missing---and so each time you have to go on
the quest looking for a full answer \textit{whatever} form it may take,
rather than trying to artificially construct vaguely hand-waving
Grailish arguments. \textit{Then} you always find the same Holy Grail
at the end.


 It was previously pointed out to me that I might be losing some of
my readers with the long essays, because I hadn't
``made it clear where I was going''\,\ldots


 \ldots but it's not so easy to just tell people
where you're going, when you're going
somewhere like \textit{that}.


 It's not very helpful to merely \textit{know that}
a form of cognition is Bayesian, if you don't
\textit{know how} it is Bayesian. If you can't see the
detailed flow of probability, you have nothing but a password---or, a
bit more charitably, a hint at the form an answer would take; but
certainly not an answer. That's why
there's a Grand Quest for the Hidden Bayes-Structure,
rather than being done when you say
``Bayes!'' Bayes-structure can be
buried under all kinds of disguises, hidden behind thickets of wheels
and gears, obscured by bells and whistles.


 The way you begin to grasp the Quest for the Holy Bayes is that
you learn about cognitive phenomenon XYZ, which seems really
useful---and there's this bunch of philosophers
who've been arguing about its true nature for
centuries, and they are still arguing---and there's a
bunch of AI scientists trying to make a computer do it, but they
can't agree on the philosophy either---


 And---\textit{Huh, that's odd!}{}---this cognitive
phenomenon didn't look anything like Bayesian on the
surface, but there's this non-obvious underlying
structure that has a Bayesian interpretation---but wait,
there's still some useful work getting done that
can't be explained in Bayesian terms---no wait,
\textit{that's} Bayesian too---\textsc{Oh My God} this
\textit{completely different} cognitive process, that \textit{also}
didn't look Bayesian on the surface, \textsc{also has Bayesian
structure}---hold on, are these non-Bayesian parts even \textit{doing}
anything?

\begin{itemize}
\item Yes: Wow, those are Bayesian too!
\item  No: Dear heavens, what a stupid design. I could eat a bucket of
  amino acids and puke a better brain architecture than that.
\end{itemize}


 Once this happens to you a few times, you kinda pick up the
rhythm. That's what I'm talking about
here, the rhythm.


 Trying to talk about the rhythm is like trying to dance about
architecture.


 This left me in a bit of a pickle when it came to trying to
explain in advance where I was going. I know from experience that if I
say, ``Bayes is the secret of the
universe,'' some people may say
``Yes! Bayes is the secret of the
universe!''; and others will snort and say,
``How narrow-minded you are; look at all these other
ad-hoc but amazingly useful methods, like regularized linear
regression, that I have in my toolbox.''


 I hoped that with a specific example in hand of
``something that doesn't look all that
Bayesian on the surface, but turns out to be Bayesian after
all''---\textit{and} an explanation of the difference
between passwords and knowledge---\textit{and} an explanation of the
difference between tools and laws---maybe \textit{then} I could convey
such of the rhythm as can be understood without personally going on the
quest.


 Of course this is not the \textit{full} Secret of the Bayesian
Conspiracy, but it's all that I can convey at this
point. Besides, the complete secret is known only to the Bayes Council,
and if I told you, I'd have to hire you.


 To \textit{see through} the surface adhockery of a cognitive
process, to the Bayesian structure \textit{underneath}{}---to perceive
the probability flows, and \textit{know how}, not just \textit{know
that}, this cognition too is Bayesian---as it always is---as it always
must be---to be able to sense the Force underlying all
cognition---this, is the Bayes-Sight.

\begin{quotation}

 ``\ldots And the Queen of Kashfa sees with the Eye
of the Serpent.''


 ``I don't know that she sees with
it,'' I said.
``She's still recovering from the
operation. But that's an interesting thought. If she
could see with it, what might she behold?''


 ``The clear, cold lines of eternity, I daresay.
Beneath all Shadow.''

{\raggedleft
 {}---Roger Zelazny, \textit{Prince of Chaos}\footnote{Roger Zelazny, \textit{Prince of Chaos} (Thorndike Press,
2001).\comment{1}}
\par}
\end{quotation}

\myendsectiontext


\chapter{Reductionism 101}

\mysection{Dissolving the Question}


 ``If a tree falls in the forest, but no one hears
it, does it make a sound?'' 


 I didn't \textit{answer} that question. I
didn't pick a position
``Yes!'' or
``No!'' and defend it. Instead I
went off and deconstructed the human algorithm for processing words,
even going so far as to sketch an illustration of a neural network. At
the end, I hope, there was no question left---not even the feeling of a
question.


 Many philosophers---particularly amateur philosophers, and ancient
philosophers---share a dangerous instinct: If you give them a question,
they try to answer it.


 Like, say, ``Do we have free
will?''


 The dangerous instinct of philosophy is to marshal the arguments
in favor, and marshal the arguments against, and weigh them up, and
publish them in a prestigious journal of philosophy, and so finally
conclude: ``Yes, we must have free
will,'' or ``No, we cannot possibly
have free will.''


 Some philosophers are wise enough to recall the warning that most
philosophical disputes are really disputes over the meaning of a word,
or confusions generated by using different meanings for the same word
in different places. So they try to define very precisely what they
mean by ``free will,'' and then ask
again, ``Do we have free will? Yes or
no?''


 A philosopher wiser yet may suspect that the confusion about
``free will'' shows the notion
itself is flawed. So they pursue the Traditional Rationalist course:
They argue that ``free will'' is
inherently self-contradictory, or meaningless because it has no
testable consequences. And then they publish these devastating
observations in a prestigious philosophy journal.


 But \textit{proving that} you are confused may not make you feel
any \textit{less} confused. Proving that a question is meaningless may
not help you any more than answering it.


 The philosopher's instinct is to find the most
defensible position, publish it, and move on. But the
``naive'' view, the instinctive
view, is a fact about human psychology. You can prove that free will is
impossible until the Sun goes cold, but this leaves an unexplained fact
of cognitive science: If free will doesn't exist, what
goes on inside the head of a human being who thinks it does? This is
not a rhetorical question!


 It is a fact about human psychology that people think they have
free will. Finding a more defensible \textit{philosophical position}
doesn't change, or explain, that \textit{psychological
fact.} Philosophy may lead you to \textit{reject} the concept, but
rejecting a concept is not the same as understanding the cognitive
algorithms behind it.


 You could look at the Standard Dispute over ``If
a tree falls in the forest, and no one hears it, does it make a
sound?,'' and you could do the Traditional
Rationalist thing: Observe that the two don't disagree
on any point of anticipated experience, and triumphantly declare the
argument pointless. That happens to be correct in this particular case;
but, as \textit{a question of cognitive science}, why did the arguers
make that mistake in the first place?


 The key idea of the heuristics and biases program is that the
\textit{mistakes} we make often reveal far more about our underlying
cognitive algorithms than our correct answers. So (I asked myself, once
upon a time) what kind of mind design corresponds to the mistake of
arguing about trees falling in deserted forests?


 The cognitive algorithms we use \textit{are} the way the world
feels. And these cognitive algorithms may not have a one-to-one
correspondence with reality---not even macroscopic reality, to say
nothing of the true quarks. There can be things in the mind that cut
skew to the world.


 For example, there can be a dangling unit in the center of a
neural network, which does not correspond to any real thing, or any
real property of any real thing, existent anywhere in the real world.
This dangling unit is often useful as a shortcut in computation, which
is why we have them. (Metaphorically speaking. Human neurobiology is
surely far more complex.)


 This dangling unit \textit{feels like} an unresolved question,
even after every answerable query is answered. No matter how much
anyone proves to you that no difference of anticipated experience
depends on the question, you're left wondering:
``But does the falling tree \textit{really} make a
sound, or not?''


 But once you understand \textit{in detail} how your brain
generates the \textit{feeling} of the question---once you realize that
your feeling of an unanswered question corresponds to an illusory
central unit wanting to know whether it should fire, even after all the
edge units are clamped at known values---or better yet, you understand
the technical workings of Naive Bayes---\textit{then}
you're done. Then there's no lingering
feeling of confusion, no vague sense of dissatisfaction.


 If there is \textit{any} lingering feeling of a remaining
unanswered question, or of having been fast-talked into something, then
this is a sign that you have not dissolved the question. A vague
dissatisfaction should be as much warning as a shout. \textit{Really}
dissolving the question doesn't leave anything behind.


 A triumphant thundering refutation of free will, an absolutely
unarguable proof that free will cannot exist, feels very
\textit{satisfying}{}---a grand cheer for the home team. And so you may
not notice that---as a point of cognitive science---you do not have a
full and satisfactory descriptive explanation of how each intuitive
sensation arises, point by point.


 You may not even want to admit your ignorance of this point of
cognitive science, because that would feel like a score against Your
Team. In the midst of smashing all foolish beliefs of free will, it
would seem like a concession to the opposing side to concede that
you've left anything unexplained.


 And so, perhaps, you'll come up with a just-so
evolutionary-psychological argument that hunter-gatherers who believed
in free will were more likely to take a positive outlook on life, and
so outreproduce other hunter-gatherers---to give one example of a
completely bogus explanation. If you say this, you are \textit{arguing
that} the brain generates an illusion of free will---but you are not
\textit{explaining how.} You are trying to dismiss the opposition by
deconstructing its motives---but in the story you tell, the illusion of
free will is a brute fact. You have not taken the illusion apart to see
the wheels and gears.


 Imagine that in the Standard Dispute about a tree falling in a
deserted forest, you first prove that no difference of anticipation
exists, and then go on to hypothesize, ``But perhaps
people who said that arguments were meaningless were viewed as having
conceded, and so lost social status, so now we have an instinct to
argue about the meanings of words.''
That's \textit{arguing that} or \textit{explaining why}
a confusion exists. Now look at the neural network structure in Feel
the Meaning. That's \textit{explaining how},
disassembling the confusion into smaller pieces that are not themselves
confusing. See the difference?


 Coming up with good hypotheses about cognitive algorithms (or even
hypotheses that hold together for half a second) is a good deal harder
than just refuting a philosophical confusion. Indeed, it is an entirely
different art. Bear this in mind, and you should feel less embarrassed
to say, ``I know that what you say
can't possibly be true, and I can prove it. But I
cannot write out a flowchart which shows how your brain makes the
mistake, so I'm not done yet, and will continue
investigating.''


 I say all this, because it sometimes seems to me that at least
20\% of the real-world effectiveness of a skilled rationalist comes
from not stopping too early. If you keep asking questions,
you'll get to your destination eventually. If you
decide too early that you've found an answer, you
won't.


 The challenge, above all, is to notice when you are
confused---even if it just feels like a little tiny bit of
confusion---and even if there's someone standing across
from you, \textit{insisting} that humans have free will, and
\textit{smirking} at you, and the fact that you don't
know \textit{exactly} how the cognitive algorithms work, has
\textit{nothing to do} with the searing folly of their position\,\ldots


 But when you can lay out the cognitive algorithm in sufficient
detail that you can walk through the thought process, step by step, and
describe how each intuitive perception arises---decompose the confusion
into smaller pieces not themselves confusing---\textit{then}
you're done.


 So be warned that you may \textit{believe} you're
done, when all you have is a mere triumphant refutation of a mistake.


 But when you're \textit{really} done,
you'll \textit{know} you're done.
Dissolving the question is an unmistakable feeling---once you
experience it, and, having experienced it, resolve not to be fooled
again. Those who dream do not know they dream, but when you wake you
know you are awake.


 Which is to say: When you're done,
you'll know you're done, but
unfortunately the reverse implication does not hold.


 So here's your homework problem: What kind of
cognitive algorithm, as felt from the inside, would generate the
observed debate about ``free
will''?


 Your assignment is not to argue about whether people have free
will, or not.


 Your assignment is not to argue that free will is compatible with
determinism, or not.


 Your assignment is not to argue that the question is ill-posed, or
that the concept is self-contradictory, or that it has no testable
consequences.

{
 You are not asked to invent an evolutionary explanation of how
people who believed in free will would have reproduced; nor an account
of how the concept of free will seems suspiciously congruent with bias
$X$. Such are mere attempts to \textit{explain why} people believe in
``free will,'' not \textit{explain
how.}}


 Your homework assignment is to write a stack trace of the internal
algorithms of the human mind as they produce the intuitions that power
the whole damn philosophical argument.


 This is one of the first real challenges I tried as an aspiring
rationalist, once upon a time. One of the easier conundrums, relatively
speaking. May it serve you likewise.

\myendsectiontext


\mysection{Wrong Questions}


 Where the mind cuts against reality's grain, it
generates \textit{wrong questions}{}---questions that cannot possibly
be answered \textit{on their own terms}, but only dissolved by
understanding the cognitive algorithm that generates the
\textit{perception} of a question. 


 One good cue that you're dealing with a
``wrong question'' is when you
cannot even \textit{imagine} any concrete, specific state of
how-the-world-is that would answer the question. When it
doesn't even seem \textit{possible} to answer the
question.


 Take the Standard Definitional Dispute, for example, about the
tree falling in a deserted forest. Is there any
way-the-world-could-be---any state of affairs---that corresponds to the
word ``sound'' \textit{really
meaning} only acoustic vibrations, or \textit{really} \textit{meaning}
only auditory experiences?


 (``Why, yes,'' says the one,
``it is the state of affairs where
`sound' means acoustic
vibrations.'' So Taboo the word
``means,'' and
``represents,'' and all similar
synonyms, and describe again: What way-the-world-can-be, what state of
affairs, would make one side right, and the other side wrong?)


 Or if that seems too easy, take free will: What concrete state of
affairs, whether in deterministic physics, or in physics with a
dice-rolling random component, could ever correspond to having free
will?


 And if \textit{that} seems too easy, then ask
``Why does anything exist at all?,''
and then tell me what a satisfactory answer to that question would even
\textit{look like.}


 And no, I don't know the answer to that last one.
But I \textit{can} guess one thing, based on my previous experience
with unanswerable questions. The answer will not consist of some grand
triumphant First Cause. The question will go away as a result of some
insight into how my mental algorithms run skew to reality, after which
I will understand how the question itself was wrong from the
beginning---how the question itself assumed the fallacy, contained the
skew.


 Mystery exists in the mind, not in reality. If I am ignorant about
a phenomenon, that is a fact about my state of mind, not a fact about
the phenomenon itself. All the more so if it seems like no possible
answer can exist: Confusion exists in the map, not in the territory.
\textit{Unanswerable} questions do not mark places where magic enters
the universe. They mark places where your mind runs skew to reality.


 Such questions \textit{must} be dissolved. Bad things happen when
you try to answer them. It inevitably generates the worst sort of
Mysterious Answer to a Mysterious Question: The one where you come up
with seemingly strong arguments for your Mysterious Answer, but the
``answer'' doesn't
let you make any new predictions even in retrospect, and the phenomenon
still possesses the same sacred inexplicability that it had at the
start.


 I could guess, for example, that the answer to the puzzle of the
First Cause is that nothing \textit{does} exist---that the whole
concept of ``existence'' is bogus.
But if you sincerely believed that, would you be any less confused? Me
neither.


 But the wonderful thing about \textit{unanswerable} questions is
that they are \textit{always} solvable, at least in my experience. What
went through Queen Elizabeth I's mind, first thing in
the morning, as she woke up on her fortieth birthday? As I can easily
\textit{imagine} answers to this question, I can readily see that I may
never be able to \textit{actually} answer it, the true information
having been lost in time.


 On the other hand, ``Why does anything exist at
all?'' seems \textit{so} absolutely impossible that I
can infer that I am just confused, one way or another, and the truth
probably isn't all that complicated in an absolute
sense, and once the confusion goes away I'll be able to
see it.


 This may seem counterintuitive if you've never
solved an unanswerable question, but I assure you that it \textit{is}
how these things work.


 Coming next: a simple trick for handling ``wrong
questions.''

\myendsectiontext

\mysection{Righting a Wrong Question}


 When you are faced with an \textit{unanswerable} question---a
question to which it seems impossible to even \textit{imagine} an
answer---there is a simple trick that can turn the question solvable. 


 Compare:

\begin{itemize}
\item  ``Why do I have free will?''
\item  ``Why do I think I have free
  will?''
\end{itemize}


 The nice thing about the second question is that it is
\textit{guaranteed} to have a real answer, \textit{whether or not}
there is any such thing as free will. Asking ``Why do
I have free will?'' or ``Do I have
free will?'' sends you off thinking about tiny
details of the laws of physics, so distant from the macroscopic level
that you couldn't begin to see them with the naked eye.
And you're asking ``Why is $X$ the
case?'' where $X$ may not be \textit{coherent}, let
alone the case.


 ``Why do I \textit{think} I have free
will?,'' in contrast, is guaranteed answerable. You
do, in fact, believe you have free will. This belief seems far more
solid and graspable than the ephemerality of free will. And there is,
\textit{in fact,} some nice solid chain of cognitive cause and effect
leading up to this belief.


 If you've already outgrown free will, choose one
of these substitutes:

\begin{itemize}
\item {
 ``Why does time move forward instead of
backward?'' versus ``Why do I think
time moves forward instead of backward?''}

\item {
 ``Why was I born as myself rather than someone
else?'' versus ``Why do I think I
was born as myself rather than someone else?''}

\item {
 ``Why am I conscious?'' versus
``Why do I think I'm
conscious?''}

\item {
 ``Why does reality exist?''
versus ``Why do I think reality
exists?''}
\end{itemize}


 The beauty of this method is that it works \textit{whether or not}
the question is confused. As I type this, I am wearing socks. I could
ask ``Why am I wearing socks?'' or
``Why do I believe I'm wearing
socks?'' Let's say I ask the second
question. Tracing back the chain of causality, I find:

\begin{itemize}
\item {
 I believe I'm wearing socks, because I can see
socks on my feet.}

\item {
 I see socks on my feet, because my retina is sending sock signals
to my visual cortex.}

\item {
 My retina is sending sock signals, because sock-shaped light is
impinging on my retina.}

\item {
 Sock-shaped light impinges on my retina, because it reflects from
the socks I'm wearing.}

\item {
 It reflects from the socks I'm wearing, because
I'm wearing socks.}

\item {
 I'm wearing socks because I put them on.}

\item {
 I put socks on because I believed that otherwise my feet would get
cold.}

\item {
  Et cetera.}
\end{itemize}


 Tracing back the chain of causality, step by step, I discover that
my belief that I'm wearing socks is fully explained by
the fact that I'm wearing socks. This is right and
proper, as you cannot gain information about something without
interacting with it.


 On the other hand, if I see a mirage of a lake in a desert, the
correct causal explanation of my vision does not involve the fact of
any actual lake in the desert. In this case, my belief in the lake is
not just \textit{explained}, but \textit{explained away.}


 But \textit{either way}, the belief itself is a real phenomenon
taking place in the real universe---psychological events are
events---and its causal history can be traced back.


 ``Why is there a lake in the middle of the
desert?'' may fail if there is no lake to be
explained. But ``Why do I \textit{perceive} a lake in
the middle of the desert?'' always has a causal
explanation, one way or the other.


 Perhaps someone will see an opportunity to be clever, and say:
``Okay. I believe in free will because I have free
will. There, I'm done.'' Of course
it's not that easy.


 My perception of socks on my feet is an event in the visual
cortex. The workings of the visual cortex can be investigated by
cognitive science, should they be confusing.


 My retina receiving light is not a mystical sensing procedure, a
magical sock detector that lights in the presence of socks for no
explicable reason; there are mechanisms that can be understood in terms
of biology. The photons entering the retina can be understood in terms
of optics. The shoe's surface reflectance can be
understood in terms of electromagnetism and chemistry. My feet getting
cold can be understood in terms of thermodynamics.


 So it's not as easy as saying,
``I believe I have free will because I have
it---there, I'm done!'' You have to
be able to break the causal chain into smaller steps, and explain the
steps in terms of elements not themselves confusing.


 The mechanical interaction of my retina with my socks is quite
clear, and can be described in terms of non-confusing components like
photons and electrons. Where's the free-will-sensor in
your brain, and how does it detect the presence or absence of free
will? How does the sensor interact with the sensed event, and what are
the mechanical details of the interaction?


 If your belief does derive from valid observation of a real
phenomenon, we will eventually reach that fact, if we start tracing the
causal chain backward from your belief.


 If what you are really seeing is your own confusion, tracing back
the chain of causality will find an algorithm that runs skew to
reality.


 Either way, the question is guaranteed to have an answer. You even
have a nice, concrete place to begin tracing---your belief, sitting
there solidly in your mind.


 Cognitive science may not seem so lofty and glorious as
metaphysics. But at least questions of cognitive science are
\textit{solvable.} Finding an answer may not be \textit{easy}, but at
least an answer \textit{exists.}


 Oh, and also: the idea that cognitive science is not so lofty and
glorious as metaphysics is simply wrong. Some readers are beginning to
notice this, I hope.

\myendsectiontext

\mysection{Mind Projection Fallacy}
\label{mind_projection_fallacy}


 In the dawn days of science fiction, alien invaders would
occasionally kidnap a girl in a torn dress and carry her off for
intended ravishing, as lovingly depicted on many ancient magazine
covers. Oddly enough, the aliens never go after men in torn shirts.


 ~

{\centering
\mygraphicss{images/img248.jpg}{2.0}
 
\par}


\bigskip


 ~


 Would a non-humanoid alien, with a different evolutionary history
and evolutionary psychology, sexually desire a human female? It seems
rather unlikely. To put it mildly.


 People don't make mistakes like that by
deliberately reasoning: ``All possible minds are
likely to be wired pretty much the same way, therefore a bug-eyed
monster will find human females attractive.''
Probably the artist did not even think to ask whether an alien
\textit{perceives} human females as attractive. Instead, a human female
in a torn dress \textit{is sexy}{}---inherently so, as an intrinsic
property.


 They who went astray did not think about the
alien's evolutionary history; they focused on the
woman's torn dress. If the dress were not torn, the
woman would be less sexy; the alien monster doesn't
enter into it.


 Apparently we instinctively represent Sexiness as a direct
attribute of the Woman data structure, \texttt{Woman.sexiness}, like
\texttt{Woman.height} or \texttt{Woman.weight}.


 If your brain uses that data structure, or something
metaphorically similar to it, then from the inside it feels like
sexiness is an inherent property of the woman, not a property of the
alien looking at the woman. Since the woman \textit{is attractive}, the
alien monster will be \textit{attracted} to her---isn't
that logical?


 E. T. Jaynes used the term Mind Projection Fallacy to denote the
error of projecting your own mind's properties into the
external world. Jaynes, as a late grand master of the Bayesian
Conspiracy, was most concerned with the mistreatment of
\textit{probabilities} as inherent properties of objects, rather than
states of partial knowledge in some particular mind. More about this
shortly.


 But the Mind Projection Fallacy generalizes as an error. It is in
the argument over the real meaning of the word sound, and in the
magazine cover of the monster carrying off a woman in the torn dress,
and Kant's declaration that space by its very nature is
flat, and Hume's definition of a priori ideas as those
``discoverable by the mere operation of thought,
without dependence on what is anywhere existent in the
universe''\,\ldots


 (Incidentally, I once read a science fiction story about a human
male who entered into a sexual relationship with a sentient alien plant
of appropriately squishy fronds; discovered that it was an androecious
(male) plant; agonized about this for a bit; and finally decided that
it didn't really matter at that point. And in Foglio
and Pollotta's \textit{Illegal Aliens}, the humans land
on a planet inhabited by sentient insects, and see a movie
advertisement showing a human carrying off a bug in a delicate chiffon
dress. Just thought I'd mention that.)

\myendsectiontext

\mysection{Probability is in the Mind}
\label{probability_in_mind}


 In the previous essay I spoke of the Mind Projection Fallacy,
giving the example of the alien monster who carries off a girl in a
torn dress for intended ravishing---a mistake which I imputed to the
artist's tendency to think that a
woman's sexiness is a property of the woman herself,
\texttt{Woman.sexiness}, rather than something that exists in the mind of an
observer, and probably wouldn't exist in an alien
mind.


 The term ``Mind Projection
Fallacy'' was coined by the late great Bayesian
Master E. T. Jaynes, as part of his long and hard-fought battle against
the accursèd frequentists. Jaynes was of the opinion that probabilities
were in the mind, not in the environment---that probabilities express
ignorance, states of partial information; and if I am ignorant of a
phenomenon, that is a fact about my state of mind, not a fact about the
phenomenon.


 I cannot do justice to this ancient war in a few words---but the
classic example of the argument runs thus:


 You have a coin.


 The coin is biased.


 You don't know which way it's
biased or how much it's biased. Someone just told you
``The coin is biased,'' and
that's all they said.


 This is all the information you have, and the only information you
have.


 You draw the coin forth, flip it, and slap it down.


 Now---before you remove your hand and look at the result---are you
willing to say that you assign a 0.5 probability to the
coin's having come up heads?


 The frequentist says, ``No. Saying
`probability 0.5' means that the coin
has an inherent propensity to come up heads as often as tails, so that
if we flipped the coin infinitely many times, the ratio of heads to
tails would approach 1:1. But we know that the coin is biased, so it
can have any probability of coming up heads \textit{except}
0.5.''


 The Bayesian says, ``Uncertainty exists in the
map, not in the territory. In the real world, the coin has either come
up heads, or come up tails. Any talk of
`probability' must refer to the
\textit{information} that I have about the coin---my state of partial
ignorance and partial knowledge---not just the coin itself.
Furthermore, I have all sorts of theorems showing that if I
don't treat my partial knowledge a certain way,
I'll make stupid bets. If I've got to
plan, I'll plan for a 50/50 state of uncertainty, where
I don't weigh outcomes conditional on heads any more
heavily in my mind than outcomes conditional on tails. You can call
that number whatever you like, but it has to obey the probability laws
on pain of stupidity. So I don't have the slightest
hesitation about calling my outcome-weighting a
probability.''


 I side with the Bayesians. You may have noticed that about me.


 Even before a fair coin is tossed, the notion that it has an
\textit{inherent} 50\% probability of coming up heads may be just plain
wrong. Maybe you're holding the coin in such a way that
it's just about guaranteed to come up heads, or tails,
given the force at which you flip it, and the air currents around you.
But, if you don't know which way the coin is biased on
this one occasion, so what?


 I believe there was a lawsuit where someone alleged that the draft
lottery was unfair, because the slips with names on them were not being
mixed thoroughly enough; and the judge replied, ``To
whom is it unfair?''


 To make the coinflip experiment repeatable, as frequentists are
wont to demand, we could build an automated coinflipper, and verify
that the results were 50\% heads and 50\% tails. But maybe a robot with
extra-sensitive eyes and a good grasp of physics, watching the
autoflipper prepare to flip, could predict the coin's
fall in advance---not with certainty, but with 90\% accuracy. Then what
would the \textit{real} probability be?


 There is no ``real
probability.'' The robot has one state of partial
information. You have a different state of partial information. The
coin itself has no mind, and doesn't assign a
probability to anything; it just flips into the air, rotates a few
times, bounces off some air molecules, and lands either heads or
tails.


 So that is the Bayesian view of things, and I would now like to
point out a couple of classic brainteasers that derive their
brain-\textit{teasing} ability from the tendency to think of
probabilities as inherent properties of objects.


 Let's take the old classic: You meet a
mathematician on the street, and she happens to mention that she has
given birth to two children on two separate occasions. You ask:
``Is at least one of your children a
boy?'' The mathematician says,
``Yes, he is.''


 What is the probability that she has two boys? If you assume that
the prior probability of a child's being a boy is 1/2,
then the probability that she has two boys, on the information given,
is 1/3. The prior probabilities were: 1/4 two boys, 1/2 one boy one
girl, 1/4 two girls. The mathematician's
``Yes'' response has probability
\~{}1 in the first two cases, and probability \~{}0 in the third.
Renormalizing leaves us with a 1/3 probability of two boys, and a 2/3
probability of one boy one girl.


 But suppose that instead you had asked, ``Is your
eldest child a boy?'' and the mathematician had
answered ``Yes.'' Then the
probability of the mathematician having two boys would be 1/2. Since
the eldest child is a boy, and the younger child can be anything it
pleases.


 Likewise if you'd asked ``Is your
youngest child a boy?'' The probability of their
being both boys would, again, be 1/2.


 Now, if at least one child is a boy, it must be either the oldest
child who is a boy, or the youngest child who is a boy. So how can the
answer in the first case be different from the answer in the latter
two?


 Or here's a very similar problem:
Let's say there are four cards, the ace of hearts, the ace
of spades, the two of hearts, and the two of spades. I draw two cards
at random. You ask me, ``Are you holding at least one
ace?'' and I reply
``Yes.'' What is the probability
that I am holding a pair of aces? It is 1/5. There are six possible
combinations of two cards, with equal prior probability, and you have
just eliminated the possibility that I am holding a pair of twos. Of
the five remaining combinations, only one combination is a pair of
aces. So 1/5.


 Now suppose that instead you asked me, ``Are you
holding the ace of spades?'' If I reply
``Yes,'' the probability that the
other card is the ace of hearts is 1/3. (You know I'm
holding the ace of spades, and there are three possibilities for the
other card, only one of which is the ace of hearts.) Likewise, if you
ask me ``Are you holding the ace of
hearts?'' and I reply
``Yes,'' the probability
I'm holding a pair of aces is 1/3.


 But then how can it be that if you ask me, ``Are
you holding at least one ace?'' and I say
``Yes,'' the probability I have a
pair is 1/5? Either I must be holding the ace of spades or the ace of
hearts, as you know; and either way, the probability that
I'm holding a pair of aces is 1/3.


 How can this be? Have I miscalculated one or more of these
probabilities?


 If you want to figure it out for yourself, do so now, because
I'm about to reveal\,\ldots


 That all stated calculations are correct.


 As for the paradox, there isn't one. The
\textit{appearance} of paradox comes from thinking that the
probabilities must be properties of the cards themselves. The ace
I'm holding has to be either hearts or spades; but that
doesn't mean that your \textit{knowledge about} my
cards must be the same as if you \textit{knew} I was holding hearts, or
\textit{knew} I was holding spades.


 It may help to think of Bayes's Theorem:

\begin{equation*}
  P(H|E) = \frac{P(E|H)P(H)}{P(E)}.
\end{equation*}



 That last term, where you divide by $P(E)$, is the part where you
throw out all the possibilities that have been eliminated, and
renormalize your probabilities over what remains. 


 Now let's say that you ask me,
``Are you holding at least one
ace?'' \textit{Before} I answer, your probability
that I say ``Yes'' should be 5/6.


 But if you ask me ``Are you holding the ace of
spades?,'' your prior probability that I say
``Yes'' is just 1/2.


 So right away you can see that you're
\textit{learning} something very different in the two cases.
You're going to be eliminating some different
possibilities, and renormalizing using a different $P(E)$. If you learn
two different items of evidence, you shouldn't be
surprised at ending up in two different states of partial information.


 Similarly, if I ask the mathematician ``Is at
least one of your two children a boy?'' then I expect
to hear ``Yes'' with probability
3/4, but if I ask ``Is your eldest child a
boy?'' then I expect to hear
``Yes'' with probability 1/2. So it
shouldn't be surprising that I end up in a different
state of partial knowledge, depending on which of the two questions I
ask.


 The only reason for seeing a
``paradox'' is thinking as though
the probability of holding a pair of aces is \textit{a property of
cards} that have at least one ace, or a property \textit{of cards} that
happen to contain the ace of spades. In which case, it would be
paradoxical for card-sets containing at least one ace to have an
inherent pair-probability of 1/5, while card-sets containing the ace of
spades had an inherent pair-probability of 1/3, and card-sets
containing the ace of hearts had an inherent pair-probability of 1/3.


 Similarly, if you think a 1/3 probability of being both boys is an
\textit{inherent property} of child-sets that include at least one boy,
then that is not consistent with child-sets' of which
the eldest is male having an \textit{inherent} probability of 1/2 of
being both boys, and child-sets' of which the youngest
is male having an inherent 1/2 probability of being both boys. It would
be like saying, ``All green apples weigh a pound, and
all red apples weigh a pound, and all apples that are green or red
weigh half a pound.''


 That's what happens when you start thinking as if
probabilities are \textit{in} things, rather than probabilities being
states of partial information \textit{about} things.


 Probabilities express uncertainty, and it is only agents who can
be uncertain. A blank map does not correspond to a blank territory.
Ignorance is in the mind.

\myendsectiontext

\mysection{The Quotation is Not the Referent}


 In classical logic, the operational definition of identity is that
whenever $A = B$ is a theorem, you can substitute $A$ for $B$ in any theorem
where $B$ appears. For example, if (2 + 2) = 4 is a theorem, and ((2 + 2)
+ 3) = 7 is a theorem, then (4 + 3) = 7 is a theorem. 


 This leads to a problem that is usually phrased in the following
terms: The morning star and the evening star happen to be the same
object, the planet Venus. Suppose John knows that the morning star and
evening star are the same object. Mary, however, believes that the
morning star is the god Lucifer, but the evening star is the god Venus.
John believes Mary believes that the morning star is Lucifer. Must John
therefore (by substitution) believe that Mary believes that the evening
star is Lucifer?


 Or here's an even simpler version of the problem.
The statement 2 + 2 = 4 is true; it is a theorem that (((2 + 2) = 4) =
\textsc{true}). Fermat's Last Theorem is also true. So: I
believe 2 + 2 = 4 $\Rightarrow $ I believe \textsc{true} $\Rightarrow $ I
believe Fermat's Last Theorem.


 Yes, I know this seems \textit{obviously} wrong. But imagine
someone writing a logical reasoning program using the principle
``equal terms can always be
substituted,'' and this happening to them. Now
imagine them writing a paper about how to prevent it from happening.
Now imagine someone else disagreeing with their solution. The argument
is still going on.


 P'rsnally, I would say that John is committing a
type error, like trying to subtract 5 grams from 20 meters.
``The morning star'' is not the same
\textit{type} as the morning star, let alone the same thing. Beliefs
are not planets.

\begin{align*}
\text{morning star} &= \text{evening star}\\
\text{``morning star''} &\neq \text{``evening star''}
\end{align*}


 The problem, in my view, stems from the failure to enforce the
type distinction between beliefs and things. The original error was
writing an AI that stores its beliefs about Mary's
beliefs about ``the morning star''
using the same representation as in its beliefs about the morning
star.


 If Mary believes the ``morning
star'' is Lucifer, that doesn't mean
Mary believes the ``evening star''
is Lucifer, because ``morning star''
${\neq}$ ``evening star.'' The whole
paradox stems from the failure to use quote marks in appropriate
places.


 You may recall that this is not the first time
I've talked about enforcing type discipline---the last
time was when I spoke about the error of confusing expected utilities
with utilities. It is immensely helpful, when one is first learning
physics, to learn to keep track of one's units---it may
seem like a bother to keep writing down
``cm'' and
``kg'' and so on, until you notice
that (a) your answer seems to be the wrong order of magnitude and (b)
it is expressed in seconds per square gram.


 Similarly, beliefs are different things than planets. If
we're talking about human beliefs, at least, then:
Beliefs live in brains, planets live in space. Beliefs weigh a few
micrograms, planets weigh a lot more. Planets are larger than beliefs\,\ldots but you get the idea.


 Merely putting quote marks around ``morning
star'' seems insufficient to prevent people from
confusing it with the morning star, due to the visual similarity of the
text. So perhaps a better way to enforce type discipline would be with
a visibly different encoding:

\begin{align*}
  \text{morning star} &= \text{evening star}\\
  \whencolumns{
    13.15.18.14.9.14.7.0.19.20.1.18 &\neq 5.22.5.14.9.14.7.0.19.20.1.18.
  }{
     \text{\scriptsize{13.15.18.14.9.14.7.0.19.20.1.18}} &\neq \text{\scriptsize{5.22.5.14.9.14.7.0.19.20.1.18}}.
  }
\end{align*}


 Studying mathematical logic may also help you learn to distinguish
the quote and the referent. In mathematical logic, ${\vdash}P$ ($P$ is a
theorem) and
${\vdash} \, \Box \ulcorner P \urcorner$
(it is provable that there exists an encoded proof of the encoded
sentence $P$ in some encoded proof system) are very distinct
propositions. If you drop a level of quotation in mathematical logic,
it's like dropping a metric unit in physics---you can
derive visibly ridiculous results, like ``The speed of
light is 299,792,458 meters long.''


 Alfred Tarski once tried to define the meaning of
``true'' using an infinite family of
sentences:

\begin{center}
 (``Snow is white'' is true) if
and only (snow is white)\\
 (``Weasels are green'' is true)
if and only if (weasels are green) \\
$\vdots$
\end{center}


 When sentences like these start seeming meaningful,
you'll know that you've started to
distinguish between encoded sentences and states of the outside world.


 Similarly, the notion of truth is quite different from the notion
of \textit{reality}. Saying ``true''
\textit{compares} a belief to reality. Reality itself does not need to
be compared to any beliefs in order to be real. Remember this the next
time someone claims that nothing is true.

\myendsectiontext

\mysection{Qualitatively Confused}
\label{qualitatively_confused}


 I suggest that a primary cause of confusion about the distinction
between ``belief,''
``truth,'' and
``reality'' is qualitative thinking
about beliefs. 


 Consider the archetypal postmodernist attempt to be clever:

\begin{quote}
{
 ``The Sun goes around the
Earth'' is true for Hunga Huntergatherer, but
``The Earth goes around the Sun'' is
true for Amara Astronomer! Different societies have different truths!}
\end{quote}


 No, different societies have different \textit{beliefs.} Belief is
of a different type than truth; it's like comparing
apples and probabilities.

\begin{quote}
{
 Ah, but there's no difference between the way you
use the word ``belief'' and the way
you use the word ``truth''! Whether
you say, ``I believe `snow is
white,'\,'' or you say,
``\,`Snow is white' is
true,'' you're expressing exactly the
same opinion.}
\end{quote}


 No, these sentences mean quite different things, which is how I
can \textit{conceive} of the possibility that my beliefs are false.

\begin{quote}
{
 Oh, you claim to \textit{conceive} it, but you never
\textit{believe} it. As Wittgenstein said, ``If there
were a verb meaning `to believe
falsely,' it would not have any significant first
person, present indicative.''}
\end{quote}


 And that's what I mean by putting my finger on
qualitative reasoning as the source of the problem. The dichotomy
between belief and disbelief, being binary, is confusingly similar to
the dichotomy between truth and untruth.


 So let's use quantitative reasoning instead.
Suppose that I assign a 70\% probability to the proposition that snow
is white. It follows that I think there's around a 70\%
chance that the sentence ``snow is
white'' will turn out to be true. If the sentence
``snow is white'' is true, is my
70\% probability assignment to the proposition, also
``true''? Well, it's
more true than it would have been if I'd assigned 60\%
probability, but not so true as if I'd assigned 80\%
probability.


 When talking about the correspondence between a probability
assignment and reality, a better word than
``truth'' would be
``accuracy.''
``Accuracy'' sounds more
quantitative, like an archer shooting an arrow: how close did your
probability assignment strike to the center of the target?


 To make a long story short, it turns out that
there's a very natural way of scoring the accuracy of a
probability assignment, as compared to reality: just take the logarithm
of the probability assigned to the real state of affairs.


 So if snow is white, my belief ``70\%:
`snow is white'\,'' will
score -0.51 bits: $\log_{2}(0.7) = -0.51$.


 But what if snow is not white, as I have conceded a 30\%
probability is the case? If ``snow is
white'' is false, my belief ``30\%
probability: `snow is not
white'\,'' will score -1.74 bits. Note
that $-1.74 < -0.51$, so I have done worse.


 About how accurate do I think my own beliefs are? Well, my
expectation over the score is 70\% {\texttimes} -0.51 + 30\%
{\texttimes} -1.74 = -0.88 bits. If snow is white, then my beliefs will
be more accurate than I expected; and if snow is not white, my beliefs
will be less accurate than I expected; but in neither case will my
belief be \textit{exactly} as accurate as I expected on average.


 All this should not be confused with the statement
``I assign 70\% credence that `snow is
white.'\,'' I may well believe
\textit{that} proposition with probability \~{}1---be quite certain
that this is in fact my belief. If so I'll expect my
meta-belief ``\~{}1: `I assign 70\%
credence that ``snow is white''\,'\,'' to score \~{}0 bits of accuracy,
which is as good as it gets.


 Just because I am uncertain about snow, does not mean I am
uncertain about my \textit{quoted probabilistic beliefs}. Snow is out
there, my beliefs are inside me. I may be a great deal less uncertain
about how uncertain I am about snow, than I am uncertain about snow.
(Though beliefs about beliefs are not always accurate.)


 Contrast this probabilistic situation to the qualitative reasoning
where I just believe that snow is white, and believe that I believe
that snow is white, and believe ``\,`snow
is white' is true,'' and believe
``my belief `\,``snow is
white'' is true' is
correct,'' etc. Since all the quantities involved are
1, it's easy to mix them up.


 Yet the nice distinctions of quantitative reasoning will be
short-circuited if you start thinking
``\,`\,``snow is
white'' with 70\% probability' is
\textit{true},'' which is a type error. It is a true
fact about you, that you \textit{believe} ``70\%
probability: `snow is
white'\,''; but that does not mean the
probability assignment \textit{itself} can possibly be
``true.'' The belief scores either
-0.51 bits or -1.74 bits of accuracy, depending on the actual state of
reality.


 The cognoscenti will recognize
``\,`\,``snow is
white'' with 70\% probability' is
true'' as the mistake of thinking that probabilities
are inherent properties of things.


 From the inside, our beliefs about the world look like the world,
and our beliefs about our beliefs look like beliefs. When you see the
world, you are experiencing a belief from the inside. When you notice
yourself believing something, you are experiencing a belief about
belief from the inside. So if your internal representations of belief,
and belief about belief, are dissimilar, then you are less likely to
mix them up and commit the Mind Projection Fallacy---I hope.


 When you think in probabilities, your beliefs, and your beliefs
about your beliefs, will hopefully not be represented similarly enough
that you mix up belief and accuracy, or mix up accuracy and reality.
When you think in probabilities \textit{about the world}, your beliefs
will be represented with probabilities in the range (0,1). Unlike the
truth-values of propositions, which are in the set
\{true,
false\}. As for the accuracy of your
probabilistic belief, you can represent that in the range (-${\infty}$,
0). Your probabilities \textit{about your} \textit{beliefs} will
typically be extreme. And things themselves---why,
they're just red, or blue, or weighing 20 pounds, or
whatever.


 Thus we will be less likely, perhaps, to mix up the map with the
territory.


 This type distinction may also help us remember that
\textit{uncertainty} is a state of mind. A coin is not
\textit{inherently} 50\% uncertain of which way it will land. The coin
is not a belief processor, and does not have partial information about
itself. In qualitative reasoning you can create a belief that
corresponds very straightforwardly to the coin, like
``The coin will land heads.'' This
belief will be true or false \textit{depending on} the coin, and there
will be a transparent implication from the truth or falsity of the
belief, to the facing side of the coin.


 But even under qualitative reasoning, to say that the coin
\textit{itself} is ``true'' or
``false'' would be a severe type
error. The coin is not a belief. It is a coin. The territory is not the
map.


 If a coin cannot be true or false, how much less can it assign a
50\% probability to itself?

\myendsectiontext

\mysection{Think Like Reality}

{
 Whenever I hear someone describe quantum physics as
``weird''---whenever I hear someone
bewailing the mysterious effects of observation on the observed, or the
bizarre existence of nonlocal correlations, or the incredible
impossibility of knowing position and momentum at the same time---then
I think to myself: \textit{This person will never understand physics no
matter how many books they read.} }


 Reality has been around since long before you showed up.
Don't go calling it nasty names like
``bizarre'' or
``incredible.'' The universe was
propagating complex amplitudes through configuration space for ten
billion years before life ever emerged on Earth. Quantum physics is not
``weird.'' \textit{You} are weird.
\textit{You} have the absolutely bizarre idea that reality ought to
consist of little billiard balls bopping around, when in fact reality
is a perfectly normal cloud of complex amplitude in configuration
space. This is \textit{your} problem, not reality's,
and \textit{you} are the one who needs to change.


 Human intuitions were produced by evolution and evolution is a
hack. The same optimization process that built your retina backward and
then routed the optic cable through your field of vision, also designed
your visual system to process persistent objects bouncing around in
three spatial dimensions because that's what it took to
chase down tigers. But ``tigers''
are leaky surface generalizations---tigers came into existence
gradually over evolutionary time, and they are not all absolutely
similar to each other. When you go down to the fundamental level, the
level on which the laws are stable, global, and exception-free, there
aren't any tigers. In fact there aren't
any persistent objects bouncing around in three spatial dimensions.
Deal with it.


 Calling reality ``weird'' keeps
you inside a viewpoint already proven erroneous. Probability theory
tells us that surprise is the measure of a poor hypothesis; if a model
is consistently stupid---consistently hits on events the model assigns
tiny probabilities---then it's time to discard that
model. A good model makes reality look \textit{normal}, not weird; a
good model assigns high probability to that which is actually the case.
Intuition is only a model by another name: poor intuitions are shocked
by reality, good intuitions make reality feel natural. You want to
reshape your intuitions so that the universe looks normal. You want to
think like reality.


 This end state cannot be forced. It is pointless to pretend that
quantum physics feels natural to you when in fact it feels strange.
This is merely denying your confusion, not becoming less confused. But
it will also hinder you to keep thinking \textit{How bizarre!} Spending
emotional energy on incredulity wastes time you could be using to
update. It repeatedly throws you back into the frame of the old, wrong
viewpoint. It feeds your sense of righteous indignation at reality
daring to contradict you.


 The principle extends beyond physics. Have you ever caught
yourself saying something like, ``I just
don't understand how a PhD physicist can believe in
astrology?'' Well, if you literally
\textit{don't understand}, this indicates a problem
with your model of human psychology. Perhaps you are
\textit{indignant}{}---you wish to express strong moral disapproval.
But if you literally \textit{don't understand}, then
your indignation is stopping you from coming to terms with reality. It
shouldn't be hard to imagine how a PhD physicist ends
up believing in astrology. People compartmentalize, enough said.


 I now try to avoid using the English idiom ``I
just don't understand how\,\ldots'' to
express indignation. If I \textit{genuinely} don't
understand how, then my model is being surprised by the facts, and I
should discard it and find a better model.


 Surprise exists in the map, not in the territory. There are no
surprising facts, only models that are surprised by facts. Likewise for
facts called such nasty names as
``bizarre,''
``incredible,''
``unbelievable,''
``unexpected,''
``strange,''
``anomalous,'' or
``weird.'' When you find yourself
tempted by such labels, it may be wise to check if the alleged fact is
really factual. But if the fact checks out, then the problem
isn't the fact---it's you.

\myendsectiontext

\mysection{Chaotic Inversion}


 I was recently having a conversation with some friends on the
topic of hour-by-hour productivity and willpower
maintenance---something I've struggled with my whole
life. 


 I can avoid running away from a hard problem the first time I see
it (perseverance on a timescale of seconds), and I can stick to the
same problem for years; but to keep working on a timescale of
\textit{hours} is a constant battle for me. It goes without saying that
I've already read reams and reams of advice; and the
most help I got from it was realizing that a sizable fraction of other
creative professionals had the same problem, and
couldn't beat it either, no matter how reasonable all
the advice sounds.


 ``What do you do when you can't
work?'' my friends asked me. (Conversation probably
not accurate, this is a very loose gist.)


 And I replied that I usually browse random websites, or watch a
short video.


 ``Well,'' they said,
``if you know you can't work for a
while, you should watch a movie or something.''


 ``Unfortunately,'' I replied,
``I have to do something whose time comes in short
units, like browsing the Web or watching short videos, because I might
become able to work again at any time, and I can't
predict when---''


 And then I stopped, because I'd just had a
revelation.


 I'd always thought of my workcycle as something
\textit{chaotic}, something \textit{unpredictable.} I never used those
words, but that was the way I \textit{treated} it.


 But here my friends seemed to be implying---what a strange
thought---that \textit{other} people could predict when they would
become able to work again, and structure their time accordingly.


 And it occurred to me for the first time that I might have been
committing that damned old chestnut the Mind Projection Fallacy, right
out there in my ordinary everyday life instead of high abstraction.


 Maybe it wasn't that my productivity was
\textit{unusually} \textit{chaotic}; maybe I was just
\textit{unusually} \textit{stupid} with respect to predicting it.


 That's what inverted stupidity looks like---chaos.
Something hard to handle, hard to grasp, hard to guess, something you
can't do anything with. It's not just
an idiom for high abstract things like Artificial Intelligence. It can
apply in ordinary life too.


 And the reason we don't think of the alternative
explanation ``I'm
stupid,'' is \textit{not}{}---I suspect---that we
think so highly of ourselves. It's just that we
don't think of ourselves at all. We just see a chaotic
feature of the environment.


 So now it's occurred to me that my productivity
problem may not be chaos, but my own stupidity.


 And that may or may not help anything. It certainly
doesn't fix the problem right away. Saying
``I'm ignorant''
doesn't make you knowledgeable.


 But it is, at least, a different path than saying
``it's too
chaotic.''

\myendsectiontext

\mysection{Reductionism}
\label{reductionism}


 Almost one year ago, in April 2007, Matthew C. submitted the
following suggestion for an \textit{Overcoming Bias} topic:

\begin{quote}
{
 How and why the current reigning philosophical hegemon
(reductionistic materialism) is obviously correct [ \ldots ], while the
reigning philosophical viewpoints of all past societies and
civilizations are obviously suspect---}
\end{quote}


 I remember this, because I looked at the request and deemed it
legitimate, but I knew I couldn't do that topic until
I'd started on the Mind Projection Fallacy sequence,
which wouldn't be for a while\,\ldots


 But now it's time to begin addressing this
question. And while I haven't yet come to the
``materialism'' issue, we can now
start on ``reductionism.''


 First, let it be said that I do indeed hold that
``reductionism,'' according to the
meaning I will give for that word, is obviously correct; and to
perdition with any past civilizations that disagreed.


 This seems like a strong statement, at least the first part of it.
General Relativity seems well-supported, yet who knows but that some
future physicist may overturn it?

{
 On the other hand, we are never going \textit{back} to Newtonian
mechanics. The ratchet of science turns, but it does not turn in
reverse. There are cases in scientific history where a theory suffered
a wound or two, and then bounced back; but when a theory takes as many
arrows through the chest as Newtonian mechanics, it \textit{stays
dead.}}


 ``To hell with what past civilizations
thought'' seems safe enough, when past civilizations
believed in something that has been falsified to the trash heap of
history.


 And reductionism is not so much a positive hypothesis, as the
\textit{absence} of belief---in particular, disbelief in a form of the
Mind Projection Fallacy.


 I once met a fellow who claimed that he had experience as a Navy
gunner, and he said, ``When you fire artillery shells,
you've got to compute the trajectories using Newtonian
mechanics. If you compute the trajectories using relativity,
you'll get the wrong answer.''


 And I, and another person who was present, said flatly,
``No.'' I added,
``You might not be able to compute the trajectories
fast enough to get the answers in time---maybe that's
what you mean? But the relativistic answer will always be more accurate
than the Newtonian one.''


 ``No,'' he said,
``I mean that relativity will give you the
\textit{wrong answer}, because things moving at the speed of artillery
shells are governed by Newtonian mechanics, not
relativity.''


 ``If that were really true,'' I
replied, ``you could publish it in a physics journal
and collect your Nobel Prize.''


 Standard physics uses the same \textit{fundamental} theory to
describe the flight of a Boeing 747 airplane, and collisions in the
Relativistic Heavy Ion Collider. Nuclei and airplanes alike, according
to our understanding, are obeying Special Relativity, quantum
mechanics, and chromodynamics.


 But we use entirely different \textit{models} to understand the
aerodynamics of a 747 and a collision between gold nuclei in the \textsc{rhic}.
A computer modeling the aerodynamics of a 747 may not contain a single
token, a single bit of RAM, that represents a quark.


 So is the 747 made of something other than quarks? No,
you're just \textit{modeling} it with
\textit{representational elements} that do not have a one-to-one
correspondence with the quarks of the 747. The map is not the
territory.


 Why \textit{not} model the 747 with a chromodynamic
representation? Because then it would take a gazillion years to get any
answers out of the model. Also we could not store the model on all the
memory on all the computers in the world, as of 2008.


 As the saying goes, ``The map is not the
territory, but you can't fold up the territory and put
it in your glove compartment.'' Sometimes you need a
smaller map to fit in a more cramped glove compartment---but this does
not change the territory. The scale of a map is not a fact about the
territory, it's a fact about the map.


 If it \textit{were} possible to build and run a chromodynamic
model of the 747, it would yield accurate predictions. Better
predictions than the aerodynamic model, in fact.


 To build a fully accurate model of the 747, it is not necessary,
in principle, for the model to contain explicit descriptions of things
like airflow and lift. There does not have to be a single token, a
single bit of RAM, that corresponds to the position of the wings. It is
possible, in principle, to build an accurate model of the 747 that
makes no mention of anything \textit{except} elementary particle fields
and fundamental forces.


 ``What?'' cries the
antireductionist. ``Are you telling me the 747
\textit{doesn't really have wings?} I can see the wings
right there!''


 The notion here is a subtle one. It's not
\textit{just} the notion that an object can have different descriptions
at different levels.


 It's the notion that ``having
different descriptions at different levels'' is
\textit{itself} something you say that belongs in the realm of Talking
About Maps, not the realm of Talking About Territory.


 It's not that the \textit{airplane itself}, the
\textit{laws of physics themselves}, use different descriptions at
different levels---as yonder artillery gunner thought. Rather
\textit{we}, for our convenience, use different simplified models at
different levels.


 If you looked at the ultimate chromodynamic model, the one that
contained only elementary particle fields and fundamental forces, that
model would contain all the facts about airflow and lift and wing
positions---but these facts would be implicit, rather than explicit.


 You, looking \textit{at} the model, and thinking \textit{about}
the model, would be able to figure out where the wings were. Having
figured it out, there would be an explicit representation in your mind
of the wing position---an explicit computational object, there in your
neural RAM. \textit{In your mind.}


 You might, indeed, deduce all sorts of explicit descriptions of
the airplane, at various levels, and even explicit rules for how your
models at different levels interacted with each other to produce
combined predictions---


 And the way that algorithm feels from inside is that the airplane
would \textit{seem} to be made up of many levels at once, interacting
with each other.


 The way a belief \textit{feels from inside} is that you seem to be
looking straight at reality. When it actually \textit{seems} that
you're looking at a belief, as such, you are really
experiencing a belief about belief.


 So when your mind simultaneously believes explicit descriptions of
many different levels, and believes explicit rules for transiting
between levels, as part of an efficient combined model, it
\textit{feels like} you are seeing a system that is \textit{made of}
different level descriptions and their rules for interaction.

%Note changed hydrogen atom to iron atom because Subatomic Physics 3rd ed, by Ernest M Henley and Alejandro Garcia says that light nuclei can be done at the quark level.

 But this is just the brain trying to efficiently compress an
object that it cannot remotely begin to model on a fundamental level.
The airplane is too large. Even an iron atom would be too large.
Quark-to-quark interactions are insanely intractable. You
can't handle the \textit{truth.}


 But the way physics \textit{really} works, as far as we can tell,
is that there is \textit{only} the most basic level---the elementary
particle fields and fundamental forces. You can't
handle the raw truth, but reality can handle it without the slightest
simplification. (I wish I knew where Reality got its computing power.)


 The laws of physics do not contain distinct additional causal
entities that correspond to lift or airplane wings, the way that
\textit{the mind of an engineer} contains distinct additional
\textit{cognitive} entities that correspond to lift or airplane wings.


 This, as I see it, is the thesis of reductionism. Reductionism is
not a positive belief, but rather, a disbelief that the higher levels
of simplified multilevel models are out there in the territory.
Understanding this on a gut level dissolves the question of
``How can you say the airplane doesn't
really have wings, when I can see the wings right
there?'' The critical words are \textit{really} and
\textit{see}.

\myendsectiontext

\mysection{Explaining vs.\ Explaining Away}


 John Keats's \textit{Lamia}
(1819)\footnote{John Keats, ``Lamia,''
\textit{The Poetical Works of John Keats} (London: Macmillan) (1884).\comment{1}} surely deserves some kind of award for Most
Famously Annoying Poetry:

\begin{verse}
 \ldots Do not all charms fly \\
 At the mere touch of cold philosophy?\\
 There was an awful rainbow once in heaven: \\
 We know her woof, her texture; she is given \\
 In the dull catalogue of common things. \\
 Philosophy will clip an Angel's wings, \\
 Conquer all mysteries by rule and line, \\
 Empty the haunted air, and gnomed mine--- \\
 Unweave a rainbow\,\ldots \\
\end{verse}


 My usual reply ends with the phrase: ``If we
cannot learn to take joy in the merely real, our lives will be empty
indeed.'' I shall expand on that later.


 Here I have a different point in mind. Let's just
take the lines:

\begin{verse}
 Empty the haunted air, and gnomed mine---\\
 Unweave a rainbow\,\ldots\\
\end{verse}


 Apparently ``the mere touch of cold
philosophy,'' i.e., the truth, has destroyed:

\begin{itemize}
\item Haunts in the air;
\item Gnomes in the mine;
\item Rainbows.
\end{itemize}


 Which calls to mind a rather different bit of verse:\footnote{\url{https://www.youtube.com/watch?v=Ect-kgxBb4M}}

\begin{verse}
 One of these things\\
 Is not like the others\\
 One of these things\\
 Doesn't belong.\\
\end{verse}


 The air has been emptied of its haunts, and the mine
de-gnomed---but the rainbow is still there!


 In Righting a Wrong Question, I wrote:

\begin{quote}
{
 Tracing back the chain of causality, step by step, I discover that
my belief that I'm wearing socks is fully explained by
the fact that I'm wearing socks\,\ldots On the other
hand, if I see a mirage of a lake in the desert, the correct causal
explanation of my vision does not involve the fact of any actual lake
in the desert. In this case, my belief in the lake is not just
\textit{explained}, but \textit{explained away.}}
\end{quote}


 The rainbow was \textit{explained.} The haunts in the air, and
gnomes in the mine, were \textit{explained away.}


 I think this is the key distinction that anti-reductionists
don't get about reductionism.


 You can see this failure to get the distinction in the classic
objection to reductionism:

\begin{quote}
{
 If reductionism is correct, then even your belief in reductionism
is just the mere result of the motion of molecules---why should I
listen to anything you say?}
\end{quote}


 The key word, in the above, is \textit{mere}; a word which implies
that accepting reductionism would explain \textit{away} all the
reasoning processes leading up to my acceptance of reductionism, the
way that an optical illusion is explained \textit{away}.


 But you can explain how a cognitive process works without its
being ``mere''! My belief that
I'm wearing socks is a mere result of my visual cortex
reconstructing nerve impulses sent from my retina which received
photons reflected off my socks\,\ldots which is to say, according to
scientific reductionism, my belief that I'm wearing
socks is a mere result of the fact that I'm wearing
socks.


 What could be going on in the anti-reductionists'
minds, such that they would put rainbows and belief-in-reductionism in
the same category as haunts and gnomes?


 Several things are going on simultaneously. But for now
let's focus on the basic idea introduced in a previous
essay: The Mind Projection Fallacy between a multi-level map and a
mono-level territory.


 (I.e.: There's no way you can model a 747
quark-by-quark, so you've \textit{got} to use a
multi-level map with explicit cognitive representations of wings,
airflow, and so on. This doesn't mean
there's a multi-level territory. The true laws of
physics, to the best of our knowledge, are only over elementary
particle fields.)


 I think that when physicists say ``There are no
\textit{fundamental} rainbows,'' the
anti-reductionists hear, ``There are no
rainbows.''


 If you don't distinguish between the multi-level
map and the mono-level territory, then when someone tries to explain to
you that the rainbow is not a fundamental thing in physics, acceptance
of this will \textit{feel like} erasing rainbows from your multi-level
map, which \textit{feels like} erasing rainbows from the world.


 When Science says ``tigers are not
\textit{elementary} particles, they are made of
quarks'' the anti-reductionist hears this as the same
sort of dismissal as ``we looked in your garage for a
dragon, but there was just empty air.''


 What scientists did to rainbows, and what scientists did to
gnomes, seemingly felt the same to Keats\,\ldots


 In support of this sub-thesis, I deliberately used several
phrasings, in my discussion of Keats's poem, that were
Mind Projection Fallacious. If you didn't notice, this
would seem to argue that such fallacies are customary enough to pass
unremarked.


 For example:

\begin{quote}
{
 The air has been emptied of its haunts, and the mine
 de-gnomed---but the rainbow is still there!}
\end{quote}


 Actually, Science emptied the \textit{model of} air of
\textit{belief in} haunts, and emptied the \textit{map of} the mine of
\textit{representations of} gnomes. Science did not actually---as
Keats's poem itself would have it---take real
Angel's wings, and destroy them with a cold touch of
truth. In reality there \textit{never were} any haunts in the air, or
gnomes in the mine.


 Another example:

\begin{quote}
{
 What scientists did to rainbows, and what scientists did to
 gnomes, seemingly felt the same to Keats.}
\end{quote}


 Scientists didn't \textit{do} anything \textit{to}
gnomes, only to ``gnomes.'' The
quotation is not the referent.


 But if you commit the Mind Projection Fallacy---and by default,
our beliefs just feel like the way the world \textit{is}{}---then at
time $T = 0$, the mines (apparently) contain gnomes; at time $T = 1$ a
scientist dances across the scene, and at time $T = 2$ the mines
(apparently) are empty. Clearly, there used to be gnomes there, but the
scientist killed them.


 Bad scientist! No poems for you, gnomekiller!


 Well, that's how it \textit{feels}, if you get
emotionally attached to the gnomes, and then a scientist says there
aren't any gnomes. It takes a strong mind, a deep
honesty, and a deliberate effort to say, at this point,
``That which can be destroyed by the truth should
be,'' and ``The scientist
hasn't taken the gnomes away, only taken my delusion
away,'' and ``I never held just
title to my belief in gnomes in the first place; I have not been
deprived of anything I \textit{rightfully} owned,''
and ``If there are gnomes, I desire to believe there
are gnomes; if there are no gnomes, I desire to believe there are no
gnomes; let me not become attached to beliefs I may not
want,'' and all the other things that rationalists
are supposed to say on such occasions.


 But with the rainbow it is not even necessary to go that far. The
rainbow is \textit{still there!}

\myendsectiontext


\mysection{Fake Reductionism}

\begin{verse}
 There was an awful rainbow once in heaven:\\
 We know her woof, her texture; she is given\\
 In the dull catalogue of common things.\\
{\raggedleft
 {}---John Keats, \textit{Lamia}
 \par}
\end{verse}



 I am guessing---though it is only a guess---that Keats himself did
\textit{not} know the woof and texture of the rainbow. Not the way that
Newton understood rainbows. Perhaps not even at all. Maybe Keats just
read, somewhere, that Newton had explained the rainbow as
``light reflected from
raindrops''---


 {}---which was actually known in the thirteenth century. Newton
only added a refinement by showing that the light was decomposed into
colored parts, rather than transformed in color. But that put rainbows
back in the news headlines. And so Keats, with Charles Lamb and William
Wordsworth and Benjamin Haydon, drank ``confusion to
the memory of Newton'' because ``he
destroyed the poetry of the rainbow by reducing it to a
prism.'' That's one reason to suspect
Keats didn't understand the subject too deeply.


 I am guessing, though it is only a guess, that Keats could
\textit{not} have sketched out on paper why rainbows only appear when
the Sun is behind your head, or why the rainbow is an arc of a circle.


 If so, Keats had a Fake Explanation. In this case, a \textit{fake
reduction}. He'd been \textit{told that} the rainbow
had been reduced, but it had not actually \textit{been reduced} in his
model of the world.


 This is another of those distinctions that anti-reductionists fail
to get---the difference between professing the flat fact that something
is reducible, and \textit{seeing} it.


 In this, the anti-reductionists are not too greatly to be blamed,
for it is part of a general problem.


 I've written before on seeming knowledge that is
not knowledge, and beliefs that are not \textit{about} their supposed
objects but only recordings to recite back in the classroom, and words
that operate as stop signs for curiosity rather than answers, and
technobabble that only conveys membership in the literary genre of
``science''\,\ldots


 There is a very great distinction between being able to
\textit{see} where the rainbow comes from, and playing around with
prisms to confirm it, and maybe making a rainbow yourself by spraying
water droplets---


 {}---versus some dour-faced philosopher just \textit{telling} you,
``No, there's nothing special about
the rainbow. Didn't you hear? Scientists have explained
it away. Just something to do with raindrops or whatever. Nothing to be
excited about.''


 I think this distinction probably accounts for a hell of a lot of
the deadly existential emptiness that supposedly accompanies scientific
reductionism.


 You have to interpret the anti-reductionists'
experience of ``reductionism,'' not
in terms of their \textit{actually seeing} how rainbows work, not in
terms of their having the critical
``Aha!,'' but in terms of their
being told that the password is
``Science.'' The effect is just to
move rainbows to a different \textit{literary genre}{}---a literary
genre they have been taught to regard as boring.


 For them, the effect of hearing ``Science has
explained rainbows!'' is to hang up a sign over
rainbows saying, ``This phenomenon has been labeled
\textsc{boring} by order of the Council of Sophisticated Literary Critics. Move
along.''


 And that's all the sign says: only that, and
nothing more.


 So the literary critics have their gnomes yanked out by force; not
dissolved in insight, but removed by flat order of authority. They are
given no beauty to replace the hauntless air, no genuine understanding
that could be interesting in its own right. Just a label saying,
``Ha! You thought rainbows were pretty? You poor,
unsophisticated fool. This is part of the literary genre of science, of
dry and solemn incomprehensible words.''


 That's how anti-reductionists experience
``reductionism.''


 Well, can't blame Keats, poor lad probably
wasn't raised right.


 But he dared to drink ``Confusion to the memory
of Newton''?


 I propose ``To the memory of
Keats's confusion'' as a toast for
rationalists. Cheers.

\myendsectiontext

\mysection{Savannah Poets}

\begin{quotation}

 Poets say science takes away from the beauty of the stars---mere
globs of gas atoms. Nothing is
``mere.'' I too can see the stars on
a desert night, and feel them. But do I see less or more?


 The vastness of the heavens stretches my imagination---stuck on
this carousel my little eye can catch one-million-year-old light. A
vast pattern---of which I am a part---perhaps my stuff was belched from
some forgotten star, as one is belching there. Or see them with the
greater eye of Palomar, rushing all apart from some common starting
point when they were perhaps all together. What is the pattern, or the
meaning, or the why? It does not do harm to the mystery to know a
little about it.


 For far more marvelous is the truth than any artists of the past
imagined! Why do the poets of the present not speak of it?


 What men are poets who can speak of Jupiter if he were like a man,
but if he is an immense spinning sphere of methane and ammonia must be
silent?

{\raggedleft
 {}---Richard Feynman, \textit{The Feynman Lectures on
Physics},\footnote{Richard P. Feynman, Robert B. Leighton, and Matthew L. Sands,
\textit{The Feynman Lectures on Physics}, 3 vols. (Reading, MA:
Addison-Wesley, 1963).\comment{1}}\newline
 Vol I, p. 3--6 (line breaks added)
\par}
\end{quotation}


 That's a real question, there on the last
line---what kind of poet can write about Jupiter the god, but not
Jupiter the immense sphere? Whether or not Feynman meant the question
rhetorically, it has a real answer:


 If Jupiter is like us, he can fall in love, and lose love, and
regain love.


 If Jupiter is like us, he can strive, and rise, and be cast down.


 If Jupiter is like us, he can laugh or weep or dance.


 If Jupiter is an immense spinning sphere of methane and ammonia,
it is more difficult for the poet to make us feel.


 There are poets and storytellers who say that the Great Stories
are timeless, and they never change, are only ever retold. They say,
with pride, that Shakespeare and Sophocles are bound by ties of craft
stronger than mere centuries; that the two playwrights could have
swapped times without a jolt.


 Donald Brown once compiled a list of over two hundred
``human universals,'' found in all
(or a vast supermajority of) studied human cultures, from San Francisco
to the !Kung of the Kalahari Desert. Marriage is on the list, and
incest avoidance, and motherly love, and sibling rivalry, and music and
envy and dance and storytelling and aesthetics, and ritual magic to
heal the sick, and poetry in spoken lines separated by pauses---


 No one who knows anything about evolutionary psychology could be
expected to deny it: The strongest emotions we have are deeply
engraved, blood and bone, brain and DNA.


 It might take a bit of tweaking, but you probably \textit{could}
tell ``Hamlet'' sitting around a
campfire on the ancestral savanna.


 So one can see why John ``Unweave a
rainbow'' Keats might feel something had been lost,
on being told that the rainbow was sunlight scattered from raindrops.
Raindrops don't dance.


 In the Old Testament, it is written that God once destroyed the
world with a flood that covered all the land, drowning all the horribly
guilty men and women of the world along with their horribly guilty
babies, but Noah built a gigantic wooden ark, etc., and after most of
the human species was wiped out, God put rainbows in the sky as a sign
that he wouldn't do it again. At least not with water.


 You can see how Keats would be \textit{shocked} that this
beautiful story was contradicted by modern science. Especially if (as I
described in the previous essay) Keats had no real understanding of
rainbows, no ``Aha!'' insight that
could be fascinating in its own right, to replace the drama
subtracted---


 Ah, but maybe Keats would be right to be disappointed \textit{even
if} he knew the math. The Biblical story of the rainbow is a tale of
bloodthirsty murder and smiling insanity. How could anything about
raindrops and refraction properly replace that? Raindrops
don't scream when they die.


 So science takes the romance away (says the Romantic poet), and
what you are given back never matches the drama of the original---


 (that is, the original delusion)


 {}---even if you do know the equations, because the equations are
not about strong emotions.


 That is the strongest rejoinder I can think of that any Romantic
poet could have said to Feynman---though I can't
remember ever hearing it said.


 You can guess that I don't agree with the Romantic
poets. So my own stance is this:


 It is not \textit{necessary} for Jupiter to be like a human,
because \textit{humans} are like humans. If Jupiter is an immense
spinning sphere of methane and ammonia, that doesn't
mean that love and hate are emptied from the universe. There
\textit{are} still loving and hating minds in the universe.
\textit{Us.}


 With more than six billion of us at the last count, does Jupiter
really need to be on the list of potential protagonists?


 It is not \textit{necessary} to tell the Great Stories about
planets or rainbows. They play out all over our world, every day. Every
day, someone kills for revenge; every day, someone kills a friend by
mistake; every day, upward of a hundred thousand people fall in love.
And even if this were not so, you could write fiction about
humans---not about Jupiter.


 Earth is old, and has played out the same stories many times
beneath the Sun. I do wonder if it might not be time for some of the
Great Stories to change. For me, at least, the story called
``Goodbye''\footnote{Yehuda Yudkowsky, 1985-2004, \url{http://yudkowsky.net/other/yehuda/}} has lost its charm.


 The Great Stories are not timeless, because the human species is
not timeless. Go far enough back in hominid evolution, and no one will
understand \textit{Hamlet}. Go far enough back in time, and you
won't find any brains.


 The Great Stories are not eternal, because the human species,
\textit{Homo sapiens sapiens}, is not eternal. I most sincerely doubt
that we have another thousand years to go in our current form. I do not
say this in sadness: I think we can do better.


 I would not like to see all the Great Stories lost completely, in
our future. I see very little difference between that outcome, and the
Sun falling into a black hole.


 But the Great Stories in their current forms have \textit{already
been} told, over and over. I do not think it ill if some of them should
change their forms, or diversify their endings.


 ``And they lived happily ever
after'' seems worth trying at least once.


 The Great Stories can and should diversify, as humankind grows up.
Part of that ethic is the idea that when we find strangeness, we should
respect it enough to tell its story truly. Even if it makes writing
poetry a little more difficult.


 If you are a good enough poet to write an ode to an immense
spinning sphere of methane and ammonia, you are writing something
\textit{original}, about a newly discovered part of the real universe.
It may not be as dramatic, or as gripping, as Hamlet. But the tale of
Hamlet has already been told! If you write of Jupiter as though it were
a human, then you are making our map of the universe just a little more
impoverished of complexity; you are forcing Jupiter into the mold of
all the stories that have already been told of Earth.


 James Thomson's ``A Poem Sacred
to the Memory of Sir Isaac Newton,'' which praises
the rainbow for what it \textit{really} is---you can argue whether or
not Thomson's poem is as gripping as John
Keats's Lamia who was loved and lost. But tales of love
and loss and cynicism had \textit{already been} told, far away in
ancient Greece, and no doubt many times before. Until we understood the
rainbow as a thing \textit{different} from tales of human-shaped magic,
the true story of the rainbow could not be poeticized.


 The border between science fiction and space opera was once drawn
as follows: If you can take the plot of a story and put it back in the
Old West, or the Middle Ages, without changing it, then it is not
\textit{real} science fiction. In real science fiction, the science is
intrinsically part of the plot---you can't move the
story from space to the savanna, not without losing something.


 Richard Feynman asked: ``What men are poets who
can speak of Jupiter if he were like a man, but if he is an immense
spinning sphere of methane and ammonia must be
silent?''


 They are \textit{savanna poets}, who can \textit{only} tell
stories that would have made sense around a campfire ten thousand years
ago. Savanna poets, who can tell \textit{only} the Great Stories in
their classic forms, and nothing more.

\myendsectiontext


\bigskip
\chapter{Joy in the Merely Real}
\label{joy_in_the_merely_real}

\mysection{Joy in the Merely Real}

\begin{verse}
 \ldots Do not all charms fly\\
 At the mere touch of cold philosophy?\\
 There was an awful rainbow once in heaven:\\
 We know her woof, her texture; she is given\\
 In the dull catalogue of common things.\\
{\raggedleft
 {}---John Keats, \textit{Lamia}
\par}
\end{verse}

\begin{quote}

 Nothing is ``mere.''

{\raggedleft
 {}---Richard Feynman
\par}
\end{quote}



 You've got to admire that phrase,
``dull catalogue of common things.''
What is it, exactly, that goes in this catalogue? Besides rainbows,
that is?


 Why, things that are mundane, of course. Things that are normal;
things that are unmagical; things that are known, or knowable; things
that play by the rules (or that play by \textit{any} rules, which makes
them boring); things that are part of the ordinary universe; things
that are, in a word, \textit{real.}


 Now that's what I call setting yourself up for a
fall.


 At that rate, sooner or later you're going to be
disappointed in \textit{everything}{}---either it will turn out not to
exist, or even worse, it will turn out to be real.


 If we cannot take joy in things that are merely real, our lives
will \textit{always} be empty.


 For what sin are rainbows demoted to the dull catalogue of common
things? For the sin of having a scientific explanation.
``We know her woof, her texture,''
says Keats---an interesting use of the word
``we,'' because I suspect that Keats
didn't know the explanation himself. I suspect that
just being told that someone else knew was too much for him to take. I
suspect that just the notion of rainbows being scientifically
explicable \textit{in principle} would have been too much to take. And
if Keats didn't think like that, well, I know plenty of
people who do.


 I have already remarked that nothing is \textit{inherently}
mysterious---nothing that actually exists, that is. If I am ignorant
about a phenomenon, that is a fact about my state of mind, not a fact
about the phenomenon; to worship a phenomenon because it seems so
wonderfully mysterious is to worship your own ignorance; a blank map
does not correspond to a blank territory, it is just somewhere we
haven't visited yet, etc., etc\ldots.


 Which is to say that \textit{everything}{}---everything that
\textit{actually} exists---is liable to end up in
``the dull catalogue of common
things,'' sooner or later.


 Your choice is either:

\begin{itemize}
\item {
 Decide that things are allowed to be unmagical, knowable,
scientifically explicable---in a word, \textit{real}{}---and yet still
worth caring about;}

\item {
 Or go about the rest of your life suffering from existential ennui
 that is \textit{unresolvable}.}
\end{itemize}


 (Self-deception might be an option for others, but not for you.)


 This puts quite a different complexion on the bizarre habit
indulged by those strange folk called \textit{scientists}, wherein they
suddenly become fascinated by pocket lint or bird droppings or
rainbows, or some other ordinary thing which world-weary and
sophisticated folk would never give a second glance.


 You might say that scientists---at least \textit{some}
scientists---are those folk who are \textit{in principle} capable of
enjoying life in the real universe.

\myendsectiontext

\mysection{Joy in Discovery}

\begin{quote}

 Newton was the greatest genius who ever lived, and the most
fortunate; for we cannot find more than once a system of the world to
establish.

{\raggedleft
 {}---Lagrange\footnote{Fred L. Wilson, \textit{History of Science: Newton} citing: Delambre, M. ``Notice sur la vie et les ouvrages de M. le comte J. L. Lagrange,'' \textit{Oeuvres de Lagrange} I. Paris, 1867, p. xx.}
\par}
\end{quote}


 I have more fun discovering things for myself than reading about
them in textbooks. This is right and proper, and only to be expected.

{
 But discovering something that \textit{no one else
knows}{}---being the \textit{first} to unravel the secret---}


 There is a story that one of the first men to realize that stars
were burning by fusion---plausible attributions I've
seen are to Fritz Houtermans and Hans Bethe{}---was walking out with
his girlfriend of a night, and she made a comment on how beautiful the
stars were, and he replied: ``Yes, and right now,
I'm the only man in the world who knows why they
shine.''


 It is attested by numerous sources that this experience, being the
first person to solve a major mystery, is a \textit{tremendous} high.
It's probably the closest experience you can get to
taking drugs, without taking drugs---though I wouldn't
know.


 \textit{That} can't be healthy.


 Not that I'm objecting to the euphoria.
It's the exclusivity clause that bothers me. Why should
a discovery be worth \textit{less}, just because someone \textit{else}
already knows the answer?


 The most charitable interpretation I can put on the psychology, is
that you don't struggle with a single problem for
months or years if it's something you can just look up
in the library. And that the tremendous high comes from having hit the
problem from every angle you can manage, and having bounced; and then
having analyzed the problem again, using every idea you can think of,
and all the data you can get your hands on---making progress a little
at a time---so that when, \textit{finally}, you crack through the
problem, all the dangling pieces and unresolved questions fall into
place at once, like solving a dozen locked-room murder mysteries with a
single clue.


 And more, the understanding you get is \textit{real}
understanding---understanding that embraces all the clues you studied
to solve the problem, when you didn't yet know the
answer. Understanding that comes from asking questions day after day
and worrying at them; understanding that no one else can get (no matter
how much you tell them the answer) unless they spend months studying
the problem in its historical context, even after it's
been solved---and even then, they won't get the high of
solving it all at once.


 That's one possible reason why James Clerk Maxwell
might have had more fun \textit{discovering} Maxwell's
equations, than you had fun reading about them.


 A slightly less charitable reading is that the tremendous high
comes from what is termed, in the \textit{politesse} of social
psychology, ``commitment'' and
``consistency'' and
``cognitive dissonance''; the part
where we value something more highly \textit{just} because it took more
work to get it. The studies showing that subjecting fraternity pledges
to a harsher initiation, causes them to be more convinced of the value
of the fraternity---identical wine in higher-priced bottles being rated
as tasting better---that sort of thing.


 Of course, if you just have more fun solving a puzzle than being
told its answer, because you enjoy doing the cognitive work for its own
sake, there's nothing wrong with that. The less
charitable reading would be if charging \$100 to be told the answer to
a puzzle made you think the answer was more interesting, worthwhile,
important, surprising, etc., than if you got the answer for free.


 (I strongly suspect that a major part of science's
PR problem in the population at large is people who instinctively
believe that if knowledge is given away for free, it cannot be
important. If you had to undergo a fearsome initiation ritual to be
told the truth about evolution, maybe people would be more satisfied
with the answer.)


 The really uncharitable reading is that the joy of first discovery
is about status. Competition. Scarcity. Beating everyone else to the
punch. It doesn't matter whether you have a three-room
house or a four-room house, what matters is having a bigger house than
the Joneses. A two-room house would be fine, if you could only ensure
that the Joneses had even less.


 I don't object to competition as a matter of
principle. I don't think that the game of Go is
barbaric and should be suppressed, even though it's
zero-sum. But if the euphoric joy of scientific discovery \textit{has}
to be about scarcity, that means it's only available to
one person per civilization for any given truth.


 If the joy of scientific discovery is one-shot per discovery,
then, from a fun-theoretic perspective, Newton probably used up a
substantial increment of the total Physics Fun available over the
entire history of Earth-originating intelligent life. That selfish
bastard explained the orbits of planets \textit{and} the tides.


 And really the situation is even worse than this, because in the
Standard Model of physics (discovered by bastards who spoiled the
puzzle for everyone else) the universe is spatially infinite,
inflationarily branching, and branching via decoherence, which is at
least three different ways that Reality is exponentially or infinitely
large.


 So aliens, or alternate Newtons, or just Tegmark duplicates of
Newton, may all have discovered gravity before \textit{our} Newton
did---if you believe that ``before''
means anything relative to those kinds of separations.


 When that thought first occurred to me, I actually found it quite
uplifting. Once I realized that someone, somewhere in the expanses of
space and time, already knows the answer to any answerable
question---even biology questions and history questions; there are
other decoherent Earths---then I realized how silly it was to think as
if the joy of discovery ought to be limited to one person. It becomes a
fully inescapable source of unresolvable existential angst, and I
regard that as a reductio.


 The consistent solution which maintains the \textit{possibility}
of fun is to stop worrying about what other people know. If you
don't know the answer, it's a mystery
to you. If you can raise your hand, and clench your fingers into a
fist, and you've got no idea of how your brain is doing
it---or even what exact muscles lay beneath your
skin---you've got to consider yourself just as ignorant
as a hunter-gatherer. Sure, someone else knows the answer---but back in
the hunter-gatherer days, someone else in an alternate Earth, or for
that matter, someone else in the future, knew what the answer was.
Mystery, and the joy of finding out, is either a personal thing, or it
doesn't exist at all---and I prefer to say
it's personal.


 The joy of assisting your civilization by telling it something it
doesn't already know does tend to be one-shot per
discovery per civilization; that kind of value is conserved, as are
Nobel Prizes. And the prospect of that reward may be what it takes to
keep you focused on one problem for the years required to develop a
really \textit{deep} understanding; plus, working on a problem unknown
to your civilization is a sure-fire way to avoid reading any spoilers.


 But as part of my general project to undo this idea that
rationalists have less fun, I want to restore the magic and mystery to
every part of the world that you do not \textit{personally} understand,
regardless of what other knowledge may exist, far away in space and
time, or even in your next-door neighbor's mind. If
\textit{you} don't know, it's a
mystery. And now think of how many things you don't
know! (If you can't think of anything, you have other
problems.) Isn't the world suddenly a much more
mysterious and magical and \textit{interesting} place? As if
you'd been transported into an alternate dimension, and
had to learn all the rules from scratch?

\begin{quote}

 A friend once told me that I look at the world as if
I've never seen it before. I thought,
that's a nice compliment\,\ldots Wait! I never
\textit{have} seen it before! What---did everyone else get a preview?


{\raggedleft
 {}---Ran Prieur\footnote{\url{http://web.archive.org/web/20080214014017/http://www.ranprieur.com/me/100things.html}}
\par}
\end{quote}

\myendsectiontext

\mysection{Bind Yourself to Reality}


 So perhaps you're reading all this, and asking:
``Yes, but what does this have to do with
reductionism?'' 


 Partially, it's a matter of leaving a line of
retreat. It's not easy to take something
\textit{important} apart into components, when you're
convinced that this removes magic from the world, unweaves the rainbow.
I do plan to take certain things apart, in this book; and I prefer not
to create pointless existential anguish.


 Partially, it's the crusade against Hollywood
Rationality, the concept that understanding the rainbow subtracts its
beauty. The rainbow is still beautiful \textit{plus} you get the beauty
of physics.


 But even more deeply, it's one of these subtle
hidden-core-of-rationality things. You know, the sort of thing where I
start talking about ``the Way.''
It's about \textit{binding yourself to reality.}


 In one of Frank Herbert's \textit{Dune} books, if
I recall correctly, it is said that a Truthsayer gains their ability to
detect lies in others by always speaking truth themselves, so that they
form a relationship with the truth whose violation they can feel. It
wouldn't work, but I still think it's
one of the more beautiful thoughts in fiction. At the very least, to
get close to the truth, you have to be willing to press yourself up
against reality as tightly as possible, without flinching away, or
sneering down.


 You can see the bind-yourself-to-reality theme in Lotteries: A
Waste of Hope. Understanding that lottery tickets have negative
expected utility does not mean that you give up the hope of being rich.
It means that you stop wasting that hope on lottery tickets. You put
the hope into your job, your school, your startup, your eBay sideline;
and if you truly have nothing worth hoping for, then maybe
it's time to start looking.


 It's not dreams I object to, only
\textit{impossible} dreams. The lottery isn't
impossible, but it is an un-actionable near-impossibility.
It's not that winning the lottery is extremely
\textit{difficult}{}---requires a desperate effort---but that
\textit{work} isn't the issue.


 I say all this, to exemplify the idea of taking emotional energy
that is flowing off to nowhere, and binding it into the realms of
reality.


 This doesn't mean setting goals that are low
enough to be ``realistic,'' i.e.,
easy and safe and parentally approved. Maybe this is good advice in
your personal case, I don't know, but
I'm not the one to say it.


 What I mean is that you can invest emotional energy in rainbows
even if they turn out \textit{not} to be magic. The future is always
absurd but it is never \textit{unreal.}


 The Hollywood Rationality stereotype is that
``rational = emotionless''; the more
reasonable you are, the more of your emotions Reason inevitably
destroys. In Feeling Rational I contrast this against
\textit{``That which can be destroyed by the truth
should be''} and \textit{``That
which the truth nourishes should thrive.''} When you
have arrived at your best picture of the truth, there is nothing
irrational about the emotions you feel as a result of that---the
emotions cannot be destroyed by truth, so they must not be irrational.


 So instead of \textit{destroying} emotional energies associated
with bad explanations for rainbows, as the Hollywood Rationality
stereotype would have it, let us \textit{redirect} these emotional
energies into reality---bind them to beliefs that are as true as we can
make them.


 Want to fly? Don't give up on flight. Give up on
flying potions and build yourself an airplane.


 Remember the theme of Think like Reality, where I talked about how
when physics seems counterintuitive, you've got to
accept that it's not \textit{physics}
that's weird, it's \textit{you}?


 What I'm talking about now is like that, only with
emotions instead of hypotheses---binding your feelings into the real
world. Not the ``realistic''
everyday world. I would be a howling hypocrite if I told you to shut up
and do your homework. I mean the \textit{real} real world, the lawful
universe, that includes absurdities like Moon landings and the
evolution of human intelligence. Just not any magic, anywhere, ever.


 It is a Hollywood Rationality meme that ``Science
takes the fun out of life.''


 Science puts the fun back \textit{into} life.


 Rationality directs your emotional energies into the universe,
rather than somewhere else.

\myendsectiontext

\mysection{If You Demand Magic, Magic Won't Help}

\begin{quote}

 Most witches don't believe in gods. They know that
the gods exist, of course. They even deal with them occasionally. But
they don't believe in them. They know them too well. It
would be like believing in the postman.

{\raggedleft
 {}---Terry Pratchett, \textit{Witches Abroad}\footnote{Terry Pratchett, \textit{Witches Abroad} (London: Corgi Books,
1992).\comment{1}}
\par}
\end{quote}


 Once upon a time, I was pondering the philosophy of fantasy
stories---


 And before anyone chides me for my ``failure to
understand what fantasy is about,'' let me say this:
I was raised in a science fiction and fantasy household. I have been
reading fantasy stories since I was five years old. I occasionally try
to \textit{write} fantasy stories.\footnote{\url{http://www.hpmor.com/}} And I am \textit{not} the sort of
person who tries to write for a genre without pondering its philosophy.
Where do you think story ideas come from?


 Anyway:


 I was pondering the philosophy of fantasy stories, and it occurred
to me that if there were actually dragons in our world---if you could
go down to the zoo, or even to a distant mountain, and meet a
fire-breathing dragon---while nobody had ever actually seen a zebra,
then our fantasy stories would contain zebras aplenty, while dragons
would be unexciting.


 Now that's what I call painting yourself into a
corner, wot? The grass is always greener on the other side of
unreality.


 In one of the standard fantasy plots, a protagonist from our
Earth, a sympathetic character with lousy grades or a crushing mortgage
but still a good heart, suddenly finds themselves in a world where
magic operates in place of science. The protagonist often goes on to
practice magic, and become in due course a (superpowerful) sorcerer.


 Now here's the question---and yes, it is a little
unkind, but I think it needs to be asked: Presumably most readers of
these novels see themselves in the protagonist's shoes,
fantasizing about their own acquisition of sorcery. Wishing for magic.
And, barring improbable demographics, most readers of these novels are
not scientists.


 Born into a world of science, they did not become scientists. What
makes them think that, in a world of magic, they would act any
differently?


 If they don't have the scientific attitude, that
nothing is ``mere''---the capacity
to be interested in merely real things---how will magic help them? If
they actually \textit{had} magic, it would be merely \textit{real}, and
lose the charm of unattainability. They might be excited at first, but
(like the lottery winners who, six months later, aren't
nearly as happy as they expected to be), the excitement would soon wear
off. Probably as soon as they had to actually \textit{study} spells.


 \textit{Unless} they can find the capacity to take joy in things
that are merely real. To be just as excited by hang-gliding, as riding
a dragon; to be as excited by making a light with electricity, as by
making a light with magic\,\ldots even if it takes a little study\,\ldots


 Don't get me wrong. I'm not
dissing dragons. Who knows, we might even create some, one of these
days.


 But if you don't have the capacity to enjoy
hang-gliding even though it is \textit{merely real}, then as soon as
dragons \textit{turn} real, you're not going to be any
more excited by dragons than you are by hang-gliding.


 Do you think you would prefer living in the Future, to living in
the present? That's a quite understandable preference.
Things do seem to be getting better over time.


 But don't forget that \textit{this is} the Future,
relative to the Dark Ages of a thousand years earlier. You have
opportunities undreamt-of even by kings.


 If the trend continues, the Future might be a very fine place
indeed in which to live. But if you do make it to the Future, what you
find, when you get there, will be another Now. If you
don't have the basic capacity to enjoy being in a
Now---if your emotional energy can \textit{only} go into the Future, if
you can \textit{only} hope for a better tomorrow---then no amount of
passing time can help you.


 (Yes, in the Future there could be a pill that fixes the emotional
problem of always looking to the Future. I don't think
this invalidates my basic point, which is about what sort of pills we
should want to take.)


 Matthew C., commenting on \textit{Less Wrong},\footnote{\url{http://lesswrong.com/lw/on/reductionism/irh}} seems very excited
about an informally specified
``theory'' by Rupert Sheldrake which
``explains'' such
non-explanation-demanding phenomena as protein folding and snowflake
symmetry. But why isn't Matthew C. just as excited
about, say, Special Relativity? Special Relativity is actually
\textit{known} to be a law, so why isn't it even
\textit{more} exciting? The advantage of becoming excited about a law
already known to be true, is that you know your excitement will not be
wasted.


 If Sheldrake's theory were accepted truth taught
in elementary schools, Matthew C. wouldn't care about
it. Or why else is Matthew C. fascinated by that one particular law
which he believes to be a law of physics, more than all the other
laws?


 The worst catastrophe you could visit upon the New Age community
would be for their rituals to start working reliably, and for UFOs to
actually appear in the skies. What would be the point of believing in
aliens, if they were just \textit{there}, and everyone else could see
them too? In a world where psychic powers were merely real, New Agers
wouldn't \textit{believe in} psychic powers, any more
than anyone cares enough about gravity to believe in it. (Except for
scientists, of course.)


 Why am I so negative about magic? Would it be \textit{wrong} for
magic to exist?


 I'm not actually negative on magic. Remember, I
occasionally try to write fantasy stories. But I'm
annoyed with this psychology that, if it were born into a world where
spells and potions did work, would pine away for a world where
household goods were abundantly produced by assembly lines.


 Part of binding yourself to reality, on an emotional as well as
intellectual level, is coming to terms with the fact that you
\textit{do live here.} Only then can you see this, your world, and
whatever opportunities it holds out for you, without wishing your sight
away.


 Not to put too fine a point on it, but
\textit{I've} found no lack of dragons to fight, or
magics to master, in this world of my birth. If I were transported into
one of those fantasy novels, I wouldn't be surprised to
find myself studying the forbidden ultimate sorcery---


 {}---because why should being transported into a magical world
change anything? It's not \textit{where} you are,
it's \textit{who} you are.


 So remember the Litany Against Being Transported Into An Alternate
Universe:\newline


\begin{verse}
 If I'm going to be happy anywhere,\\
 Or achieve greatness anywhere,\\
 Or learn true secrets anywhere,\\
 Or save the world anywhere,\\
 Or feel strongly anywhere,\\
 Or help people anywhere,\\
 I may as well do it in reality.\\
\end{verse}

\myendsectiontext


\bigskip

\mysection{Mundane Magic}


 I think that part of the rationalist ethos is \textit{binding
yourself emotionally} to an absolutely lawful reductionistic
universe---a universe containing no supernatural things such as souls
or magic---and pouring all your hope and all your care into that merely
real universe and its possibilities, without disappointment. 


 There's an old trick for combating dukkha where
you make a list of things you're grateful for, like a
roof over your head.


 So why not make a list of abilities you have that would be
amazingly cool \textit{if they were magic}, or if only a few chosen
individuals had them?


 For example, suppose that instead of one eye, you possessed a
magical \textit{second} eye embedded in your forehead. And this second
eye enabled you to \textit{see into the third dimension}{}---so that
you could somehow tell \textit{how far away} things were---where an
ordinary eye would see only a two-dimensional shadow of the true world.
Only the possessors of this ability can accurately aim the legendary
distance-weapons that kill at ranges far beyond a sword, or use to
their fullest potential the shells of ultrafast machinery called
``cars.''


 ``Binocular vision'' would be
too light a term for this ability. We'll only
appreciate it once it has a properly impressive name, like Mystic Eyes
of Depth Perception.


 So here's a list of some of my favorite magical
powers:

\begin{itemize}
\item {
 \textit{Vibratory Telepathy}. By transmitting invisible vibrations
through the very air itself, two users of this ability can
\textit{share thoughts}. As a result, Vibratory Telepaths can form
emotional bonds much deeper than those possible to other primates.}

\item {
 \textit{Psychometric Tracery.} By tracing small fine lines on a
surface, the Psychometric Tracer can leave impressions of emotions,
history, knowledge, even the structure of other spells. This is a
higher level than Vibratory Telepathy as a Psychometric Tracer can
share the thoughts of long-dead Tracers who lived thousands of years
earlier. By reading one Tracery and inscribing another simultaneously,
Tracers can duplicate Tracings; and these replicated Tracings can even
contain the detailed pattern of other spells and magics. Thus, the
Tracers wield almost unimaginable power as magicians; but Tracers can
get in trouble trying to use complicated Traceries that they could not
have Traced themselves.}

\item {
 \textit{Multidimensional Kinesis.} With simple, almost unthinking
acts of will, the Kinetics can cause extraordinarily complex forces to
flow through small tentacles and into any physical object within
touching range---not just pushes, but combinations of pushes at many
points that can effectively apply torques and twists. The Kinetic
ability is far subtler than it first appears: they use it not only to
wield existing objects with martial precision, but also to apply forces
that sculpt objects into forms more suitable for Kinetic wielding. They
even create tools that extend the power of their Kinesis and enable
them to sculpt ever-finer and ever-more-complicated tools, a positive
feedback loop fully as impressive as it sounds.}

\item {
 \textit{The Eye.} The user of this ability can perceive
infinitesimal traveling twists in the Force that binds matter---tiny
vibrations, akin to the life-giving power of the Sun that falls on
leaves, but far more subtle. A bearer of the Eye can sense objects far
beyond the range of touch using the tiny disturbances they make in the
Force. Mountains many days travel away can be known to them as if
within arm's reach. According to the bearers of the
Eye, when night falls and sunlight fails, they can sense huge fusion
fires burning at unthinkable distances---though no one else has any way
of verifying this. Possession of a single Eye is said to make the
bearer equivalent to royalty.}
\end{itemize}


 And finally,

\begin{itemize}
\item {
  \textit{The Ultimate Power.} The user of this ability contains a
smaller, imperfect echo of the entire universe, enabling them to search
out paths through probability to any desired future. If this sounds
like a ridiculously powerful ability, you're
right---game balance goes right out the window with this one. Extremely
rare among life forms, it is the \textit{sekai no ougi} or
``hidden technique of the world.''

Nothing can oppose the Ultimate Power except the Ultimate Power. Any
less-than-ultimate Power will simply be
``comprehended'' by the Ultimate and
disrupted in some inconceivable fashion, or even absorbed into the
Ultimates' own power base. For this reason the Ultimate
Power is sometimes called the ``master technique of
techniques'' or the ``trump card
that trumps all other trumps.'' The more powerful
Ultimates can stretch their
``comprehension'' across galactic
distances and aeons of time, and even perceive the bizarre laws of the
hidden ``world beneath the world.''

Ultimates have been killed by immense natural catastrophes, or by
extremely swift surprise attacks that give them no chance to use their
power. But all such victories are ultimately a matter of luck---it does
not confront the Ultimates on their own probability-bending level, and
if they survive they will begin to bend Time to avoid future attacks.

But the Ultimate Power itself is also dangerous, and many Ultimates
have been destroyed by their own powers---falling into one of the flaws
in their imperfect inner echo of the world.

Stripped of weapons and
armor and locked in a cell, an Ultimate is still one of the most
dangerous life-forms on the planet. A sword can be broken and a limb
can be cut off, but the Ultimate Power is ``the power
that cannot be removed without removing you.''

Perhaps because this connection is so intimate, the Ultimates regard
one who loses their Ultimate Power permanently---without hope of
regaining it---as \textit{schiavo}, or ``dead while
breathing.'' The Ultimates argue that the Ultimate
Power is so important as to be a necessary part of what makes a
creature an end in itself, rather than a means. The Ultimates even
insist that anyone who lacks the Ultimate Power cannot begin to truly
comprehend the Ultimate Power, and hence, cannot understand why the
Ultimate Power is morally important---a suspiciously self-serving
argument.

The users of this ability form an absolute aristocracy and
treat all other life forms as their pawns. }
\end{itemize}

\myendsectiontext

\mysection{The Beauty of Settled Science}


 Facts do not need to be unexplainable to be beautiful; truths do
not become less worth learning if someone else knows them; beliefs do
not become less worthwhile if many others share them\,\ldots 


 \ldots and if you only care about scientific issues that are
controversial, you will end up with a head stuffed full of garbage.


 The media thinks that only the cutting edge of science is worth
reporting on. How often do you see headlines like
``General Relativity Still Governing Planetary
Orbits'' or ``Phlogiston Theory
Remains False''? So, by the time anything is solid
science, it is no longer a breaking headline.
``Newsworthy'' science is often
based on the thinnest of evidence and wrong half the time---if it were
not on the uttermost fringes of the scientific frontier, it would not
be breaking news.


 Scientific \textit{controversies} are problems \textit{so
difficult} that even people who've spent years
mastering the field can still fool themselves. That's
what makes for the heated arguments that attract all the media
attention.


 Worse, if you aren't in the field and part of the
game, controversies \textit{aren't even fun}.


 Oh, sure, you can have the fun of picking a side in an argument.
But you can get that in any football game. That's not
what the fun of science is about.


 Reading a well-written textbook, you get: Carefully phrased
explanations for incoming students, math derived step by step (where
applicable), plenty of experiments cited as illustration (where
applicable), test problems on which to display your new mastery, and a
reasonably good guarantee that what you're learning is
actually true.


 Reading press releases, you usually get: Fake explanations that
convey nothing except the delusion of understanding of a result that
the press release author didn't understand and that
probably has a better-than-even chance of failing to replicate.


 Modern science is built on discoveries, built on discoveries,
built on discoveries, and so on, all the way back to people like
Archimedes, who discovered facts like why boats float, that can make
sense even if you don't know about other discoveries. A
good place to start traveling that road is at the beginning.


 Don't be embarrassed to read \textit{elementary}
science textbooks, either. If you want to pretend to be sophisticated,
go find a play to sneer at. If you just want to have \textit{fun},
remember that simplicity is at the core of scientific beauty.


 And thinking you can jump right into the frontier, when you
haven't learned the settled science, is like\,\ldots

{
 \ldots like trying to climb only the \textit{top} half of Mount
Everest (which is the only part that interests you) by standing at the
base of the mountain, bending your knees, and jumping \textit{really
hard} (so you can pass over the boring parts).}


 Now I'm not saying that you should never pay
attention to scientific controversies. If 40\% of oncologists think
that white socks cause cancer, and the other 60\% violently disagree,
this is an important fact to know.


 Just don't go thinking that science \textit{has}
to be controversial to be interesting.


 Or, for that matter, that science has to be recent to be
interesting. A steady diet of science \textit{news} is bad for you: You
are what you eat, and if you eat only science reporting on fluid
situations, without a solid textbook now and then, your brain will turn
to liquid.

\myendsectiontext

\mysection{Amazing Breakthrough Day: April 1st}


 So you're thinking, ``April 1st\,\ldots isn't that already supposed to be April
Fool's Day?'' 


 Yes---and that will provide the ideal cover for celebrating
Amazing Breakthrough Day.


 As I argued in The Beauty of Settled Science, it is a major
problem that media coverage of science focuses only on \textit{breaking
news}. Breaking news, in science, occurs at the furthest fringes of the
scientific frontier, which means that the new discovery is often:

\begin{itemize}
\item  Controversial;
\item  Supported by only one experiment;
\item  Way the heck more complicated than an ordinary mortal can handle,
and requiring lots of prerequisite science to understand, which is why
it wasn't solved three centuries ago;
\item  Later shown to be wrong.
\end{itemize}


 People never get to see the \textit{solid} stuff, let alone the
\textit{understandable} stuff, because it isn't
\textit{breaking news}.


 On Amazing Breakthrough Day, I propose, journalists who really
care about science can report---under the protective cover of April
1st---such important but neglected science stories as:

\begin{itemize}
\item \textsc{Boats Explained:} Centuries-Old Problem Solved By Bathtub Nudist
\item \textsc{You Shall Not Cross!} Königsberg Tourists' Hopes
Dashed
\item \textsc{Are Your Lungs on \em{Fire}?} Link Between Respiration And
  Combustion Gains Acceptance Among Scientists
\end{itemize}


 Note that every one of these headlines are \textit{true}{}---they
describe events that did, in fact, happen. They just
didn't happen \textit{yesterday.}


 There have been many humanly understandable amazing breakthroughs
in the history of science, that can be understood without a PhD or even
a BSc. The operative word here is \textit{history}. Think of
Archimedes's
``Eureka!'' when he understood the
relation between the water a ship displaces, and the reason the ship
floats. This is \textit{far enough back} in scientific history that you
don't need to know fifty other discoveries to
understand the theory; it can be explained in a couple of graphs;
anyone can see how it's useful; and the confirming
experiments can be duplicated in your own bathtub.


 Modern science is built on discoveries built on discoveries built
on discoveries and so on all the way back to Archimedes. Reporting
science \textit{only} as breaking news is like wandering into a movie
three-fourths of the way through, writing a story about
``Bloody-handed man kisses girl holding
gun!'' and wandering back out again.


 And if your editor says, ``Oh, but our readers
won't be interested in that---''


 Then point out that Reddit and Digg don't link
\textit{only} to breaking news. They also link to short webpages that
give good explanations of old science. Readers vote it up, and that
should tell you something. Explain that if your newspaper
doesn't change to look more like Reddit,
you'll have to start selling drugs to make payroll.
Editors love to hear that sort of thing, right?


 On the Internet, a good new explanation of old science \textit{is}
news and it spreads like news. Why couldn't the science
sections of newspapers work the same way? Why isn't a
new \textit{explanation} worth reporting on?


 But all this is too visionary for a first step. For now,
let's just see if any journalists out there pick up on
Amazing Breakthrough Day, where you report on some
\textit{understandable} science breakthrough as though it had just
occurred.


 April 1st. Put it on your calendar.

\myendsectiontext

\mysection{Is Humanism a Religion Substitute?}


 For many years before the Wright Brothers, people dreamed of
flying with magic potions. There was nothing irrational about the
\textit{raw desire} to fly. There was nothing \textit{tainted} about
the wish to look down on a cloud from above. Only the
``magic potions'' part was
irrational.


 Suppose you were to put me into an fMRI scanner, and take a movie
of my brain's activity levels, while I watched a space
shuttle launch. (Wanting to visit space is not
``realistic,'' but it is an
essentially lawful dream---one that can be fulfilled in a lawful
universe.) The fMRI might---maybe, maybe not---resemble the fMRI of a
devout Christian watching a nativity scene.


 Should an experimenter obtain this result, there's
a lot of people out there, both Christians and some atheists, who would
gloat: ``Ha, ha, space travel is your
religion!''


 But that's drawing the wrong category boundary.
It's like saying that, because some people once tried
to fly by irrational means, no one should ever enjoy looking out of an
airplane window on the clouds below.


 If a rocket launch is what it takes to give me a feeling of
aesthetic transcendence, I do not see this as a \textit{substitute} for
religion. That is theomorphism---the viewpoint from gloating
religionists who assume that everyone who
\textit{isn't} religious has a hole in their mind that
wants filling.


 Now, to be fair to the religionists, this is not \textit{just} a
gloating assumption. There \textit{are} atheists who have
religion-shaped holes in their minds. I \textit{have} seen attempts to
substitute atheism or even transhumanism for religion. And the result
is invariably awful. Utterly awful. Absolutely abjectly awful.


 I call such efforts, ``hymns to the nonexistence
of God.''


 When someone sets out to write an atheistic
hymn---``Hail, oh unintelligent
universe,'' blah, blah, blah---the result will,
without exception, suck.


 Why? Because they're being imitative. Because they
have no motivation for writing the hymn \textit{except} a vague feeling
that since churches have hymns, they ought to have one too. And, on a
purely artistic level, that puts them far beneath genuine religious art
that is not an imitation of anything, but an original expression of
emotion.


 Religious hymns were (often) written by people who \textit{felt
strongly} and \textit{wrote honestly} and put serious effort into the
prosody and imagery of their work---that's what gives
their work the grace that it possesses, of artistic integrity.


 So are atheists doomed to hymnlessness?


 There is an acid test of attempts at post-theism. The acid test
is: ``If religion had never existed among the human
species---if we had \textit{never made} the original mistake---would
this song, this art, this ritual, this way of thinking, still make
sense?''


 If humanity had never made the original mistake, there would be no
hymns to the nonexistence of God. But there would still be marriages,
so the notion of an atheistic marriage ceremony makes perfect
sense---as long as you don't suddenly launch into a
lecture on how God doesn't exist. Because, in a world
where religion \textit{never had} existed, nobody would interrupt a
wedding to talk about the implausibility of a distant hypothetical
concept. They'd talk about love, children, commitment,
honesty, devotion, but who the heck would mention God?


 And, in a human world where religion \textit{never had} existed,
there would still be people who got tears in their eyes watching a
space shuttle launch.


 Which is why, even if experiment shows that watching a shuttle
launch makes ``religion''-associated
areas of my brain light up, associated with feelings of transcendence,
I do not see that as a \textit{substitute} for religion; I expect the
same brain areas would light up, for the same reason, if I lived in a
world where religion had never been invented.


 A good ``atheistic hymn'' is
simply a song about anything worth singing about that
doesn't happen to be religious.


 Also, reversed stupidity is not intelligence. The
world's greatest idiot may say the Sun is shining, but
that doesn't make it dark out. The point is
\textit{not} to create a life that resembles religion as little as
possible in every surface aspect---this is the same kind of thinking
that inspires hymns to the nonexistence of God. If humanity had never
made the original mistake, no one would be \textit{trying to avoid}
things that vaguely resembled religion. Believe accurately, then feel
accordingly: If space launches actually exist, and watching a rocket
rise makes you want to sing, then write the song, dammit.


 If I get tears in my eyes at a space shuttle launch, it
doesn't mean I'm trying to fill a hole
left by religion---it means that my emotional energies, my
\textit{caring}, are bound into the real world.


 If God did speak plainly, and answer prayers reliably, God would
just become one more boringly real thing, no more worth believing in
than the postman. If God were real, it would destroy the inner
uncertainty that brings forth outward fervor in compensation. And if
everyone else believed God were real, it would destroy the specialness
of being one of the elect.


 If you invest your emotional energy in space travel, you
don't have those vulnerabilities. I can \textit{see}
the Space Shuttle rise without losing the awe. Everyone else can
believe that Space Shuttles are real, and it doesn't
make them any less special. I haven't painted myself
into the corner.


 The choice between God and humanity is not just a choice of drugs.
Above all, humanity \textit{actually exists.}

\myendsectiontext

\mysection{Scarcity}


 What follows is taken primarily from Robert
Cialdini's \textit{Influence: The Psychology of
Persuasion}.\footnote{Robert B. Cialdini, \textit{Influence: The Psychology of
Persuasion: Revised Edition} (New York: Quill, 1993).\comment{1}} I own three copies of this book: one
for myself, and two for loaning to friends. 

{
 \textit{Scarcity}, as that term is used in social psychology, is
when things become \textit{more desirable} as they appear \textit{less
obtainable}.}

\begin{itemize}
\item {
 If you put a two-year-old boy in a room with two toys, one toy in
the open and the other behind a Plexiglas wall, the two-year-old will
ignore the easily accessible toy and go after the apparently forbidden
one. If the wall is low enough to be easily climbable, the toddler is
no more likely to go after one toy than the other.\footnote{Sharon S. Brehm and Marsha Weintraub,
``Physical Barriers and Psychological Reactance:
Two-year-olds' Responses to Threats to
Freedom,'' \textit{Journal of Personality and Social
Psychology} 35 (1977): 830--836.\comment{2}}}

\item {
 When Dade County forbade use or possession of phosphate
detergents, many Dade residents drove to nearby counties and bought
huge amounts of phosphate laundry detergents. Compared to Tampa
residents not affected by the regulation, Dade residents rated
phosphate detergents as gentler, more effective, more powerful on
stains, and even believed that phosphate detergents poured more
easily.\footnote{Michael B. Mazis, Robert B. Settle, and Dennis C. Leslie,
``Elimination of Phosphate Detergents and
Psychological Reactance,'' \textit{Journal of
Marketing Research} 10 (1973): 2; Michael B. Mazis,
``Antipollution Measures and Psychological Reactance
Theory: A Field Experiment,'' \textit{Journal of
  Personality and Social Psychology} 31 (1975): 654--666.\comment{3}}}
\end{itemize}


 Similarly, information that appears forbidden or secret seems more
important and trustworthy:

\begin{itemize}
\item {
 When University of North Carolina students learned that a speech
opposing coed dorms had been banned, they became more opposed to coed
dorms (without even hearing the speech).\footnote{Richard D. Ashmore, Vasantha Ramchandra, and Russell A. Jones,
``Censorship as an Attitude Change
Induction,'' \textit{Paper presented at Eastern
Psychological Association meeting} (1971).\comment{4}}}

\item {
 When a driver said he had liability insurance, experimental jurors
awarded his victim an average of four thousand dollars more than if the
driver said he had no insurance. If the judge afterward informed the
jurors that information about insurance was inadmissible and must be
ignored, jurors awarded an average of thirteen thousand dollars more
than if the driver had no insurance.\footnote{Dale Broeder, ``The University of Chicago Jury
Project,'' \textit{Nebraska Law Review} 38 (1959):
760--774.\comment{5}}}

\item {
 Buyers for supermarkets, told by a supplier that beef was in
scarce supply, gave orders for twice as much beef as buyers told it was
readily available. Buyers told that beef was in scarce supply, and
furthermore, that the information about scarcity was itself
scarce---that the shortage was not general knowledge---ordered six
times as much beef. (Since the study was conducted in a real-world
context, the information provided was in fact
correct.)\footnote{A. Knishinsky, ``The Effects of Scarcity of
Material and Exclusivity of Information on Industrial Buyer Perceived
Risk in Provoking a Purchase Decision'' (Doctoral
dissertation, Arizona State University, 1982).\comment{6}}}
\end{itemize}


 The conventional theory for explaining this is
``psychological reactance,''
social-psychology-speak for ``When you tell people
they can't do something, they'll just
try even harder.'' The fundamental instincts involved
appear to be preservation of status and preservation of options. We
resist dominance, when any human agency tries to restrict our freedom.
And when options seem to be in danger of disappearing, even from
natural causes, we try to leap on the option before
it's gone.


 Leaping on disappearing options may be a good adaptation in a
hunter-gatherer society---gather the fruits while they are still
ripe---but in a money-based society it can be rather costly. Cialdini
reports that in one appliance store he observed, a salesperson who saw
that a customer was evincing signs of interest in an appliance would
approach, and sadly inform the customer that the item was out of stock,
the last one having been sold only twenty minutes ago. Scarcity
creating a sudden jump in desirability, the customer would often ask
whether there was any chance that the salesperson could locate an
unsold item in the back room, warehouse, or anywhere.
``Well,'' says the salesperson,
``that's possible, and
I'm willing to check; but do I understand that this is
the model you want, and if I can find it at this price,
you'll take it?''


 As Cialdini remarks, a chief sign of this malfunction is that you
dream of \textit{possessing} something, rather than \textit{using} it.
(Timothy Ferriss offers similar advice on planning your life: ask which
\textit{ongoing experiences} would make you happy, rather than which
possessions or status-changes.)


 But the really fundamental problem with desiring the unattainable
is that as soon as you actually \textit{get} it, it stops being
unattainable. If we cannot take joy in the merely available, our lives
will \textit{always} be frustrated\,\ldots

\myendsectiontext


\bigskip

\mysection{The Sacred Mundane}


 So I was reading (around the first half of) Adam
Frank's \textit{The Constant Fire},\footnote{Adam Frank, \textit{The Constant Fire: Beyond the Science vs.
Religion Debate} (University of California Press, 2009).\comment{1}}
in preparation for my Bloggingheads dialogue with him. Adam
Frank's book is about the experience of the sacred. I
might not usually call it that, but of course I know the experience
Frank is talking about. It's what I feel when I watch a
video of a space shuttle launch; or what I feel---to a lesser extent,
because in this world it is too common---when I look up at the stars at
night, and think about what they mean. Or the birth of a child, say.
That which is significant in the Unfolding Story. 


 Adam Frank holds that this experience is something that science
holds deeply in common with religion. As opposed to e.g.~being a basic
human quality which religion corrupts.


 \textit{The Constant Fire} quotes William James's
\textit{The Varieties of Religious Experience} as saying:

\begin{quote}
{
 Religion\,\ldots shall mean for us the feelings, acts, and
experiences of individual men in their solitude; so far as they
apprehend themselves to stand in relation to whatever they may consider
the divine.\footnote{William James, The varieties of religious experience, pg.~31}
}
\end{quote}


 And this theme is developed further: Sacredness is something
intensely \textit{private} and \textit{individual.}


 Which completely nonplussed me. Am I supposed to not have any
feeling of sacredness if I'm one of \textit{many}
people watching the video of \textit{SpaceShipOne} winning the X-Prize?
Why not? Am I supposed to think that my experience of sacredness has to
be somehow \textit{different} from that of all the \textit{other}
people watching? Why, when we all have the same brain design? Indeed,
why would I \textit{need} to believe I was unique? (But
``unique'' \textit{is} another word
Adam Frank uses; so-and-so's ``unique
experience of the sacred.'') Is the feeling private
in the same sense that we have difficulty communicating \textit{any}
experience? Then why emphasize this of sacredness, rather than
sneezing?


 The light came on when I realized that I was looking at a trick of
Dark Side Epistemology---if you make something \textit{private}, that
shields it from criticism. You can say, ``You
can't criticize me, because this is my private, inner
experience that you can never access to question
it.''


 But the price of shielding yourself from criticism is that you are
cast into solitude---the solitude that William James admired as the
core of religious experience, as if loneliness were a \textit{good}
thing.


 Such relics of Dark Side Epistemology are key to understanding the
many ways that religion twists the experience of sacredness:


 \textbf{Mysteriousness}{}---why should the sacred have to be
mysterious? A space shuttle launch gets by just fine without being
mysterious. How much \textit{less} would I appreciate the stars if I
did \textit{not} know what they were, if they were just little points
in the night sky? But if your religious beliefs are questioned---if
someone asks, ``Why doesn't God heal
amputees?''---then you take refuge and say, in a tone
of deep profundity, ``It is a sacred
mystery!'' There are questions that must not be
asked, and answers that must not be acknowledged, to defend the lie.
Thus unanswerability comes to be associated with sacredness. And the
price of shielding yourself from criticism is giving up the true
curiosity that truly wishes to find answers. You will worship your own
ignorance of the temporarily unanswered questions of your own
generation---probably including ones that are already answered.


 \textbf{Faith}{}---in the early days of religion, when people were
more naive, when even intelligent folk actually believed that stuff,
religions staked their reputation upon the testimony of miracles in
their scriptures. And Christian archaeologists set forth truly
expecting to find the ruins of Noah's Ark. But when no
such evidence was forthcoming, \textit{then} religion executed what
William Bartley called \textit{the retreat to commitment},
``I believe because I believe!''
Thus \textit{belief without good evidence} came to be associated with
the experience of the sacred. And the price of shielding yourself from
criticism is that you sacrifice your ability to think clearly about
that which is sacred, and to progress in your understanding of the
sacred, and relinquish mistakes.


 \textbf{Experientialism}{}---if before you thought that the
rainbow was a sacred contract of God with humanity, and then you begin
to realize that God doesn't exist, then you may execute
a \textit{retreat to pure experience}{}---to praise yourself just for
\textit{feeling} such wonderful sensations when you think about God,
whether or not God actually \textit{exists}. And the price of shielding
yourself from criticism is solipsism: your experience is stripped of
its \textit{referents.} What a terrible hollow feeling it would be to
watch a space shuttle rising on a pillar of flame, and say to yourself,
``But it doesn't really matter whether
the space shuttle actually exists, so long as I
feel.''


 \textbf{Separation}{}---if the sacred realm is not subject to
ordinary rules of evidence or investigable by ordinary means, then it
must be different in kind from the world of mundane matter: and so we
are less likely to think of a space shuttle as a candidate for
sacredness, because it is a work of merely \textit{human} hands. Keats
lost his admiration of the rainbow and demoted it to the
``dull catalogue of mundane things''
for the crime of its woof and texture being known. And the price of
shielding yourself from all ordinary criticism is that you lose the
sacredness of all merely real things.


 \textbf{Privacy}{}---of this I have already spoken.


 Such distortions are why we had best \textit{not} to try to
salvage religion. No, not even in the form of
``spirituality.'' Take away the
institutions and the factual mistakes, subtract the churches and the
scriptures, and you're left with\,\ldots all this
nonsense about mysteriousness, faith, solipsistic experience, private
solitude, and discontinuity.


 The original lie is only the beginning of the problem. Then you
have all the ill habits of thought that have evolved to defend it.
Religion is a poisoned chalice, from which we had best not even sip.
Spirituality is the same cup after the original pellet of poison has
been taken out, and only the dissolved portion remains---a little less
directly lethal, but still not good for you.


 When a lie has been defended for ages upon ages, the true origin
of the inherited habits lost in the mists, with layer after layer of
undocumented sickness; then the wise, I think, will start over from
scratch, rather than trying to selectively discard the original lie
while keeping the habits of thought that protected it. \textit{Just
admit you were wrong}, give up \textit{entirely} on the mistake, stop
defending it \textit{at all}, stop trying to say you were even a little
right, stop trying to save face, just say
``Oops!'' and throw out the
\textit{whole} thing and begin again.


 That capacity---to really, \textit{really,} without defense, admit
you were \textit{entirely} wrong---is why religious experience will
never be like scientific experience. No religion can absorb
\textit{that} capacity without losing itself \textit{entirely} and
becoming simple humanity\,\ldots


 \ldots to just look up at the distant stars. Believable without
strain, without a constant distracting struggle to fend off your
awareness of the counterevidence. Truly there \textit{in the world},
the experience united with the referent, a solid part of that unfolding
story. Knowable without threat, offering true meat for curiosity.
Shared in togetherness with the many other onlookers, no need to
retreat to privacy. Made of the same fabric as yourself and all other
things. Most holy and beautiful, the sacred mundane.

\myendsectiontext


\bigskip

\mysection{To Spread Science, Keep It Secret}


 Sometimes I wonder if the Pythagoreans had the right idea. 


 Yes, I've written about how
``science'' is inherently public.
I've written that
``science'' is distinguished from
merely rational knowledge by the in-principle ability to reproduce
scientific experiments for yourself, to know without relying on
authority. I've said that
``science'' should be defined as the
publicly accessible knowledge of humankind. I've even
suggested that future generations will regard all papers not published
in an open-access journal as non-science, i.e., it
can't be part of the public knowledge of humankind if
you make people pay to read it.\footnote{Edit 2018: And of course Every Cause Wants to Be a Cult, and as a practical matter, how do you actually keep Science a secret without draconian policies?}


 But that's only one vision of the future. In
another vision, the knowledge we now call
``science'' is taken \textit{out} of
the public domain---the books and journals hidden away, guarded by
mystic cults of gurus wearing robes, requiring fearsome initiation
rituals for access---so that more people will \textit{actually} study
it.


 I mean, right now, people \textit{can} study science but they
\textit{don't.}


 ``Scarcity,''
it's called in social psychology. What appears to be in
limited supply is more highly valued. And this effect is
\textit{especially} strong with information---we're
much more likely to try to obtain information that we believe is
secret, and to value it more when we do obtain it.


 With science, I think, people assume that if the information is
freely available, it must not be important. So instead people join
cults that have the sense to keep their Great Truths secret. The Great
Truth may actually be gibberish, but it's more
satisfying than coherent science, because it's
\textit{secret.}


 Science is the great Purloined Letter of our times, left out in
the open and ignored.


 Sure, scientific openness helps the scientific elite.
They've already \textit{been} through the initiation
rituals. But for the rest of the planet, science is kept secret a
hundred times more effectively by making it freely available, than if
its books were guarded in vaults and you had to walk over hot coals to
get access. (This being a fearsome trial indeed, since the great
secrets of insulation are only available to Physicist-Initiates of the
Third Level.)


 If scientific knowledge were hidden in ancient vaults (rather than
hidden in inconvenient pay-for-access journals), at least then people
would \textit{try} to get into the vaults. They'd be
\textit{desperate} to learn science. Especially when they saw the power
that Eighth Level Physicists could wield, and were told that they
\textit{weren't allowed to know} the explanation.


 And if you tried to start a cult around oh, say, Scientology,
you'd get some degree of public interest, at first. But
people would very quickly start asking uncomfortable questions like
``Why haven't you given a public
demonstration of your Eighth Level powers, like the
Physicists?'' and ``How come none of
the Master Mathematicians seem to want to join your
cult?'' and ``Why should I follow
your Founder when they aren't an Eighth Level anything
outside their own cult?'' and ``Why
should I study \textit{your} cult \textit{first}, when the Dentists of
Doom can do things that are so much more
impressive?''


 When you look at it from that perspective, the escape of math from
the Pythagorean cult starts to look like a major strategic blunder for
humanity.


 Now, I know what you're going to say:
``But science \textit{is} surrounded by fearsome
initiation rituals! Plus it's \textit{inherently}
difficult to learn! Why doesn't \textit{that}
count?'' Because the public \textit{thinks} that
science is freely available, that's why. If
you're \textit{allowed} to learn, it must not be
important enough \textit{to} learn.


 It's an image problem, people taking their cues
from others' attitudes. Just \textit{anyone} can walk
into the supermarket and buy a light bulb, and nobody looks at it with
awe and reverence. The physics supposedly isn't secret
(even though \textit{you} don't know), and
there's a one-paragraph explanation in the newspaper
that sounds vaguely authoritative and convincing---essentially, no one
treats the lightbulb as a sacred mystery, so neither do you.


 Even the simplest little things, completely inert objects like
crucifixes, can become magical if everyone \textit{looks} at them like
they're magic. But since you're
theoretically \textit{allowed} to know why the light bulb works without
climbing the mountain to find the remote Monastery of Electricians,
there's no need to \textit{actually} bother to learn.


 Now, because science does in fact have initiation rituals both
social and cognitive, scientists are not wholly dissatisfied with their
science. The problem is that, in the present world, very few people
bother to study science in the first place. Science cannot be the true
Secret Knowledge, because just anyone is allowed to know
it---\textit{even though, in fact, they don't}.


 If the Great Secret of Natural Selection, passed down from Darwin
Who Is Not Forgotten, was only ever imparted to you after you paid
\$2,000 and went through a ceremony involving torches and robes and
masks and sacrificing an ox, \textit{then} when you were shown the
fossils, and shown the optic cable going through the retina under a
microscope, and finally told the Truth, you would say
``That's the most brilliant thing
ever!'' and \textit{be satisfied}. After that, if
some other cult tried to tell you it was actually a bearded man in the
sky 6000 years ago, you'd laugh like hell.


 And you know, it might actually be more \textit{fun} to do things
that way. Especially if the initiation required you to put together
some of the evidence for yourself---together, or with
classmates---before you could tell your Science Sensei you were ready
to advance to the next level. It wouldn't be
\textit{efficient}, sure, but it would be \textit{fun.}


 If humanity had never made the mistake---never gone down the
religious path, and never learned to fear anything that smacks of
religion---then maybe the PhD granting ceremony would involve litanies
and chanting, because, hey, that's what people like.
Why take the fun out of everything?


 Maybe we're just doing it wrong.


 And no, I'm not \textit{seriously} proposing that
we try to reverse the last five hundred years of openness and classify
all the science secret. At least, not at the moment. Efficiency is
important for now, especially in things like medical research.
I'm just explaining why it is that I
won't tell anyone the Secret of how the ineffable
difference between blueness and redness arises from mere atoms for less
than \$100,000---


 Ahem! I meant to say, I'm telling you about this
vision of an alternate Earth, so that you give science equal treatment
with cults. So that you don't undervalue scientific
truth when you learn it, \textit{just} because it
doesn't seem to be protected appropriately to its
value. \textit{Imagine} the robes and masks. Visualize yourself
creeping into the vaults and stealing the Lost Knowledge of Newton. And
don't be fooled by any organization that \textit{does}
use robes and masks, unless they also show you the data.


 People seem to have holes in their minds for Esoteric Knowledge,
Deep Secrets, the Hidden Truth. And I'm not even
criticizing this psychology! There \textit{are} deep secret esoteric
hidden truths, like quantum mechanics or Bayes-structure.
We've just gotten into the habit of presenting the
Hidden Truth in a very \textit{unsatisfying} way, wrapped up in false
mundanity.


 But if the holes for secret knowledge are not filled by true
beliefs, they will be filled by false beliefs. There is \textit{nothing
but} science to learn---the emotional energy must either be invested in
reality, or wasted in total nonsense, or destroyed. For myself, I think
it is better to invest the emotional energy; fun should not be
needlessly cast away.


 Right now, we've got the worst of both worlds.
Science isn't \textit{really} free, because the courses
are expensive and the textbooks are expensive. But the public
\textit{thinks} that anyone is allowed to know, so it must not be
important.


 Ideally, you would want to arrange things the other way around.

\myendsectiontext

\mysection{Initiation Ceremony}


 The torches that lit the narrow stairwell burned intensely and in
the wrong color, flame like melting gold or shattered suns. 


 \textit{192\,\ldots 193\,\ldots}


 Brennan's sandals clicked softly on the stone
steps, snicking in sequence, like dominos very slowly falling.


 \textit{227\,\ldots 228\,\ldots}


 Half a circle ahead of him, a trailing fringe of dark cloth
whispered down the stairs, the robed figure itself staying just out of
sight.


 \textit{239\,\ldots 240\,\ldots}


 \textit{Not much longer}, Brennan predicted to himself, and his
guess was accurate:


 Sixteen times sixteen steps was the number, and they stood before
the portal of glass.


 The great curved gate had been wrought with cunning, humor, and
close attention to indices of refraction: it warped light, bent it,
folded it, and generally abused it, so that there were hints of what
was on the other side (stronger light sources, dark walls) but no
possible way of \textit{seeing through}{}---unless, of course, you had
the key: the counter-door, thick for thin and thin for thick, in which
case the two would cancel out.


 From the robed figure beside Brennan, two hands emerged, gloved in
reflective cloth to conceal skin's color. Fingers like
slim mirrors grasped the handles of the warped gate---handles that
Brennan had not guessed; in all that distortion, shapes could only be
anticipated, not seen.


 ``Do you want to know?''
whispered the guide; a whisper nearly as loud as an ordinary voice, but
not revealing the slightest hint of gender.


 Brennan paused. The answer to the question seemed suspiciously,
indeed extraordinarily obvious, even for ritual.


 ``Yes,'' Brennan said finally.


 The guide only regarded him silently.


 ``Yes, I want to know,'' said
Brennan.


 ``Know \textit{what},
exactly?'' whispered the figure.


 Brennan's face scrunched up in concentration,
trying to visualize the game to its end, and hoping he
hadn't blown it already; until finally he fell back on
the first and last resort, which is the truth:


 ``It doesn't
matter,'' said Brennan, ``the answer
is still yes.''


 The glass gate parted down the middle, and slid, with only the
tiniest scraping sound, into the surrounding stone.


 The revealed room was lined, wall-to-wall, with figures robed and
hooded in light-absorbing cloth. The straight walls were not themselves
black stone, but mirrored, tiling a square grid of dark robes out to
infinity in all directions; so that it seemed as if the people of some
much vaster city, or perhaps the whole human kind, watched in assembly.
There was a hint of moist warmth in the air of the room, the breath of
the gathered: a scent of crowds.


 Brennan's guide moved to the center of the square,
where burned four torches of that relentless yellow flame. Brennan
followed, and when he stopped, he realized with a slight shock that all
the cowled hoods were now looking directly at him. Brennan had never
before in his life been the focus of such absolute attention; it was
frightening, but not entirely unpleasant.


 ``He is here,'' said the guide
in that strange loud whisper.


 The endless grid of robed figures replied in one voice: perfectly
blended, exactly synchronized, so that not a single individual could be
singled out from the rest, and betrayed:


 ``\textit{Who is absent?}''


 ``Jakob Bernoulli,'' intoned
the guide, and the walls replied:

{
 ``\textit{Is dead but not
forgotten.}''}


 ``Abraham de Moivre,''

{
 ``\textit{Is dead but not
forgotten.}''}


 ``Pierre-Simon Laplace,''

{
 ``\textit{Is dead but not
forgotten.}''}


 ``Edwin Thompson Jaynes,''

{
 ``\textit{Is dead but not
forgotten.}''}


 ``They died,'' said the guide,
``and they are lost to us; but we still have each
other, and the project continues.''


 In the silence, the guide turned to Brennan, and stretched forth a
hand, on which rested a small ring of nearly transparent material.


 Brennan stepped forward to take the ring---


 But the hand clenched tightly shut.


 ``If three-fourths of the humans in this room are
women,'' said the guide, ``and
three-fourths of the women and half of the men belong to the Heresy of
Virtue, and I am a Virtuist, what is the probability that I am a
man?''


 ``Two-elevenths,'' Brennan said
confidently.


 There was a moment of absolute silence.


 Then a titter of shocked laughter.


 The guide's whisper came again, truly quiet this
time, almost nonexistent: ``It's
one-sixth, actually.''


 Brennan's cheeks were flaming so hard that he
thought his face might melt off. The instinct was very strong to run
out of the room and up the stairs and flee the city and change his name
and start his life over again and get it right this time.


 ``An honest mistake is at least
honest,'' said the guide, louder now,
``and we may know the honesty by its relinquishment.
If I am a Virtuist, what is the probability that I am a
man?''


 ``One---'' brennan started to
say.


 Then he stopped. Again, the horrible silence.


 ``Just say
`one-sixth' already,''
stage-whispered the figure, this time loud enough for the walls to
hear; then there was more laughter, not all of it kind.


 Brennan was breathing rapidly and there was sweat on his forehead.
If he was wrong about this, he really \textit{was} going to flee the
city. ``Three fourths women times three fourths
Virtuists is nine sixteenths female Virtuists in this room. One fourth
men times one half Virtuists is two sixteenths male Virtuists. If I
have only that information and the fact that you are a Virtuist, I
would then estimate odds of two to nine, or a probability of
two-elevenths, that you are male. Though I do not, in fact, believe the
information given is correct. For one thing, it seems too neat. For
another, there are an odd number of people in this
room.''


 The hand stretched out again, and opened.


 Brennan took the ring. It looked almost invisible, in the
torchlight; not glass, but some material with a refractive index very
close to air. The ring was warm from the guide's hand,
and felt like a tiny living thing as it embraced his finger.


 The relief was so great that he nearly didn't hear
the cowled figures applauding.


 From the robed guide came one last whisper:


 ``You are now a novice of the Bayesian
Conspiracy.''

\myendsectiontext

\chapter{Physicalism 201}

\mysection{Hand vs.\ Fingers}


 Back to our original topic: Reductionism and the Mind Projection
Fallacy. There can be emotional problems in accepting reductionism, if
you think that things have to be fundamental to be fun. But this
position commits us to never taking joy in anything more complicated
than a quark, and so I prefer to reject it. 


 To review, the reductionist thesis is that we use multi-level
models for computational reasons, but physical reality has only a
single level.


 Here I'd like to pose the following conundrum:
When you pick up a cup of water, is it your \textit{hand} that picks it
up?


 Most people, of course, go with the naive popular answer:
``Yes.''


 Recently, however, scientists have made a stunning discovery:
It's not your \textit{hand} that holds the cup,
it's actually your fingers, thumb, and palm.


 Yes, I know! I was shocked too. But it seems that after scientists
measured the forces exerted on the cup by each of your fingers, your
thumb, and your palm, they found there was no force left over---so the
force exerted by your \textit{hand} must be zero.


 The theme here is that, if you can \textit{see how} (not just
\textit{know that}) a higher level reduces to a lower one, they will
not seem like separate things within your map; you will be able to
\textit{see} how silly it is to think that your fingers could be in one
place, and your hand somewhere else; you will be able to \textit{see}
how silly it is to argue about whether it is your hand that picks up
the cup, or your fingers.


 The operative word is ``see,''
as in concrete visualization. Imagining your hand causes you to imagine
the fingers and thumb and palm; conversely, imagining fingers and thumb
and palm causes you to identify a hand in the mental picture. Thus the
high level \textit{of your map} and the low level \textit{of your map}
will be tightly bound together \textit{in your mind}.

{
 In reality, of course, the levels are bound together even tighter
than that---bound together by the tightest possible binding: physical
identity. You can \textit{see} this: You can \textit{see} that saying
(1) ``hand'' or (2)
``fingers and thumb and palm,'' does
not refer to different \textit{things}, but different \textit{points of
view}.}


 But suppose you lack the knowledge to so tightly bind together the
levels of your map. For example, you could have a
``hand scanner'' that showed a
``hand'' as a dot on a map (like an
old-fashioned radar display), and similar scanners for
fingers/thumbs/palms; then you would see a cluster of dots around the
hand, but you would be able to \textit{imagine} the hand-dot moving off
from the others. So, even though the physical reality of the hand (that
is, the thing the dot corresponds to) was identical with / strictly
composed of the physical realities of the fingers and thumb and palm,
you would not be able to see this fact; even if someone told you, or
you guessed from the correspondence of the dots, you would only
\textit{know} the fact of reduction, not \textit{see} it. You would
still be able to \textit{imagine} the hand dot moving around
independently, even though, if the physical makeup of the sensors were
held constant, it would be physically impossible for this to actually
happen.


 Or, at a still lower level of binding, people might just tell you
``There's a hand over there, and some
fingers over there''---in which case you would know
little more than a Good-Old-Fashioned AI representing the situation
using suggestively named \textsc{lisp} tokens. There wouldn't be
anything \textit{obviously} contradictory about asserting:


$\vdash$\texttt{Inside(Room,Hand)}

$\vdash\lnot$\texttt{Inside(Room,Fingers)},


 because you would not possess the \textit{knowledge}

 $\vdash$\texttt{Inside(x,Hand)$\Rightarrow $Inside(x,Fingers)}.


 None of this says that a hand can actually detach its existence
from your fingers and crawl, ghostlike, across the room; it just says
that a Good-Old-Fashioned AI with a propositional representation may
not \textit{know} any better. The map is not the territory.


 In particular, you shouldn't draw too many
conclusions from how it seems \textit{conceptually possible}, in the
mind of some specific conceiver, to separate the hand from its
constituent elements of fingers, thumb, and palm. Conceptual
possibility is not the same as logical possibility or physical
possibility.


 It is \textit{conceptually} possible \textit{to you} that 235,757
is prime, because you don't know any better. But it
isn't \textit{logically} possible that 235,757 is
prime; if you were logically omniscient, 235,757 would be obviously
composite (and you would know the factors). That that's
why we have the notion of impossible possible worlds, so that we can
put probability distributions on propositions that may or may not be
\textit{in fact} logically impossible.

{
 And you can imagine philosophers who criticize
``eliminative fingerists'' who
contradict the direct facts of experience---we can \textit{feel} our
hand holding the cup, after all---by suggesting that
``hands''
\textit{don't really exist}, in which case, obviously,
the cup would fall down. And philosophers who suggest
``appendigital bridging laws'' to
explain how a particular configuration of fingers evokes a hand into
existence---with the note, of course, that while our world contains
those particular appendigital bridging laws, the laws could have been
conceivably different, and so are not in any sense \textit{necessary
facts}, etc.}


 All of these are cases of Mind Projection Fallacy, and what I call
``naive philosophical
realism''---the confusion of philosophical intuitions
for direct, veridical information about reality. Your inability to
imagine something is just a computational fact about what your brain
can or can't imagine. Another brain might work
differently.

\myendsectiontext

\mysection{Angry Atoms}
\label{angry_atoms}


 Fundamental physics---quarks 'n'
stuff---is far removed from the levels we can \textit{see}, like hands
and fingers. At best, you can know how to replicate the experiments
that show that your hand (like everything else) is composed of quarks,
and you may know how to derive a few equations for things like atoms
and electron clouds and molecules. 


 At worst, the existence of quarks beneath your hand may just be
something you were told. In which case it's
questionable in what sense you can be said to
``know'' it at all, even if you
repeat back the same word ``quark''
that a physicist would use to convey knowledge to another physicist.


 Either way, you can't actually \textit{see} the
identity between levels---no one has a brain large enough to
\textit{visualize} avogadros of quarks and recognize a hand-pattern in
them.


 But we at least understand what hands \textit{do}. Hands push on
things, exert forces on them. When we're told about
atoms, we visualize little billiard balls bumping into each other. This
makes it seem obvious that ``atoms''
can push on things too, by bumping into them.


 Now this notion of atoms is not quite correct. But so far as
\textit{human imagination} goes, it's relatively easy
to imagine our hand being made up of a little galaxy of swirling
billiard balls, pushing on things when our
``fingers'' touch them. Democritus
imagined this 2,400 years ago, and there was a time, roughly
1803--1922, when Science thought he was right.


 But what about, say, anger?


 How could little billiard balls be angry? Tiny frowny faces on the
billiard balls?


 Put yourself in the shoes of, say, a hunter-gatherer---someone who
may not even have a notion of writing, let alone the notion of using
base matter to perform computations---someone who has no idea that such
a thing as neurons exist. Then you can imagine the \textit{functional}
gap that your ancestors might have perceived between billiard balls and
``Grrr! Aaarg!''


 Forget about subjective experience for the moment, and consider
the sheer \textit{behavioral} gap between anger and billiard balls. The
difference between what little billiard balls \textit{do}, and what
anger makes people \textit{do.} Anger can make people raise their fists
and hit someone---or say snide things behind their backs---or plant
scorpions in their tents at night. Billiard balls just push on things.


 Try to put yourself in the shoes of the hunter-gatherer
who's never had the
``Aha!'' of information-processing.
Try to avoid hindsight bias about things like neurons and computers.
Only then will you be able to see the uncrossable explanatory gap:


 How can you explain angry behavior in terms of billiard balls?


 Well, the \textit{obvious} materialist conjecture is that the
little billiard balls push on your arm and make you hit someone, or
push on your tongue so that insults come out.


 But how do the little billiard balls know how to do this---or how
to guide your tongue and fingers through long-term plots---if they
aren't angry themselves?


 And besides, if you're not seduced
by---gasp!---scientism, you can see from a first-person perspective
that this explanation is obviously false. Atoms can push on your arm,
but they can't make you \textit{want} anything.


 Someone may point out that drinking wine can make you angry. But
who says that wine is made exclusively of little billiard balls? Maybe
wine just contains a potency of angerness.


 Clearly, reductionism is just a flawed notion.


 (The novice goes astray and says ``The art failed
me''; the master goes astray and says
``I failed my art.'')


 What does it take to cross this gap? It's not just
the idea of ``neurons'' that
``process information''---if you say
only this and nothing more, it just inserts a magical, unexplained
level-crossing rule into your model, where you go from billiards to
thoughts.


 But an Artificial Intelligence programmer who knows how to create
a chess-playing program out of base matter has taken a \textit{genuine}
step toward crossing the gap. If you understand concepts like
consequentialism, backward chaining, utility functions, and search
trees, you can make merely causal/mechanical systems compute plans.


 The trick goes something like this: For each possible chess move,
compute the moves your opponent could make, then your responses to
those moves, and so on; evaluate the furthest position you can see
using some local algorithm (you might simply count up the material);
then trace back using minimax\footnote{\url{https://en.wikipedia.org/wiki/Minimax}} to find the best move on the current
board; then make that move.


 More generally: If you have chains of causality inside the mind
that have a kind of mapping---a mirror, an echo---to what goes on in
the environment, then you can run a utility function over the end
products of imagination, and find an action that achieves something
that the utility function rates highly, and output that action. It is
not necessary for the chains of causality inside the mind, that are
similar to the environment, to be made out of billiard balls that have
little auras of intentionality. Deep Blue's transistors
do not need little chess pieces carved on them, in order to work. See
also page \pageref{the_simple_truth}, The Simple Truth.


 All this is still tremendously oversimplified, but it should, at
least, reduce the apparent length of the gap. If you can understand all
that, you can see how a planner built out of base matter can be
influenced by alcohol to output more angry behaviors. The billiard
balls in the alcohol push on the billiard balls making up the utility
function.


 But even if you know how to write small AIs, you
can't \textit{visualize} the level-crossing between
transistors and chess. There are too many transistors, and too many
moves to check.


 Likewise, even if you knew all the facts of neurology, you would
not be able to \textit{visualize} the level-crossing between neurons
and anger---let alone the level-crossing between atoms and anger. Not
the way you can visualize a hand consisting of fingers, thumb, and
palm.


 And suppose a cognitive scientist just flatly tells you
``Anger is hormones''? Even if you
repeat back the words, it doesn't mean
you've crossed the gap. You may believe you believe it,
but that's not the same as understanding what little
billiard balls have to do with wanting to hit someone.


 So you come up with interpretations like, ``Anger
is \textit{mere} hormones, it's caused by little
molecules, so it must not be justified in any moral
sense---\textit{that's} why you should learn to control
your anger.''


 Or, ``There isn't really any such
thing as anger---it's an illusion, a quotation with no
referent, like a mirage of water in the desert, or looking in the
garage for a dragon and not finding one.''


 These are both tough pills to swallow (not that you
\textit{should} swallow them) and so it is a good deal easier to
profess them than to believe them.


 I think this is what non-reductionists/non-materialists think they
are criticizing when they criticize reductive materialism.


 But materialism isn't that easy.
It's not as cheap as saying, ``Anger
is made out of atoms---there, now I'm
done.'' That wouldn't explain how to
get from billiard balls to hitting. You need the specific insights of
computation, consequentialism, and search trees before you can start to
close the explanatory gap.


 All this was a relatively easy example \textit{by modern
standards}, because I restricted myself to talking about angry
\textit{behaviors.} Talking about outputs doesn't
require you to appreciate how an algorithm feels from inside (cross a
first-person/third-person gap) or dissolve a wrong question (untangle
places where the interior of your own mind runs skew to reality).


 Going from material substances that bend and break, burn and fall,
push and shove, to angry \textit{behavior}, is just a practice problem
by the standards of modern philosophy. But it is an \textit{important}
practice problem. It can only be fully appreciated, if you realize how
\textit{hard} it would have been to solve before writing was invented.
There was once an explanatory gap here---though it may not seem that
way in hindsight, now that it's been bridged for
generations.


 Explanatory gaps can be crossed, if you accept help from science,
and don't trust the view from the interior of your own
mind.

\myendsectiontext

\mysection{Heat vs.\ Motion}


 After the last essay, it occurred to me that
there's a much simpler example of reductionism jumping
a gap of apparent-difference-in-kind: the reduction of heat to motion.



 Today, the equivalence of heat and motion may seem too obvious in
hindsight---everyone says that ``heat is
motion,'' therefore, it can't be a
``weird'' belief.


 But there was a time when the kinetic theory of heat was a highly
controversial scientific hypothesis, contrasting to belief in a caloric
fluid that flowed from hot objects to cold objects. Still earlier, the
main theory of heat was
``Phlogiston!''


 Suppose you'd \textit{separately} studied kinetic
theory and caloric theory. You now know something about kinetics:
collisions, elastic rebounds, momentum, kinetic energy, gravity,
inertia, free trajectories. Separately, you know something about heat:
temperatures, pressures, combustion, heat flows, engines, melting,
vaporization.


 Not only is this state of knowledge a plausible one, it is the
state of knowledge possessed by e.g.~Sadi Carnot, who, working strictly
from within the caloric theory of heat, developed the principle of the
Carnot cycle---a heat engine of maximum efficiency, whose existence
implies the Second Law of Thermodynamics. This in 1824, when kinetics
was a highly developed science.


 Suppose, like Carnot, you know a great deal about kinetics, and a
great deal about heat, as \textit{separate} entities. Separate entities
\textit{of knowledge}, that is: your brain has separate filing baskets
for beliefs about kinetics and beliefs about heat. But from the inside,
this state of knowledge \textit{feels} like living in a world of moving
things and hot things, a world where motion and heat are independent
properties of matter.


 Now a Physicist From The Future comes along and tells you:
``Where there is heat, there is motion, and vice
versa. That's why, for example, rubbing things together
makes them hotter.''


 There are (at least) two possible interpretations you could attach
to this statement, ``Where there is heat, there is
motion, and vice versa.''


 First, you could suppose that heat and motion exist
separately---that the caloric theory is correct---but that among our
universe's physical laws is a
``bridging law'' which states that,
where objects are moving quickly, caloric will come into existence. And
conversely, another bridging law says that caloric can exert pressure
on things and make them move, which is why a hotter gas exerts more
pressure on its enclosure (thus a steam engine can use steam to drive a
piston).


 Second, you could suppose that heat and motion are, in some
as-yet-mysterious sense, \textit{the same thing}.


 ``Nonsense,'' says Thinker 1,
``the words `heat' and
`motion' have two different meanings;
that is why we have two different words. We know how to determine when
we will call an observed phenomenon
`heat'---heat can melt things, or make
them burst into flame. We know how to determine when we will say that
an object is `moving quickly'---it
changes position; and when it crashes, it may deform, or shatter. Heat
is concerned with change of substance; motion, with change of position
and shape. To say that these two words have the same meaning is simply
to confuse yourself.''


 ``Impossible,'' says Thinker 2.
``It may be that, in our world, heat and motion are
associated by bridging laws, so that it is a law of physics that motion
creates caloric, and vice versa. But I can easily imagine a world where
rubbing things together does \textit{not} make them hotter, and gases
\textit{don't} exert more pressure at higher
temperatures. Since there are possible worlds where heat and motion are
not associated, they must be different properties---this is true a
priori.''


 Thinker 1 is confusing the quotation and the referent: 2 + 2 = 4,
but ``2 + 2'' ${\neq}$
``4.'' The string
``2 + 2'' contains five characters
(including whitespace) and the string
``4'' contains only one character.
If you type the two strings into a Python interpreter, they yield the
same output, \verb'>>> 4'. So you
can't conclude, from looking at the strings
``2 + 2'' and
``4,'' that just because the strings
are different, they must have different
``meanings'' relative to the Python
Interpreter.


 The words ``heat'' and
``kinetic energy'' can be said to
``refer to'' the same thing, even
before we \textit{know} how heat reduces to motion, in the sense that
we don't know yet what the referent is, but the
referents are in fact the same. You might imagine an Idealized
Omniscient Science Interpreter that would give the same output when we
typed in ``heat'' and
``kinetic energy'' on the command
line.


 I talk about the Science Interpreter to emphasize that, to
dereference the pointer, you've got to step outside
cognition. The end result of the dereference is something out there in
reality, not in anyone's mind. So you can \textit{say}
``real referent'' or
``actual referent,'' but you
can't \textit{evaluate} the words locally, from the
inside of your own head. You can't reason using the
actual heat-referent---if you thought using \textit{real heat},
thinking ``one million Kelvin''
would vaporize your brain. But, by forming a belief about your belief
about heat, you can talk \textit{about} your belief about heat, and say
things like ``It's possible that my
belief about heat doesn't much resemble \textit{real}
heat.'' You can't actually perform
that comparison right there in your own mind, but you can talk
\textit{about} it.


 Hence you can say, ``My beliefs about heat and
motion are not the same beliefs, but it's possible that
actual heat and actual motion are the same thing.''
It's just like being able to acknowledge that
``the morning star'' and
``the evening star'' might be the
same planet, while also understanding that you can't
determine this just by examining your beliefs---you've
got to haul out the telescope.


 Thinker 2's mistake follows similarly. A physicist
told them, ``Where there is heat, there is
motion'' and Thinker 2 mistook this for a statement
of \textit{physical law}: The presence of caloric \textit{causes} the
existence of motion. What the physicist really means is more akin to an
\textit{inferential rule}: Where you are told there is
``heat,'' deduce the presence of
``motion.''


 From this basic projection of a multilevel model into a multilevel
reality follows another, distinct error: the conflation of conceptual
possibility with logical possibility. To Sadi Carnot, it is
\textit{conceivable} that there could be another world where heat and
motion are not associated. To Richard Feynman, armed with specific
knowledge of how to derive equations about heat from equations about
motion, this idea is not only inconceivable, but so wildly inconsistent
as to make one's head explode.

{
 I should note, in fairness to philosophers, that there are
philosophers who have said these things. For example, Hilary Putnam,
writing on the ``Twin Earth''
thought experiment:\footnote{Hilary Putnam, ``The Meaning of
Meaning,'' in \textit{The Twin Earth Chronicles}, ed.
Andrew Pessin and Sanford Goldberg (M. E. Sharpe, Inc., 1996), 3--52.\comment{1}}}

\begin{quotation}
{
 Once we have discovered that water (in the actual world) is
H\textsubscript{2}O, \textit{nothing counts as a possible world in
which water isn't
H\textsubscript{2}O}. In particular, if a
``logically possible'' statement is
one that holds in some ``logically possible
world,'' \textit{it isn't logically
possible that water isn't
H\textsubscript{2}O.}}

{
 On the other hand, we can perfectly well imagine having
experiences that would convince us (and that would make it rational to
believe that) water \textit{isn't} H\textsubscript{2}O.
In that sense, it is conceivable that water isn't
H\textsubscript{2}O. It is conceivable but it isn't
logically possible! Conceivability is no proof of logical possibility.}
\end{quotation}


 It appears to me that ``water''
is being used in two different senses in these two paragraphs---one in
which the word ``water''
\textit{refers} to what we type into the Science Interpreter, and one
in which ``water'' \textit{refers}
to what we get out of the Science Interpreter when we type
``water'' into it. In the first
paragraph, Hilary seems to be saying that after we do some experiments
and find out that water is H\textsubscript{2}O, water becomes
automatically redefined to \textit{mean} H\textsubscript{2}O. But you
could coherently hold a different position about whether the word
``water'' now \textit{means}
``H\textsubscript{2}O'' or
``whatever is \textit{really} in that bottle next to
me,'' so long as you use your terms consistently.


 I believe the above has already been said as well? Anyway\,\ldots


 It is quite possible for there to be only \textit{one} thing
out-there-in-the-world, but for it to take on sufficiently different
forms, and for you yourself to be sufficiently ignorant of the
reduction, that it feels like living in a world containing two entirely
different things. Knowledge concerning these two different phenomena
may be taught in two different classes, and studied by two different
academic fields, located in two different buildings of your
university.


 You've got to put yourself quite a ways back, into
a historically realistic frame of mind, to remember how
\textit{different} heat and motion once seemed. Though, depending on
how much you know today, it may not be as hard as all that, if you can
look past the pressure of conventionality (that is,
``heat is motion'' is an un-weird
belief, ``heat is not motion'' is a
weird belief). I mean, suppose that tomorrow the physicists stepped
forward and said, ``Our popularizations of science
have always contained one lie. Actually, heat has nothing to do with
motion.'' Could you \textit{prove} they were wrong?


 Saying ``Maybe heat and motion are the same
thing!'' is easy. The difficult part is explaining
\textit{how}. It takes a great deal of detailed knowledge to get
yourself to the point where you can no longer \textit{conceive} of a
world in which the two phenomena go separate ways. Reduction
isn't cheap, and that's why it buys so
much.


 Or maybe you could say: ``Reductionism is easy,
reduction is hard.'' But it does kinda help to be a
reductionist, I think, when it comes time to go looking for a
reduction.

\myendsectiontext


\bigskip

\mysection{Brain Breakthrough! It's Made of Neurons!}
\label{brain_breakthrough}


 In an amazing breakthrough, a multinational team of scientists led
by Nobel laureate Santiago Ramón y Cajal announced that the brain is
composed of a \textit{ridiculously} complicated network of tiny cells
connected to each other by infinitesimal threads and branches. 


 The multinational team---which also includes the famous technician
Antonie van Leeuwenhoek, and possibly Imhotep, promoted to the Egyptian
god of medicine---issued this statement:


 ``The present discovery culminates years of
research indicating that the convoluted squishy thing inside our skulls
is even more complicated than it looks. Thanks to
Cajal's application of a new staining technique
invented by Camillo Golgi, we have learned that this structure is not a
continuous network like the blood vessels of the body, but is actually
composed of many tiny cells, or
`neurons,' connected to one another by
even more tiny filaments.


 ``Other extensive evidence, beginning from Greek
medical researcher Alcmaeon and continuing through Paul
Broca's research on speech deficits, indicates that the
brain is the seat of reason.


 ``Nemesius, the Bishop of Emesia, has previously
argued that brain tissue is too earthy to act as an intermediary
between the body and soul, and so the mental faculties are located in
the ventricles of the brain. However, if this is correct, there is no
reason why this organ should turn out to have an immensely complicated
internal composition.


 ``Charles Babbage has independently suggested
that many small mechanical devices could be collected into an
`Analytical Engine,' capable of
performing activities, such as arithmetic, which are widely believed to
require thought. The work of Luigi Galvani and Hermann von Helmholtz
suggests that the activities of neurons are electrochemical in nature,
rather than mechanical pressures as previously believed. Nonetheless,
we think an analogy with Babbage's
`Analytical Engine' suggests that a
vastly complicated network of neurons could similarly exhibit
thoughtful properties.


 ``We have found an enormously complicated
material system located where the mind should be. The implications are
shocking, and must be squarely faced. We believe that the present
research offers strong experimental evidence that Benedictus Spinoza
was correct, and René Descartes wrong: Mind and body are of one
substance.


 ``In combination with the work of Charles Darwin
showing how such a complicated organ could, in principle, have arisen
as the result of processes not themselves intelligent, the bulk of
scientific evidence now seems to indicate that intelligence is
ontologically non-fundamental and has an extended origin in time. This
strongly weighs against theories which assign mental entities an
ontologically fundamental or causally primal status, including all
religions ever invented.


 ``Much work remains to be done on discovering the
specific identities between electrochemical interactions between
neurons, and thoughts. Nonetheless, we believe our discovery offers the
promise, though not yet the realization, of a full scientific account
of thought. The problem may now be declared, if not solved, then
solvable.''


 We regret that Cajal and most of the other researchers involved on
the Project are no longer available for comment.

\myendsectiontext

\mysection{When Anthropomorphism Became Stupid}


 It turns out that most things in the universe
don't have minds. 


 This statement would have provoked incredulity among many earlier
cultures. ``Animism'' is the usual
term. They thought that trees, rocks, streams, and hills all had
spirits because, hey, why not?


 I mean, those lumps of flesh known as
``humans'' contain thoughts, so why
shouldn't the lumps of wood known as
``trees''?


 My muscles move at my will, and water flows through a river.
Who's to say that the river doesn't
have a will to move the water? The river overflows its banks, and
floods my tribe's gathering-place---why not think that
the river was angry, since it moved its parts to hurt us?
It's what we would think when someone's
fist hit our nose.


 There is no obvious reason---no reason obvious \textit{to a
hunter-gatherer}{}---why this cannot be so. It only seems like a
\textit{stupid} mistake if you confuse weirdness with stupidity.
Naturally the belief that rivers have animating spirits seems
``weird'' to us, since it is not a
belief of our tribe. But there is nothing obviously stupid about
thinking that great lumps of moving water have spirits, just like our
own lumps of moving flesh.


 If the idea were \textit{obviously} stupid, no one would have
believed it. Just like, for the longest time, nobody believed in the
obviously stupid idea that the Earth moves while seeming motionless.


 Is it obvious that trees can't think? Trees, let
us not forget, \textit{are in fact} our distant cousins. Go far enough
back, and you have a common ancestor with your fern. If lumps of flesh
can think, why not lumps of wood?


 For it to be \textit{obvious} that wood doesn't
think, you have to belong to a culture with microscopes. Not just
\textit{any} microscopes, but really \textit{good} microscopes.


 Aristotle thought the brain was an organ for cooling the blood.
(It's a good thing that what we believe about our
brains has very little effect on their actual operation.)


 Egyptians threw the brain away during the process of
mummification.


 Alcmaeon of Croton, a Pythagorean of the fifth century BCE, put
his finger on the brain as the seat of intelligence, because
he'd traced the optic nerve from the eye to the brain.
Still, with the amount of evidence he had, it was only a guess.


 When did the central role of the brain stop being a guess? I do
not know enough history to answer this question, and probably there
wasn't any sharp dividing line. Maybe we could put it
at the point where someone traced the anatomy of the nerves, and
discovered that severing a nervous connection \textit{to the brain}
blocked movement and sensation?


 Even so, that is only a mysterious spirit moving through the
nerves. Who's to say that wood and water, even if they
lack the little threads found in human anatomy, might not carry the
same mysterious spirit by different means?


 I've spent some time online trying to track down
the exact moment when someone noticed the vastly tangled internal
structure of the brain's neurons, and said,
``Hey, I bet all this giant tangle is doing complex
information-processing!'' I haven't
had much luck. (It's not Camillo Golgi---the
tangledness of the circuitry was known before Golgi.) Maybe there was
never a watershed moment there, either.


 But the discovery of that tangledness, and Charles
Darwin's theory of natural selection, and the notion of
cognition as computation, is where I would put the gradual beginning of
anthropomorphism's descent into being
\textit{obviously} wrong.


 It's the point where you can look at a tree, and
say: ``I don't see anything in the
tree's biology that's doing complex
information-processing. Nor do I see it in the behavior, and if
it's hidden in a way that doesn't
affect the tree's behavior, how would a selection
pressure for such complex information-processing
arise?''


 It's the point where you can look at a river, and
say, ``Water doesn't contain patterns
replicating with distant heredity and substantial variation subject to
iterative selection, so how would a river come to have any pattern so
complex and functionally optimized as a brain?''


 It's the point where you can look at an atom, and
say: ``Anger may look simple, but it's
not, and there's no room for it to fit in something as
simple as an atom---not unless there are whole universes of
subparticles inside quarks; and even then, since we've
never seen any sign of atomic anger, it wouldn't have
any effect on the high-level phenomena we know.''


 It's the point where you can look at a puppy, and
say: ``The puppy's parents may push it
to the ground when it does something wrong, but that
doesn't mean the puppy is doing moral reasoning. Our
current theories of evolutionary psychology holds that moral reasoning
arose as a response to more complex social challenges than that---in
their full-fledged human form, our moral adaptations are the result of
selection pressures over linguistic arguments about tribal
politics.''


 It's the point where you can look at a rock, and
say, ``This lacks even the simple search trees
embodied in a chess-playing program---where would it get the
\textit{intentions} to \textit{want} to roll downhill, as Aristotle
once thought?''


 It is written:\footnote{Zhuangzi, chapter 17}

{
 \textit{Zhuangzi and Huizi were strolling along the dam of the Hao
Waterfall when Zhuangzi said, ``See how the minnows
come out and dart around where they please! That's what
fish really enjoy!''}}

{
 \textit{Huizi said, ``You're not
a fish---how do you know what fish enjoy?''}}

{
 \textit{Zhuangzi said, ``You're
not I, so how do you know I don't know what fish
enjoy?''}}


 Now we know.

\myendsectiontext

\mysection{A Priori}


 Traditional Rationality is phrased as social rules, with
violations interpretable as cheating: if you break the rules and no one
else is doing so, you're the first to defect---making
you a bad, bad person. To Bayesians, the brain is an engine of
accuracy: if you violate the laws of rationality, the engine
doesn't run, and this is equally true whether anyone
else breaks the rules or not. 


 Consider the problem of Occam's Razor, as
confronted by Traditional philosophers. If two hypotheses fit the same
observations equally well, why believe the simpler one is more likely
to be true? You could argue that Occam's Razor has
worked in the past, and is therefore likely to continue to work in the
future. But this, itself, appeals to a prediction from
Occam's Razor.
``Occam's Razor works up to October
8th, 2027 and then stops working thereafter'' is more
complex, but it fits the observed evidence equally well.


 You could argue that Occam's Razor is a reasonable
distribution on prior probabilities. But what is a
``reasonable'' distribution? Why not
label ``reasonable'' a very
complicated prior distribution, which makes Occam's
Razor work in all observed tests so far, but generates exceptions in
future cases?


 Indeed, it seems there is no way to \textit{justify}
Occam's Razor except by \textit{appealing} to
Occam's Razor, making this \textit{argument} unlikely
to \textit{convince} any \textit{judge} who does not already
\textit{accept} Occam's Razor. (What's
special about the words I italicized?)


 If you are a philosopher whose daily work is to write papers,
criticize other people's papers, and respond to
others' criticisms of your own papers, then you may
look at Occam's Razor and shrug. Here is an end to
justifying, arguing and convincing. You decide to call a truce on
writing papers; if your fellow philosophers do not demand justification
for your un-arguable beliefs, you will not demand justification for
theirs. And as the symbol of your treaty, your white flag, you use the
phrase ``a priori truth.''


 But to a Bayesian, in this era of cognitive science and
evolutionary biology and Artificial Intelligence, saying
``a priori'' doesn't
explain why the brain-engine runs. If the brain has an amazing
``a priori truth factory'' that
\textit{works} to produce accurate beliefs, it makes you wonder why a
thirsty hunter-gatherer can't use the
``a priori truth factory'' to locate
drinkable water. It makes you wonder why eyes evolved in the first
place, if there are ways to produce accurate beliefs without looking at
things.


 James R. Newman\footnote{James Roy Newman, \textit{The World of Mathematics}, Vol 3, pg 1614} said: ``The fact that one apple
added to one apple invariably gives two apples helps in the teaching of
arithmetic, but has no bearing on the truth of the proposition that 1 +
1 = 2.'' The \textit{Internet Encyclopedia of
Philosophy} defines ``a priori''
propositions as those knowable independently of experience. Wikipedia
quotes\footnote{\url{http://en.wikipedia.org/wiki/A_priori_and_a_posteriori_\%28philosophy\%29}} Hume: Relations of ideas are ``discoverable by
the mere operation of thought, without dependence on what is anywhere
existent in the universe.'' You can see that 1 + 1 =
2 \textit{just by thinking about it}, without looking at apples.


 But in this era of neurology, one ought to be aware that
\textit{thoughts} are existent in the universe; they are identical to
the operation of brains. Material brains, real in the universe,
composed of quarks in a single unified mathematical physics whose laws
draw no border between the inside and outside of your skull.


 When you add 1 + 1 and get 2 by thinking, these thoughts are
themselves embodied in flashes of neural patterns. In principle, we
could \textit{observe}, experientially, the exact same material events
as they occurred within someone else's brain. It would
require some advances in computational neurobiology and brain-computer
interfacing, but in principle, it could be done. You could see someone
else's engine operating materially, through material
chains of cause and effect, to compute by ``pure
thought'' that 1 + 1 = 2. How is observing this
pattern in \textit{someone else's} brain any different,
as a way of knowing, from observing your own brain doing the same
thing? When ``pure thought'' tells
you that 1 + 1 = 2, ``independently of any experience
or observation,'' you are, in effect, observing your
own brain as evidence.


 If this seems counterintuitive, try to see minds/brains as
engines---an engine that collides the neural pattern for 1 and the
neural pattern for 1 and gets the neural pattern for 2. If this engine
works at all, then it should \textit{have the same output} if it
observes (with eyes and retina) a similar brain-engine carrying out a
similar collision, and copies into itself the resulting pattern. In
other words, for every form of a priori knowledge obtained by
``pure thought,'' you are learning
exactly the same thing you would learn if you saw an outside
brain-engine carrying out the same pure flashes of neural activation.
The engines are equivalent, the bottom-line outputs are equivalent, the
belief-entanglements are the same.


 There is nothing you can know ``a
priori,'' which you could not know with equal
validity by observing the chemical release of neurotransmitters within
some outside brain. What do you think you \textit{are}, dear reader?


 This is \textit{why} you can predict the result of adding 1 apple
and 1 apple by imagining it first in your mind, or punch
``3 {\texttimes} 4'' into a
calculator to predict the result of imagining 4 rows with 3 apples per
row. You and the apple exist within a boundary-less unified physical
process, and one part may echo another.


 Are the sort of neural flashes that philosophers label
``a priori beliefs''
\textit{arbitrary}? Many AI algorithms function better with
``regularization'' that biases the
solution space toward simpler solutions. But the regularized algorithms
are themselves more complex; they contain an extra line of code (or
1,000 extra lines) compared to unregularized algorithms. The human
brain is biased toward simplicity, and we think more efficiently
thereby. If you press the Ignore button at this point,
you're left with a complex brain that exists for no
reason and works for no reason. So don't try to tell me
that ``a priori'' beliefs are
arbitrary, because they sure aren't generated by
rolling random numbers. (What does the adjective
``arbitrary'' \textit{mean},
anyway?)


 You can't excuse calling a proposition
``a priori'' by pointing out that
\textit{other} philosophers are having trouble justifying
\textit{their} propositions. If a philosopher fails to explain
something, this fact cannot supply electricity to a refrigerator, nor
act as a magical factory for accurate beliefs. There's
no truce, no white flag, until you understand why the engine works.


 If you clear your mind of \textit{justification}, of
\textit{argument}, then it seems obvious why Occam's
Razor works in practice: we live in a simple world, a low-entropy
universe in which there are short explanations to be found.
``But,'' you cry,
``why is the universe itself
orderly?'' This I do not know, but it is what I see
as the next mystery to be explained. This is not the same question as
``How do I argue Occam's Razor to a
hypothetical debater who has not already accepted
it?''


 Perhaps you cannot argue \textit{anything} to a hypothetical
debater who has not accepted Occam's Razor, just as you
cannot argue anything to a rock. A mind needs a certain amount of
dynamic structure to be an argument-acceptor. If a mind
doesn't implement Modus Ponens, it can accept
``$A$'' and ``$A \rightarrow B$'' all day long without ever
producing ``$B$.'' How do you justify
Modus Ponens to a mind that hasn't accepted it? How do
you argue a rock into becoming a mind?


 Brains evolved from non-brainy matter by natural selection; they
were not justified into existence by arguing with an ideal philosophy
student of perfect emptiness. This does not make our judgments
meaningless. A brain-engine can work correctly, producing accurate
beliefs, even if it was merely \textit{built}{}---by human hands or
cumulative stochastic selection pressures---rather than argued into
existence. But to be satisfied by this answer, one must see rationality
in terms of engines, rather than arguments.

\myendsectiontext

\mysection{Reductive Reference}


 The reductionist thesis (as I formulate it) is that human minds,
for reasons of efficiency, use a multi-level map in which we separately
\textit{think} about things like
``atoms'' and
``quarks,''
``hands'' and
``fingers,'' or
``heat'' and
``kinetic energy.'' Reality itself,
on the other hand, is single-level in the sense that it does not seem
to contain atoms as \textit{separate, additional, causally efficacious}
entities \textit{over and above} quarks. 


 Sadi Carnot formulated the (precursor to) the Second Law of
Thermodynamics using the caloric theory of heat, in which heat was just
a fluid that flowed from hot things to cold things, produced by fire,
making gases expand---the effects of heat were studied separately from
the science of kinetics, considerably before the reduction took place.
If you're trying to design a steam engine, the effects
of all those tiny vibrations and collisions which we name
``heat'' can be summarized into a
much simpler description than the full quantum mechanics of the quarks.
Humans compute efficiently, thinking of only significant effects on
goal-relevant quantities.


 But reality itself does seem to use the full quantum mechanics of
the quarks. I once met a fellow who thought that if you used General
Relativity to compute a low-velocity problem, like an artillery shell,
General Relativity would give you the \textit{wrong answer}{}---not
just a slow answer, but an \textit{experimentally wrong}
answer---because at low velocities, artillery shells are governed by
Newtonian mechanics, not General Relativity. This is exactly how
physics does \textit{not} work. Reality just seems to go on crunching
through General Relativity, even when it only makes a difference at the
fourteenth decimal place, which a human would regard as a huge waste of
computing power. Physics does it with brute force. No one has
\textit{ever} caught physics simplifying its calculations---or if
someone did catch it, the Matrix Lords erased the memory afterward.


 Our map, then, is very much unlike the territory; our maps are
multi-level, the territory is single-level. Since the representation is
so incredibly unlike the referent, in what sense can a belief like
``I am wearing socks'' be called
\textit{true}, when in reality itself, there are only quarks?


 In case you've forgotten what the word
``true'' means, the classic
definition was given by Alfred Tarski:

\begin{quote}
{
 The statement ``snow is white''
 is \textit{true} if and only if snow is white.}
\end{quote}


 In case you've forgotten what the difference is
between the statement ``I believe `snow
is white'\,'' and
``\,`Snow is white' is
true,'' see page \pageref{qualitatively_confused}, Qualitatively Confused. Truth
can't be evaluated \textit{just} by looking inside your
own head---if you want to know, for example, whether
``the morning star = the evening
star,'' you need a telescope; it's
not enough just to look at the beliefs themselves.


 This is the point missed by the postmodernist folks screaming,
``But how do you \textit{know} your beliefs are
true?'' When you do an experiment, you actually
\textit{are} going outside your own head. You're
engaging in a complex interaction whose outcome is causally determined
by the thing you're reasoning about, not just your
beliefs about it. I once defined
``reality'' as follows:\footnote{See page \pageref{reality_defined}}

\begin{quote}
{
 Even when I have a simple hypothesis, strongly supported by all
the evidence I know, sometimes I'm still surprised. So
I need different names for the thingies that determine my predictions
and the thingy that determines my experimental results. I call the
former thingies ``belief,'' and the
latter thingy ``reality.''}
\end{quote}


 The interpretation of your experiment still depends on your prior
beliefs. I'm not going to talk, for the moment, about
Where Priors Come From, because that is not the subject of this essay.
My point is that truth refers to an \textit{ideal} comparison between a
belief and reality. Because we understand that planets are distinct
from beliefs about planets, we can design an experiment to test whether
the belief ``the morning star and the evening star are
the same planet'' is \textit{true.} This experiment
will involve telescopes, not just introspection, because we understand
that ``truth'' involves comparing an
internal belief to an external fact; so we use an instrument, the
telescope, whose perceived behavior we believe to depend on the
external fact of the planet.


 Believing that the telescope helps us evaluate the
``truth'' of
``morning star = evening star''
relies on our prior beliefs about the telescope interacting with the
planet. Again, I'm not going to address that in this
particular essay, except to quote one of my favorite Raymond Smullyan
lines: ``If the more sophisticated reader objects to
this statement on the grounds of its being a mere tautology, then
please at least give the statement credit for not being
inconsistent.'' Similarly, I don't
see the use of a telescope as circular logic, but as reflective
coherence; for every systematic way of arriving at truth, there ought
to be a rational explanation for how it works.


 The question on the table is what it \textit{means} for
``snow is white'' to be
\textit{true}, when, in reality, there are just quarks.


 There's a certain pattern of neural connections
making up your beliefs about
``snow'' and
``whiteness''---we believe this, but
we do not know, and cannot concretely visualize, the actual neural
connections. Which are, themselves, embodied in a pattern of quarks
even less known. Out there in the world, there are water molecules
whose temperature is low enough that they have arranged themselves in
tiled repeating patterns; they look nothing like the tangles of
neurons. In what sense, comparing one (ever-fluctuating) pattern of
quarks to the other, is the belief ``snow is
white'' \textit{true}?


 Obviously, neither I nor anyone else can offer an Ideal Quark
Comparer Function that accepts a quark-level description of a neurally
embodied belief (including the surrounding brain) and a quark-level
description of a snowflake (and the surrounding laws of optics), and
outputs ``true'' or
``false'' over
``snow is white.'' And who says the
fundamental level is \textit{really} about particle fields?


 On the other hand, throwing out all beliefs because they
aren't written as gigantic unmanageable specifications
about quarks we can't even see\,\ldots
doesn't seem like a very prudent idea. Not the best way
to optimize our goals.


 It seems to me that a word like
``snow'' or
``white'' can be taken as a kind of
promissory note---not a \textit{known} specification of exactly which
physical quark configurations count as
``snow,'' but, nonetheless, there
are things you call snow and things you don't call
snow, and even if you got a few items wrong (like plastic snow), an
Ideal Omniscient Science Interpreter would see a tight cluster in the
center and redraw the boundary to have a simpler definition.


 In a single-layer universe whose bottom layer is unknown, or
uncertain, or just too large to talk about, the concepts in a
multi-layer mind can be said to represent a kind of promissory
note---we don't know \textit{what} they correspond to,
out there. But it seems to us that we can distinguish positive from
negative cases, in a predictively productive way, so we think---perhaps
in a fully general sense---that there is \textit{some} difference of
quarks, \textit{some} difference of configurations at the fundamental
level, that explains the differences that feed into our senses, and
ultimately result in our saying
``snow'' or ``not
snow.''


 I see this white stuff, and it is the same on several occasions,
so I hypothesize a stable latent cause in the environment---I give it
the name ``snow'';
``snow'' is then a promissory note
referring to a believed-in simple boundary that could be drawn around
the unseen causes of my experience.


 Hilary Putnam's ``Twin
Earth'' thought experiment (where water is not
H\textsubscript{2}O but some strange other substance denoted XYZ,
otherwise behaving much like water), and the subsequent philosophical
debate, helps to highlight this issue.
``Snow'' doesn't
have a logical definition known to us---it's more like
an empirically determined pointer to a logical definition. This is true
even if you believe that snow is ice crystals is low-temperature tiled
water molecules. The water molecules are made of quarks. What if quarks
turn out to be made of something else? What \textit{is} a snowflake,
then? You don't know---but it's still a
snowflake, not a fire hydrant.


 And of course, these very paragraphs I have just written are
likewise far above the level of quarks. ``Sensing
white stuff, visually categorizing it, and thinking
`snow' or `not
snow'\,''---this is also talking very
far above the quarks. So my meta-beliefs are also promissory notes, for
things that an Ideal Omniscient Science Interpreter might know about
which configurations of the quarks (or whatever) making up my brain
correspond to ``believing `snow is
white.'\,''


 But then, the entire grasp that we have upon reality is made up of
promissory notes of this kind. So, rather than calling it circular, I
prefer to call it self-consistent.


 This can be a bit unnerving---maintaining a precarious epistemic
perch, in both object-level beliefs and reflection, far above a huge
unknown underlying fundamental reality, and hoping one
doesn't fall off.


 On reflection, though, it's hard to see how things
could be any other way.


 So at the end of the day, the statement ``reality
does not contain hands as fundamental, additional, separate causal
entities, over and above quarks'' is not the same
statement as ``hands do not exist''
or ``I don't have any
hands.'' There are no \textit{fundamental} hands;
hands are made of fingers, palm, and thumb, which in turn are made of
muscle and bone, all the way down to elementary particle fields, which
are the fundamental causal entities, so far as we currently know.


 This is not the same as saying, ``there are no
`hands.'\,'' It is not
the same as saying, ``the word
`hands' is a promissory note that will
never be paid, because there is no empirical cluster that corresponds
to it''; or ``the
`hands' note will never be paid, because
it is logically impossible to reconcile its supposed
characteristics''; or ``the
statement `humans have hands' refers to
a sensible state of affairs, but reality is not in that
state.''


 Just: There are patterns that exist \textit{in} reality where we
see ``hands,'' and these patterns
have something in common, but they are not fundamental.


 If I \textit{really} had no hands---if reality suddenly
transitioned to be in a state that we would describe as
``Eliezer has no hands''---reality
would shortly thereafter correspond to a state we would describe as
``Eliezer screams as blood jets out of his wrist
stumps.''


 And this is \textit{true}, even though the above paragraph
hasn't specified any quark positions.


 The previous sentence is likewise meta-true.


 The map is multilevel, the territory is single-level. This
doesn't mean that the higher levels
``don't exist,''
like looking in your garage for a dragon and finding nothing there, or
like seeing a mirage in the desert and forming an expectation of
drinkable water when there is nothing to drink. The higher levels of
your map are not \textit{false}, without referent; they have referents
\textit{in} the single level of physics. It's not that
the wings of an airplane unexist---then the airplane would drop out of
the sky. The ``wings of an
airplane'' exist \textit{explicitly} in an
engineer's multilevel model of an airplane, and the
wings of an airplane exist \textit{implicitly} in the quantum physics
of the real airplane. Implicit existence is not the same as
nonexistence. The exact description of this implicitness is not known
to us---is not explicitly represented in our map. But this does not
prevent our map from working, or even prevent it from being
\textit{true.}


 Though it is a bit unnerving to contemplate that every single
concept and belief in your brain, including these meta-concepts about
how your brain works and why you can form accurate beliefs, are perched
orders and orders of magnitude above reality\,\ldots

\myendsectiontext

\mysection{Zombies! Zombies?}


 Your ``zombie,'' in the
philosophical usage of the term, is putatively a being that is exactly
like you in \textit{every} respect---identical behavior, identical
speech, identical brain; every atom and quark in \textit{exactly} the
same position, moving according to the same causal laws of
motion---\textit{except} that your zombie is not conscious.


 It is furthermore claimed that if zombies are
``possible'' (a term over which
battles are still being fought), then, purely from our knowledge of
this ``possibility,'' we can deduce
a priori that consciousness is extra-physical, in a sense to be
described below; the standard term for this position is
``epiphenomenalism.''


 (For those unfamiliar with zombies, I emphasize that \textit{this
is not a strawman}. See, for example, the \textit{Stanford Encyclopedia
of Philosophy} entry on Zombies.\footnote{\url{http://plato.stanford.edu/entries/zombies/}} The
``possibility'' of zombies is
accepted by a substantial fraction, possibly a majority, of academic
philosophers of consciousness.)


 I once read somewhere, ``You are not the one who
speaks your thoughts---you are the one who \textit{hears} your
thoughts.'' In Hebrew, the word for the highest soul,
that which God breathed into Adam, is
N'Shama---``the
hearer.''


 If you conceive of
``consciousness'' as a purely
passive listening, then the notion of a zombie initially seems easy to
imagine. It's someone who lacks the
N'Shama, the hearer.


 (Warning: \textit{Very} long 6,600-word essay involving David
Chalmers ahead. This may be taken as my demonstrative counterexample to
Richard Chappell's Arguing with Eliezer Part II,\footnote{\url{http://www.philosophyetc.net/2008/03/arguing-with-eliezer-part-ii.html}} in
which Richard accuses me of not engaging with the complex arguments of
real philosophers.)


 When you open a refrigerator and find that the orange juice is
gone, you think ``Darn, I'm out of
orange juice.'' The sound of these words is probably
represented in your auditory cortex, as though you'd
heard someone else say it. (Why do I think this? Because native Chinese
speakers can remember longer digit sequences than English-speakers.
Chinese digits are all single syllables, and so Chinese speakers can
remember around ten digits, versus the famous ``seven
plus or minus two'' for English speakers. There
appears to be a loop of repeating sounds back to yourself, a size limit
on working memory in the auditory cortex, which is genuinely
phoneme-based.)


 Let's suppose the above is correct; as a
postulate, it should certainly present no problem for advocates of
zombies. Even if humans are not like this, it seems easy enough to
imagine an AI constructed this way (and imaginability is what the
zombie argument is all about). It's not only
conceivable in principle, but quite possible in the next couple of
decades, that surgeons will lay a network of neural taps over
someone's auditory cortex and read out their internal
narrative. (Researchers have already tapped the lateral geniculate
nucleus of a cat and reconstructed recognizable visual inputs.)\footnote{Stanley GB, Li FF, Dan Y, ``Reconstruction of natural scenes from ensemble responses in the lateral geniculate nucleus'', \textit{J Neurosci}. 1999 Sep 15;19(18):8036-42.}


 So your zombie, being physically identical to you down to the last
atom, will open the refrigerator and form auditory cortical patterns
for the phonemes ``Darn, I'm out of
orange juice.'' On this point, epiphenomalists would
willingly agree.


 But, says the epiphenomenalist, in the zombie there is no one
inside to \textit{hear}; the inner listener is missing. The internal
narrative is spoken, but unheard. You are not the one who speaks your
thoughts. You are the one who hears them.


 It seems a lot more straightforward (they would say) to make an AI
that prints out some kind of internal narrative, than to show that an
inner listener hears it.


 The Zombie Argument is that if the Zombie World is
\textit{possible}{}---not necessarily physically possible in our
universe, just ``possible in
theory,'' or
``imaginable,'' or something along
those lines---then consciousness must be extra-physical, something over
and above mere atoms. Why? Because even if you somehow knew the
positions of all the atoms in the universe, you would still have be
told, as a separate and additional fact, that people were
conscious---that they had inner listeners---that we were not in the
Zombie World, as seems \textit{possible.}


 Zombie-ism is not the same as dualism. Descartes thought there was
a body-substance and a wholly different kind of mind-substance, but
Descartes also thought that the mind-substance was a \textit{causally
active} principle, interacting with the body-substance, controlling our
speech and behavior. Subtracting out the mind-substance from the human
would leave a \textit{traditional} zombie, of the lurching and groaning
sort.

{
 And though the Hebrew word for the innermost soul is
N'Shama, that-which-hears, I can't
recall hearing a rabbi arguing for the possibility of zombies. Most
rabbis would probably be aghast at the idea that the divine part which
God breathed into Adam \textit{doesn't actually do
anything.}}


 The technical term for the belief that consciousness is there, but
has no effect on the physical world, is \textit{epiphenomenalism.}


 Though there are other elements to the zombie argument
(I'll deal with them below), I think that the intuition
of the passive listener is what first seduces people to zombie-ism. In
particular, it's what seduces a lay audience to
zombie-ism. The core notion is simple and easy to access: The lights
are on but no one's home.


 Philosophers are appealing to the intuition of the passive
listener when they say ``Of course the zombie world is
imaginable; you know exactly what it would be
like.''


 One of the great battles in the Zombie Wars is over what, exactly,
is meant by saying that zombies are
``possible.'' Early zombie-ist
philosophers (in the 1970s) just thought it was obvious that zombies
were ``possible,'' and
didn't bother to define what sort of possibility was
meant.

{
 Because of my reading in mathematical logic, what instantly comes
into my mind is logical possibility. If you have a collection of
statements like $\{(A \Rightarrow 
B),(B \Rightarrow  C),(C \Rightarrow
\lnot A)\}$, then the compound
belief is \textit{logically possible} if it has a
\textit{model}{}---which, in the simple case above, reduces to finding
a value assignment to
$\{A,B,C\}$
that makes all of the statements $(A \Rightarrow  B)$, $(B \Rightarrow
 C)$, and $(C \Rightarrow \lnot A)$ true. In this case, $A = B = C
= 0$ works, as does $\{A = 0,B = C =
1\}$ or
$\{A = B = 0,C =
1\}$.}


 Something will \textit{seem} possible---will seem
``conceptually possible'' or
``imaginable''---if you can consider
the collection of statements without \textit{seeing} a contradiction.
But it is, in general, a very hard problem to see contradictions
\textit{or} to find a full specific model! If you limit yourself to
simple Boolean propositions of the form (($A$ or $B$ or $C$) and ($B$ or
$\lnot C$ or $D$) and ($D$ or $\lnot A$ or $\lnot C$){\dots}),
conjunctions of disjunctions of three variables, then this is a very
famous problem called \textsf{3-SAT}, which is one of the first problems ever to
be proven \textsf{NP}-complete.


 So just because you don't see a contradiction in
the Zombie World at first glance, it doesn't mean that
no contradiction is there. It's like not seeing a
contradiction in the Riemann Hypothesis at first glance. From
conceptual possibility (``I don't see
a problem'') to \textit{logical possibility}, in the
full technical sense, is a very great leap. It's easy
to make it an \textsf{NP}-complete leap, and with first-order theories you can
make it arbitrarily hard to compute even for finite questions. And
it's \textit{logical} possibility of the Zombie World,
not conceptual possibility, that is needed to suppose that a logically
omniscient mind could know the positions of all the atoms in the
universe, and yet need to be told as an \textit{additional}
non-entailed fact that we have inner listeners.


 Just because you don't see a contradiction
\textit{yet} is no guarantee that you won't see a
contradiction in another thirty seconds. ``All odd
numbers are prime. Proof: 3 is prime, 5 is prime, 7 is prime\,\ldots''


 So let us ponder the Zombie Argument \textit{a little longer}: Can
we think of a counterexample to the assertion
``Consciousness has no third-party-detectable causal
impact on the world''?


 If you close your eyes and concentrate on your inward awareness,
you will begin to form thoughts, in your internal narrative, that go
along the lines of ``I am aware''
and ``My awareness is separate from my
thoughts'' and ``I am not the one
who speaks my thoughts, but the one who hears them''
and ``My stream of consciousness is not my
consciousness'' and ``It seems like
there is a part of me that I can imagine being eliminated without
changing my outward behavior.''


 You can even say these sentences out loud, as you meditate. In
principle, someone with a super-fMRI could probably read the phonemes
out of your auditory cortex; but saying it out loud removes all doubt
about whether you have entered the realms of testability and physical
consequences.


 This certainly seems like the inner listener is being
\textit{caught in the act of listening} by whatever part of you writes
the internal narrative and flaps your tongue.


 Imagine that a mysterious race of aliens visit you, and leave you
a mysterious black box as a gift. You try poking and prodding the black
box, but (as far as you can tell) you never succeed in eliciting a
reaction. You can't make the black box produce gold
coins or answer questions. So you conclude that the black box is
causally inactive: ``For all $X$, the black box
doesn't do $X$.'' The black box is an
effect, but not a cause; epiphenomenal; without causal potency. In your
mind, you test this general hypothesis to see if it is true in some
trial cases, and it seems to be true---``Does the
black box turn lead to gold? No. Does the black box boil water?
No.''


 But you can \textit{see} the black box; it absorbs light, and
weighs heavy in your hand. This, too, is part of the dance of
causality. If the black box were \textit{wholly} outside the causal
universe, you couldn't see it; you would have no way to
know it existed; you could not say, ``Thanks for the
black box.'' You didn't
\textit{think} of this counterexample, when you formulated the general
rule: ``All $X$: Black box doesn't do
$X$.'' But it was there all along.


 (Actually, the aliens left you \textit{another} black box, this
one \textit{purely} epiphenomenal, and you haven't the
slightest clue that it's there in your living room.
That was their joke.)


 If you can close your eyes, and sense yourself sensing---if you
can be aware of yourself being aware, and think ``I am
aware that I am aware''---and say out loud,
``I am aware that I am
aware''---then your consciousness is not without
effect on your internal narrative, or your moving lips. You can see
yourself seeing, and your internal narrative reflects this, and so do
your lips if you choose to say it out loud.


 I have not seen the above argument written out that particular
way---``the listener caught in the act of
listening''---though it may well have been said
before.


 But it is a standard point{}---which zombie-ist philosophers
accept!---that the Zombie World's philosophers, being
atom-by-atom identical to our own philosophers, write identical papers
about the philosophy of consciousness.


 At this point, the Zombie World stops being an intuitive
consequence of the idea of a passive listener.


 Philosophers writing papers about consciousness would
\textit{seem} to be at least one effect of consciousness upon the
world. You can argue clever reasons why this is not so, but you have to
be clever.


 You would intuitively suppose that if your inward awareness went
away, this would change the world, in that your internal narrative
would no longer say things like ``There is a
mysterious listener within me,'' because the
mysterious listener would be gone. It is usually right \textit{after}
you focus your awareness on your awareness, that your internal
narrative says ``I am aware of my
awareness,'' which suggests that if the first event
never happened again, neither would the second. You can argue clever
reasons why this is not so, but you have to be clever.


 You can form a propositional belief that
``Consciousness is without effect,''
and not \textit{see} any contradiction at first, if you
don't realize that talking about consciousness is an
effect of being conscious. But once you see the connection from the
general rule that consciousness has no effect, to the specific
implication that consciousness has no effect on how philosophers write
papers about consciousness, zombie-ism stops being intuitive and starts
requiring you to postulate strange things.


 One strange thing you might postulate is that
there's a Zombie Master, a god within the Zombie World
who surreptitiously takes control of zombie philosophers and makes them
talk and write about consciousness.


 A Zombie Master doesn't seem impossible. Human
beings often don't sound all that coherent when talking
about consciousness. It might not be that hard to fake their discourse,
to the standards of, say, a human amateur talking in a bar. Maybe you
could take, as a corpus, one thousand human amateurs trying to discuss
consciousness; feed them into a non-conscious but sophisticated AI,
better than today's models but not self-modifying; and
get back discourse about
``consciousness'' that sounded as
sensible as most humans, which is to say, not very.


 But this speech about
``consciousness'' would not be
spontaneous. It would not be produced \textit{within} the AI. It would
be a recorded imitation of someone else talking. That is just a
holodeck, with a central AI writing the speech of the non-player
characters. This is \textit{not} what the Zombie World is about.


 By supposition, the Zombie World is atom-by-atom identical to our
own, except that the inhabitants lack consciousness. Furthermore, the
atoms in the Zombie World move under the same laws of physics as in our
own world. If there are ``bridging
laws'' that govern \textit{which configurations of
atoms evoke consciousness}, those bridging laws are absent. But, by
hypothesis, the difference is not experimentally detectable. When it
comes to saying whether a quark zigs or zags or exerts a force on
nearby quarks---anything experimentally measurable---the same physical
laws govern.


 The Zombie World has no \textit{room} for a Zombie Master, because
a Zombie Master has to control the zombie's lips, and
that control is, in principle, experimentally detectable. The Zombie
Master moves lips, therefore it has observable consequences. There
would be a point where an electron zags, instead of zigging, because
the Zombie Master says so. (Unless the Zombie Master is actually
\textit{in} the world, as a pattern of quarks---but then the Zombie
World is not atom-by-atom identical to our own, unless you think
\textit{this} world also contains a Zombie Master.)


 When a philosopher in our world types, ``I think
the Zombie World is possible,'' their fingers strike
keys in sequence: Z-O-M-B-I-E. There is a chain of causality that can
be traced back from these keystrokes: muscles contracting, nerves
firing, commands sent down through the spinal cord, from the motor
cortex---and then into less understood areas of the brain, where the
philosopher's internal narrative first began talking
about ``consciousness.''


 And the philosopher's zombie twin strikes the same
keys, \textit{for the same reason,} causally speaking. There is no
cause within the chain of explanation for why the philosopher writes
the way they do that is not also present in the zombie twin. The zombie
twin also has an internal narrative about
``consciousness,'' that a super-fMRI
could read out of the auditory cortex. And whatever other thoughts, or
other causes of any kind, led to that internal narrative, they are
exactly the same in our own universe and in the Zombie World.


 So you can't say that the philosopher is writing
about consciousness \textit{because of} consciousness, while the zombie
twin is writing about consciousness \textit{because of} a Zombie Master
or AI chatbot. When you trace back the chain of causality behind the
keyboard, to the internal narrative echoed in the auditory cortex, to
the cause of the narrative, you must find the \textit{same} physical
explanation in our world as in the zombie world.


 As the most formidable advocate of zombie-ism, David Chalmers,
writes:\footnote{Chalmers, \textit{The Conscious Mind}.\comment{1}}

\begin{quotation}

 Think of my zombie twin in the universe next door. He talks about
conscious experience all the time---in fact, he seems obsessed by it.
He spends ridiculous amounts of time hunched over a computer, writing
chapter after chapter on the mysteries of consciousness. He often
comments on the pleasure he gets from certain sensory qualia,
professing a particular love for deep greens and purples. He frequently
gets into arguments with zombie materialists, arguing that their
position cannot do justice to the realities of conscious experience.


 And yet he has no conscious experience at all! In his universe,
the materialists are right and he is wrong. Most of his claims about
conscious experience are utterly false. But there is certainly a
physical or functional explanation of why he makes the claims he makes.
After all, his universe is fully law-governed, and no events therein
are miraculous, so there must be some explanation of his claims.

{
 \ldots Any explanation of my twin's behavior will
equally count as an explanation of my behavior, as the processes inside
his body are precisely mirrored by those inside mine. The explanation
of his claims obviously does not depend on the existence of
consciousness, as there is no consciousness in his world. It follows
that the explanation of my claims is also independent of the existence
of consciousness.}
\end{quotation}


 Chalmers is not arguing \textit{against} zombies; those are his
actual beliefs!

\begin{quotation}
{
 This paradoxical situation is at once delightful and disturbing.
It is not obviously fatal to the nonreductive position, but it is at
least something that we need to come to grips with\,\ldots}
\end{quotation}


 I would seriously nominate this as the largest bullet ever bitten
in the history of time. And that is a backhanded compliment to David
Chalmers: A lesser mortal would simply fail to see the implications, or
refuse to face them, or rationalize a reason it wasn't
so.


 Why would anyone bite a bullet that large? Why would anyone
postulate unconscious zombies who write papers about consciousness for
\textit{exactly the same reason} that our own genuinely conscious
philosophers do?


 Not because of the first intuition I wrote about, the intuition of
the passive listener. That intuition may say that zombies can drive
cars or do math or even fall in love, but it doesn't
say that zombies write philosophy papers about their passive
listeners.


 The zombie argument does not rest \textit{solely} on the intuition
of the passive listener. If this was all there was to the zombie
argument, it would be dead by now, I think. The intuition that the
``listener'' can be eliminated
without effect would go away as soon as you realized that your internal
narrative routinely \textit{seems} to catch the listener in the act of
listening.


 No, the drive to bite \textit{this} bullet comes from an entirely
different intuition---the intuition that no matter how many atoms you
add up, no matter how many masses and electrical charges interact with
each other, they will never \textit{necessarily} produce a subjective
sensation of the mysterious redness of red. It may be a fact about our
physical universe (Chalmers says) that putting such-and-such atoms into
such-and-such a position \textit{evokes} a sensation of redness; but if
so, it is not a \textit{necessary} fact, it is something to be
explained above and beyond the motion of the atoms.


 But if you consider the second intuition on its own, without the
intuition of the passive listener, it is hard to see why it implies
zombie-ism. Maybe there's just a \textit{different kind
of stuff}, apart from and additional to atoms, that is \textit{not}
causally passive---a soul that actually \textit{does} stuff, a soul
that plays a real causal role in why we write about
``the mysterious redness of red.''
Take out the soul, and\,\ldots well, assuming you don't
just fall over in a coma, you certainly won't write any
more papers about consciousness!


 This is the position taken by Descartes and most other ancient
thinkers: The soul is of a different kind, but it \textit{interacts}
with the body. Descartes's position is technically
known as \textit{substance dualism}{}---there is a thought-stuff, a
mind-stuff, and it is not like atoms; but it is causally potent,
interactive, and leaves a visible mark on our universe.


 Zombie-ists are \textit{property dualists}{}---they
don't believe in a \textit{separate} soul; they believe
that matter in our universe has \textit{additional properties} beyond
the physical.


 ``Beyond the physical''? What
does that mean? It means the extra properties are there, but they
don't influence the motion of the atoms, like the
properties of electrical charge or mass. The extra properties are not
experimentally detectable \textit{by third parties}; \textit{you} know
you are conscious, from the \textit{inside} of your extra properties,
but no scientist can ever directly detect this from outside.


 So the additional properties are there, but not causally active.
The extra properties do not move atoms around, which is why they
can't be detected by third parties.


 And that's why we can (allegedly) imagine a
universe just like this one, with all the atoms in the same places, but
the extra properties missing, so that everything goes on the same as
before, but no one is conscious.


 The Zombie World may not be \textit{physically} possible, say the
zombie-ists---because it is a fact that all the matter in our universe
has the extra properties, or obeys the bridging laws that evoke
consciousness---but the Zombie World is \textit{logically} possible:
the bridging laws could have been different.


 But, once you realize that conceivability is not the same as
logical possibility, and that the Zombie World isn't
even all that intuitive, why say that the Zombie World is logically
possible?


 Why, oh why, say that the extra properties are epiphenomenal and
indetectable?


 We can put this dilemma very sharply: Chalmers believes that there
\textit{is} something called consciousness, and this consciousness
embodies the true and indescribable substance of the mysterious redness
of red. It may be a property beyond mass and charge, but
it's \textit{there}, and it \textit{is} consciousness.
Now, having said the above, Chalmers furthermore specifies that this
true stuff of consciousness is epiphenomenal, without causal
potency---but \textit{why say that}?


 Why say that you could subtract this true stuff of consciousness,
and leave all the atoms in the same place doing the same things? If
that's true, we need some \textit{separate} physical
explanation for why Chalmers talks about ``the
mysterious redness of red.'' That is, there exists
both a mysterious redness of red, which is extra-physical, and
\textit{an entirely separate} reason, \textit{within} physics, why
Chalmers \textit{talks} about the ``mysterious redness
of red.''


 Chalmers does confess that these two things seem like they ought
to be related, but really, why do you need both? Why not just pick one
or the other?


 Once you've postulated that there is a mysterious
redness of red, why not just say that it interacts with your internal
narrative and makes you talk about the ``mysterious
redness of red''?


 Isn't Descartes taking the simpler approach, here?
The \textit{strictly} simpler approach?


 Why postulate an extramaterial soul, \textit{and then} postulate
that the soul has no effect on the physical world, \textit{and then}
postulate a mysterious unknown \textit{material} process that causes
your internal narrative to talk about conscious experience?


 Why not postulate the true stuff of consciousness which no amount
of mere mechanical atoms can add up to, \textit{and then,} having gone
that far already, let this true stuff of consciousness have causal
effects like making philosophers talk about consciousness?


 I am not endorsing Descartes's view. But at least
I can understand where Descartes is coming from. Consciousness seems
mysterious, so you postulate a mysterious stuff of consciousness.
Fine.


 But now the zombie-ists postulate that this mysterious stuff
\textit{doesn't do anything}, so you need a
\textit{whole new} explanation for why you \textit{say}
you're conscious.


 That isn't vitalism. That's
something so bizarre that vitalists would spit out their coffee.
``When fires burn, they release phlogiston.
\textit{But} phlogiston doesn't have any experimentally
detectable impact on our universe, so you'll have to go
looking for a \textit{separate} explanation of why a fire can melt
snow.'' \textit{What?}


 Are property dualists under the impression that if they postulate
a new \textit{active} force, something that has a causal impact on
observables, they will be sticking their necks out too far?


 Me, I'd say that if you postulate a mysterious,
separate, additional, inherently mental property of consciousness,
above and beyond positions and velocities, then, at that point, you
have \textit{already} stuck your neck out as far as it can go. To
postulate this stuff of consciousness, and then further postulate that
it \textit{doesn't do anything}{}---for the love of
cute kittens, \textit{why?}


 There isn't even an obvious career motive.
``Hi, I'm a philosopher of
consciousness. My subject matter is the most important thing in the
universe and I should get lots of funding? Well, it's
nice of you to say so, but actually the phenomenon I study
doesn't do anything whatsoever.''
(Argument from career impact is not valid, but I say it to leave a line
of retreat.)


 Chalmers critiques substance dualism on the grounds that
it's hard to see what new theory of physics, what new
substance that interacts with matter, could possibly explain
consciousness. But property dualism has exactly the same problem. No
matter what kind of dual property you talk about, how exactly does it
explain consciousness?


 When Chalmers postulated an extra property that \textit{is}
consciousness, he \textit{took} that leap across the unexplainable. How
does it help his theory to further specify that this extra property
\textit{has no effect}? Why not just let it be causal?


 If I were going to be unkind, this would be the time to drag in
the dragon---to mention Carl Sagan's parable of the
dragon in the garage. ``I have a dragon in my
garage.'' Great! I want to see it,
let's go! ``You can't
see it---it's an invisible dragon.''
Oh, I'd like to hear it then. ``Sorry,
it's an inaudible dragon.''
I'd like to measure its carbon dioxide output.
``It doesn't
breathe.'' I'll toss a bag of flour
into the air, to outline its form. ``The dragon is
permeable to flour.''


 One motive for trying to make your theory unfalsifiable is that
deep down you fear to put it to the test. Sir Roger Penrose (physicist)
and Stuart Hameroff (neurologist) are substance dualists; they think
that there is something mysterious going on in quantum, that Everett is
wrong and that the ``collapse of the
wavefunction'' is physically real, and that this is
where consciousness lives and how it exerts causal effect upon your
lips when you say aloud ``I think therefore I
am.'' Believing this, they predicted that neurons
would protect themselves from decoherence long enough to maintain
macroscopic quantum states.


 This is in the process of being tested, and so far, prospects are
not looking good for Penrose---


 {}---but Penrose's basic conduct is scientifically
respectable. Not Bayesian, maybe, but still fundamentally healthy. He
came up with a wacky hypothesis. He said how to test it. He went out
and tried to actually test it.


 As I once said to Stuart Hameroff, ``I think the
hypothesis you're testing is completely hopeless, and
your experiments should \textit{definitely} be funded. Even if you
don't find exactly what you're looking
for, you're looking in a place where no one else is
looking, and you might find something interesting.''


 So a nasty dismissal of epiphenomenalism would be that zombie-ists
are afraid to say the consciousness-stuff can have \textit{effects},
because then scientists could go \textit{looking} for the extra
properties, and fail to find them.


 I don't think this is actually true of Chalmers,
though. If Chalmers lacked self-honesty, he could make things a
\textit{lot} easier on himself.


 (But just in case Chalmers is reading this and does have
falsification-fear, I'll point out that if
epiphenomenalism is false, then there \textit{is} some other
explanation for that-which-we-call consciousness, and it will
eventually be found, leaving Chalmers's theory in
ruins; so if Chalmers cares about his place in history, he has no
motive to endorse epiphenomenalism unless he really thinks
it's true.)


 Chalmers is one of the most frustrating philosophers I know.
Sometimes I wonder if he's pulling an Atheism
Conquered.\footnote{\url{http://www.expatsingapore.com/forum/index.php?topic=16763.msg126809}} Chalmers does this really \textit{sharp} analysis\,\ldots and
then turns left at the last minute. He lays out everything
that's wrong with the Zombie World scenario, and then,
having reduced the whole argument to smithereens, calmly accepts it.


 Chalmers does the same thing when he lays out, in calm detail, the
problem with saying that our own beliefs in consciousness are
justified, when our zombie twins say exactly the same thing for exactly
the same reasons and are wrong.


 On Chalmers's theory, Chalmers's
saying that he believes in consciousness cannot be \textit{causally}
justified; the belief is not caused by the fact itself. In the absence
of consciousness, Chalmers would write the same papers for the same
reasons.


 On epiphenomenalism, Chalmers's saying that he
believes in consciousness cannot be justified as the product of a
process that systematically outputs true beliefs, because the zombie
twin writes the same papers using the same systematic process and is
wrong.


 Chalmers admits this. Chalmers, in fact, explains the argument in
great detail in his book. Okay, so Chalmers has solidly proven that he
is not justified in believing in epiphenomenal consciousness, right?
No. Chalmers writes:

\begin{quotation}

 Conscious experience lies at the center of our epistemic universe;
we have access to it \textit{directly.} This raises the question: what
is it that justifies our beliefs about our experiences, if it is not a
causal link to those experiences, and if it is not the mechanisms by
which the beliefs are formed? I think the answer to this is clear: it
is \textit{having} the experiences that justifies the beliefs. For
example, the very fact that I have a red experience now provides
justification for my belief that I am having a red experience\,\ldots


 Because my zombie twin lacks experiences, he is in a very
different epistemic situation from me, and his judgments lack the
corresponding justification. It may be tempting to object that if my
belief lies in the physical realm, its justification must lie in the
physical realm; but this is a \textit{non sequitur.} From the fact that
there is no justification in the physical realm, one might conclude
that the \textit{physical} portion of me (my brain, say) is not
justified in its belief. But the question is whether \textit{I} am
justified in the belief, not whether my \textit{brain} is justified in
the belief, and if property dualism is correct than there is more to me
than my brain.

\end{quotation}

 So---if I've got this thesis
right---there's a core you, above and beyond your
brain, that believes it is not a zombie, and directly experiences not
being a zombie; and so its beliefs are justified.


 But Chalmers just \textit{wrote all that stuff down}, in his very
physical \textit{book}, and so did the zombie-Chalmers.


 The zombie Chalmers can't have written the book
\textit{because} of the zombie's core self above the
brain; there must be some entirely different reason, within the laws of
physics.


 It follows that even if there \textit{is} a part of Chalmers
hidden away that is conscious and believes in consciousness, directly
and without mediation, there is also a \textit{separable subspace} of
Chalmers---a causally closed cognitive subsystem that acts entirely
\textit{within} physics---and this ``outer
self'' is what speaks Chalmers's
internal narrative, and writes papers on consciousness.


 I do not see any way to evade the charge that, on
Chalmers's own theory, this separable outer Chalmers is
deranged. This is the part of Chalmers that is the same in this world,
or the Zombie World; and in either world it writes philosophy papers on
consciousness \textit{for no valid reason.} Chalmers's
philosophy papers are not output by that inner core of awareness and
belief-in-awareness; they are output by the mere physics of the
internal narrative that makes Chalmers's fingers strike
the keys of his computer.


 And yet this deranged outer Chalmers is writing philosophy papers
that \textit{just happen} to be perfectly right, \textit{by a separate
and additional miracle}. Not a logically necessary miracle (then the
Zombie World would not be logically possible). A physically contingent
miracle, that happens to be true in what we think is our universe, even
though science can never distinguish our universe from the Zombie
World.


 Or at least, that would seem to be the implication of what the
self-confessedly deranged outer Chalmers is telling us.


 I think I speak for all reductionists when I say \textit{Huh?}


 That's not epicycles. That's,
``Planetary motions follow these epicycles---but
epicycles don't actually \textit{do}
anything---there's something else that makes the
planets move the same way the epicycles say they should, which I
haven't been able to explain---and by the way, I would
say this even if there weren't any
epicycles.''


 I have a nonstandard perspective on philosophy because I look at
everything with an eye to designing an AI; specifically, a
self-improving Artificial General Intelligence with stable motivational
structure.


 When I think about designing an AI, I ponder principles like
probability theory, the Bayesian notion of evidence as differential
diagnostic, and above all, reflective coherence. Any self-modifying AI
that starts out in a reflectively inconsistent state
won't stay that way for long.


 If a self-modifying AI looks at a part of itself that concludes
``$B$'' on condition $A$---a part of
itself that writes ``$B$'' to memory
whenever condition $A$ is true---and the AI inspects this part,
determines how it (causally) operates in the context of the larger
universe, and the AI decides that this part systematically tends to
write false data to memory, then the AI has found what appears to be a
bug, and the AI will self-modify not to write
``$B$'' to the belief pool under
condition $A$.


 Any epistemological theory that disregards reflective coherence is
not a good theory to use in constructing self-improving AI. This is a
knockdown argument from my perspective, considering what I intend to
actually use philosophy \textit{for}. So I have to invent a
reflectively coherent theory anyway. And when I do, by golly,
reflective coherence turns out to make intuitive sense.


 So that's the unusual way in which I tend to think
about these things. And now I look back at Chalmers:


 The causally closed ``outer
Chalmers'' (that is not influenced in any way by the
``inner Chalmers'' that has separate
additional awareness and beliefs) must be carrying out some
systematically unreliable, unwarranted operation which \textit{in some
unexplained fashion} causes the internal narrative to produce beliefs
about an ``inner Chalmers'' that are
\textit{correct for no logical reason} in what happens to be our
universe.


 But there's no possible warrant for the outer
Chalmers \textit{or any reflectively coherent self-inspecting AI} to
believe in this mysterious correctness. A good AI design should, I
think, look like a reflectively coherent intelligence embodied in a
causal system, with a \textit{testable} theory of how that selfsame
causal system produces systematically accurate beliefs on the way to
achieving its goals.


 So the AI will scan Chalmers and see a closed causal cognitive
system producing an internal narrative that is uttering nonsense.
Nonsense that seems to have a high impact on what Chalmers thinks
\textit{should be considered a morally valuable person.}


 This is not a \textit{necessary} problem for Friendly AI
theorists. It is \textit{only} a problem if you happen to be an
epiphenomenalist. If you believe either the reductionists
(consciousness happens \textit{within} the atoms) or the substance
dualists (consciousness is \textit{causally potent} immaterial stuff),
people talking about consciousness are talking about something real,
and a reflectively consistent Bayesian AI can see this by tracing back
the chain of causality for what makes people say
``consciousness.''


 According to Chalmers, the causally closed cognitive system of
Chalmers's internal narrative is (mysteriously)
malfunctioning in a way that, not by necessity, but just in
\textit{our} universe, miraculously happens to be correct. Furthermore,
the internal narrative asserts ``the internal
narrative is mysteriously malfunctioning, but miraculously happens to
be correctly echoing the justified thoughts of the epiphenomenal inner
core,'' and again, in \textit{our} universe,
miraculously happens to be correct.


 \textit{Oh, come on!}


 Shouldn't there come a point where you just give
up on an idea? Where, on some raw intuitive level, you just go:
\textit{What on Earth was I thinking?}

{
 Humanity has accumulated some broad experience with what correct
theories of the world look like. \textit{This is not what a correct
theory looks like.}}


 ``Argument from incredulity,''
you say. Fine, you want it spelled out? The said Chalmersian theory
postulates multiple unexplained complex miracles. This drives down its
prior probability, by the conjunction rule of probability and
Occam's Razor. It is therefore dominated by at least
two theories that postulate fewer miracles, namely:

\begin{itemize}
\item

  Substance dualism:
    \begin{itemize}
    \item
There is a stuff of consciousness which is not
yet understood, an extraordinary super-physical stuff that
\textit{visibly affects} our world; and this stuff is what makes us
talk about consciousness.
\end{itemize}


\item

  Not-quite-faith-based reductionism:
  \begin{itemize}
    \item
  That-which-we-name
``consciousness'' happens
\textit{within} physics, in a way not yet understood, just like what
happened the last three thousand times humanity ran into something
mysterious.
\item
Your intuition that no material substance can possibly add
up to consciousness is incorrect. If you \textit{actually} knew
\textit{exactly} why you talk about consciousness, this would give you
new insights, of a form you can't now anticipate; and
afterward you would realize that your arguments about normal physics
having no room for consciousness were flawed.
\end{itemize}


\end{itemize}


 Compare to:

\begin{itemize}
  \item
{
  Epiphenomenal property dualism:
\begin{itemize}
\item  Matter has additional
consciousness-properties which are not yet understood. These properties
are epiphenomenal with respect to ordinarily observable physics---they
make no difference to the motion of particles.
\item
  \textit{Separately,}
there exists a not-yet-understood reason \textit{within normal physics}
why philosophers talk about consciousness and invent theories of dual
properties.
\item
  \textit{Miraculously,} when philosophers talk about
consciousness, the bridging laws of \textit{our} world are exactly
right to make this talk about consciousness correct, even though it
arises from a malfunction (drawing of logically unwarranted
conclusions) in the causally closed cognitive system that types
philosophy papers.
\end{itemize}
}
\end{itemize}


 I know I'm speaking from limited experience, here.
But based on my limited experience, the Zombie Argument may be a
candidate for \textit{the most deranged idea in all of philosophy}.


 There are times when, as a rationalist, you have to believe things
that seem weird to you. Relativity seems weird, quantum mechanics seems
weird, natural selection seems weird.


 But these weirdnesses are pinned down by massive evidence.
There's a difference between believing something weird
because science has confirmed it overwhelmingly---


 {}---versus believing a proposition that seems downright
\textit{deranged}, because of a great big complicated philosophical
argument centered around unspecified miracles and giant blank spots not
even claimed to be understood---


 {}---in a case where \textit{even if you accept everything that
has been told to you so far}, afterward the phenomenon will still seem
like a mystery and still have the same quality of wondrous
impenetrability that it had at the start.


 The correct thing for a rationalist to say at this point, if all
of David Chalmers's arguments seem individually
plausible---which they don't seem to me---is:


 ``Okay\,\ldots I don't know how
consciousness works\,\ldots I admit that\,\ldots and maybe
I'm approaching the whole problem wrong, or asking the
wrong questions\,\ldots but this zombie business
\textit{can't possibly be right.} The arguments
aren't nailed down enough to make me believe
this---especially when accepting it won't make me feel
any less confused. On a core gut level, this just
\textit{doesn't look} like the way reality could
\textit{really really} work.''


 Mind you, I am not saying this is a substitute for careful
analytic refutation of Chalmers's thesis. System 1 is
not a substitute for System 2, though it can help point the way. You
still have to track down where the problems are \textit{specifically}.


 Chalmers wrote a big book, not all of which is available through
free Google preview. I haven't duplicated the long
chains of argument where Chalmers lays out the arguments against
himself in calm detail. I've just tried to tack on a
final refutation of Chalmers's last presented defense,
which Chalmers has not yet countered to my knowledge. Hit the ball back
into his court, as it were.


 But, yes, on a core level, the \textit{sane} thing to do when you
see the conclusion of the zombie argument, is to say
``That can't \textit{possibly} be
right'' and start looking for a flaw.

\myendsectiontext


\bigskip

\mysection{Zombie Responses}


 I'm a bit tired today, having stayed up until 3
a.m. writing yesterday's {\textgreater}6,000-word essay
on zombies, so today I'll just reply to Richard, and
tie up a loose end I spotted the next day.


 \textbf{(A)} Richard Chappell writes:\footnote{\url{http://lesswrong.com/lw/p7/zombies_zombies/j7g}}

\begin{quote}
{
 A terminological note (to avoid unnecessary confusion): what you
call ``conceivable,'' others of us
would merely call ``\textit{apparently}
conceivable.''}
\end{quote}


 The gap between ``I don't see a
contradiction yet'' and ``this is
logically possible'' is so huge (it's
\textsf{NP}-complete even in some simple-seeming cases) that you really should
have two different words. As the zombie argument is boosted to the
extent that this huge gap can be swept under the rug of minor
terminological differences, I really think it would be a good idea to
say ``conceivable'' versus
``logically possible'' or maybe even
have a still more visible distinction. I can't choose
professional terminology that has already been established, but in a
case like this, I might seriously refuse to use it.


 Maybe I will say ``apparently
conceivable'' for the kind of information that zombie
advocates get by imagining Zombie Worlds, and
``logically possible'' for the kind
of information that is established by exhibiting a complete model or
logical proof. Note the size of the gap between the information you can
get by closing your eyes and imagining zombies, and the information you
need to carry the argument for epiphenomenalism.

\begin{quote}


 That is, your view would be characterized as a form of Type-A
materialism, the view that zombies are not even (genuinely)
conceivable, let alone metaphysically possible.

\end{quote}


 Type-A materialism is a large bundle; you
shouldn't attribute the bundle to me until you see me
agree with each of the parts. I think that someone who asks
``What is consciousness?'' is asking
a legitimate question, has a legitimate demand for insight; I
don't necessarily think that the \textit{answer} takes
the form of ``Here is this stuff that has all the
properties you would attribute to consciousness, for such-and-such
reason,'' but may to some extent consist of insights
that cause you to realize you were asking the question the wrong way.


 This is not being eliminative about consciousness. It is being
realistic about what kind of insights to expect, faced with a problem
that (1) seems like it must have \textit{some} solution, (2) seems like
it cannot possibly have any solution, and (3) is being
\textit{discussed} in a fashion that has a great big dependence on the
not-fully-understood ad-hoc architecture of human cognition.

\begin{quote}
{
 (1) You haven't, so far as I can tell, identified
any \textit{logical contradiction} in the description of the zombie
world. You've just pointed out that
it's kind of strange. But there are many bizarre
possible worlds out there. That's no reason to posit an
implicit contradiction. So it's still completely
mysterious to me what this alleged contradiction is supposed to be.}
\end{quote}


 Okay, I'll spell it out from a materialist
standpoint:

\begin{enumerate}
\item{
 The zombie world, by definition, contains all parts of our world
that are within the closure of the ``caused
by'' or ``effect
of'' relation of any observable phenomenon. In
particular, it contains the \textit{cause of} my visibly saying,
``I think therefore I am.''}

\item{
 When I focus my inward awareness on my inward awareness, I shortly
thereafter experience my internal narrative saying ``I
am focusing my inward awareness on my inward
awareness,'' and can, if I choose, say so out loud.}

\item{
 Intuitively, it sure seems like my inward awareness is causing my
internal narrative to say certain things, and that my internal
narrative can cause my lips to say certain things.}

\item{
 The word ``consciousness,'' if
it has any meaning at all, refers to that-which-is or that-which-causes
or that-which-makes-me-say-I-have inward awareness.}

\item{
 From (3) and (4) it would follow that if the zombie world is
closed with respect to the causes of my saying ``I
think therefore I am,'' the zombie world contains
that which we refer to as
``consciousness.''}

\item{
 By definition, the zombie world does not contain consciousness.}

\item{
 (3) seems to me to have a rather high probability of being
empirically true. Therefore I evaluate a high empirical probability
that the zombie world is logically impossible.}
\end{enumerate}


 You can save the Zombie World by letting the cause of my internal
narrative's saying ``I think therefore
I am'' be something entirely other than
consciousness. In conjunction with the assumption that consciousness
does exist, this is the part that struck me as deranged.


 But if the above is \textit{conceivable}, then
isn't the Zombie World conceivable?


 No, because the two constructions of the Zombie World involve
giving the word ``consciousness''
different empirical referents, like
``water'' in our world meaning
H\textsubscript{2}O versus ``water''
in Putnam's Twin Earth meaning XYZ. For the Zombie
World to be logically possible, it does not suffice that, for all
\textit{you} knew about how the empirical world worked, the word
``consciousness'' \textit{could}
have referred to an epiphenomenon that is entirely different from the
consciousness we know. The Zombie World lacks consciousness, not
``consciousness''---it is a world
without H\textsubscript{2}O, not a world without
``water.'' This is what is required
to carry the empirical statement, ``You could
eliminate the referent of whatever is meant by
`consciousness' from our world, while
keeping all the atoms in the same place.''


 Which is to say: I hold that it is an \textit{empirical} fact,
given what the word
``consciousness'' actually refers
to, that it is \textit{logically} impossible to eliminate consciousness
without moving any atoms. What it would mean to eliminate
``consciousness'' from a world,
rather than consciousness, I will not speculate.

\begin{quote}
{
 (2) It's misleading to say it's
``miraculous'' (on the property
dualist view) that our qualia line up so neatly with the physical
world. There's a natural law which guarantees this,
after all. So it's no more miraculous than any other
logically contingent nomic necessity (e.g.~the constants in our
physical laws).}
\end{quote}


 It is the natural law itself that is
``miraculous''---counts as an
additional complex-improbable element of the theory to be postulated,
without having been itself justified in terms of things already known.
One postulates (a) an inner world that is conscious, (b) a
malfunctioning outer world that talks about consciousness for no
reason, and (c) that the two align perfectly. Statement (c) does not
follow from (a) and (b), and so is a separate postulate.


 I agree that this usage of
``miraculous'' conflicts with the
philosophical sense of violating a natural law; I meant it in the sense
of improbability appearing from no apparent source, a la perpetual
motion belief. Hence the word was ill-chosen in context. But is this
not \textit{intuitively} the sort of thing we should call a miracle?
Your consciousness doesn't really cause you to say
you're conscious, there's a separate
physical thing that makes you say you're conscious, but
also there's a law aligning the two---this is indeed an
event on a similar order of wackiness to a cracker taking on the
substance of Christ's flesh while possessing the exact
appearance and outward behavior of a cracker, there's
just a natural law which guarantees this, you know.

\begin{quote}
{
 That is, Zombie (or ``Outer'')
Chalmers doesn't actually conclude \textit{anything},
because his utterances are meaningless. A fortiori, he
doesn't conclude anything unwarrantedly.
He's just making noises; these are no more susceptible
to epistemic assessment than the chirps of a bird.}
\end{quote}


 Looking at this from an AI-design standpoint, it seems to me like
you should be able to build an AI that systematically refines an inner
part of itself that correlates (in the sense of mutual information or
systematic relations) to the environment, perhaps including
floating-point numbers of a sort that I would call
``probabilities'' because they obey
the internal relations mandated by Cox's Theorems when
the AI encounters new information---pardon me, new sense inputs.


 You will say that, unless the AI is more than mere
transistors---unless it has the dual aspect---the AI has no beliefs.


 I think my views on this were expressed pretty clearly in The
Simple Truth.


 To me, it seems pretty straightforward to construct maps that
correlate to territories in systematic ways, without mentioning
anything other than things of pure physical causality. The AI outputs a
map of Texas. Another AI flies with the map to Texas and checks to see
if the highways are in the corresponding places, chirping
``True'' when it detects a match and
``False'' when it detects a
mismatch. You can refuse to call this ``a map of
Texas'' but the AIs themselves are still chirping
``True'' or
``False,'' and the said AIs are
going to chirp ``False'' when they
look at Chalmers's belief in an epiphenomenal inner
core, and I for one would agree with them.


 It's clear that the \textit{function of mapping
reality} is performed strictly by Outer Chalmers. The whole business of
\textit{producing belief representations} is handled by Bayesian
structure in causal interactions. There's nothing left
for the Inner Chalmers to do, but bless the whole affair with
epiphenomenal \textit{meaning}. Where now
``meaning'' is something entirely
unrelated to systematic map-territory correspondence or the ability to
use that map to navigate reality. So when it comes to talking about
``accuracy,'' let alone
``systematic accuracy,'' it seems to
me like we should be able to determine it strictly by looking at the
Outer Chalmers.


 \textbf{(B)} In yesterday's text, I left out an
 assumption when I wrote:

\begin{quotation}


 If a self-modifying AI looks at a part of itself that concludes
``$B$'' on condition $A$---a part of
itself that writes ``$B$'' to memory
whenever condition $A$ is true---and the AI inspects this part,
determines how it (causally) operates in the context of the larger
universe, and the AI decides that this part systematically tends to
write false data to memory, then the AI has found what appears to be a
bug, and the AI will self-modify not to write
``$B$'' to the belief pool under
condition $A$.


 \ldots


 But there's no possible warrant for the outer
Chalmers \textit{or any reflectively coherent self-inspecting AI} to
believe in this mysterious correctness. A good AI design should, I
think, be a reflectively coherent intelligence with a testable theory
of how it operates as a causal system, hence with a testable theory of
how that causal system produces systematically accurate beliefs on the
way to achieving its goals.

\end{quotation}


 Actually, you need an additional assumption to the above, which is
that a ``good AI design'' (the kind
I was thinking of, anyway) judges its own rationality in a modular way;
it enforces global rationality by enforcing local rationality. If there
is a piece that, relative to its context, is locally systematically
unreliable---for some possible beliefs
``$B_{i}$'' and
conditions $A_{i}$, it adds some
``$B_{i}$'' to the belief
pool under local condition $A_{i}$, where reflection by the
system indicates that $B_{i}$ is not true (or in the case of
probabilistic beliefs, not accurate) when the local condition
$A_{i}$ is true---then this is a bug. This kind of
modularity is \textit{a} way to make the problem tractable, and
it's how I currently think about the first-generation
AI design. [Edit 2013: The actual notion I had in mind here has now
been fleshed out and formalized in Tiling Agents for Self-Modifying AI,\footnote{\url{http://intelligence.org/files/TilingAgents.pdf}}
section 6.]


 The notion is that a causally closed cognitive system---such as an
AI designed by its programmers to use only causally efficacious parts;
or an AI whose theory of its own functioning is entirely testable; or
the outer Chalmers that writes philosophy papers---that believes that
it has an epiphenomenal inner self, must be doing something
systematically unreliable because it would conclude the same thing in a
Zombie World. A mind all of whose parts are systematically locally
reliable, relative to their contexts, would be systematically globally
reliable. Ergo, a mind that is globally unreliable must contain at
least one locally unreliable part. So a causally closed cognitive
system inspecting itself for local reliability must discover that at
least one step involved in adding the belief of an epiphenomenal inner
self is unreliable.


 If there are other ways for minds to be reflectively coherent that
avoid this proof of disbelief in zombies, philosophers are welcome to
try and specify them.


 The reason why I have to specify all this is that otherwise you
get a kind of extremely cheap reflective coherence where the AI can
never label itself unreliable. E.g., if the AI finds a part of itself
that computes 2 + 2 = 5 (in the surrounding context of counting sheep)
the AI will reason: ``Well, this part malfunctions and
says that 2 + 2 = 5\,\ldots but by pure coincidence, 2 + 2 \textit{is}
equal to 5, or so it seems to me\,\ldots so while the part looks
systematically unreliable, I better keep it the way it is, or it will
handle this special case wrong.''
That's why I talk about enforcing global reliability by
enforcing local systematic reliability---if you just compare your
global beliefs to your global beliefs, you don't go
anywhere.


 This does have a general lesson: Show your arguments are globally
reliable by virtue of each step being locally reliable;
don't just compare the arguments'
conclusions to your intuitions. [Edit 2013: See Proofs, Implications,
and Models\footnote{\url{http://lesswrong.com/lw/f43/proofs_implications_and_models/}} for a discussion of the fact that valid logic is locally
valid.]


 \textbf{(C)} An anonymous poster wrote:

\begin{quotation}

{
 A sidepoint, this, but I believe your etymology for
``n'shama'' is
wrong. It is related to the word for
``breath,'' not
``hear.'' The root for
``hear'' contains an ayin, which
n'shama does not.}
\end{quotation}


 Now that's what I call a miraculously misleading
coincidence---although the word N'Shama arose for
completely different reasons, it sounded \textit{exactly the right way}
to make me think it referred to an inner listener.


 Oops.

\myendsectiontext

\mysection{The Generalized Anti{}-Zombie Principle}

\begin{quote}

 Each problem that I solved became a rule which served afterwards
to solve other problems.

{\raggedleft
 {}---René Descartes, \textit{Discours de la
Méthode}\footnote{René Descartes, \textit{Discours de la Méthode}, vol. 45
(Librairie des Bibliophiles, 1887).\comment{1}}
\par}
\end{quote}



 ``Zombies'' are putatively
beings that are atom-by-atom identical to us, governed by all the same
third-party-visible physical laws, except that they are not conscious.


 Though the philosophy is complicated, the core argument against
zombies is simple: When you focus your inward awareness on your inward
awareness, your internal narrative (the little voice inside your head
that speaks your thoughts) says ``I am aware of being
aware'' soon after, and then you say it out loud, and
then you type it into a computer keyboard, and create a third-party
visible blog post.


 Consciousness, whatever it may be---a substance, a process, a name
for a confusion---is not epiphenomenal; your mind can catch the inner
listener in the act of listening, and say so out loud. \textit{The fact
that I have typed this paragraph} would at least \textit{seem} to
refute the idea that consciousness has no experimentally detectable
consequences.


 I hate to say ``So now let's
accept this and move on,'' over such a
philosophically controversial question, but it seems like a
considerable majority of \textit{Overcoming Bias} commenters do accept
this. And there are other conclusions you can only get to after you
accept that you cannot subtract consciousness and leave the universe
looking exactly the same. So now let's accept this and
move on.


 The form of the Anti-Zombie Argument seems like it should
generalize, becoming an Anti-Zombie Principle. But what is the proper
generalization?


 Let's say, for example, that someone says:
``I have a switch in my hand, which does not affect
your brain in any way; and if this switch is flipped, you will cease to
be conscious.'' Does the Anti-Zombie Principle rule
this out as well, with the same structure of argument?


 It appears to me that in the case above, the answer is yes. In
particular, you can say: ``Even after your switch is
flipped, I will still talk about consciousness \textit{for exactly the
same reasons} I did before. If I am conscious right now, I will still
be conscious after you flip the switch.''


 Philosophers may object, ``But now
you're equating consciousness with talking about
consciousness! What about the Zombie Master, the chatbot that
regurgitates a remixed corpus of amateur human discourse on
consciousness?''


 But I did \textit{not} equate
``consciousness'' with verbal
behavior. The core premise is that, \textit{among other things}, the
true referent of ``consciousness''
is \textit{also} the \textit{cause in humans} of talking about inner
listeners.


 As I argued (at some length) in the sequence on words, what you
want in defining a word is not always a perfect Aristotelian
necessary-and-sufficient definition; sometimes you just want a treasure
map that leads you to the extensional referent. So
``that which \textit{does in fact} make me talk about
an unspeakable awareness'' is not a
necessary-and-sufficient definition. But if what does \textit{in fact}
cause me to discourse about an unspeakable awareness is not
``consciousness,'' then\,\ldots


 \ldots then the discourse gets pretty futile. That is not a
knockdown argument against zombies---an empirical question
can't be settled by mere difficulties of discourse. But
if you try to defy the Anti-Zombie Principle, you will have problems
with the \textit{meaning} of your discourse, not just its
plausibility.


 Could we \textit{define} the word
``consciousness'' to mean
``whatever actually makes humans talk about
`consciousness'\,''?
This would have the powerful advantage of guaranteeing that there is at
least one real fact named by the word
``consciousness.'' Even if our
belief in consciousness is a confusion,
``consciousness'' would name the
cognitive architecture that generated the confusion. But to establish a
definition is only to promise to use a word consistently; it
doesn't settle any empirical questions, such as whether
our inner awareness makes us talk about our inner awareness.


 Let's return to the Off-Switch.


 If we allow that the Anti-Zombie Argument applies against the
Off-Switch, then the Generalized Anti-Zombie Principle does
\textit{not} say only, ``Any change that is not
in-principle experimentally detectable (\textsc{iped}) cannot remove your
consciousness.'' The switch's
flipping is experimentally detectable, but it still seems
\textit{highly} unlikely to remove your consciousness.


 Perhaps the Anti-Zombie Principle says, ``Any
change that does not affect you in any \textsc{iped} way cannot remove your
consciousness''?


 But is it a reasonable stipulation to say that flipping the switch
does not affect you in \textit{any} \textsc{iped} way? All the particles in the
switch are interacting with the particles composing your body and
brain. There are gravitational effects---tiny, but real and \textsc{iped}. The
gravitational pull from a one-gram switch ten meters away is around $6 \times
 10^{-16}\, \mathrm{m/s}^2$.
That's around half a neutron diameter per second per
second, far below thermal noise, but way above the Planck level.


 We could flip the switch light-years away, in which case the flip
would have no immediate causal effect on you (whatever
``immediate'' means in this case)
(if the Standard Model of physics is correct).


 But it doesn't seem like we \textit{should} have
to alter the thought experiment in this fashion. It seems that, if a
disconnected switch is flipped on the other side of a room, you should
not expect your inner listener to go out like a light, because the
switch ``obviously doesn't
change'' that which is the true cause of your talking
about an inner listener. Whatever you really are, you
don't expect the switch to mess with it.


 This is a \textit{large} step.


 If you deny that it is a reasonable step, you had better never go
near a switch again. But still, it's a large step.


 The key idea of reductionism is that our maps of the universe are
multi-level to save on computing power, but physics seems to be
strictly single-level. All our discourse about the universe takes place
using references far above the level of fundamental particles.


 The switch's flip \textit{does} change the
fundamental particles of your body and brain. It nudges them by whole
neutron diameters away from where they would have otherwise been.


 In ordinary life, we gloss a change this small by saying that the
switch ``doesn't affect
you.'' But it \textit{does} affect you. It changes
everything by whole neutron diameters! What could possibly be remaining
the same? Only the \textit{description} that you would give of the
higher levels of organization---the cells, the proteins, the spikes
traveling along a neural axon. As the map is far less detailed than the
territory, it must map many different states to the same description.


 Any reasonable sort of humanish \textit{description} of the brain
that talks about neurons and activity patterns (or even the
conformations of individual microtubules making up axons and dendrites)
won't change when you flip a switch on the other side
of the room. Nuclei are larger than neutrons, atoms are larger than
nuclei, and by the time you get up to talking about the
\textit{molecular} level, that tiny little gravitational force has
vanished from the list of things you bother to \textit{track}.


 But if you add up enough tiny little gravitational pulls, they
will eventually yank you across the room and tear you apart by tidal
forces, so clearly a small effect is \textit{not} ``no
effect at all.''


 Maybe the tidal force from that tiny little pull, by an
\textit{amazing} coincidence, pulls a single extra calcium ion just a
tiny bit closer to an ion channel, causing it to be pulled in just a
tiny bit sooner, making a single neuron fire infinitesimally sooner
than it would otherwise have done, a difference which amplifies
chaotically, finally making a whole neural spike occur that otherwise
wouldn't have occurred, sending you off on a different
train of thought, that triggers an epileptic fit, that kills you,
causing you to cease to be conscious\,\ldots


 If you add up a lot of tiny quantitative effects, you get a big
quantitative effect---big enough to mess with anything you care to
name. And so claiming that the switch has literally \textit{zero}
effect on the things you care about, is taking it too far.


 But with just one switch, the force exerted is vastly less than
thermal uncertainties, never mind quantum uncertainties. If you
don't expect your consciousness to flicker in and out
of existence as the result of thermal jiggling, then you certainly
shouldn't expect to go out like a light when someone
sneezes a kilometer away.


 The alert Bayesian will note that I have just made an argument
about \textit{expectations}, states of \textit{knowledge}, justified
\textit{beliefs} about what can and can't switch off
your consciousness.


 This doesn't necessarily destroy the Anti-Zombie
Argument. Probabilities are not certainties, but the \textit{laws of}
probability are theorems; if rationality says you can't
believe something on your current information, then that is a law, not
a suggestion.


 Still, this version of the Anti-Zombie Argument is weaker. It
doesn't have the nice, clean, absolutely clear-cut
status of, ``You can't possibly
eliminate consciousness while leaving all the atoms in \textit{exactly}
the same place.'' (Or for ``all the
atoms'' substitute ``all causes with
in-principle experimentally detectable effects,'' and
``same wavefunction'' for
``same place,'' etc.)


 But the new version of the Anti-Zombie Argument still carries. You
can say, ``I don't know what
consciousness really is, and I suspect I may be fundamentally confused
about the question. But if the word refers to anything at all, it
refers to something that is, among other things, the cause of my
talking about consciousness. Now, I don't know why I
talk about consciousness. But it happens inside my skull, and I expect
it has something to do with neurons firing. Or maybe, if I really
understood consciousness, I would have to talk about an even more
fundamental level than that, like microtubules, or neurotransmitters
diffusing across a synaptic channel. But still, that switch you just
flipped has an effect on my neurotransmitters and microtubules
that's much, much less than thermal noise at 310
Kelvin. So whatever the true cause of my talking about consciousness
may be, I don't expect it to be hugely affected by the
gravitational pull from that switch. Maybe it's just a
tiny little infinitesimal bit affected? But it's
certainly not going to go out like a light. I expect to go on talking
about consciousness in \textit{almost exactly} the same way afterward,
for \textit{almost exactly} the same reasons.''


 This application of the Anti-Zombie Principle is weaker. But
it's also much more general. And, in terms of sheer
common sense, correct.


 The reductionist and the substance dualist actually have two
different versions of the above statement. The reductionist furthermore
says, ``Whatever makes me talk about consciousness, it
seems likely that the important parts take place on a much higher
functional level than atomic nuclei. Someone who understood
consciousness could abstract away from individual neurons firing, and
talk about high-level cognitive architectures, and still describe how
my mind produces thoughts like `I think therefore I
am.' So nudging things around by the diameter of a
nucleon shouldn't affect my consciousness (except maybe
with very small probability, or by a very tiny amount, or not until
after a significant delay).''


 The substance dualist furthermore says,
``Whatever makes me talk about consciousness,
it's got to be something beyond the computational
physics we know, which means that it might very well involve quantum
effects. But still, my consciousness doesn't flicker on
and off whenever someone sneezes a kilometer away. If it did, I would
\textit{notice}. It would be like skipping a few seconds, or coming out
of a general anesthetic, or sometimes saying, `I
don't think therefore I'm
not.' So since it's a physical fact
that thermal vibrations don't disturb the stuff of my
awareness, I don't expect flipping the switch to
disturb it either.''


 Either way, you \textit{shouldn't} expect your
sense of awareness to vanish when someone says the word
``Abracadabra,'' even if that does
have some infinitesimal physical effect on your brain---


 But hold on! If you \textit{hear} someone say the word
``Abracadabra,'' that has a very
noticeable effect on your brain---so large, even your brain can notice
it. It may alter your internal narrative; you may think,
``Why did that person just say
`Abracadabra'?''


 Well, but \textit{still} you expect to go on talking about
consciousness in almost exactly the same way afterward, for almost
exactly the same reasons.


 And again, it's not that
``consciousness'' is being
\textit{equated} to ``that which makes you talk about
consciousness.'' It's just that
consciousness, \textit{among other things}, makes you talk about
consciousness. So anything that makes your consciousness go out like a
light should make you stop talking about consciousness.


 If we do something to you, where you don't see how
it could \textit{possibly} change your internal narrative---the little
voice in your head that sometimes says things like ``I
think therefore I am,'' whose words you can choose to
say aloud---then it shouldn't make you cease to be
conscious.


 And this is true even if the internal narrative is just
``pretty much the same,'' and the
causes of it are also pretty much the same; among the causes that are
pretty much the same is whatever you mean by
``consciousness.''


 If you're wondering where all this is going, and
why it's important to go to such tremendous lengths to
ponder such an obvious-seeming Generalized Anti-Zombie Principle, then
consider the following debate:

\begin{quotation}

 \textsc{Albert}: ``Suppose I replaced all the neurons in
your head with tiny robotic artificial neurons that had the same
connections, the same local input-output behavior, and analogous
internal state and learning rules.''


 \textsc{Bernice}: ``That's killing me!
There wouldn't be a conscious being there
anymore.''


 \textsc{Charles}: ``Well, there'd still be
a conscious being there, but it wouldn't be
\textit{me.}''


 \textsc{Sir Roger Penrose}: ``The thought experiment you
propose is impossible. You \textit{can't} duplicate the
behavior of neurons without tapping into quantum gravity. That said,
there's not much point in me taking further part in
this conversation.'' \textit{(Wanders away.)}


 \textsc{Albert}: ``Suppose that the replacement is carried
out one neuron at a time, and the swap occurs so fast that it
doesn't make any difference to global
processing.''


 \textsc{Bernice}: ``How could that possibly be the
case?''


 \textsc{Albert}: ``The little robot swims up to the
neuron, surrounds it, scans it, learns to duplicate it, and then
suddenly takes over the behavior, between one spike and the next. In
fact, the imitation is \textit{so} good that your outward behavior is
just the same as it would be if the brain were left undisturbed. Maybe
not \textit{exactly} the same, but the causal impact is much less than
thermal noise at 310 Kelvin.''


 \textsc{Charles}: ``So what?''


 \textsc{Albert}: ``So don't your beliefs
violate the Generalized Anti-Zombie Principle? Whatever just happened,
it didn't change your internal narrative!
You'll go around talking about consciousness for
exactly the same reason as before.''


 \textsc{Bernice}: ``Those little robots are a Zombie
Master. They'll make me talk about consciousness even
though I'm not conscious. The Zombie World is possible
if you allow there to be an added, extra, experimentally detectable
Zombie Master---which those robots \textit{are}.''


 \textsc{Charles}: ``Oh, that's not right,
Bernice. The little robots aren't plotting how to fake
consciousness, or processing a corpus of text from human amateurs.
They're doing the same thing neurons do, just in
silicon instead of carbon.''


 \textsc{Albert}: ``Wait, didn't you just
agree with me?''


 \textsc{Charles}: ``I never said the new person
wouldn't be conscious. I said it
wouldn't be \textit{me.}''


 \textsc{Albert}: ``Well, obviously the Anti-Zombie
Principle generalizes to say that this operation hasn't
disturbed the true cause of your talking about this \textit{me}
thing.''


 \textsc{Charles}: ``Uh-uh! Your operation certainly did
disturb the true cause of my talking about consciousness. It
substituted a \textit{different} cause in its place, the robots. Now,
just because that new cause \textit{also} happens to be
conscious---talks about consciousness for the same \textit{generalized}
reason---doesn't mean it's the
\textit{same} cause that was originally there.''


 \textsc{Albert}: ``But I wouldn't even
have to \textit{tell} you about the robot operation. You
wouldn't \textit{notice.} If you think, going on
introspective evidence, that you are in an important sense
`the same person' that you were five
minutes ago, and I do something to you that doesn't
change the introspective evidence available to you, then your
conclusion that you are the same person that you were five minutes ago
should be equally justified. Doesn't the Generalized
Anti-Zombie Principle say that if I do something to you that alters
your consciousness, let alone makes you a completely different person,
then you ought to \textit{notice} somehow?''


 \textsc{Bernice}: ``Not if you replace me with a Zombie
Master. Then there's no one there \textit{to}
notice.''


 \textsc{Charles}: ``Introspection isn't
perfect. Lots of stuff goes on inside my brain that I
don't notice.''


 \textsc{Albert}: ``You're postulating
epiphenomenal facts about consciousness and
identity!''


 \textsc{Bernice}: ``No I'm not! I can
experimentally detect the difference between neurons and
robots.''


 \textsc{Charles}: ``No I'm not! I can
experimentally detect the moment when the old me is replaced by a new
person.''


 \textsc{Albert}: ``Yeah, and I can detect the switch
flipping! You're detecting something that
doesn't \textit{make a noticeable difference} to the
\textit{true cause} of your talk about consciousness and personal
identity. And the proof is, you'll talk just the same
way afterward.''


 \textsc{Bernice}: ``That's because of your
robotic Zombie Master!''

{
 \textsc{Charles}: ``Just because two people talk about
`personal identity' for similar reasons
 doesn't make them the same person.''}
\end{quotation}


 I think the Generalized Anti-Zombie Principle supports
Albert's position, but the reasons shall have to wait
for future essays. I need other prerequisites, and besides, this essay
is already too long.


 But you see the importance of the question, ``How
far can you generalize the Anti-Zombie Argument and have it still be
valid?''


 The makeup of future galactic civilizations may be determined by
the answer\,\ldots

\myendsectiontext


\bigskip

\mysection{GAZP vs.\ GLUT}

{
 In ``The Unimagined Preposterousness of
Zombies,'' Daniel Dennett says:\footnote{Daniel C. Dennett, ``The Unimagined
Preposterousness of Zombies,'' \textit{Journal of
Consciousness Studies} 2 (4 1995): 322--26.\comment{1}}}

\begin{quote}
{
 To date, several philosophers have told me that they plan to
accept my challenge to offer a non-question-begging defense of zombies,
but the only one I have seen so far involves postulating a
``logically possible'' but fantastic
being---a descendent of Ned Block's Giant Lookup Table
fantasy\,\ldots}
\end{quote}


 A Giant Lookup Table, in programmer's parlance, is
when you implement a function as a giant table of inputs and outputs,
usually to save on runtime computation. If my program needs to know the
multiplicative product of two inputs between 1 and 100, I can write a
multiplication algorithm that computes each time the function is
called, or I can precompute a Giant Lookup Table with 10,000 entries
and two indices. There are times when you \textit{do} want to do this,
though not for multiplication---times when you're going
to reuse the function a lot and it doesn't have many
possible inputs; or when clock cycles are cheap while
you're initializing, but very expensive while
executing.


 Giant Lookup Tables get very large, very fast. A \textsc{glut} of all
possible twenty-ply conversations with ten words per remark, using only
850-word Basic English, would require $7.6 \times 10^{585}$ entries.


 Replacing a human brain with a Giant Lookup Table of all possible
sense inputs and motor outputs (relative to some fine-grained
digitization scheme) would require an \textit{unreasonably large
amount} of memory storage. But ``in
principle,'' as philosophers are fond of saying, it
could be done.


 The \textsc{glut} is not a zombie in the classic sense, because it is
microphysically dissimilar to a human. (In fact, a \textsc{glut}
can't \textit{really} run on the same physics as a
human; it's too large to fit in our universe. For
philosophical purposes, we shall ignore this and suppose a supply of
unlimited memory storage.)


 But is the \textsc{glut} a zombie at \textit{all}? That is, does it behave
exactly like a human without being conscious?


 The \textsc{glut}-ed body's tongue talks about
consciousness. Its fingers write philosophy papers. In every way, so
long as you don't peer inside the skull, the \textsc{glut} seems
just like a human\,\ldots which certainly seems like a valid example of a
zombie: it behaves just like a human, but there's no
one home.


 Unless the \textsc{glut} is conscious, in which case it
wouldn't be a valid example.


 I can't recall ever seeing \textit{anyone} claim
that a \textsc{glut} is conscious. (Admittedly my reading in this area is not up
to professional grade; feel free to correct me.) Even people who are
accused of being (gasp!) functionalists don't claim
that \textsc{glut}s can be conscious.


 \textsc{Glut}s are the reductio ad absurdum to anyone who suggests that
consciousness \textit{is simply} an input-output pattern, thereby
disposing of all troublesome worries about what goes on inside.


 So what does the Generalized Anti-Zombie Principle (\textsc{gazp}) say
about the Giant Lookup Table (\textsc{glut})?


 At first glance, it would seem that a \textsc{glut} is the very archetype
of a Zombie Master---a distinct, additional, detectable, non-conscious
system that animates a zombie and makes it talk about consciousness for
\textit{different} reasons.


 In the interior of the \textsc{glut}, there's merely a very
simple computer program that looks up inputs and retrieves outputs.
Even talking about a ``simple computer
program'' is overshooting the mark, in a case like
this. A \textsc{glut} is more like ROM than a CPU. We could equally well talk
about a series of switched tracks by which some balls roll out of a
previously stored stack and into a trough---\textit{period};
that's \textit{all} the \textsc{glut} does.


 A spokesperson from People for the Ethical Treatment of Zombies
replies: ``Oh, that's what all the
anti-mechanists say, isn't it? That when you look in
the brain, you just find a bunch of neurotransmitters opening ion
channels? If ion channels can be conscious, why not levers and balls
rolling into bins?''


 ``The problem isn't the
levers,'' replies the functionalist,
``the problem is that a \textsc{glut} has the \textit{wrong
pattern} of levers. You need levers that implement things like, say,
formation of beliefs about beliefs, or self-modeling\,\ldots Heck, you
need the ability to write things to memory just so that time can pass
for the computation. Unless you think it's possible to
program a conscious being in Haskell.\footnote{Edit 2017: While a conscious being could not be programmed as one Haskell function called once, repeated calling of a function in Haskell would allow this.  $f(M \times S) \to M \times A$ where $M$ is the memory, $S$ is the sensory input and $A$ is the action allows a Haskell function to update memory and choose an action.}''


 ``I don't know about
that,'' says the \textsc{petz} spokesperson,
``all I know is that this so-called zombie writes
philosophical papers about consciousness. Where do these philosophy
papers come from, if not from consciousness?''


 Good question! Let us ponder it deeply.


 There's a game in physics called
Follow-The-Energy. Richard Feynman's father played it
with young Richard:\footnote{\url{http://www.textbookleague.org/103feyn.htm}}

\begin{quotation}

 It was the kind of thing my father would have talked about:
``What makes it go? Everything goes because the Sun is
shining.'' And then we would have fun discussing it:


 ``No, the toy goes because the spring is wound
up,'' I would say. ``How did the
spring get wound up?'' he would ask.


 ``I wound it up.''


 ``And how did you get
moving?''


 ``From eating.''

{
 ``And food grows only because the Sun is shining.
So it's because the Sun is shining that all these
things are moving.'' That would get the concept
across that motion is simply the \textit{transformation} of the
Sun's power.\footnote{Richard P. Feynman, ``Judging Books by Their
Covers,'' in \textit{Surely You're
  Joking, Mr. Feynman!} (New York: W. W. Norton \& Company, 1985).\comment{2}}}
\end{quotation}


 When you get a little older, you learn that energy is conserved,
never created or destroyed, so the notion of \textit{using up} energy
doesn't make much sense. You can never change the total
amount of energy, so in what sense are you \textit{using} it?


 So when physicists grow up, they learn to play a new game called
Follow-The-Negentropy---which is really the same game they were playing
all along; only the rules are mathier, the game is more useful, and the
principles are harder to wrap your mind around conceptually.


 Rationalists learn a game called Follow-The-Improbability, the
grownup version of ``How Do You
Know?'' The rule of the rationalist's
game is that every improbable-seeming belief needs an equivalent amount
of evidence to justify it. (This game has \textit{amazingly similar}
rules to Follow-The-Negentropy.)


 Whenever someone violates the rules of the
rationalist's game, you can find a place in their
argument where a quantity of improbability appears from nowhere; and
this is as much a sign of a problem as, oh, say, an ingenious design of
linked wheels and gears that keeps itself running forever.


 The one comes to you and says: ``I believe with
firm and abiding faith that there's an object in the
asteroid belt, one foot across and composed entirely of chocolate cake;
you can't prove that this is
impossible.'' But, unless the one had access to some
kind of evidence for this belief, it would be highly improbable for a
correct belief to form \textit{spontaneously}. So either the one can
point to evidence, or the belief won't turn out to be
true. ``But you can't prove
it's \textit{impossible} for my mind to spontaneously
generate a belief that happens to be correct!'' No,
but that kind of spontaneous generation is \textit{highly improbable},
just like, oh, say, an egg unscrambling itself.


 In Follow-The-Improbability, it's highly
suspicious to even \textit{talk} about a specific hypothesis without
having had enough evidence to narrow down the space of possible
hypotheses. Why aren't you giving equal air time to a
decillion other equally plausible hypotheses? You need sufficient
evidence to find the ``chocolate cake in the asteroid
belt'' hypothesis in the hypothesis space---otherwise
there's no reason to give it more air time than a
trillion other candidates like
``There's a wooden dresser in the
asteroid belt'' or ``The Flying
Spaghetti Monster threw up on my sneakers.''


 In Follow-The-Improbability, you are not allowed to pull out big
complicated specific hypotheses from thin air without \textit{already}
having a corresponding amount of evidence; because it's
not realistic to suppose that you could spontaneously start discussing
the \textit{true} hypothesis by \textit{pure coincidence.}


 A philosopher says, ``This
zombie's skull contains a Giant Lookup Table of all the
inputs and outputs for some human's
brain.'' This is a very \textit{large} improbability.
So you ask, ``How did this improbable event occur?
Where did the \textsc{glut} come from?''


 Now this is not standard philosophical procedure for thought
experiments. In standard philosophical procedure, you are allowed to
postulate things like ``Suppose you were riding a beam
of light\,\ldots'' without worrying about physical
possibility, let alone mere improbability. But in this case, the origin
of the \textsc{glut} matters; and that's why
it's important to understand the motivating question,
``Where did the improbability come
from?''


 The obvious answer is that you took a computational specification
of a human brain, and used \textit{that} to precompute the Giant Lookup
Table. (Thereby creating uncounted googols of human beings, some of
them in extreme pain, the supermajority gone quite mad in a universe of
chaos where inputs bear no relation to outputs. But damn the ethics,
this is for \textit{philosophy}.)


 In this case, the \textsc{glut} \textit{is} writing papers about
consciousness because of a conscious algorithm. The \textsc{glut} is no zombie,
any more than a cellphone is a zombie because it can talk about
consciousness while being just a small consumer electronic device. The
cellphone is just transmitting philosophy speeches from whoever happens
to be on the other end of the line. A \textsc{glut} generated from an originally
human brain-specification is doing the same thing.


 ``All right,'' says the
philosopher, ``the \textsc{glut} was generated randomly, and
\textit{just happens} to have the same input-output relations as some
reference human.''


 How, exactly, did you randomly generate the \textsc{glut}?


 ``We used a true randomness source---a quantum
device.''


 But a quantum device just implements the Branch Both Ways
instruction; when you generate a bit from a quantum randomness source,
the deterministic result is that one set of universe-branches (locally
connected amplitude clouds) see 1, and another set of universes see 0.
Do it 4 times, create 16 (sets of) universes.


 So, really, this is like saying that you got the \textsc{glut} by writing
down all possible \textsc{glut}-sized sequences of 0s and 1s, in a really damn
huge bin of lookup tables; and then reaching into the bin, and
\textit{somehow} pulling out a \textsc{glut} that happened to correspond to a
human brain-specification. Where did the improbability come from?


 Because if this \textit{wasn't just a
coincidence}{}---if you had some reach-into-the-bin function that
pulled out a human-corresponding \textsc{glut} by \textit{design}, not just
chance---then that reach-into-the-bin function is probably conscious,
and so the \textsc{glut} is again a cellphone, not a zombie.
It's connected to a human at two removes, instead of
one, but it's still a cellphone! Nice try at concealing
the source of the improbability there!


 Now behold where Follow-The-Improbability has taken us: where is
the source of this body's tongue talking about an inner
listener? The consciousness isn't in the lookup table.
The consciousness isn't in the factory that
manufactures lots of possible lookup tables. The consciousness was in
whatever \textit{pointed to one particular already-manufactured lookup
table}, and said, ``Use \textit{that}
one!''


 You can see why I introduced the game of Follow-The-Improbability.
Ordinarily, when we're talking to a person, we tend to
think that whatever is inside the skull must be
``where the consciousness is.''
It's only by playing Follow-The-Improbability that we
can realize that the real source of the conversation
we're having is that-which-is-responsible-for the
\textit{improbability} of the conversation---however distant in time or
space, as the Sun moves a wind-up toy.


 ``No, no!'' says the
philosopher. ``In the thought experiment, they
aren't randomly generating lots of \textsc{glut}s, and then
using a conscious algorithm to pick out one \textsc{glut} that seems humanlike!
I am \textit{specifying} that, in this thought experiment, they reach
into the inconceivably vast \textsc{glut} bin, and \textit{by pure chance} pull
out a \textsc{glut} that is identical to a human brain's inputs
and outputs! \textit{There!} I've got you cornered now!
You can't play Follow-The-Improbability any
further!''


 Oh. So your \textit{specification} is the source of the
improbability here.


 When we play Follow-The-Improbability again, we end up
\textit{outside the thought experiment}, looking at the
\textit{philosopher.}


 That which points to the one \textsc{glut} that talks about consciousness,
out of all the vast space of possibilities, is now\,\ldots the conscious
person asking us to imagine this whole scenario. And our own brains,
which will fill in the blank when we imagine, ``What
will this \textsc{glut} say in response to `Talk about your inner
listener'?''


 The moral of this story is that when you follow back discourse
about ``consciousness,'' you
generally find consciousness. It's not always right in
front of you. Sometimes it's very cleverly hidden. But
it's there. Hence the Generalized Anti-Zombie
Principle.


 If there is a Zombie Master in the form of a chatbot that
processes and remixes amateur human discourse about
``consciousness,'' the humans who
generated the original text corpus are conscious.


 If someday you come to understand consciousness, and look back,
and see that there's a program you can write that will
output confused philosophical discourse that sounds an awful lot like
humans without itself being conscious---then when I ask
``How did this program come to sound similar to
humans?'' the answer is that \textit{you} wrote it to
sound similar \textit{to conscious humans}, rather than choosing on the
criterion of similarity to something else. This doesn't
mean your little Zombie Master is conscious---but it does mean I can
find consciousness somewhere in the universe by tracing back the chain
of causality, which means we're not entirely in the
Zombie World.


 But suppose someone actually \textit{did} reach into a \textsc{glut}-bin
and by \textit{genuinely pure }\textit{chance} pulled out a \textsc{glut} that
wrote philosophy papers?


 Well, then it wouldn't be conscious. In my humble
opinion.


 I mean, there's got to be more to it than inputs
and outputs.


 Otherwise even a \textsc{glut} would be conscious, right?


 Oh, and for those of you wondering how this sort of thing relates
to my day job\,\ldots


 In this line of business you meet an awful lot of people who think
that an arbitrarily generated powerful AI will be
``moral.'' They
can't agree among themselves on why, or what they mean
by the word ``moral''; but they all
agree that doing Friendly AI theory is unnecessary. And when you ask
them how an arbitrarily generated AI ends up with moral outputs, they
proffer elaborate rationalizations aimed at AIs of that which they deem
``moral''; and there are all sorts
of problems with this, but the number one problem is,
``Are you \textit{sure} the AI would follow the same
line of thought you invented to argue human morals, when, unlike you,
the AI doesn't start out knowing what \textit{you} want
it to rationalize?'' You could call the
counter-principle Follow-The-Decision-Information, or something along
those lines. You can account for an AI that does improbably nice things
by telling me how you chose the AI's design from a huge
space of possibilities, but otherwise the improbability is being pulled
out of nowhere---though more and more heavily disguised, as
rationalized premises are rationalized in turn.


 So I've already done a whole series of essays
which I myself generated using Follow-The-Improbability. But I
didn't spell out the rules \textit{explicitly} at that
time, because I hadn't done the thermodynamics essays
yet\,\ldots


 Just thought I'd mention that.
It's amazing how many of my essays coincidentally turn
out to include ideas surprisingly relevant to discussion of Friendly AI
theory\,\ldots if you believe in coincidence.

\myendsectiontext


\bigskip

\mysection{Belief in the Implied Invisible}


 One generalized lesson \textit{not} to learn from the Anti-Zombie
Argument is, ``Anything you can't see
doesn't exist.'' 


 It's tempting to conclude the general rule. It
would make the Anti-Zombie Argument much simpler, on future occasions,
if we could take this as a premise. But unfortunately
that's just not Bayesian.


 Suppose I transmit a photon out toward infinity, not aimed at any
stars, or any galaxies, pointing it toward one of the great voids
between superclusters. Based on standard physics, in other words, I
don't expect this photon to intercept anything on its
way out. The photon is moving at light speed, so I
can't chase after it and capture it again.


 If the expansion of the universe is accelerating, as current
cosmology holds, there will come a future point where I
don't expect to be able to interact with the photon
even in principle---a future time beyond which I don't
expect the photon's future light cone to intercept my
world-line. Even if an alien species captured the photon and rushed
back to tell us, they couldn't travel fast enough to
make up for the accelerating expansion of the universe.


 Should I believe that, in the moment where I can no longer
interact with it even in principle, the photon disappears?


 No.


 It would violate Conservation of Energy. And the Second Law of
Thermodynamics. And just about every other law of physics. And probably
the Three Laws of Robotics. It would imply the photon knows I care
about it and knows exactly when to disappear.


 It's a \textit{silly idea}.


 But if you can believe in the continued existence of photons that
have become experimentally undetectable to you, why
doesn't this imply a general license to believe in the
invisible?


 (If you want to think about this question on your own, do so
before reading on\,\ldots)


 Though I failed to Google a source, I remember reading that when
it was first proposed that the Milky Way was our
\textit{galaxy}{}---that the hazy river of light in the night sky was
made up of millions (or even billions) of stars---that
Occam's Razor was invoked against the new hypothesis.
Because, you see, the hypothesis vastly multiplied the number of
``entities'' in the believed
universe. Or maybe it was the suggestion that
``nebulae''---those hazy patches
seen through a telescope---might be galaxies full of stars, that got
the invocation of Occam's Razor.

{
 \textit{Lex parsimoniae: Entia non sunt multiplicanda praeter
necessitatem.}}


 That was Occam's original formulation, the law of
parsimony: Entities should not be multiplied beyond necessity.


 If you postulate billions of stars that no one has ever believed
in before, you're multiplying entities,
aren't you?


 No. There are two Bayesian formalizations of
Occam's Razor: Solomonoff induction, and Minimum
Message Length. Neither penalizes galaxies for being big.


 Which they had better not do! One of the lessons of history is
that what-we-call-reality keeps turning out to be bigger and bigger and
huger yet. Remember when the Earth was at the center of the universe?
Remember when no one had invented Avogadro's number? If
Occam's Razor was weighing against the multiplication
of entities every time, we'd have to start doubting
Occam's Razor, because it would have consistently
turned out to be wrong.


 In Solomonoff induction, the complexity of your model is the
amount of \textit{code} in the computer program you have to write to
simulate your model. The amount of \textit{code}, not the amount of RAM
it uses or the number of cycles it takes to compute. A model of the
universe that contains billions of galaxies containing billions of
stars, each star made of a billion trillion decillion quarks, will take
a lot of RAM to run---but the \textit{code} only has to describe the
behavior of the quarks, and the stars and galaxies can be left to run
themselves. I am speaking semi-metaphorically here---there are things
in the universe besides quarks\footnote{Edit 2017: The full list of understood physics is the Standard Model (which includes quantum mechanics) and General Relativity.  The Standard Model has six quarks (up, down, charm, strange, top and bottom), six leptons (electron, muon, tau, electron neutrino, muon neutrino, tau neutrino), the bosons (gluon, photon, Z boson, W boson and Higgs boson) and three forces (electromagnetic, weak and strong).  The quarks and leptons have opposite sign antiparticles, and the quarks come in three varieties that are the same except for `color'.  The Standard Model can be described in the Lagrangian form that will fit on a single sheet of paper (\url{https://www.symmetrymagazine.org/article/the-deconstructed-standard-model-equation}).  General relativity can be described with the Einstein field equations that fit on one line. The object you are reading this on is made of electrons, protons (each made of two up quarks and one down quark), and neutrons (each made of one up quark and two down quarks).}---but the point is, postulating an extra
billion galaxies doesn't count against the size of your
code, if you've already described one galaxy. It just
takes a bit more RAM, and Occam's Razor
doesn't care about RAM.


 Why not? The Minimum Message Length formalism, which is nearly
equivalent to Solomonoff induction, may make the principle clearer: If
you have to tell someone how your model of the universe works, you
don't have to individually specify the location of each
quark in each star in each galaxy. You just have to write down some
equations. The amount of ``stuff''
that obeys the equation doesn't affect how long it
takes to write the equation down. If you encode the equation into a
file, and the file is 100 bits long, then there are
$2^{100}$ other models that would be around the same file
size, and you'll need roughly 100 bits of supporting
evidence. You've got a limited amount of probability
mass; and a priori, you've got to divide that mass up
among all the messages you could send; and so postulating a model from
within a model space of $2^{100}$ alternatives, means
you've got to accept a $2^{-100}$ prior
probability penalty---but having more galaxies doesn't
add to this.


 Postulating billions of stars in billions of galaxies
doesn't affect the length of your message describing
the overall behavior of all those galaxies. So you
don't take a probability hit from having the
\textit{same} equations describing more things. (So long as your
model's predictive successes aren't
sensitive to the exact initial conditions. If you've
got to specify the exact positions of all the quarks for your model to
predict as well as it does, the extra quarks do count as a hit.)


 If you suppose that the photon disappears when you are no longer
looking at it, this is an \textit{additional law} in your model of the
universe. It's the laws that are
``entities,'' costly under the laws
of parsimony. Extra quarks are free.


 So does it boil down to, ``I believe the photon
goes on existing as it wings off to nowhere, because my priors say
it's simpler for it to go on existing than to
disappear''?


 This is what I thought at first, but on reflection,
it's not quite right. (And not just because it opens
the door to obvious abuses.)

{
 I would boil it down to a distinction between belief in the
\textit{implied invisible}, and belief in the \textit{additional
invisible}.}


 When you believe that the photon goes on existing as it wings out
to infinity, you're not believing that as an
\textit{additional} fact.


 What you believe (assign probability to) is a set of simple
equations; you believe these equations describe the universe. You
believe these equations because they are the simplest equations you
could find that describe the evidence. These equations are
\textit{highly} experimentally testable; they explain huge mounds of
evidence visible in the past, and predict the results of many
observations in the future.


 You believe these equations, and it is a \textit{logical
implication} of these equations that the photon goes on existing as it
wings off to nowhere, so you believe that as well.


 Your priors, or even your probabilities, don't
\textit{directly} talk about the photon. What you assign probability to
is not the photon, but the general laws. When you assign probability to
the laws of physics as we know them, you \textit{automatically}
contribute that same probability to the photon continuing to exist on
its way to nowhere---if you believe the logical implications of what
you believe.


 It's not that you believe in the invisible
\textit{as such}, from reasoning about invisible things. Rather the
experimental evidence supports certain laws, and belief in those laws
logically implies the existence of certain entities that you
can't interact with. This is belief in the
\textit{implied invisible.}


 On the other hand, if you believe that the photon is eaten out of
existence by the Flying Spaghetti Monster---maybe on just this one
occasion---or even if you believed without reason that the photon hit a
dust speck on its way out---then you would be believing in a specific
extra invisible event, on its own. If you thought that this sort of
thing happened in general, you would believe in a specific extra
invisible law. This is belief in the \textit{additional invisible}.


 To make it clear why you would sometimes want to think about
implied invisibles, suppose you're going to launch a
spaceship, at nearly the speed of light, toward a faraway supercluster.
By the time the spaceship gets there and sets up a colony, the
universe's expansion will have accelerated too much for
them to ever send a message back. Do you deem it worth the purely
altruistic effort to set up this colony, for the sake of all the people
who will live there and be happy? Or do you think the spaceship blips
out of existence before it gets there? This could be a very real
question at some point.


 The whole matter would be a lot simpler, admittedly, if we could
just rule out the existence of entities we can't
interact with, once and for all---have the universe stop existing at
the edge of our telescopes. But this requires us to be very silly.


 Saying that you shouldn't ever need a separate and
additional belief about invisible things---that you only believe
invisibles that are \textit{logical implications} of general laws which
are themselves testable, and even then, don't have any
further beliefs about them that are not logical implications of visibly
testable general rules---actually does seem to rule out all abuses of
belief in the invisible, when applied correctly.


 Perhaps I should say, ``you should assign
unaltered prior probability to additional
invisibles,'' rather than saying,
``do not believe in them.'' But if
you think of a \textit{belief} as something evidentially additional,
something you bother to track, something where you bother to count up
support for or against, then it's questionable whether
we should ever have additional beliefs about additional invisibles.


 There are exotic cases that break this in theory. (E.g.: The
epiphenomenal demons are watching you, and will torture 3 $\uparrow
\uparrow \uparrow $ 3 victims for a year, somewhere you
can't ever verify the event, if you ever say the word
``Niblick.'') But I
can't think of a case where the principle fails in
human practice.

\myendsectiontext

\mysection{Zombies: The Movie}


 \textsc{Fade in} around a serious-looking group of uniformed military
 officers. At the head of the table, a senior, heavy-set man,
 \textsc{General Fred}, speaks.


 \textsc{General Fred}: The reports are confirmed. New York has been overrun\,\ldots by \textit{zombies}.


 \textsc{Colonel Todd}: Again? But we just had a zombie invasion 28 days
ago!


 \textsc{General Fred}: These zombies\,\ldots are different.
They're\,\ldots \textit{philosophical} zombies.


 \textsc{Captain Mudd}: Are they filled with rage, causing them to bite
people?


 \textsc{Colonel Todd}: Do they lose all capacity for reason?


 \textsc{General Fred}: No. They behave\,\ldots \textit{exactly} like we do\,\ldots except that they're not conscious.


 (\textit{Silence grips the table.})


 \textsc{Colonel Todd}: Dear God.


 \textsc{General Fred} moves over to a computerized display.


 \textsc{General Fred}: This is New York City, two weeks ago.


 The display shows crowds bustling through the streets, people
eating in restaurants, a garbage truck hauling away trash.


 \textsc{General Fred}: \textit{This\,\ldots} is New York City\,\ldots
\textit{now.}


 The display changes, showing a crowded subway train, a group of
students laughing in a park, and a couple holding hands in the
sunlight.


 \textsc{Colonel Todd}: It's worse than I imagined.


 \textsc{Captain Mudd}: How can you tell, exactly?


 \textsc{Colonel Todd}: I've never seen anything so brutally
ordinary.


 A lab-coated \textsc{Scientist} stands up at the foot of the table.


 \textsc{Scientist}: The zombie disease eliminates consciousness without
changing the brain in any way. We've been trying to
understand how the disease is transmitted. Our conclusion is that,
since the disease attacks dual properties of ordinary matter, it must,
itself, operate outside our universe. We're dealing
with an \textit{epiphenomenal virus}.


 \textsc{General Fred}: Are you sure?


 \textsc{Scientist}: As sure as we can be in the total absence of evidence.


 \textsc{General Fred}: All right. Compile a report on every epiphenomenon
ever observed. What, where, and who. I want a list of everything that
hasn't happened in the last fifty years.


 \textsc{Captain Mudd}: If the virus is epiphenomenal, how do we know it
exists?


 \textsc{Scientist}: The same way we know \textit{we're}
conscious.


 \textsc{Captain Mudd}: Oh, okay.


 \textsc{General Fred}: Have the doctors made any progress on finding an
epiphenomenal cure?


 \textsc{Scientist}: They've tried every placebo in the
book. No dice. Everything they do has an effect.


 \textsc{General Fred}: Have you brought in a homeopath?


 \textsc{Scientist}: I tried, sir! I couldn't find any!


 \textsc{General Fred}: Excellent. And the Taoists?


 \textsc{Scientist}: They refuse to do anything!


 \textsc{General Fred}: Then we may yet be saved.


 \textsc{Colonel Todd}: What about David Chalmers? Shouldn't
he be here?


 \textsc{General Fred}: Chalmers\,\ldots was one of the first victims.


 \textsc{Colonel Todd}: Oh no.


 (\textit{Cut} to the \textsc{interior} of a cell, completely walled in by
reinforced glass, where \textsc{David Chalmers} paces back and forth.)


 \textsc{Doctor}: David! David Chalmers! Can you hear me?


 \textsc{Chalmers}: Yes.


 \textsc{Nurse}: It's no use, doctor.


 \textsc{Chalmers}: I'm perfectly fine. I've
been introspecting on my consciousness, and I can't
detect any difference. I \textit{know} I would be expected to say that,
but---


 The \textsc{Doctor} turns away from the glass screen in horror.

{
 \textsc{Doctor}: His words, they\,\ldots they \textit{don't
mean anything.}}


 \textsc{Chalmers}: This is a grotesque distortion of my philosophical
views. This sort of thing can't actually happen!


 \textsc{Doctor}: Why not?


 \textsc{Nurse}: Yes, why not?


 \textsc{Chalmers}: Because---


 (\textit{Cut} to two \textsc{Police Officers}, guarding a dirt road leading
up to the imposing steel gate of a gigantic concrete complex. On their
uniforms, a badge reads \textsc{Bridging Law Enforcement Agency}.)


 \textsc{Officer 1}: You've got to watch out for those
clever bastards. They look like humans. They can talk like humans.
They're identical to humans on the atomic level. But
they're not human.


 \textsc{Officer 2}: Scumbags.


 The huge noise of a throbbing engine echoes over the hills. Up
rides the \textsc{Man} on a white motorcycle. The \textsc{Man} is wearing black
sunglasses and a black leather business suit with a black leather tie
and silver metal boots. His white beard flows in the wind. He pulls to
a halt in front of the gate.


 The \textsc{Officers} bustle up to the motorcycle.


 \textsc{Officer 1}: State your business here.


 \textsc{Man}: Is this where you're keeping David Chalmers?


 \textsc{Officer 2}: What's it to you? You a friend of his?


 \textsc{Man}: Can't say I am. But even zombies have
rights.


 \textsc{Officer 1}: All right, buddy, let's see your
qualia.


 \textsc{Man}: I don't have any.


 \textsc{Officer 2} suddenly pulls a gun, keeping it trained on the \textsc{Man}.


 \textsc{Officer 2}: Aha! A zombie!


 \textsc{Officer 1}: No, zombies claim to have qualia.


 \textsc{Officer 2}: So he's an ordinary human?


 \textsc{Officer 1}: No, they also claim to have qualia.


 The \textsc{Officers} look at the \textsc{Man}, who waits calmly.


 \textsc{Officer 2}: Um\,\ldots


 \textsc{Officer 1}: Who \textit{are} you?


 \textsc{Man}: I'm Daniel Dennett, bitches.

{
 Seemingly from nowhere, \textsc{Dennett} pulls a sword and slices \textsc{Officer
2}'s gun in half with a steely noise. \textsc{Officer 1} begins
to reach for his own gun, but \textsc{Dennett} is suddenly standing behind
\textsc{Officer 1} and chops with a fist, striking the junction of \textsc{Officer
1}'s shoulder and neck. \textsc{Officer 1} drops to the ground.}


 \textsc{Officer 2} steps back, horrified.


 \textsc{Officer 2}: That's not possible!
How'd you do that?


 \textsc{Dennett}: I am one with my body.


 \textsc{Dennett} drops \textsc{Officer 2} with another blow, and strides toward the
gate. He looks up at the imposing concrete complex, and grips his sword
tighter.


 \textsc{Dennett} \textit{(quietly to himself)}: There is a spoon.


 (\textit{Cut} back to \textsc{General Fred} and the other military
officials.)


 \textsc{General Fred}: I've just received the reports.
We've lost Detroit.


 \textsc{Captain Mudd}: I don't want to be the one to say
``Good riddance,'' but---


 \textsc{General Fred}: Australia has been\,\ldots \textit{reduced to atoms.}


 \textsc{Colonel Todd}: The epiphenomenal virus is spreading faster.
Civilization itself threatens to dissolve into total normality. We
could be looking at the middle of humanity.


 \textsc{Captain Mudd}: Can we negotiate with the zombies?


 \textsc{General Fred}: We've sent them messages. They sent
only a single reply.


 \textsc{Captain Mudd}: Which was\,\ldots ?


 \textsc{General Fred}: It's on its way now.


 An orderly brings in an envelope, and hands it to \textsc{General Fred}.


 \textsc{General Fred} opens the envelope, takes out a single sheet of
paper, and reads it.


 Silence envelops the room.


 \textsc{Captain Mudd}: What's it say?


 \textsc{General Fred}: It says\,\ldots that \textit{we're}
the ones with the virus.


 (A silence falls.)


 \textsc{Colonel Todd} raises his hands and stares at them.


 \textsc{Colonel Todd}: My God, it's true.
It's true. I\,\ldots


 (A tear rolls down \textsc{Colonel Todd}'s cheek.)


 \textsc{Colonel Todd}: I don't feel anything.


 The screen goes black.


 The sound goes silent.


 The movie continues exactly as before.

\myendsectiontext

\mysection{Excluding the Supernatural}
\label{excluding_the_supernatural}


 Occasionally, you hear someone claiming that creationism should
not be taught in schools, especially not as a competing hypothesis to
evolution, because creationism is \textit{a priori and automatically}
excluded from scientific consideration, in that it invokes the
``supernatural.'' 


 So\,\ldots is the idea here, that creationism \textit{could} be
true, but \textit{even if it were true}, you wouldn't
be \textit{allowed} to teach it in science class, because science is
only about ``natural'' things?


 It seems clear enough that this notion stems from the desire to
avoid a confrontation between science and religion. You
don't want to come right out and say that science
doesn't teach Religious Claim $X$ because $X$ has been
tested by the scientific method and found false. So instead, you can\,\ldots um\,\ldots claim that science is excluding hypothesis $X$ a priori.
That way you don't have to discuss how experiment has
falsified $X$ a posteriori.


 Of course this plays right into the creationist claim that
Intelligent Design isn't getting a fair shake from
science---that science has \textit{prejudged} the issue in favor of
atheism, regardless of the evidence. If science excluded Intelligent
Design a priori, this would be a justified complaint!


 But let's back up a moment. The one comes to you
and says: ``Intelligent Design is excluded from being
science a priori, because it is
`supernatural,' and science only deals
in `natural'
explanations.''


 What exactly do they mean,
``supernatural''? Is any explanation
invented by someone with the last name
``Cohen'' a supernatural one? If
we're going to summarily kick a set of hypotheses out
of science, what is it that we're supposed to exclude?


 By \textit{far} the best definition I've ever
heard of the supernatural is Richard Carrier's: A
``supernatural'' explanation appeals
to \textit{ontologically basic mental things}, mental entities that
cannot be reduced to nonmental entities.


 This is the difference, for example, between saying that water
rolls downhill because it \textit{wants} to be lower, and setting forth
differential equations that claim to describe only motions, not
desires. It's the difference between saying that a tree
puts forth leaves because of a tree spirit, versus examining plant
biochemistry. Cognitive science takes the fight against supernaturalism
into the realm of the mind.


 Why is this an excellent definition of the supernatural? I refer
you to Richard Carrier\footnote{\url{http://richardcarrier.blogspot.com/2007/01/defining-supernatural.html}} for the full argument. But consider: Suppose
that you discover what seems to be a \textit{spirit}, inhabiting a
tree---a dryad who can materialize outside or inside the tree, who
speaks in English about the need to protect her tree, et cetera. And
then suppose that we turn a microscope on this tree spirit, and she
turns out to be made of parts---not inherently spiritual and ineffable
parts, like fabric of desireness and cloth of belief, but rather the
same sort of parts as quarks and electrons, parts whose behavior is
defined in motions rather than minds. Wouldn't the
dryad immediately be demoted to the dull catalogue of common things?

{
 But if we accept Richard Carrier's definition of
the supernatural, then a dilemma arises: we \textit{want} to give
religious claims a fair shake, but it seems that we have \textit{very
good} grounds for excluding supernatural explanations \textit{a
priori.}}


 I mean, what \textit{would} the universe look like if reductionism
were false?


 I previously defined the reductionist thesis as follows: human
minds create multi-level \textit{models} of reality in which high-level
patterns and low-level patterns are separately and explicitly
\textit{represented.} A physicist knows Newton's
equation for gravity, Einstein's equation for gravity,
and the derivation of the former as a low-speed approximation of the
latter. But these three separate mental representations are only a
convenience of human cognition. It is not that \textit{reality itself}
has an Einstein equation that governs at high speeds, a Newton equation
that governs at low speeds, and a ``bridging
law'' that smooths the interface. Reality itself has
only a single level, Einsteinian gravity. It is only the Mind
Projection Fallacy that makes some people talk as if the higher levels
could have a separate existence---different levels of organization can
have separate representations in human maps, but the territory itself
is a single unified low-level mathematical object.


 Suppose this were wrong.


 Suppose that the Mind Projection Fallacy was not a fallacy, but
simply true.


 Suppose that a 747 had a fundamental physical existence apart from
the quarks making up the 747.


 What experimental observations would you expect to make, if you
found yourself in such a universe?


 If you can't come up with a good answer to that,
it's not \textit{observation} that's
ruling out ``non-reductionist''
beliefs, but a priori logical incoherence. If you can't
say what predictions the
``non-reductionist'' model makes,
how can you say that experimental evidence rules it out?


 My thesis is that non-reductionism is a \textit{confusion}; and
once you realize that an idea is a confusion, it becomes a tad
difficult to envision what the universe would look like if the
confusion were \textit{true.} Maybe I've got some
multi-level model of the world, and the multi-level model has a
one-to-one direct correspondence with the causal elements of the
physics? But once all the rules are specified, why
wouldn't the model just flatten out into yet another
list of fundamental things and their interactions? Does everything I
can \textit{see in} the model, like a 747 or a human mind, have to
become a separate real thing? But what if I see a pattern in that new
supersystem?


 Supernaturalism is a special case of non-reductionism, where it is
not 747s that are irreducible, but just (some) mental things. Religion
is a special case of supernaturalism, where the irreducible mental
things are God(s) and souls; and perhaps also sins, angels, karma,
etc.


 If I propose the existence of a powerful entity with the ability
to survey and alter each element of our observed universe, but with the
entity reducible to nonmental parts that interact with the elements of
our universe in a lawful way; if I propose that this entity wants
certain particular things, but
``wants'' using a brain composed of
particles and fields; then this is not yet a religion, just a
naturalistic hypothesis about a naturalistic Matrix. If tomorrow the
clouds parted and a vast glowing amorphous figure thundered forth the
above description of reality, then this would not imply that the figure
was necessarily honest; but I would show the movies in a science class,
and I would try to derive testable predictions from the theory.


 Conversely, religions have ignored the discovery of that ancient
bodiless thing: omnipresent in the working of Nature and immanent in
every falling leaf; vast as a planet's surface and
billions of years old; itself unmade and arising from the structure of
physics; designing without brain to shape all life on Earth and the
minds of humanity. Natural selection, when Darwin proposed it, was not
hailed as the long-awaited Creator: It wasn't
\textit{fundamentally} mental.


 But now we get to the dilemma: if the staid conventional normal
boring understanding of physics and the brain \textit{is} correct,
there's no way \textit{in principle} that a human being
can concretely envision, and derive testable experimental predictions
about, an alternate universe in which things \textit{are} irreducibly
mental. Because if the boring old normal model is correct, your brain
is made of quarks, and so your brain will only be able to envision and
concretely predict things that can predicted by quarks. You will only
ever be able to construct models made of interacting simple things.


 People who live in reductionist universes cannot concretely
envision non-reductionist universes. They can pronounce the syllables
``non-reductionist'' but they
can't \textit{imagine} it.


 The basic error of anthropomorphism, and the reason why
supernatural explanations sound much simpler than they really are, is
your brain using itself as an opaque black box to predict other things
labeled ``mindful.'' Because you
already have big, complicated webs of neural circuitry that implement
your ``wanting'' things, it seems
like you can easily describe water that
``wants'' to flow downhill---the one
word ``want'' acts as a lever to set
your \textit{own} complicated wanting-machinery in motion.


 Or you imagine that God likes beautiful things, and therefore made
the flowers. Your own ``beauty''
circuitry determines what is
``beautiful'' and
``not beautiful.'' But you
don't know the diagram of your own synapses. You
can't describe a \textit{nonmental} system that
computes the same label for what is
``beautiful'' or
``not
beautiful''---can't write a computer
program that predicts your own labelings. But this is just a defect of
knowledge on your part; it doesn't mean that the brain
has no explanation.


 If the ``boring view'' of
reality is correct, then you can \textit{never} predict anything
irreducible because \textit{you} are reducible. You can never get
Bayesian confirmation for a hypothesis of irreducibility, because any
\textit{prediction you can make} is, therefore, something that could
also be predicted by a reducible thing, namely your brain.


 Some boxes you really \textit{can't} think
outside. If our universe \textit{really is} Turing computable, we will
never be able to \textit{concretely} envision anything that
isn't Turing-computable---no matter how many levels of
halting oracle hierarchy our mathematicians can talk \textit{about}, we
won't be able to predict what a halting oracle would
actually \textit{say}, in such fashion as to experimentally
discriminate it from merely computable reasoning.


 Of course, that's all assuming the
``boring view'' is correct.
\textit{To the extent} that you believe evolution is true, you should
not expect to encounter strong evidence against evolution. To the
extent you believe reductionism is true, you should expect
non-reductionist hypotheses to be \textit{incoherent} as well as wrong.
To the extent you believe supernaturalism is false, you should expect
it to be \textit{inconceivable} as well.


 If, on the other hand, a supernatural hypothesis turns out to be
true, then presumably you will also discover that it is not
inconceivable.


 So let us bring this back full circle to the matter of Intelligent
Design:


 Should ID be excluded a priori from experimental falsification and
science classrooms, because, by invoking the supernatural, it has
placed itself outside of natural philosophy?


 I answer: ``Of course not.''
The \textit{irreducibility} of the intelligent designer is not an
indispensable part of the ID hypothesis. For every irreducible God that
can be proposed by the IDers, there exists a corresponding reducible
alien that behaves in accordance with the same predictions---since the
IDers themselves are reducible. To the extent I believe reductionism is
in fact correct, which is a rather strong extent, I must expect to
discover reducible formulations of all supposedly supernatural
predictive models.


 If we're going over the archeological records to
test the assertion that Jehovah parted the Red Sea out of an explicit
desire to display its superhuman power, then it makes little difference
whether Jehovah is ontologically basic, or an alien with nanotech, or a
Dark Lord of the Matrix. You do some archeology, find no skeletal
remnants or armor at the Red Sea site, and indeed find records that
Egypt ruled much of Canaan at the time. So you stamp the historical
record in the Bible ``disproven''
and carry on. The hypothesis is coherent, falsifiable and wrong.


 Likewise with the evidence from biology that foxes are designed to
chase rabbits, rabbits are designed to evade foxes, and neither is
designed ``to carry on their
species'' or ``protect the harmony
of Nature''; likewise with the retina being designed
backwards with the light-sensitive parts at the bottom; and so on
through a thousand other items of evidence for splintered, immoral,
incompetent design. The Jehovah model of our alien god is coherent,
falsifiable, and wrong---coherent, that is, so long as you
don't care whether Jehovah is ontologically basic or
just an alien.


 Just convert the supernatural hypothesis into the corresponding
natural hypothesis. Just make the same predictions the same way,
without asserting any mental things to be ontologically basic. Consult
your brain's black box if necessary to make
predictions---say, if you want to talk about an
``angry god'' without building a
full-fledged angry AI to label behaviors as angry or not angry. So you
derive the predictions, or look up the predictions made by ancient
theologians without advance knowledge of our experimental results. If
experiment conflicts with those predictions, then it is fair to speak
of the religious claim having been scientifically refuted. It was given
its just chance at confirmation; it is being excluded a posteriori, not
a priori.


 Ultimately, reductionism is just disbelief in
\textit{fundamentally complicated} things. If
``fundamentally complicated'' sounds
like an oxymoron\,\ldots well, that's why I think that
the doctrine of non-reductionism is a \textit{confusion}, rather than a
way that things could be, but aren't. You would be wise
to be wary, if you find yourself supposing such things.


 But the ultimate rule of science is to look and see. If ever a God
appeared to thunder upon the mountains, it would be something that
people looked at and saw.


 \textit{Corollary:} Any supposed designer of Artificial General
Intelligence who talks about religious beliefs in respectful tones is
clearly not an expert on reducing mental things to nonmental things;
and indeed knows so very little of the uttermost basics, as for it to
be scarcely plausible that they could be expert at the art; unless
their \textit{idiot savancy} is complete. Or, of course, if
they're outright lying. We're not
talking about a subtle mistake.

\myendsectiontext

\mysection{Psychic Powers}


 In the last essay, I wrote:

\begin{quote}
{
 If the ``boring view'' of
reality is correct, then you can \textit{never} predict anything
irreducible because \textit{you} are reducible. You can never get
Bayesian confirmation for a hypothesis of irreducibility, because any
\textit{prediction you can make} is, therefore, something that could
also be predicted by a reducible thing, namely your brain.}
\end{quote}


 Benja Fallenstein commented:\footnote{\url{http://lesswrong.com/lw/tv/excluding_the_supernatural/n6f}}

\begin{quotation}

 I think that while you can in this case never devise an empirical
test whose outcome could \textit{logically prove} irreducibility, there
is no clear reason to believe that you cannot devise a test whose
counterfactual outcome in an irreducible world would make
irreducibility subjectively \textit{much more probable} (given an
Occamian prior).

{
 Without getting into reducibility/irreducibility, consider the
scenario that the physical universe makes it possible to build a
hypercomputer---that performs operations on arbitrary real numbers, for
example---but that our brains do not actually make use of this: they
can be simulated perfectly well by an ordinary Turing machine, thank
you very much\,\ldots}
\end{quotation}


 Well, that's a very intelligent argument, Benja
Fallenstein. But I have a crushing reply to your argument, such that,
once I deliver it, you will at once give up further debate with me on
this particular point:


 You're right.


 Alas, I don't get modesty credit on this one,
because after publishing the last essay I realized a similar flaw on my
own---this one concerning Occam's Razor and psychic
powers:


 If beliefs and desires are irreducible and ontologically basic
entities, or have an ontologically basic \textit{component} not covered
by existing science, that would make it far more likely that there was
an ontological rule governing the interaction of different minds---an
interaction which bypassed ordinary
``material'' means of communication
like sound waves, known to existing science.


 If naturalism is correct, then there exists a conjugate
reductionist model that makes the \textit{same predictions} as any
concrete prediction that any parapsychologist can make about
telepathy.


 Indeed, if naturalism is correct, the only reason we can
\textit{conceive} of beliefs as
``fundamental'' is due to lack of
self-knowledge of our own neurons---that the peculiar reflective
architecture of our own minds exposes the
``belief'' class but hides the
machinery behind it.


 Nonetheless, the discovery of information transfer between brains,
in the absence of any known material connection between them, is
\textit{probabilistically} a privileged prediction of supernatural
models (those that contain ontologically basic mental entities). Just
because it is so much \textit{simpler} in that case to have a new law
relating beliefs between different minds, compared to the
``boring'' model where beliefs are
complex constructs of neurons.


 The hope of psychic powers arises from treating beliefs and
desires as sufficiently fundamental objects that they can have
\textit{unmediated} connections to reality. If beliefs are patterns of
neurons made of known material, with inputs given by organs like eyes
constructed of known material, and with outputs through muscles
constructed of known material, and this seems sufficient to account for
all known mental powers of humans, then there's no
reason to expect anything more---no reason to postulate additional
connections. This is why reductionists don't expect
psychic powers. Thus, observing psychic powers would be strong evidence
for the supernatural in Richard Carrier's sense.


 We have an Occam rule that counts the number of ontologically
basic classes and ontologically basic laws in the model, and penalizes
the count of entities. If naturalism is correct, then the attempt to
count ``belief'' or the
``relation between belief and
reality'' as a single basic entity is simply
misguided anthropomorphism; we are only tempted to it by a quirk of our
brain's internal architecture. But if you \textit{just
go with} that misguided view, then it assigns a much higher probability
to psychic powers than does naturalism, because you can implement
psychic powers using apparently simpler laws.


 Hence the actual discovery of psychic powers would imply that the
human-naive Occam rule was in fact better-calibrated than the
sophisticated naturalistic Occam rule. It would argue that
reductionists had been wrong all along in trying to take apart the
brain; that what our minds exposed as a seemingly simple lever was in
fact a simple lever. The naive dualists would have been right from the
beginning, which is why their ancient wish would have been enabled to
come true.


 So telepathy, and the ability to influence events just by wishing
at them, and precognition, would all, if discovered, be strong Bayesian
evidence in favor of the hypothesis that beliefs are ontologically
fundamental. Not logical proof, but strong Bayesian evidence.

{
 If reductionism is correct, then any science-fiction story
containing psychic powers can be output by a system of simple elements
(i.e., the story's author's brain); but
if we \textit{in fact} discover psychic powers, that would make it much
more probable that events were occurring which could not \textit{in
fact} be described by reductionist models.}


 Which just goes to say: The existence of psychic powers is a
privileged probabilistic assertion of non-reductionist
worldviews---\textit{they own} that advance prediction; they devised it
and put it forth, in defiance of reductionist expectations. So by the
laws of science, if psychic powers are discovered, non-reductionism
wins.


 I am therefore confident in dismissing psychic powers as a priori
implausible, despite all the claimed experimental evidence in favor of
them.

\myendsectiontext

\chapter{Quantum Physics and Many Worlds}

\mysection{Quantum Explanations}


 There's a widespread belief that quantum mechanics
is \textit{supposed} to be confusing. This is not a good frame of mind
for either a teacher or a student.


 And I find that legendarily
``confusing'' subjects often are not
really all that complicated \textit{as math}, particularly if you just
want a very basic---but still mathematical---grasp on what goes on down
there.


 I am not a physicist, and physicists famously hate it when
non-professional-physicists talk about quantum mechanics. But I do have
some experience with explaining mathy things that are allegedly
``hard to understand.''


 I wrote the Intuitive Explanation of Bayesian Reasoning because
people were complaining that Bayes's Theorem was
``counterintuitive''---in fact it
was \textit{famously} counterintuitive---and this did not seem right.
The equation just did not seem complicated enough to deserve the
fearsome reputation it had. So I tried explaining it \textit{my way},
and I did not manage to reach my original target of elementary school
students, but I get frequent grateful emails from formerly confused
folks ranging from reporters to outside academic college professors.


 Besides, as a Bayesian, I don't believe in
phenomena that are \textit{inherently} confusing. Confusion exists in
our models of the world, not in the world itself. If a subject is
widely known as \textit{confusing}, not just \textit{difficult}\,\ldots
you shouldn't leave it at that. It
doesn't satisfice; it is not an okay place to be. Maybe
you can fix the problem, maybe you can't; but you
shouldn't be \textit{happy} to leave students
confused.


 The first way in which my introduction is going to depart from the
traditional, standard introduction to quantum mechanics, is that I am
\textit{not} going to tell you that quantum mechanics is supposed to be
confusing.


 I am not going to tell you that it's okay for you
to not understand quantum mechanics, because no one understands quantum
mechanics, as Richard Feynman once claimed. There was a historical time
when this was true, but we no longer live in that era.


 I am not going to tell you: ``You
don't understand quantum mechanics, you just get used
to it.'' (As von Neumann is reputed to have said;
back in the dark decades when, in fact, no one \textit{did} understand
quantum mechanics.)


 Explanations are supposed to make you \textit{less confused}. If
you feel like you don't understand something, this
indicates a \textit{problem}{}---either with you, or your teacher---but
at any rate a problem; and you should move to \textit{resolve} the
problem.


 I am not going to tell you that quantum mechanics is
\textit{weird}, \textit{bizarre}, \textit{confusing}, or
\textit{alien}. Quantum mechanics is counterintuitive, but that is a
problem with your intuitions, not a problem with quantum mechanics.
Quantum mechanics has been around for billions of years before the Sun
coalesced from interstellar hydrogen. Quantum mechanics was here before
you were, and if you have a problem with that, \textit{you} are the one
who needs to change. Quantum mechanics sure won't.
There are no \textit{surprising facts}, only \textit{models} that are
\textit{surprised by} facts; and if a model is surprised by the facts,
it is no credit to that model.


 It is always best to think of reality as perfectly normal. Since
the beginning, not one unusual thing has ever happened.


 The \textit{goal} is to become completely at home in a quantum
universe. Like a native. Because, in fact, that is where you live.


 In the coming sequence on quantum mechanics, I am going to
consistently speak as if quantum mechanics is \textit{perfectly
normal}; and when human intuitions depart from quantum mechanics, I am
going to make fun of the \textit{intuitions} for being weird and
unusual. This may seem odd, but the point is to swing your mind around
to a \textit{native} quantum point of view.


 Another thing: The traditional introduction to quantum mechanics
closely follows the order in which quantum mechanics was discovered.


 The traditional introduction starts by saying that matter
sometimes behaves like little billiard balls bopping around, and
sometimes behaves like crests and troughs moving through a pool of
water. Then the traditional introduction gives some examples of matter
acting like a little billiard ball, and some examples of it acting like
an ocean wave.


 Now, it happens to be a historical fact that, back when students
of matter were working all this stuff out and had \textit{no clue}
about the true underlying math, those early scientists first thought
that matter was like little billiard balls. And then that it was like
waves in the ocean. And then that it was like billiard balls again. And
then the early scientists got \textit{really} confused, and stayed that
way for several decades, until it was finally sorted out in the second
half of the twentieth century.


 Dragging a modern-day student through all this may be a
\textit{historically realistic} approach to the subject matter, but it
also ensures the historically realistic outcome of \textit{total
bewilderment.} Talking to aspiring young physicists about
``wave/particle duality'' is like
starting chemistry students on the Four Elements.


 An electron is \textit{not} a billiard ball, and
it's \textit{not} a crest and trough moving through a
pool of water. An electron is a mathematically different sort of
entity, \textit{all the time and under all circumstances}, and it has
to be accepted on its own terms.


 The universe is not wavering between using particles and waves,
unable to make up its mind. It's only human
\textit{intuitions} about quantum mechanics that swap back and forth.
The intuitions we have for billiard balls, and the intuitions we have
for crests and troughs in a pool of water, both look \textit{sort of}
like they're applicable to electrons, at different
times and under different circumstances. But the truth is that both
intuitions simply \textit{aren't applicable.}


 If you try to think of an electron as being like a billiard ball
on some days, and like an ocean wave on other days, you will
\textit{confuse the living daylights} out of yourself.


 Yet it's your eyes that are wobbling and unstable,
not the world.


 Furthermore:

{
 The order in which humanity \textit{discovered} things is not
necessarily the best order in which to \textit{teach} them. First,
humanity noticed that there were other animals running around. Then we
cut them open and found that they were full of organs. Then we examined
the organs carefully and found they were made of tissues. Then we
looked at the tissues under a microscope and discovered cells, which
are made of proteins and some other chemically synthesized stuff. Which
are made of molecules, which are made of atoms, which are made of
protons and neutrons and electrons \textit{which are way simpler than
entire animals but were discovered tens of thousands of years later.}}


 Physics doesn't start by talking about biology. So
why should it start by talking about very high-level complicated
phenomena, like, say, the observed results of experiments?


 The ordinary way of teaching quantum mechanics keeps stressing the
experimental results. Now I do understand why that sounds nice from a
rationalist perspective. Believe me, I understand.


 But it seems to me that the upshot is dragging in big complicated
mathematical tools that you need to analyze real-world situations,
before the student understands what \textit{fundamentally} goes on in
the simplest cases.


 It's like trying to teach programmers how to write
concurrent multithreaded programs before they know how to add two
variables together, because concurrent multithreaded programs are
closer to everyday life. Being close to everyday life is not always a
strong recommendation for what to teach first.


 Maybe the monomaniacal focus on experimental observations made
sense in the dark decades when \textit{no one} understood what was
fundamentally going on, and you \textit{couldn't} start
there, and all your models were just mysterious maths that gave good
experimental predictions\,\ldots you can still find this view of quantum
physics presented in many books\,\ldots but maybe today
it's worth trying a different angle? The result of the
standard approach is standard confusion.


 The classical world is strictly implicit in the quantum world, but
seeing from a classical perspective makes everything bigger and more
complicated. Everyday life is a higher level of organization, like
molecules versus quarks---huge catalogue of molecules, six quarks. I
think it is worth trying to teach from the perspective of the quantum
world first, and talking about classical experimental results
afterward.


 I am not going to start with the normal classical world and then
talk about a bizarre quantum backdrop hidden behind the scenes. The
quantum world \textit{is} the scene and it defines normality.


 I am not going to talk as if the classical world is real life, and
occasionally the classical world transmits a request for an
experimental result to a quantum-physics server, and the
quantum-physics server does some peculiar calculations and transmits
back a classical experimental result. I am going to talk as if the
quantum world is the really real and the classical world something far
away. Not just because that makes it easier to be a native of a quantum
universe, but because, at a core level, it's the
truth.


 Finally, I am going to take a strictly realist perspective on
quantum mechanics---the quantum world is really out there, our
equations describe the territory and not our maps of it, and the
classical world only exists implicitly within the quantum one. I am not
going to discuss non-realist views in the early stages of my
introduction, except to say why you should not be confused by certain
intuitions that non-realists draw upon for support. I am not going to
apologize for this, and I would like to ask any non-realists on the
subject of quantum mechanics to wait and hold their comments until
called for in a later essay. Do me this favor, please. I think
non-realism is one of the main things that confuses prospective
students, and prevents them from being able to concretely visualize
quantum phenomena. I \textit{will} discuss the issues explicitly in a
future essay.


 But everyone should be aware that, even though I'm
not going to discuss the issue at first, there is a sizable community
of scientists who dispute the realist perspective on quantum mechanics.
Myself, I don't think it's worth
figuring both ways; I'm a pure realist, for reasons
that will become apparent. But if you read my introduction, you are
getting my view. It is not only my view. It is probably the majority
view among theoretical physicists, if that counts for anything (though
I will argue the matter separately from opinion polls). Still, it is
not the only view that exists in the modern physics community. I do not
feel obliged to present the other views \textit{right away}, but I feel
obliged to warn my readers that there \textit{are} other views, which I
will not be presenting during the initial stages of the introduction.

{
 To sum up, my goal will be to teach you to think like a
\textit{native of a quantum universe}, not a \textit{reluctant
tourist}.}


 Embrace reality. Hug it tight.

\myendsectiontext

\mysection{Configurations and Amplitude}


 So the universe isn't made of little billiard
balls, and it isn't made of crests and troughs in a
pool of aether\,\ldots Then what is the stuff that stuff is made of?

%230.1
\myfigure{images/img291.jpg}{two_detectors}


 In Figure \ref{two_detectors}, we see, at $A$, a half-silvered mirror, and two
photon detectors, Detector 1 and Detector 2.


 Early scientists, when they ran experiments like this, became
confused about what the results meant. They would send a photon toward
the half-silvered mirror, and half the time they would see Detector 1
click, and the other half of the time they would see Detector 2 click.


 The early scientists---you're going to laugh at
this---thought that the silver mirror deflected the photon half the
time, and let it through half the time.


 Ha, ha! As if the half-silvered mirror did different things on
different occasions! I want you to let go of this idea, because if you
cling to what early scientists thought, you will become extremely
confused. The half-silvered mirror obeys the same rule every time.


 If you were going to write a computer program that \textit{was}
this experiment---not a computer program that \textit{predicted} the
result of the experiment, but a computer program that resembled the
underlying reality---it might look sort of like this:


 At the start of the program (the start of the experiment, the
start of time) there's a certain mathematical entity,
called a \textit{configuration}. You can think of this configuration as
corresponding to ``there is one photon heading from
the photon source toward the half-silvered mirror,''
or just ``a photon heading toward
$A$.''


 A configuration can store a single complex
value---``complex'' as in the
complex numbers $(a + bi)$, with $i$ defined as $\sqrt{-1}$. At the start
of the program, there's already a complex number stored
in the configuration ``a photon heading toward
$A$.'' The exact value doesn't matter
so long as it's not zero. We'll let the
configuration ``a photon heading toward
$A$'' have a value of $(-1 + 0i)$.


 All this is a fact within the territory, not a description of
anyone's knowledge. A configuration
isn't a proposition or a possible way the world could
be. A configuration is a variable in the program---you can think of it
as a kind of memory location whose index is ``a photon
heading toward $A$''---and it's out
there in the territory.


 As the complex numbers that get assigned to configurations are not
positive real numbers between 0 and 1, there is no danger of confusing
them with probabilities. ``A photon heading toward
$A$'' has complex value -1, which is hard to see as a
degree of belief. The complex numbers are values within the program,
again out there in the territory. We'll call the
complex numbers \textit{amplitudes.}


 There are two other configurations, which we'll
call ``a photon going from $A$ to Detector
1'' and ``a photon going from $A$ to
Detector 2.'' These configurations
don't have a complex value yet; it gets assigned as the
program runs.


 We are going to calculate the amplitudes of ``a
photon going from $A$ toward 1'' and
``a photon going from $A$ toward 2''
using the value of ``a photon going toward
$A$,'' and the rule that describes the half-silvered
mirror at $A$.

{
 Roughly speaking, the half-silvered mirror rule is
``multiply by 1 when the photon goes straight, and
multiply by $i$ when the photon turns at a right
angle.'' This is the universal rule that relates the
amplitude of the configuration of ``a photon going
in,'' to the amplitude that goes to the
configurations of ``a photon coming out
straight'' or ``a photon being
deflected.''\footnote{\textbf{Editor's Note:} Strictly speaking, a
standard half-silvered mirror would yield a rule
``multiply by -1 when the photon turns at a right
angle,'' not ``multiply by
$i$.'' The basic scenario described by the author is
not physically impossible, and its use does not affect the substantive
argument. However, physics students may come away confused if they
compare the discussion here to textbook discussions of Mach--Zehnder
interferometers. We've left this idiosyncrasy in the
text because it eliminates any need to specify which side of the mirror
is half-silvered, simplifying the experiment.\comment{1}}}


 So we pipe the amplitude of the configuration ``a
photon going toward $A$,'' which is $(-1 + 0i)$, into the
half-silvered mirror at $A$, and this transmits an amplitude of $(-1 + 0i) 
\times i = (0 -i)$ to ``a photon going from $A$
toward 1,'' and also transmits an amplitude of $(-1 +
0i) \times 1 = (-1 + 0i)$ to ``a photon going
from $A$ toward 2.''


 In the Figure \ref{two_detectors} experiment, these are all the configurations
and all the transmitted amplitude we need to worry about, so
we're done. Or, if you want to think of
``Detector 1 gets a photon'' and
``Detector 2 gets a photon'' as
separate configurations, they'd just inherit their
values from ``$A$ to 1'' and
``$A$ to 2'' respectively. (Actually,
the values inherited should be multiplied by another complex factor,
corresponding to the distance from $A$ to the detector; but we will
ignore that for now, and suppose that all distances traveled in our
experiments happen to correspond to a complex factor of 1.)


 So the final program state is:


 Configuration ``a photon going toward
A'': $(-1 + 0i)$


 Configuration ``a photon going from A toward
1'': $(0 - i)$


 Configuration ``a photon going from A toward
2'': $(-1 + 0i)$


 \textit{and optionally}


 Configuration ``Detector 1 gets a
photon'': $(0 - i)$


 Configuration ``Detector 2 gets a
photon'': $(-1 + 0i)$.


 This same result occurs---the same amplitudes stored in the same
configurations---every time you run the program (every time you do the
experiment).


 Now, for \textit{complicated} reasons that we
aren't going to go into here---considerations that
belong on a higher level of organization than fundamental quantum
mechanics, the same way that atoms are more complicated than
quarks---there's no \textit{simple} measuring
instrument that can directly tell us the exact amplitudes of each
configuration. We can't directly see the program
state.


 So how do physicists know what the amplitudes are?


 We \textit{do} have a magical measuring tool that can tell us the
\textit{squared modulus} of a configuration's
amplitude. If the original complex amplitude is $(a + bi)$, we can get
the positive real number $(a^{2} + b^{2})$.
Think of the Pythagorean theorem: if you imagine the complex number as
a little arrow stretching out from the origin on a two-dimensional
plane, then the magic tool tells us the squared length of the little
arrow, but it doesn't tell us the direction the arrow
is pointing.


 To be more precise, the magic tool actually just tells us the
\textit{ratios} of the squared lengths of the amplitudes in some
configurations. We don't know how long the arrows are
in an absolute sense, just how long they are relative to each other.
But this turns out to be enough information to let us reconstruct the
laws of physics---the rules of the program. And so I can talk about
amplitudes, not just ratios of squared moduli.


 When we wave the magic tool over ``Detector 1
gets a photon'' and ``Detector 2
gets a photon,'' we discover that these
configurations have the same squared modulus---the lengths of the
arrows are the same. Thus speaks the magic tool. By doing more
\textit{complicated} experiments (to be seen shortly), we can tell that
the original complex numbers had a ratio of $i$ to 1.


 And what is this magical measuring tool?


 Well, from the perspective of everyday life---way, way, way above
the quantum level and a lot more complicated---the magical measuring
tool is that we send some photons toward the half-silvered mirror, one
at a time, and count up how many photons arrive at Detector 1 versus
Detector 2 over a few thousand trials. The ratio of these values is the
ratio of the squared moduli of the amplitudes. But the reason for this
is \textit{not} something we are going to consider yet. Walk before you
run. It is not possible to understand what happens \textit{all the way
up} at the level of everyday life, before you understand what goes on
in much simpler cases.


 For today's purposes, we have a magical
squared-modulus-ratio reader. And the magic tool tells us that the
little two-dimensional arrow for the configuration
``Detector 1 gets a photon'' has the
same squared length as for ``Detector 2 gets a
photon.'' That's all.


 You may wonder, ``Given that the magic tool works
this way, what motivates us to use quantum theory, instead of thinking
that the half-silvered mirror reflects the photon around half the
time?''


 Well, that's just begging to be confused---putting
yourself into a historically realistic frame of mind like that and
using everyday intuitions. Did I say anything about a little billiard
ball going one way or the other and possibly bouncing off a mirror?
That's not how reality works. \textit{Reality} is about
complex amplitudes flowing between configurations, and the laws of the
flow are stable.


 But if you insist on seeing a more complicated situation that
billiard-ball ways of thinking can't handle,
here's a more complicated experiment.

%230.2
\myfigure{images/img292.jpg}{four_mirrors}


 In Figure \ref{four_mirrors}, $B$ and $C$ are full mirrors, and $A$ and $D$ are
half-mirrors. The line from $D$ to $E$ is dashed for reasons that will
become apparent, but amplitude is flowing from $D$ to $E$ under exactly the
same laws.


 Now let's apply the rules we learned before:


 At the beginning of time ``a photon heading
toward $A$'' has amplitude $(-1 + 0i)$.


 We proceed to compute the amplitude for the configurations
``a photon going from $A$ to $B$'' and
``a photon going from $A$ to $C$'':

{\centering
 ``a photon going from $A$ to $B$''
= $i \times$ ``a photon heading toward
A'' = $(0 - i)$.
\par}



 Similarly,

{\centering
 ``a photon going from $A$ to $C$''
= $1 \times$ ``a photon heading toward
A'' = $(-1 + 0i)$.
\par}



 The full mirrors behave (as one would expect) like half of a
half-silvered mirror---a full mirror just bends things by right angles
and multiplies them by $i$. (To state this slightly more precisely: For a
full mirror, the amplitude that flows, from the configuration of a
photon heading in, to the configuration of a photon heading out at a
right angle, is multiplied by a factor of $i$.)


 So:

{\centering
 ``a photon going from B to D''
= $i \times$ ``a photon going from $A$ to
$B$'' = $(1 + 0i)$,
\par}


{\centering
 ``a photon going from $C$ to $D$''
= $i \times$ ``a photon going from $A$ to
$C$'' = $(0 - i)$.
\par}



 ``$B$ to $D$'' and
``$C$ to $D$'' are two different
configurations---we don't simply write
``a photon at $D$''---because the
photons are arriving at two different angles in these two different
configurations. And what $D$ does to a photon depends on the angle at
which the photon arrives.


 Again, the rule (speaking loosely) is that when a half-silvered
mirror bends light at a right angle, the amplitude that flows from the
photon-going-in configuration to the photon-going-out configuration, is
the amplitude of the photon-going-in configuration multiplied by $i$. And
when two configurations are related by a half-silvered mirror letting
light straight through, the amplitude that flows from the
photon-going-in configuration is multiplied by 1.


 So:

\begin{itemize}
\item {
 From the configuration ``a photon going from $B$ to
 $D$,'' with original amplitude $(1 + 0i)$:
\begin{itemize}
\item Amplitude of
$(1 + 0i) \times i = (0 + i)$ flows to ``a photon
  going from $D$ to $E$.''
  \item Amplitude of $(1 + 0i)
\times 1 = (1 + 0i)$ flows to ``a photon going
from $D$ to $F$.''
\end{itemize}
}

\item {
 From the configuration ``a photon going from $C$ to
 $D$,'' with original amplitude $(0 - i)$:
 \begin{itemize}
   \item
 Amplitude of $(0
-i) \times i = (1 + 0i)$ flows to ``a photon
going from $D$ to $F$.''
\item Amplitude of $(0 - i)
\times 1 = (0 - i)$ flows to ``a photon going
from $D$ to $E$.''
\end{itemize}
}

\end{itemize}

 Therefore:

\begin{itemize}
\item {
 The \textit{total} amplitude flowing to configuration
``a photon going from $D$ to $E$'' is $(0
+ i) + (0 - i) = (0 + 0i) = 0$.}

\item {
 The total amplitude flowing to configuration ``a
photon going from $D$ to $F$'' is $(1 + 0i) + (1 + 0i) =
(2 + 0i)$.}
\end{itemize}


 (You may want to try working this out yourself on pen and paper if
you lost track at any point.)


 But the upshot, from that super-high-level
``experimental'' perspective that we
think of as normal life, is that we see \textit{no} photons detected at
$E$. Every photon seems to end up at $F$. The ratio of squared moduli
between ``$D$ to $E$'' and
``$D$ to $F$'' is 0 to 4.
That's why the line from $D$ to $E$ is dashed, in this
figure.


 This is not something it is possible to explain by thinking of
half-silvered mirrors deflecting little incoming billiard balls half
the time. You've \textit{got} to think in terms of
amplitude flows.


 If half-silvered mirrors deflected a little billiard ball half the
time, in this setup, the little ball would end up at Detector 1 around
half the time and Detector 2 around half the time. Which it
doesn't. So don't think that.


 You may say, ``But wait a minute! I can think of
another hypothesis that accounts for this result. What if, when a
half-silvered mirror reflects a photon, it does something to the photon
that ensures it doesn't get reflected next time? And
when it lets a photon go through straight, it does something to the
photon so it gets reflected next time.''


 Now really, there's no need to go making the rules
so complicated. Occam's Razor, remember. Just stick
with simple, normal amplitude flows between configurations.


 But if you want \textit{another} experiment that disproves your
\textit{new} alternative hypothesis, it's Figure \ref{with_a_stop}.

%230.3
\myfigure{images/img293.jpg}{with_a_stop}


 Here, we've left the whole experimental setup the
same, and just put a little blocking object between $B$ and $D$. This
ensures that the amplitude of ``a photon going from $B$
to $D$'' is 0.


 Once you eliminate the amplitude contributions from that
configuration, you end up with totals of $(1 + 0i)$ in
``a photon going from $D$ to $F$,'' and
$(0 -i)$ in ``a photon going from $D$ to
$E$.''


 The squared moduli of $(1 + 0i)$ and $(0 - i)$ are both 1, so the
magic measuring tool should tell us that the ratio of squared moduli is
1. Way back up at the level where physicists exist, we should find that
Detector 1 goes off half the time, and Detector 2 half the time.


 The same thing happens if we put the block between $C$ and $D$. The
amplitudes are different, but the ratio of the squared moduli is still
1, so Detector 1 goes off half the time and Detector 2 goes off half
the time.


 This cannot \textit{possibly} happen with a little billiard ball
that either does or doesn't get reflected by the
half-silvered mirrors.


 Because complex numbers can have opposite directions, like 1 and
-1, or $i$ and $-i$, amplitude flows can cancel each other out. Amplitude
flowing from configuration $X$ into configuration $Y$ can be canceled out
by an equal and opposite amplitude flowing from configuration $Z$ into
configuration $Y$. In fact, that's exactly what happens
in this experiment.


 In probability theory, when something can either happen one way or
another, $X$ or $\lnot X$, then $P(Z) = P(Z|X)P(X) +
P(Z|\lnot X)P(\lnot X)$. And all probabilities are
positive. So if you establish that the probability of $Z$ happening given
$X$ is $1/2$, and the probability of $X$ happening is $1/3$, then the total
probability of $Z$ happening is \textit{at least} $1/6$ no matter
\textit{what} goes on in the case of $\lnot X$.
There's no such thing as negative probability,
less-than-impossible credence, or $(0 + i)$ credibility, so
\textit{degrees of belief} can't cancel each other out
like amplitudes do.


 Not to mention that probability is in the mind to begin with; and
we are talking \textit{about} the territory, the
program-that-is-reality, not talking \textit{about} human cognition or
states of partial knowledge.


 By the same token, configurations are not \textit{propositions},
not \textit{statements}, not \textit{ways the world could conceivably
be}. Configurations are not semantic constructs. Adjectives like
\textit{probable} do not apply to them; they are not beliefs or
sentences or possible worlds. They are not \textit{true} or
\textit{false} but simply \textit{real}.


 In the experiment of Figure \ref{four_mirrors}, do not be tempted to think
anything like: ``The photon goes to either $B$ or $C$, but
it \textit{could} have gone the other way, and this possibility
interferes with its ability to go to $E$\,\ldots''


 It makes no sense to think of something that
``could have happened but
didn't'' exerting an effect on the
world. We can \textit{imagine} things that could have happened but
didn't---like thinking, ``Gosh, that
car almost hit me''---and our imagination can have an
effect on our future behavior. But the event of imagination is a real
event, that actually happens, and \textit{that} is what has the effect.
It's your imagination of the unreal event---your very
real imagination, implemented within a quite physical brain---that
affects your behavior.


 To think that the \textit{actual event} of a car hitting
you---this event which could have happened to you, but in fact
didn't---is directly exerting a \textit{causal} effect
on your behavior, is mixing up the map with the territory.


 What affects the world is real. (If things can affect the world
without being ``real,''
it's hard to see what the word
``real'' means.) Configurations and
amplitude flows are causes, and they have visible effects; they are
real. Configurations are not possible worlds and amplitudes are not
degrees of belief, any more than your chair is a possible world or the
sky is a degree of belief.


 So what \textit{is} a configuration, then?


 Well, you'll be getting a clearer idea of that in
later essays.


 But to give you a quick idea of how the real picture differs from
the simplified version we saw in this essay\,\ldots


 Our experimental setup only dealt with one moving particle, a
single photon. Real configurations are about multiple particles. The
next essay will deal with the case of more than one particle, and that
should give you a much clearer idea of what a configuration is.


 Each configuration we talked about \textit{should} have described
a joint position of all the particles in the mirrors and detectors, not
just the position of one photon bopping around.


 In fact, the \textit{really real} configurations are over joint
positions of all the particles in the universe, including the particles
making up the experimenters. You can see why I'm saving
the notion of \textit{experimental results} for later essays.


 In the real world, amplitude is a continuous distribution over a
continuous \textit{space} of configurations. This
essay's
``configurations'' were blocky and
digital, and so were our ``amplitude
flows.'' It was as if we were talking about a photon
teleporting from one place to another.


 If none of that made sense, don't worry. It will
be cleared up in later essays. Just wanted to give you some idea of
where this was heading.

\myendsectiontext


\mysection{Joint Configurations}


 The key to understanding configurations, and hence the key to
understanding quantum mechanics, is realizing on a truly gut level that
configurations are about more than one particle.

%231.1
\myfigure{images/img295.jpg}{two_photons}


 Continuing from the previous essay, Figure \ref{two_photons} shows an altered
version of the experiment where we send in \textit{two} photons toward
$D$ at the same time, from the sources $B$ and $C$.


 The starting configuration then is:

\begin{verse}
 ``a photon going from $B$ to $D$,\\
  and a photon going from $C$ to $D$.''\\
\end{verse}


 Again, let's say the starting configuration has
amplitude $(-1 + 0i)$.


 And remember, the rule of the half-silvered mirror (at $D$) is that
a right-angle deflection multiplies by $i$, and a straight line
multiplies by 1.


 So the amplitude flows from the starting configuration, separately
considering the four cases of deflection/non-deflection of each photon,
are:

\begin{enumerate}
\item The ``$B$ to $D$'' photon is
deflected and the ``$C$ to $D$'' photon
is deflected. This amplitude flows to the configuration
``a photon going from $D$ to $E$, and a photon going from
$D$ to $F$.'' The amplitude flowing is $(-1 + 0i)
\times i \times i = (1 + 0i)$.

\item  The ``$B$ to $D$'' photon is
deflected and the ``$C$ to $D$'' photon
goes straight. This amplitude flows to the configuration
``two photons going from $D$ to $E$.''
The amplitude flowing is $(-1 + 0i) \times i \times 1 = (0 -
i)$.

\item The ``$B$ to $D$'' photon goes
straight and the ``$C$ to $D$'' photon
is deflected. This amplitude flows to the configuration
``two photons going from $D$ to $F$.''
The amplitude flowing is $(-1 + 0i) \times 1 \times i = (0 -
i)$.

\item  The ``$B$ to $D$'' photon goes
straight and the ``$C$ to $D$'' photon
goes straight. This amplitude flows to the configuration
``a photon going from $D$ to $F$, and a photon going from
$D$ to $E$.'' The amplitude flowing is $(-1 + 0i)
\times 1 \times 1 = (-1 + 0i)$.
\end{enumerate}


 Now---and this is a \textit{very important and fundamental idea in
quantum mechanics}{}---the amplitudes in cases 1 and 4 are flowing to
the \textit{same} configuration. Whether the $B$ photon and $C$ photon both
go straight, or both are deflected, the resulting configuration is
\textit{one photon going toward $E$ and another photon going toward $F$}.


 So we add up the two incoming amplitude flows from case 1 and case
4, and get a total amplitude of $(1 + 0i) + (-1 + 0i) = 0$.


 When we wave our magic squared-modulus-ratio reader over the three
final configurations, we'll find that
``two photons at Detector 1'' and
``two photons at Detector 2'' have
the same squared modulus, but ``a photon at Detector 1
and a photon at Detector 2'' has squared modulus
zero.


 Way up at the level of experiment, we never find Detector 1 and
Detector 2 both going off. We'll find Detector 1 going
off twice, or Detector 2 going off twice, with equal frequency.
(Assuming I've gotten the math and physics right. I
didn't actually perform the experiment.)


 The configuration's identity is \textit{not},
``the $B$ photon going toward $E$ and the $C$ photon going
toward $F$.'' Then the resultant configurations in case
1 and case 4 would not be equal. Case 1 would be, ``$B$
photon to $E$, $C$ photon to $F$'' and case 4 would be
``$B$ photon to $F$, $C$ photon to $E$.''
These would be two distinguishable configurations, \textit{if}
configurations had photon-tracking structure.


 So we would not add up the two amplitudes and cancel them out. We
would keep the amplitudes in two separate configurations. The total
amplitudes would have non-zero squared moduli. And when we ran the
experiment, we would find (around half the time) that Detector 1 and
Detector 2 each registered one photon. Which doesn't
happen, if my calculations are correct.


 Configurations don't keep track of where particles
come from. $A$ configuration's identity is just,
``a photon here, a photon there; an electron here, an
electron there.'' No matter how you get into that
situation, so long as there are the same species of particles in the
same places, it counts as the same configuration.


 I say again that the question ``What kind of
information does the configuration's structure
incorporate?'' has \textit{experimental
consequences.} You can deduce, from experiment, the way that reality
itself must be treating configurations.


 In a classical universe, there would be no experimental
consequences. If the photon were like a little billiard ball that
either went one way or the other, and the configurations were our
beliefs about possible states the system could be in, and instead of
amplitudes we had probabilities, it would not make a difference whether
we tracked the origin of photons or threw the information away.


 In a classical universe, I could assign a 25\% probability to both
photons going to $E$, a 25\% probability of both photons going to $F$, a
25\% probability of the $B$ photon going to $E$ and the $C$ photon going to
$F$, and 25\% probability of the $B$ photon going to $F$ and the $C$ photon
going to $E$. Or, since I \textit{personally} don't care
which of the two latter cases occurred, I could decide to collapse the
two possibilities into one possibility and add up their probabilities,
and just say, ``a 50\% probability that each detector
gets one photon.''


 With probabilities, we can aggregate events as we like---draw our
boundaries around sets of possible worlds as we please---and the
numbers will still work out the same. The probability of two mutually
exclusive events always equals the probability of the first event plus
the probability of the second event.


 But you can't arbitrarily collapse configurations
together, or split them apart, in your model, and get the same
experimental predictions. Our magical tool tells us the ratios of
squared moduli. When you add two complex numbers, the squared modulus
of the sum is not the sum of the squared moduli of the parts:

\whencolumns{\begin{align*}
 \text{Squared\_Modulus}(C1 + C2) &\neq \text{Squared\_Modulus}(C1)\\ &+
\text{Squared\_Modulus}(C2).
\end{align*}}{\begin{align*}
    &\text{Squared\_Modulus}(C1 + C2) \\
    &\neq \text{Squared\_Modulus}(C1)\\
    &+\text{Squared\_Modulus}(C2).\\
\end{align*}}
E.g.:

\begin{align*}
\text{S\_M}((2 + i) + (1 - i)) &= \text{S\_M}(3 + 0i)\\
 &= 3^2 + 0^2\\
 &= 9,\\
 \text{S\_M}(2 + i) + \text{S\_M}(1 - i) &= (2^2 + 1^2)+ ( 1^2 + (-1)^2)\\
 &= (4 + 1) + (1 + 1)\\
 &= 7.
\end{align*}




 Or in the current experiment of discourse, we had flows of $(1 +
0i)$ and $(-1 + 0i)$ cancel out, adding up to 0, whose squared modulus is
0, where the squared modulus of the parts would have been 1 and 1.


 If in place of Squared\_Modulus, our magical tool was some linear
function---any function where $F(X + Y) = F(X) + F(Y)$---then all the
quantumness would instantly vanish and be replaced by a classical
physics. (A \textit{different} classical physics, not the same illusion
of classicality we hallucinate from inside the higher levels of
organization in our own quantum world.)


 If amplitudes were just probabilities, they
couldn't cancel out when flows collided. If
configurations were just states of knowledge, you could reorganize them
however you liked.


 But the configurations are nailed in place, indivisible and
unmergeable without changing the laws of physics.


 And part of what is nailed is the way that configurations treat
multiple particles. A configuration says, ``a photon
here, a photon there,'' not
``\textit{this} photon here, \textit{that} photon
there.'' ``\textit{This} photon
here, \textit{that} photon there'' does not have a
different identity from ``\textit{that} photon here,
\textit{this} photon there.''


 The result, visible in today's experiment, is that
you can't factorize the physics of our universe to be
about particles with individual identities.


 Part of the reason why humans have trouble coming to grips with
\textit{perfectly normal} quantum physics, is that humans bizarrely
keep trying to factor reality into a sum of individually real billiard
balls.


 Ha ha! Silly humans.

\myendsectiontext

\mysection{Distinct Configurations}


 The experiment in the previous essay carried two key lessons: 


 First, we saw that because amplitude flows can cancel out, and
because our magic measure of squared modulus is not linear, the
identity of configurations is nailed down---you can't
reorganize configurations the way you can regroup possible worlds.
Which configurations are the same, and which are distinct, has
experimental consequences; it is an observable fact.


 Second, we saw that configurations are about multiple particles.
If there are two photons entering the apparatus, that
doesn't mean there are two initial configurations.
Instead the initial configuration's identity is
``two photons coming in.'' (Ideally,
each configuration we talk about would include every particle in the
experiment---including the particles making up the mirrors and
detectors. And in the real universe, every configuration is about
\textit{all} the particles\,\ldots \textit{everywhere}.)


 What makes for distinct configurations is not distinct particles.
Each configuration is about every particle. What makes configurations
distinct is particles occupying different positions---at least one
particle in a different state.


 To take one important demonstration\,\ldots

%232.1
\myfigure{images/img297.jpg}{sensitive_thingy}


 Figure \ref{sensitive_thingy} is the same experiment as Figure \ref{four_mirrors}, with one
important change: Between $A$ and $C$ has been placed a sensitive thingy,
$S$. The key attribute of $S$ is that if a photon goes past $S$, then $S$ ends
up in a slightly different state.


 Let's say that the two possible states of $S$ are
\textit{Yes} and \textit{No}. The sensitive thingy $S$ starts out in
state \textit{No}, and ends up in state \textit{Yes} if a photon goes
past.


 Then the initial configuration is:


 ``photon heading toward $A$; and $S$ in state
\textit{No},'' $(-1 + 0i)$.


 Next, the action of the half-silvered mirror at $A$. In the previous
version of this experiment, without the sensitive thingy, the two
resultant configurations were ``$A$ to
$B$'' with amplitude $-i$ and ``$A$ to
$C$'' with amplitude -1. Now, though, a new element has
been introduced into the system, and all configurations are about all
particles, and so every configuration mentions the new element. So the
amplitude flows from the initial configuration are to:


 ``photon from $A$ to $B$; and $S$ in state
\textit{No},'' $(0 - i)$


 ``photon from $A$ to $C$; and $S$ in state
\textit{Yes},'' $(-1 + 0i)$.


 Next, the action of the full mirrors at $B$ and $C$:


 ``photon from $B$ to $D$; and $S$ in state
\textit{No},'' $(1 + 0i)$


 ``photon from $C$ to $D$; and $S$ in state
\textit{Yes},'' $(0 - i)$.


 And then the action of the half-mirror at $D$, on the amplitude
flowing from both of the above configurations:

\begin{enumerate}
\item {
 ``photon from $D$ to $E$; and $S$ in state
\textit{No},'' $(0 + i)$}

\item {
 ``photon from $D$ to $F$; and $S$ in state
\textit{No},'' $(1 + 0i)$}

\item {
 ``photon from $D$ to $E$; and $S$ in state
\textit{Yes},'' $(0 - i)$}

\item {
 ``photon from $D$ to $F$; and $S$ in state
  \textit{Yes},'' $(1 + 0i)$.}
\end{enumerate}


 When we did this experiment without the sensitive thingy, the
amplitude flows (1) and (3) of $(0 + i)$ and $(0 - i)$ to the
``$D$ to $E$'' configuration canceled
each other out. We were left with no amplitude for a photon going to
Detector 1 (way up at the experimental level, we never observe a photon
striking Detector 1).


 But in this case, the two amplitude flows (1) and (3) are now to
distinct configurations; at least one entity, $S$, is in a different
state between (1) and (3). The amplitudes don't cancel
out.


 When we wave our magical squared-modulus-ratio detector over the
four final configurations, we find that the squared moduli of all are
equal: 25\% probability each. Way up at the level of the real world, we
find that the photon has an equal chance of striking Detector 1 and
Detector 2.


 All the above is true, even if we, the researchers,
don't care about the state of $S$. Unlike possible
worlds, configurations cannot be regrouped on a whim. The laws of
\textit{physics} say the two configurations are distinct;
it's not a question of how \textit{we} can most
conveniently parse up the world.


 All the above is true, even if we don't bother to
look at the state of $S$. The configurations (1) and (3) are distinct in
physics, even if we don't know the distinction.


 All the above is true, even if we don't know $S$
exists. The configurations (1) and (3) are distinct whether or not
\textit{we} have distinct \textit{mental representations} for the two
possibilities.


 All the above is true, even if we're in space, and
$S$ transmits a new photon off toward the interstellar void in two
distinct directions, depending on whether the photon of interest passed
it or not. So that we couldn't \textit{ever} find out
whether $S$ had been in \textit{Yes} or \textit{No}. The state of $S$ would
be embodied in the photon transmitted off to nowhere. The lost photon
can be an implied invisible, and the state of $S$ pragmatically
undetectable; but the configurations are still distinct.


 (The main reason it \textit{wouldn't} work, is if
$S$ were nudged, but $S$ had an original spread in configuration space that
was larger than the nudge. Then you couldn't rely on
the nudge to separate the amplitude distribution over configuration
space into distinct lumps. In reality, all this takes place within a
differentiable amplitude distribution over a continuous configuration
space.)


 Configurations are not belief states. Their distinctness is an
objective fact with experimental consequences. The configurations are
distinct even if no one knows the state of $S$; distinct even if no
intelligent entity can ever find out. The configurations are distinct
so long as at least \textit{one particle} in the universe
\textit{anywhere} is in a different position. This is experimentally
demonstrable.


 Why am I emphasizing this? Because back in the dark ages when no
one understood quantum physics\,\ldots

%232.2
\myfigure{images/img292.jpg}{none_at_one}


 Okay, so imagine that you've got no clue
what's really going on, and you try the experiment in
Figure \ref{none_at_one}, and no photons show up at Detector 1. Cool.


 You also discover that when you put a block between $B$ and $D$,
\textit{or} a block between $A$ and $C$, photons show up at Detector 1 and
Detector 2 in equal proportions. But only one at a time---Detector 1 or
Detector 2 goes off, not both simultaneously.


 So, yes, it \textit{does} seem to you like you're
dealing with a particle---the photon is only in one place at one time,
every time \textit{you} see it.

{
 And yet there's some kind of\,\ldots
\textit{mysterious phenomenon\,\ldots} that prevents the photon from
showing up in Detector 1. And this mysterious phenomenon depends on the
photon being \textit{able} to go both ways. Even though the photon only
shows up in one detector or the other, which shows, \textit{you would
think,} that the photon is only in one place at a time.}

%232.3
\myfigure{images/img293.jpg}{bizarre_block}


 Which makes the whole pattern of the experiments seem pretty
bizarre! After all, the photon either goes from $A$ to $C$, or from $A$ to $B$;
one or the other. (Or so you would think, if you were instinctively
trying to break reality down into individually real particles.) But
when you block off one course or the other, as in Figure \ref{bizarre_block}, you
start getting different experimental results!


 It's like the photon wants to be \textit{allowed}
to go both ways, even though (you would think) it only goes one way or
the other. And it can \textit{tell} if you try to block it off, without
actually going \textit{there}{}---if it'd gone there,
it would have run into the block, and not hit any detector at all.


 It's as if mere \textit{possibilities} could have
causal effects, in defiance of what the word
``real'' is usually thought to
\textit{mean}\,\ldots


 But it's a bit early to jump to conclusions like
\textit{that}, when you don't have a complete picture
of what goes on inside the experiment.

%232.4
\myfigure{images/img297.jpg}{sensor_to_tell}


 So it occurs to you to put a sensor between $A$ and $C$, like in
Figure \ref{sensor_to_tell}, so you can tell which way the photon \textit{really} goes
on each occasion.


 And the mysterious phenomenon goes away.


 I mean, now how crazy is that? What kind of paranoia does that
inspire in some poor scientist?


 Okay, so in the twenty-first century we realize in order to
``know'' a photon's
history, the particles making up your brain have to be correlated with
the photon's history. If having a tiny little sensitive
thingy $S$ that correlates to the photon's history is
enough to distinguish the final configurations and prevent the
amplitude flows from canceling, then an entire sensor with a digital
display, never mind a human brain, will put \textit{septillions} of
particles in different positions and prevent the amplitude flows from
canceling.


 But if you hadn't worked that out yet\,\ldots


 Then you would ponder the sensor having banished the Mysterious
Phenomenon, and think:


 The photon doesn't just want to be
\textit{physically} free to go either way. It's not a
little wave going along an unblocked pathway, because then just having
a physically unblocked pathway would be enough.


 No\,\ldots I'm not allowed to \textit{know} which
way the photon went.


 The mysterious phenomenon\,\ldots \textit{doesn't
want me looking at it too closely}\,\ldots while it's
doing its mysterious thing.


 It's not \textit{physical possibilities} that have
an effect on reality\,\ldots only \textit{epistemic possibilities.} If I
\textit{know} which way the photon went, it's no longer
\textit{plausible} that it went the other way\,\ldots which cuts off the
mysterious phenomenon as effectively as putting a block between $B$ and
$D$.


 I have to \textit{not observe} which way the photon went, in order
for it to always end up at Detector 2. It has to be \textit{reasonable}
that the photon could have gone to either $B$ or $C$. What I can
\textit{know} is the determining factor, regardless of which physical
paths I leave open or closed.

\textsc{
 Stop the presses! Mind is fundamental after all! Conscious
awareness determines our experimental results!}


 You can \textit{still read} this kind of stuff. In \textit{physics
textbooks.} Even now, when a majority of theoretical physicists know
better. Stop the presses. Please, stop the presses.


 Hindsight is 20/20; and so it's easy to say that,
in hindsight, there were certain clues that this interpretation was not
correct.


 Like, if you put the sensor between $A$ and $C$ \textit{but
don't read it}, the mysterious phenomenon
\textit{still} goes away, and the photon still sometimes ends up at
Detector 1. (Oh, but you \textit{could} have read it, and possibilities
are real now\,\ldots)


 But it doesn't even have to be a \textit{sensor},
a scientific instrument that you built. A single particle that gets
nudged far enough will dispel the interference. A photon radiating off
to where you'll never see it again can do the trick.
Not much human involvement there. Not a whole lot of conscious
awareness.


 Maybe before you pull the dualist fire alarm on human brains being
physically special, you should provide experimental proof that a rock
can't play the same role in dispelling the Mysterious
Phenomenon as a human researcher?


 But that's hindsight, and it's
easy to call the shots in hindsight. Do you \textit{really} think you
could've done better than John von Neumann, if
you'd been alive at the time? The point of this kind of
retrospective analysis is to ask what kind of fully general clues you
could have followed, and whether there are any similar clues
you're ignoring now on current mysteries.


 Though it \textit{is} a little embarrassing that even
\textit{after} the theory of amplitudes and configurations had been
worked out---with the theory now giving the definite prediction that
any nudged particle would do the trick---early scientists
\textit{still} didn't get it.


 But you see\,\ldots it had been established as Common Wisdom that
configurations were possibilities, it was epistemic possibility that
mattered, amplitudes were a very strange sort of partial information,
and conscious observation made quantumness go away. And that it was
best to avoid thinking too hard about the whole business, so long as
your experimental predictions came out right.

\myendsectiontext

\mysection{Collapse Postulates}


 Macroscopic decoherence{}---also known as
``many-worlds''---is the idea that
the known quantum laws that govern microscopic events simply govern at
all levels without alteration. Back when people didn't
know about decoherence---before it occurred to anyone that the laws
deduced with such precision for microscopic physics might apply
universally---what did people \textit{think} was going on? 


 The initial reasoning seems to have gone something like:

\begin{quote}
{
 When my calculations showed an amplitude of $(-1/3)i$ for this
photon to get absorbed, my experimental statistics showed that the
photon was absorbed around 107 times out of 1,000, which is a good fit
to $1/9$, the square of the modulus.}
\end{quote}


 to

\begin{quote}
{
 The amplitude \textit{is} the probability (by way of the squared
 modulus).}
\end{quote}


 to

\begin{quote}
{
 Once you measure something and \textit{know it
didn't happen}, its \textit{probability} goes to zero.}
\end{quote}


 Read literally, this implies that knowledge itself---or even
conscious awareness---causes the collapse. Which was in fact the form
of the theory put forth by Werner Heisenberg!


 But people became increasingly nervous about the notion of
importing dualistic language into fundamental physics---as well they
should have been! And so the original reasoning was replaced by the
notion of an objective ``collapse''
that destroyed all parts of the wavefunction except one, and was
triggered sometime before superposition grew to human-sized levels.


 Now, once you're supposing that parts of the
wavefunction can just vanish, you might think to ask:

\begin{quote}
{
 Is there only \textit{one} survivor? Maybe there are many
surviving worlds, but they survive with a frequency determined by their
integrated squared modulus, and so the typical surviving world has
experimental statistics that match the Born rule.}
\end{quote}


 Yet collapse theories considered in modern academia only postulate
\textit{one} surviving world. Why?

{
 Collapse theories were devised in a time when it \textit{simply
didn't occur} to any physicists that more than one
world \textit{could} exist! People took for granted that measurements
had single outcomes---it was an assumption so deep it was invisible,
because it was what they \textit{saw happening.} Collapse theories were
devised to explain \textit{why measurements had single outcomes},
rather than (in full generality) \textit{why experimental statistics
matched the Born rule.}}


 For similar reasons, the ``collapse
postulates'' considered academically suppose that
collapse occurs \textit{before} any human beings get superposed. But
experiments are steadily ruling out the possibility of
``collapse'' in increasingly large
entangled systems. Apparently an experiment is underway to demonstrate
quantum superposition at 50-micrometer scales, which is bigger than
most neurons and getting up toward the diameter of some human hairs!


 So why doesn't someone try jumping ahead of the
game, and ask:

\begin{quote}
{
 Say, we keep having to postulate the collapse occurs steadily
later and later. What if collapse occurs only once superposition
reaches planetary scales and substantial divergence occurs---say,
Earth's wavefunction collapses around once a minute?
Then, while the surviving Earths at any given time would
\textit{remember} a long history of quantum experiments that matched
the Born statistics, a supermajority of those Earths would begin
obtaining non-Born results from quantum experiments and then abruptly
cease to exist a minute later.}
\end{quote}


 Why don't collapse theories like \textit{that} one
have a huge academic following, among the many people who apparently
think it's okay for parts of the wavefunction to just
vanish? Especially given that experiments are proving superposition in
steadily larger systems?


 A cynic might suggest that the reason for
collapse's continued support isn't the
\textit{physical plausibility} of having large parts of the
wavefunction suddenly vanish, or the hope of somehow explaining the
Born statistics. The point is to keep the intuitive appeal of
``I don't remember the measurement
having more than one result, therefore only one thing happened; I
don't remember splitting, so there must be only one of
me.'' You don't remember dying, so
superposed humans must never collapse. A theory that dared to stomp on
intuition would be missing the whole point. You might as well just move
on to decoherence.


 So a cynic might suggest.


 But surely it is too early to be attacking the motives of collapse
supporters. That is mere argument ad hominem. What about the actual
physical plausibility of collapse theories?


 Well, first: Does any collapse theory have any experimental
support? No.


 With that out of the way\,\ldots


 If collapse actually worked the way its adherents say it does, it
would be:

\begin{enumerate}
\item {
 The only non-linear evolution in all of quantum mechanics.}

\item {
 The only non-unitary evolution in all of quantum mechanics.}

\item {
 The only non-differentiable (in fact, discontinuous) phenomenon in
all of quantum mechanics.}

\item {
 The only phenomenon in all of quantum mechanics that is non-local
in the configuration space.}

\item {
 The only phenomenon in all of physics that violates CPT symmetry.}

\item {
 The only phenomenon in all of physics that violates
Liouville's Theorem (has a many-to-one mapping from
initial conditions to outcomes).}

\item {
 The only phenomenon in all of physics that is acausal /
non-deterministic / inherently random.}

\item {
 The only phenomenon in all of physics that is non-local in
 spacetime and propagates an influence faster than light.}
\end{enumerate}

\textsc{
 What does the god-damned collapse postulate have to {\em do}
for physicists to reject it? Kill a god-damned puppy?}

\myendsectiontext

\mysection{Decoherence is Simple}


 An epistle to the physicists: 


 When I was but a little lad, my father, a PhD physicist, warned me
sternly against meddling in the affairs of physicists; he said that it
was hopeless to try to comprehend physics without the formal math.
Period. No escape clauses. But I had read in Feynman's
popular books that if you really understood physics, you ought to be
able to explain it to a nonphysicist. I believed Feynman instead of my
father, because Feynman had won the Nobel Prize and my father had not.


 It was not until later---when I was reading the \textit{Feynman
Lectures}, in fact---that I realized that my father had given me the
simple and honest truth. No math = no physics.


 By vocation I am a Bayesian, not a physicist. Yet although I was
raised not to meddle in the affairs of physicists, my hand has been
forced by the occasional gross misuse of three terms: \textit{simple},
\textit{falsifiable}, and \textit{testable}.


 The foregoing introduction is so that you don't
laugh, and say, ``Of course I know what those words
mean!'' There is math here. What follows will be a
restatement of the points in Belief in the Implied Invisible, as they
apply to quantum physics.


 Let's begin with the remark that started me down
this whole avenue, of which I have seen several versions; paraphrased,
it runs:

\begin{quote}
{
 The many-worlds interpretation of quantum mechanics postulates
that there are vast numbers of other worlds, existing alongside our
own. Occam's Razor says we should not multiply entities
unnecessarily.}
\end{quote}


 Now it must be said, in all fairness, that those who say this will
usually also confess:

\begin{quote}
{
 But this is not a universally accepted application of
Occam's Razor; some say that Occam's
Razor should apply to the laws governing the model, not the number of
objects inside the model.}
\end{quote}


 So it is good that we are all acknowledging the contrary
arguments, and telling both sides of the story---


 But suppose you had to \textit{calculate} the simplicity of a
theory.


 The original formulation of William of Ockham stated:\footnote{Edit 2018: Which has not been found in any writing of Ockham's that we know of, but he did write \textit{Numquam ponenda est pluralitas sine necessitate} (``Plurality must never be posited without necessity'') and \textit{Frustra fit per plura, quod potest fieri per pauciora.} (``It is pointless to do with more what can be done with fewer.'') \url{https://en.wikiquote.org/wiki/William_of_Ockham}}

\begin{quote}
{
 \textit{Lex parsimoniae: Entia non sunt multiplicanda praeter
   necessitatem.}}
\end{quote}


 ``The law of parsimony: Entities should not be
multiplied beyond necessity.''


 But this is qualitative advice. It is not enough to say whether
one theory seems more simple, or seems more complex, than another---you
have to assign a number; and the number has to be meaningful, you
can't just make it up. Crossing this gap is like the
difference between being able to eyeball which things are moving
``fast'' or
``slow,'' and starting to measure
and calculate velocities.


 Suppose you tried saying: ``Count the
words---that's how complicated a theory
is.''


 Robert Heinlein once claimed (tongue-in-cheek, I hope) that the
``simplest explanation'' is always:
``The woman down the street is a witch; she did
it.'' Eleven words---not many physics papers can beat
that.


 Faced with this challenge, there are two different roads you can
take.


 First, you can ask: ``The woman down the street
is a \textit{what}?'' Just because English has one
word to indicate a concept doesn't mean that the
concept itself is simple. Suppose you were talking to aliens who
didn't know about witches, women, or streets---how long
would it take you to explain your theory to them? Better yet, suppose
you had to write a computer program that embodied your hypothesis, and
output what you say are your hypothesis's
predictions---how big would that computer program have to be?
Let's say that your task is to predict a time series of
measured positions for a rock rolling down a hill. If you write a
subroutine that simulates witches, this doesn't seem to
help narrow down where the rock rolls---the extra subroutine just
inflates your code. You might find, however, that your code necessarily
includes a subroutine that squares numbers.


 Second, you can ask: ``The woman down the street
is a witch; she did \textit{what}?'' Suppose you want
to describe some event, as precisely as you possibly can given the
evidence available to you---again, say, the distance/time series of a
rock rolling down a hill. You can preface your explanation by saying,
``The woman down the street is a
witch,'' but your friend then says,
``What did she \textit{do}?,'' and
you reply, ``She made the rock roll one meter after
the first second, nine meters after the third second\,\ldots'' Prefacing your message with
``The woman down the street is a
witch,'' doesn't help to
\textit{compress} the rest of your description. On the whole, you just
end up sending a longer message than necessary---it makes more sense to
just leave off the ``witch'' prefix.
On the other hand, if you take a moment to talk about Galileo, you may
be able to greatly compress the next five thousand detailed time series
for rocks rolling down hills.


 If you follow the first road, you end up with
what's known as Kolmogorov complexity and Solomonoff
induction. If you follow the second road, you end up with
what's known as Minimum Message Length.

\begin{quote}
{
  Ah, so I can pick and choose among definitions of simplicity?}
\end{quote}


 No, actually the two formalisms in their most highly developed
forms were proven equivalent.

\begin{quote}
{
 And I suppose now you're going to tell me that
both formalisms come down on the side of ``Occam means
counting laws, not counting objects.''}
\end{quote}


 More or less. In Minimum Message Length, so long as you can tell
your friend an exact recipe they can mentally follow to get the rolling
rock's time series, we don't care how
much mental work it takes to follow the recipe. In Solomonoff
induction, we count bits in the program code, not bits of RAM used by
the program as it runs. ``Entities''
are lines of code, not simulated objects. And as said, these two
formalisms are ultimately equivalent.


 Now before I go into any further detail on formal simplicity, let
me digress to consider the objection:

\begin{quote}
{
 So what? Why can't I just invent my \textit{own}
formalism that does things differently? Why should I pay any attention
to the way you happened to decide to do things, over in your field? Got
any \textit{experimental} evidence that shows I should do things this
way?}
\end{quote}


 Yes, actually, believe it or not. But let me start at the
beginning.


 The conjunction rule of probability theory states:

\begin{equation*}
 P(X,Y) \leq P(X).
\end{equation*}



 For any propositions $X$ and $Y$, the probability that
``$X$ is true, and $Y$ is true,'' is
\textit{less than or equal to} the probability that
``$X$ is true (whether or not $Y$ is
true).'' (If this statement sounds not terribly
profound, then let me assure you that it is easy to find cases where
human probability assessors violate this rule.) 


 You usually can't apply the conjunction rule
$P(X,Y) \leq P(X)$ directly to a conflict between mutually exclusive
hypotheses. The conjunction rule only applies directly to cases where
the left-hand-side strictly implies the right-hand-side. Furthermore,
the conjunction is just an inequality; it doesn't give
us the kind of quantitative calculation we want.


 But the conjunction rule does give us a rule of monotonic decrease
in probability: as you tack more details onto a story, and each
additional detail can potentially be true or false, the
story's probability goes down monotonically. Think of
probability as a conserved quantity: there's only so
much to go around. As the number of details in a story goes up, the
number of possible stories increases exponentially, but the sum over
their probabilities can never be greater than 1. For every story
``$X$ and $Y$,'' there is a story
``$X$ and $\lnot Y$.'' When you
\textit{just} tell the story ``$X$,''
you get to \textit{sum over} the possibilities $Y$ and $\lnot Y$.


 If you add ten details to $X$, each of which could potentially be
true or false, then that story must compete with $2^{10}
- 1$ other equally detailed stories for precious probability. If on the
other hand it suffices to \textit{just} say $X$, you can sum your
probability over $2^{10}$ stories

\begin{align*}
 (&(X\text{ and }Y\text{ and }Z\text{ and }\ldots)\text{ or }\whencolumns{}{\\&}(X\text{ and }\lnot Y\text{ and }Z\text{ and }\ldots)
\text{ or }\ldots).
\end{align*}


 The ``entities'' counted by
Occam's Razor should be individually costly in
probability; this is why we prefer theories with fewer of them. 


 Imagine a lottery which sells up to a million tickets, where each
possible ticket is sold only once, and the lottery has sold every
ticket at the time of the drawing. A friend of yours has bought one
ticket for \$1---which seems to you like a poor investment, because the
payoff is only \$500,000. Yet your friend says, ``Ah,
but consider the alternative hypotheses, `Tomorrow,
someone will win the lottery' and
`Tomorrow, I will win the lottery.'
Clearly, the latter hypothesis is simpler by Occam's
Razor; it only makes mention of one person and one ticket, while the
former hypothesis is more complicated: it mentions a million people and
a million tickets!''


 To say that Occam's Razor only counts laws, and
not objects, is not quite correct: what counts against a theory are the
entities it must mention \textit{explicitly}, because these are the
entities that cannot be \textit{summed over}. Suppose that you and a
friend are puzzling over an amazing billiards shot, in which you are
told the starting state of a billiards table, and which balls were
sunk, but not how the shot was made. You propose a theory which
involves ten specific collisions between ten specific balls; your
friend counters with a theory that involves five specific collisions
between five specific balls. What counts against your theories is not
\textit{just} the laws that you claim to govern billiard balls, but any
\textit{specific} billiard balls that had to be in some
\textit{particular} state for your model's prediction
to be successful.


 If you measure the temperature of your living room as
22\degree{} Celsius, it does not make sense to say:
``Your thermometer is probably in error; the room is
much more likely to be 20\degree{} C. Because, when you
consider all the particles in the room, there are exponentially vastly
more states they can occupy if the temperature is really
22\degree{} C---which makes any \textit{particular} state all
the more improbable.'' But no matter which exact
22\degree{} C state your room occupies, you can make the same
prediction (for the supervast majority of these states) that your
thermometer will end up showing 22\degree{} C, and so you are
not sensitive to the \textit{exact} initial conditions. You do not need
to specify an exact position of all the air molecules in the room, so
that is not counted against the probability of your explanation.


 On the other hand---returning to the case of the lottery---suppose
your friend won ten lotteries in a row. At this point you should
suspect the fix is in. The hypothesis ``My friend wins
the lottery every time'' is more complicated than the
hypothesis ``Someone wins the lottery every
time.'' But the former hypothesis is predicting the
data much more precisely.


 In the Minimum Message Length formalism, saying
``There is a single person who wins the lottery every
time'' at the beginning of your message compresses
your description of who won the next ten lotteries; you can just say
``And that person is Fred Smith'' to
finish your message. Compare to, ``The first lottery
was won by Fred Smith, the second lottery was won by Fred Smith, the
third lottery was\,\ldots''


 In the Solomonoff induction formalism, the prior probability of
``My friend wins the lottery every
time'' is low, because the program that describes the
lottery now needs explicit code that singles out your friend; but
because that program can produce a \textit{tighter probability
distribution} over potential lottery winners than
``Someone wins the lottery every
time,'' it can, by Bayes's Rule,
overcome its prior improbability and win out as a hypothesis.


 Any formal theory of Occam's Razor should
quantitatively define, not only
``entities'' and
``simplicity,'' but also the
``necessity'' part.


 Minimum Message Length defines necessity as
``that which compresses the
message.''


 Solomonoff induction assigns a prior probability to each possible
computer program, with the entire distribution, over every possible
computer program, summing to no more than 1. This can be accomplished
using a binary code where no valid computer program is a prefix of any
other valid computer program (``prefix-free
code''), e.g.~because it contains a stop code. Then
the prior probability of any program $P$ is simply
$2^{-L(P)}$ where $L(P)$ is the length of $P$ in bits.


 The program $P$ itself can be a program that takes in a (possibly
zero-length) string of bits and outputs the conditional probability
that the \textit{next} bit will be 1; this makes $P$ a probability
distribution over all binary sequences. This version of Solomonoff
induction, for any string, gives us a mixture of posterior
probabilities dominated by the shortest programs that most precisely
predict the string. Summing over this mixture gives us a prediction for
the next bit.


 The upshot is that it takes more Bayesian evidence---more
successful predictions, or more precise predictions---to justify more
complex hypotheses. But it can be done; the burden of prior
improbability is not infinite. If you flip a coin four times, and it
comes up heads every time, you don't conclude right
away that the coin produces only heads; but if the coin comes up heads
twenty times in a row, you should be considering it very seriously.
What about the hypothesis that a coin is fixed to produce \textsc{htthtt}\,\ldots
in a repeating cycle? That's more bizarre---but after a
hundred coinflips you'd be a fool to deny it.


 Standard chemistry says that in a gram of hydrogen gas there are
six hundred billion trillion hydrogen atoms. This is a startling
statement, but there was some amount of evidence that sufficed to
convince physicists in general, and you particularly, that this
statement was true.


 Now ask yourself how much evidence it would take to convince you
of a theory with six hundred billion trillion separately specified
physical laws.


 Why doesn't the prior probability of a program, in
the Solomonoff formalism, include a measure of how much RAM the program
uses, or the total running time?


 The simple answer is, ``Because space and time
resources used by a program aren't mutually exclusive
possibilities.'' It's not like the
program specification, that can only have a 1 or a 0 in any particular
place.


 But the even simpler answer is, ``Because,
historically speaking, that heuristic doesn't
work.''

{
 Occam's Razor was raised as an objection to the
suggestion that nebulae were actually distant galaxies---it seemed to
vastly multiply the number of entities in the universe. \textit{All
those stars!}}


 Over and over, in human history, the universe has gotten bigger. A
variant of Occam's Razor which, on each such occasion,
would label the vaster universe as \textit{more unlikely}, would fare
less well under humanity's historical experience.


 This is part of the ``experimental
evidence'' I was alluding to earlier. While you can
justify theories of simplicity on mathy sorts of grounds, it is also
desirable that they actually work in practice. (The other part of the
``experimental evidence'' comes from
statisticians / computer scientists / Artificial Intelligence
researchers, testing which definitions of
``simplicity'' let them construct
computer programs that do empirically well at predicting future data
from past data. Probably the Minimum Message Length paradigm has proven
most productive here, because it is a very adaptable way to think about
real-world problems.)


 Imagine a spaceship whose launch you witness with great fanfare;
it accelerates away from you, and is soon traveling at 0.9c. If the
expansion of the universe continues, as current cosmology holds it
should, there will come some future point where---according to your
model of reality---you don't expect to be able to
interact with the spaceship even in principle; it has gone over the
cosmological horizon relative to you, and photons leaving it will not
be able to outrace the expansion of the universe.


 Should you believe that the spaceship literally, physically
disappears from the universe at the point where it goes over the
cosmological horizon relative to you?


 If you believe that Occam's Razor counts the
objects in a model, then yes, you should. Once the spaceship goes over
your cosmological horizon, the model in which the spaceship instantly
disappears, and the model in which the spaceship continues onward, give
indistinguishable predictions; they have no Bayesian evidential
advantage over one another. But one model contains many fewer
``entities''; it need not speak of
all the quarks and electrons and fields composing the spaceship. So it
is simpler to suppose that the spaceship vanishes.


 Alternatively, you could say: ``Over numerous
experiments, I have generalized certain laws that govern observed
particles. The spaceship is made up of such particles. Applying these
laws, I deduce that the spaceship should continue on after it crosses
the cosmological horizon, with the same momentum and the same energy as
before, on pain of violating the conservation laws that I have seen
holding in every examinable instance. To suppose that the spaceship
vanishes, I would have to add a new law, `Things vanish
as soon as they cross my cosmological
horizon.'\,''


 The decoherence (a.k.a.~many-worlds) version of quantum mechanics
states that measurements obey the same quantum-mechanical rules as all
other physical processes. Applying these rules to macroscopic objects
in exactly the same way as microscopic ones, we end up with observers
in states of superposition. Now there are many questions that can be
asked here, such as ``But then why
don't all binary quantum measurements appear to have
50/50 probability, since different versions of us see both
outcomes?''


 However, the objection that decoherence violates
Occam's Razor on account of multiplying objects in the
model is simply wrong.


 Decoherence does not require the wavefunction to take on some
complicated exact initial state. Many-worlds is not specifying all its
worlds by hand, but generating them via the compact laws of quantum
mechanics. A computer program that directly simulates quantum mechanics
to make experimental predictions, would require a great deal of RAM to
run---but simulating the wavefunction is exponentially expensive in
\textit{any} flavor of quantum mechanics! Decoherence is simply more
so. \textit{Many} physical discoveries in human history, from stars to
galaxies, from atoms to quantum mechanics, have vastly increased the
apparent CPU load of what we believe to be the universe.


 Many-worlds is not a zillion worlds worth of complicated, any more
than the atomic hypothesis is a zillion atoms worth of complicated. For
anyone with a quantitative grasp of Occam's Razor that
is simply not what the term
``complicated'' means.


 As with the historical case of galaxies, it may be that people
have mistaken their \textit{shock} at the notion of a universe that
large, for a probability penalty, and invoked Occam's
Razor in justification. But if there are probability penalties for
decoherence, the \textit{largeness of the implied universe}, per se, is
definitely not their source!


 The notion that decoherent worlds are additional entities
penalized by Occam's Razor is just plain mistaken. It
is not sort-of-right. It is not an argument that is weak but still
valid. It is not a defensible position that could be shored up with
further arguments. It is entirely defective as probability theory. It
is not fixable. It is bad math. 2 + 2 = 3.

\myendsectiontext

\mysection{Decoherence is Falsifiable and Testable}


 The words ``falsifiable'' and
``testable'' are sometimes used
interchangeably, which imprecision is the price of speaking in English.
There are two different probability-theoretic qualities I wish to
discuss here, and I will refer to one as
``falsifiable'' and the other as
``testable'' because it seems like
the best fit.


 As for the math, it begins, as so many things do, with:

\begin{equation*}
  P(A_i|B) = \frac{P(B|A_i)P(A_i)}
  {\sum_j P(B|A_j)P(A_j)}.
\end{equation*}


\bigskip


 This is Bayes's Theorem. I own at least two
distinct items of clothing printed with this theorem, so it must be
important. 


 To review quickly, $B$ here refers to an item of evidence,
$A_{i}$ is some hypothesis under consideration, and the
$A_{j}$ are competing, mutually exclusive hypotheses. The
expression $P(B|A_{i})$ means
``the probability of seeing $B$, if hypothesis
$A_{i}$ is true'' and
$P(A_{i}|B)$ means ``the
probability hypothesis $A_{i}$ is true, if we see
$B$.''


 The mathematical phenomenon that I will call
``falsifiability'' is the
scientifically desirable property of a hypothesis that it should
concentrate its probability mass into preferred outcomes, which implies
that it must also assign low probability to some un-preferred outcomes;
probabilities must sum to 1 and there is only so much probability to go
around. Ideally there should be possible observations which would drive
down the hypothesis's probability to nearly zero: There
should be things the hypothesis \textit{cannot} explain, conceivable
experimental results with which the theory is \textit{not} compatible.
A theory that can explain everything prohibits nothing, and so gives us
no advice about what to expect.

\begin{equation*}
  P(A_i|B) = \frac{P(B|A_i)P(A_i)}
  {\sum_j P(B|A_j)P(A_j)}
\end{equation*}



\bigskip


 In terms of Bayes's Theorem, if there is at least
some observation $B$ that the hypothesis $A_{i}$
can't explain, i.e., $P(B|A_{i})$
is tiny, then the numerator
$P(B|A_{i})P(A_{i})$ will also be
tiny, and likewise the posterior probability
$P(A_{i}|B)$. Updating on having seen the
impossible result $B$ has driven the probability of $A_{i}$
down to nearly zero. A theory that refuses to make itself vulnerable in
this way will need to spread its probability widely, so that it has no
holes; it will not be able to strongly concentrate probability into a
few preferred outcomes; it will not be able to offer precise advice.


 Thus is the rule of science derived in probability theory.


 As depicted here,
``falsifiability'' is something you
evaluate by looking at a \textit{single} hypothesis, asking,
``How narrowly does it concentrate its probability
distribution over possible outcomes? How narrowly does it tell me what
to expect? Can it explain some possible outcomes much better than
others?''


 Is the decoherence interpretation of quantum mechanics
\textit{falsifiable}? Are there experimental results that could drive
its probability down to an infinitesimal?


 Sure: We could measure entangled particles that should always have
opposite spin, and find that if we measure them far enough apart, they
sometimes have the same spin.


 Or we could find apples falling upward, the planets of the Solar
System zigging around at random, and an atom that kept emitting photons
without any apparent energy source. Those observations would also
falsify decoherent quantum mechanics. They're things
that, on the hypothesis that decoherent quantum mechanics governs the
universe, we should definitely \textit{not expect} to see.


 So there do exist observations $B$ whose
$P(B|A_{deco})$ is infinitesimal, which would drive
$P(A_{deco}|B)$ down to an infinitesimal.

\begin{quote}
{
 But that's just because decoherent quantum
mechanics is still quantum mechanics! What about the decoherence part,
per se, versus the collapse postulate?}
\end{quote}


 We're getting there. The point is that I just
defined a test that leads you to think about one hypothesis at a time
(and called it ``falsifiability'').
If you want to distinguish decoherence \textit{versus} collapse, you
have to think about at least \textit{two} hypotheses at a time.


 Now really the
``falsifiability'' test is not quite
\textit{that} singly focused, i.e., the sum in the denominator has got
to contain \textit{some} other hypothesis. But what I just defined as
``falsifiability'' pinpoints the
kind of problem that Karl Popper was complaining about, when he said
that Freudian psychoanalysis was
``unfalsifiable'' because it was
equally good at coming up with an explanation for every possible thing
the patient could do.


 If you belonged to an alien species that had never invented the
collapse postulate or Copenhagen Interpretation---if the only physical
theory you'd \textit{ever} heard of was decoherent
quantum mechanics---if \textit{all} you had in your head was the
differential equation for the wavefunction's evolution
plus the Born probability rule---you would still have sharp
expectations of the universe. You would not live in a magical world
where anything was probable.

\begin{quote}
{
 But you could say exactly the same thing about quantum mechanics
\textit{without} (macroscopic) decoherence.}
\end{quote}


 Well, yes! Someone walking around with the differential equation
for the wavefunction's evolution, plus a collapse
postulate that obeys the Born probabilities and is triggered before
superposition reaches macroscopic levels, still lives in a universe
where apples fall down rather than up.

\begin{quote}
{
 But where does decoherence make a \textit{new} prediction, one
 that lets us \textit{test} it?}
\end{quote}


 A ``new'' prediction relative
to what? To the state of knowledge possessed by the ancient Greeks? If
you went back in time and showed them decoherent quantum mechanics,
they would be enabled to make many experimental predictions they could
not have made before.


 When you say ``new
prediction,'' you mean
``new'' relative to some other
hypothesis that defines the ``old
prediction.'' This gets us into the theory of what
I've chosen to label \textit{testability}; and the
algorithm inherently considers at least two hypotheses at a time. You
cannot call something a ``\textit{new}
prediction'' by considering only one hypothesis in
isolation.


 In Bayesian terms, you are looking for an item of evidence $B$ that
will produce evidence for one hypothesis over another, distinguishing
between them, and the process of producing this evidence we could call
a ``test.'' You are looking for an
experimental result $B$ such that

\begin{equation*}
 P(B|A_{d}) \neq P(B|A_{c});
\end{equation*}



 that is, some outcome $B$ which has a different probability,
conditional on the decoherence hypothesis being true, versus its
probability if the collapse hypothesis is true. Which in turn implies
that the posterior odds for decoherence and collapse will become
different from the prior odds:

\begin{align*}
  \frac{P(B|A_d)}{P(B|A_c)} &\neq 1 \text{ implies} \\
  \frac{P(A_d|B)}{P(A_c|B)} &= \frac{P(B|A_d)}{P(B|A_c)} \times \frac{P(A_d)}{P(A_c)} \\
  \frac{P(A_d|B)}{P(A_c|B)} &\neq \frac{P(A_d)}{P(A_c)} .
\end{align*}


\bigskip


 This equation is symmetrical (assuming no probability is literally
equal to 0). There isn't one $A_{j}$ labeled
``old hypothesis'' and another
$A_{j}$ labeled ``new
hypothesis.''


 This symmetry is a feature, not a bug, of probability theory! If
you are designing an artificial reasoning system that arrives at
different beliefs depending on the order in which the evidence is
presented, this is labeled
``hysteresis'' and considered a Bad
Thing. I hear that it is also frowned upon in Science.


 From a probability-theoretic standpoint we have various trivial
theorems that say it shouldn't matter whether you
update on $X$ first and then $Y$, or update on $Y$ first and then $X$. At least
they'd be trivial if human beings
didn't violate them so often and so lightly.


 If decoherence is
``untestable'' relative to collapse,
then so too, collapse is
``untestable'' relative to
decoherence. What if the history of physics had transpired
differently---what if Hugh Everett and John Wheeler had stood in the
place of Bohr and Heisenberg, and vice versa? Would it then be right
and proper for the people of that world to look at the collapse
interpretation, and snort, and say, ``Where are the
\textit{new} predictions?''


 What if someday we meet an alien species that invented decoherence
before collapse? Are we each bound to keep the theory we invented
first? Will Reason have nothing to say about the issue, leaving no
recourse to settle the argument but interstellar war?

\begin{quote}
{
 But if we revoke the requirement to yield new predictions, we are
left with scientific chaos. You can add arbitrary untestable
complications to old theories, and get experimentally equivalent
predictions. If we reject what you call
``hysteresis,'' how can we defend
our current theories against every crackpot who proposes that electrons
have a new property called
``scent,'' just like quarks have
``flavor''?}
\end{quote}


 Let it first be said that I quite agree that you should reject the
one who comes to you and says: ``Hey,
I've got this brilliant new idea! Maybe
it's not the electromagnetic field
that's tugging on charged particles. Maybe there are
tiny little angels who actually push on the particles, and the
electromagnetic field just tells them how to do it. Look, I have all
these successful experimental predictions---the predictions you used to
call your own!''


 So yes, I agree that we shouldn't buy this amazing
new theory, but it is not the \textit{newness} that is the problem.


 Suppose that human history had developed only slightly
differently, with the Church being a primary grant agency for Science.
And suppose that when the laws of electromagnetism were first being
worked out, the phenomenon of magnetism had been taken as proof of the
existence of unseen spirits, of angels. James Clerk becomes Saint
Maxwell, who described the laws that direct the actions of angels.


 A couple of centuries later, after the Church's
power to burn people at the stake has been restrained, someone comes
along and says: ``Hey, do we really need the
angels?''


 ``Yes,'' everyone says.
``How else would the mere numbers of the
electromagnetic field translate into the actual motions of
particles?''


 ``It might be a fundamental
law,'' says the newcomer, ``or it
might be something other than angels, which we will discover later.
What I am suggesting is that interpreting the numbers \textit{as the
action of angels} doesn't really add anything, and we
should just keep the numbers and throw out the angel
part.''


 And they look one at another, and finally say,
``But your theory doesn't make any new
experimental predictions, so why should we adopt it? How do we test
your assertions about the absence of angels?''


 From a normative perspective, it seems to me that if we should
reject the crackpot angels in the first scenario, \textit{even without
being able to distinguish the two theories experimentally,} then we
should also reject the angels of established science in the second
scenario, even without being able to distinguish the two theories
experimentally.


 It is ordinarily the crackpot who adds on new useless
complications, rather than scientists who accidentally build them in at
the start. But the problem is not that the complications are new, but
that they are useless whether or not they are new.


 A Bayesian would say that the extra complications of the angels in
the theory lead to penalties on the prior probability of the theory. If
two theories make equivalent predictions, we keep the one that can be
described with the shortest message, the smallest program. If you are
evaluating the prior probability of each hypothesis by counting bits of
code, and then applying Bayesian updating rules on all the evidence
available, then it makes no difference which hypothesis you hear about
first, or the order in which you apply the evidence.


 It is usually not possible to apply formal probability theory in
real life, any more than you can predict the winner of a tennis match
using quantum field theory. But if probability theory can serve as a
guide to practice, this is what it says: Reject \textit{useless}
complications \textit{in general}, not just when they are
\textit{new}.

\begin{quote}
{
 Yes, and \textit{useless} is precisely what the many worlds of
decoherence are! There are supposedly all these worlds alongside our
own, and they don't \textit{do} anything to our world,
but I'm supposed to believe in them anyway?}
\end{quote}


 No, according to decoherence, what you're supposed
to believe are the general laws that govern wavefunctions---and these
general laws are very visible and testable.


 I have argued elsewhere that the imprimatur of science should be
associated with general laws, rather than particular events, because it
is the general laws that, in principle, anyone can go out and test for
themselves. I assure you that I happen to be wearing white socks right
now as I type this. So you are probably \textit{rationally} justified
in believing that this is a historical fact. But it is not the
specially strong kind of statement that we canonize as a provisional
belief of science, because there is no experiment that you can do for
yourself to determine the truth of it; you are stuck with my authority.
Now, if I were to tell you the mass of an electron in general, you
could go out and find your own electron to test, and thereby see for
yourself the truth of the general law in that particular case.


 The ability of anyone to go out and verify a general scientific
law for themselves, by constructing some particular case, is what makes
our belief in the general law specially reliable.


 What decoherentists say they believe in is the differential
equation that is observed to govern the evolution of
wavefunctions---which you can go out and test yourself any time you
like; just look at a hydrogen atom.


 Belief in the existence of separated portions of the universal
wavefunction is not \textit{additional}, and it is not
\textit{supposed} to be explaining the price of gold in London; it is
just a deductive consequence of the wavefunction's
evolution. If the evidence of many particular cases gives you cause to
believe that $X \rightarrow  Y$ is a general law, and the evidence of
some particular case gives you cause to believe $X$, then you should have
$P(Y) \geq P(X \text{ and } (X \rightarrow Y))$.


 Or to look at it another way, if $P(Y|X) \approx 1$,
then $P(X \text{ and } Y) \approx P(X)$.


 Which is to say, believing extra details doesn't
cost you extra probability when they are \textit{logical implications}
of general beliefs you already have. Presumably the general beliefs
themselves are falsifiable, though, or why bother?


 This is why we don't believe that spaceships blink
out of existence when they cross the cosmological horizon relative to
us. True, the spaceship's continued existence
doesn't have an impact on our world. The
spaceship's continued existence isn't
helping to explain the price of gold in London. But we get the
invisible spaceship for free as a consequence of general laws that
imply conservation of mass and energy. If the
spaceship's continued existence were \textit{not} a
deductive consequence of the laws of physics as we presently model
them, \textit{then} it would be an additional detail, cost extra
probability, and we would have to question why our theory must include
this assertion.


 The part of decoherence that is supposed to be testable is not the
many worlds per se, but just the general law that governs the
wavefunction. The decoherentists note that, applied universally, this
law implies the existence of entire superposed worlds. Now there are
critiques that can be leveled at this theory, most notably,
``But then where do the Born probabilities come
from?'' But within the internal logic of decoherence,
the many worlds are not offered as an explanation for anything, nor are
they the substance of the theory that is meant to be tested; they are
simply a logical consequence of those general laws that constitute the
substance of the theory.


 If $A \Rightarrow B$ then $\lnot B \Rightarrow
 \lnot A$. To deny the existence of superposed worlds is
necessarily to deny the universality of the quantum laws formulated to
govern hydrogen atoms and every other examinable case; it is this
denial that seems to the decoherentists like the extra and untestable
detail. You can't see the other parts of the
wavefunction---why postulate \textit{additionally} that they
don't exist?


 The events surrounding the decoherence controversy may be unique
in scientific history, marking the first time that serious scientists
have come forward and said that by historical accident humanity has
developed a powerful, successful, mathematical physical theory that
includes angels. That there is an entire law, the collapse postulate,
that can simply be thrown away, leaving the theory \textit{strictly}
simpler.


 To this discussion I wish to contribute the assertion that, in the
light of a mathematically solid understanding of probability theory,
decoherence is not ruled out by Occam's Razor, nor is
it unfalsifiable, nor is it untestable.


 We may consider e.g.~decoherence and the collapse postulate, side
by side, and evaluate critiques such as
``Doesn't decoherence definitely
predict that quantum probabilities should always be
50/50?'' and
``Doesn't collapse violate Special
Relativity by implying influence at a distance?'' We
can consider the relative merits of these theories on grounds of their
compatibility with experience and the apparent character of physical
law.


 To assert that decoherence is not even in the game---because the
many worlds themselves are ``extra
entities'' that violate Occam's
Razor, or because the many worlds themselves are
``untestable,'' or because
decoherence makes no ``new
predictions''---all this is, I would argue, an
outright error of probability theory. The discussion should simply
discard those particular arguments and move on.

\myendsectiontext

\mysection{Privileging the Hypothesis}


 Suppose that the police of Largeville, a town with a million
inhabitants, are investigating a murder in which there are few or no
clues---the victim was stabbed to death in an alley, and there are no
fingerprints and no witnesses. 


 Then, one of the detectives says, ``Well\,\ldots we
have no idea who did it\,\ldots no particular evidence singling out any
of the million people in this city\,\ldots but let's
\textit{consider the hypothesis} that this murder was committed by
Mortimer Q. Snodgrass, who lives at 128 Ordinary Ln. It \textit{could}
have been him, after all.''


 I'll label this \textit{the fallacy of privileging
the hypothesis.} (Do let me know if it already has an official name---I
can't recall seeing it described.)


 Now the detective may perhaps have some form of rational evidence
that is not legal evidence admissible in court---hearsay from an
informant, for example. But if the detective does not have
\textit{some} justification \textit{already in hand} for promoting
Mortimer to the police's special attention---if the
name is pulled entirely out of a hat---then Mortimer's
rights are being violated.


 And this is true even if the detective is not claiming that
Mortimer ``did'' do it, but only
asking the police to spend time pondering that Mortimer \textit{might}
have done it---unjustifiably promoting that particular hypothesis to
attention. It's human nature to look for confirmation
rather than disconfirmation. Suppose that three detectives each suggest
their hated enemies, as names to be considered; and Mortimer is
brown-haired, Frederick is black-haired, and Helen is blonde. Then a
witness is found who says that the person leaving the scene was
brown-haired. ``Aha!'' say the
police. ``We previously had no evidence to distinguish
among the possibilities, but \textit{now} we know that Mortimer did
it!''


 This is related to the principle I've started
calling ``locating the hypothesis,''
which is that if you have a billion boxes only one of which contains a
diamond (the truth), and your detectors only provide 1 bit of evidence
apiece, then it takes much more evidence to promote the truth to your
particular attention---to narrow it down to ten good possibilities,
each deserving of our individual attention---than it does to figure out
\textit{which} of those ten possibilities is true. It takes 27 bits to
narrow it down to ten, and just another 4 bits will give us better than
even odds of having the right answer.


 Thus the detective, in calling Mortimer to the particular
attention of the police, for no reason out of a million other people,
is skipping over \textit{most of the evidence} that needs to be
supplied against Mortimer.


 And the detective ought to have this evidence in their possession,
at the first moment when they bring Mortimer to the
police's attention \textit{at all.} It may be mere
rational evidence rather than legal evidence, but if
there's \textit{no evidence} then the detective is
harassing and persecuting poor Mortimer.


 During my recent diavlog with Scott Aaronson on quantum mechanics,\footnote{\url{http://bloggingheads.tv/videos/2220}}
I did manage to corner Scott to the extent of getting Scott to admit
that there was no concrete evidence whatsoever that favors a collapse
postulate or single-world quantum mechanics. But, said Scott, we might
encounter \textit{future} evidence in favor of single-world quantum
mechanics, and many-worlds still has the open question of the Born
probabilities.\footnote{\url{http://lesswrong.com/lw/py/the_born_probabilities/}}


 This is indeed what I would call the fallacy of privileging the
hypothesis. There must be a trillion better ways to answer the Born
question without adding a collapse postulate that would be the only
non-linear, non-unitary, discontinous, non-differentiable,
non-CPT-symmetric, non-local in the configuration space,
Liouville's-Theorem-violating,
privileged-space-of-simultaneity-possessing,
faster-than-light-influencing, acausal, informally specified law in all
of physics. Something that unphysical is not worth \textit{saying out
loud} or even \textit{thinking about as a possibility} without a rather
large weight of evidence---far more than the current grand total of
zero.


 But because of a historical accident, collapse postulates and
single-world quantum mechanics are indeed on everyone's
lips and in everyone's mind to be thought of, and so
the open question of the Born probabilities is offered up (by Scott
Aaronson no less!) as evidence that many-worlds can't
yet offer a complete picture of the world. Which is taken to mean that
single-world quantum mechanics is still in the running somehow.


 In the minds of human beings, if you can get them to think about
this particular hypothesis rather than the trillion other possibilities
that are no more complicated or unlikely, you really \textit{have} done
a huge chunk of the work of persuasion. Anything thought about is
treated as ``in the running,'' and
if other runners seem to fall behind in the race a little,
it's assumed that this runner is edging forward or even
entering the lead.


 And yes, this is just the same fallacy committed, on a much more
blatant scale, by the theist who points out that modern science does
not offer an absolutely complete explanation of the entire universe,
and takes this as evidence for the existence of Jehovah. Rather than
Allah, the Flying Spaghetti Monster, or a trillion other gods no less
complicated---never mind the space of naturalistic explanations!


 To talk about ``intelligent
design'' whenever you point to a purported flaw or
open problem in evolutionary theory is, again, privileging the
hypothesis---you must have evidence \textit{already in hand} that
points to intelligent design \textit{specifically} in order to justify
\textit{raising that particular idea to our attention}, rather than a
thousand others.


 So that's the \textit{sane} rule. And the
corresponding anti-epistemology is to talk endlessly of
``possibility'' and how you
``can't disprove''
an idea, to hope that future evidence may confirm it without presenting
past evidence already in hand, to dwell and dwell on
\textit{possibilities} without evaluating possibly unfavorable
evidence, to draw glowing word-pictures of confirming observations that
\textit{could} happen but haven't happened
\textit{yet}, or to try and show that piece after piece of negative
evidence is ``not conclusive.''


 Just as Occam's Razor says that more complicated
propositions require more evidence to believe, more complicated
propositions also ought to require more work to raise to attention.
Just as the principle of burdensome details requires that each part of
a belief be separately justified, it requires that each part be
separately raised to attention.


 As discussed in Perpetual Motion Beliefs, faith and type 2
perpetual motion machines (water $\rightarrow $ ice cubes +
electricity) have in common that they purport to \textit{manufacture
improbability from nowhere}, whether the improbability of water forming
ice cubes or the improbability of arriving at correct beliefs without
observation. Sometimes most of the anti-work involved in manufacturing
this improbability is getting us to \textit{pay attention} to an
unwarranted belief---thinking on it, dwelling on it. In large answer
spaces, attention without evidence is more than halfway to belief
without evidence.


 Someone who spends all day thinking about whether the
\textit{Trinity} does or does not exist, rather than Allah or Thor or
the Flying Spaghetti Monster, is more than halfway to Christianity. If
leaving, they're less than half departed; if arriving,
they're more than halfway there.


 An oft-encountered mode of privilege is to try to make uncertainty
within a space, slop outside of that space onto the privileged
hypothesis. For example, a creationist seizes on some (allegedly)
debated aspect of contemporary theory, argues that scientists are
\textit{uncertain about evolution}, and then says,
``We don't really know which theory is
right, so maybe intelligent design is right.'' But
the uncertainty is uncertainty \textit{within} the realm of
naturalistic theories of evolution---we have no reason to believe that
we'll need to leave that realm to deal with our
uncertainty, still \textit{less} that we would jump out of the realm of
standard science and land \textit{on Jehovah in particular.} That is
privileging the hypothesis---taking doubt \textit{within} a normal
space, and trying to slop doubt \textit{out} of the normal space, onto
a privileged (and usually discredited) \textit{extremely} abnormal
target.


 Similarly, our uncertainty about where the Born statistics come
from should be uncertainty \textit{within} the space of quantum
theories that are continuous, linear, unitary, slower-than-light,
local, causal, naturalistic, et cetera---the usual character of
physical law. Some of that uncertainty might slop outside the standard
space onto theories that violate \textit{one} of these standard
characteristics. It's indeed possible that we might
have to think outside the box. But single-world theories violate
\textit{all} these characteristics, and there is no reason to privilege
that hypothesis.

\myendsectiontext

\mysection{Living in Many Worlds}


 Some commenters have recently expressed disturbance at the thought
of constantly splitting into zillions of other people, as is the
straightforward and unavoidable prediction of quantum mechanics. 


 Others have confessed themselves unclear as to the implications of
many-worlds for planning: If you decide to buckle your seat belt in
this world, does that increase the chance of another self unbuckling
their seat belt? Are you being selfish at their expense?

{
 Just remember Egan's Law: \textit{It all adds up
to normality.}}


 (After Greg Egan, in \textit{Quarantine}.\footnote{Greg Egan, \textit{Quarantine} (London: Legend Press, 1992).\comment{1}})

{
 Frank Sulloway said:\footnote{Robert S. Boynton, ``The Birth of an Idea: A
Profile of Frank Sulloway,'' \textit{The New Yorker}
(October 1999).\comment{2}}}

\begin{quote}
{
 Ironically, psychoanalysis has it over Darwinism precisely because
its predictions are so outlandish and its explanations are so
counterintuitive that we think, \textit{Is that really true? How
radical!} Freud's ideas are so intriguing that people
are willing to pay for them, while one of the great disadvantages of
Darwinism is that we feel we know it already, because, in a sense, we
do.}
\end{quote}


 When Einstein overthrew the Newtonian version of gravity, apples
didn't stop falling, planets didn't
swerve into the Sun. Every new theory of physics must \textit{capture}
the successful predictions of the old theory it displaced; it should
predict that the sky will be blue, rather than green.


 So don't think that many-worlds is there to make
strange, radical, exciting predictions. It all adds up to normality.


 Then why should anyone care?


 Because there was once asked the question, fascinating unto a
rationalist: \textit{What} all adds up to normality?


 And the answer to this question turns out to be: quantum
mechanics. It is \textit{quantum mechanics} that adds up to normality.


 If there were something else there \textit{instead} of quantum
mechanics, \textit{then} the world would look strange and unusual.

{
 Bear this in mind, when you are wondering how to live in the
strange new universe of many worlds: \textit{You have always been
there.}}


 Religions, anthropologists tell us, usually exhibit a property
called \textit{minimal counterintuitiveness}; they are startling enough
to be memorable, but not so bizarre as to be \textit{difficult} to
memorize. Anubis has the head of a dog, which makes him memorable, but
the rest of him is the body of a man. Spirits can see through walls;
but they still become hungry.


 But physics is not a religion, set to surprise you just exactly
enough to be memorable. The underlying phenomena are so
counterintuitive that it takes long study for humans to come to grips
with them. But the surface phenomena are entirely ordinary. You will
\textit{never} catch a glimpse of another world out of the corner of
your eye. You will \textit{never} hear the voice of some other self.
That is unambiguously prohibited outright by the laws. Sorry,
you're just schizophrenic.


 The act of making \textit{decisions} has no special interaction
with the process that branches worlds. In your \textit{mind}, in your
\textit{imagination}, a decision seems like a branching point where the
world could go two different ways. But you would feel just the same
uncertainty, visualize just the same alternatives, if there were only
one world. That's what people thought for centuries
before quantum mechanics, and they still visualized alternative
outcomes that could result from their decisions.


 \textit{Decision} and \textit{decoherence} are \textit{entirely
orthogonal concepts.} If your brain never became decoherent, then that
single cognitive process would still have to imagine different choices
and their different outcomes. And a rock, which makes no decisions,
obeys the same laws of quantum mechanics as anything else, and splits
frantically as it lies in one place.


 You don't split \textit{when you come to a
decision} in \textit{particular}, any more than you particularly split
when you take a breath. You're just splitting all the
time as the result of decoherence, which has nothing to do with
choices.


 There is a population of worlds, and in each world, it all adds up
to normality: apples don't stop falling. In each world,
people choose the course that seems best to them. Maybe they happen on
a different line of thinking, and see new implications or miss others,
and come to a different choice. But it's not that one
world chooses each choice. It's not that one version of
you chooses what seems best, and another version chooses what seems
worst. In each world, apples go on falling and people go on doing what
seems like a good idea.


 Yes, you can nitpick exceptions to this rule, but
they're \textit{normal} exceptions. It all adds up to
normality, in all the worlds.


 You cannot ``choose which world to end up
in.'' In all the worlds, people's
choices determine outcomes in the same way they would in just one
single world.


 The choice you make here does not have some strange balancing
influence on some world elsewhere. There is no causal communication
between decoherent worlds. In each world, people's
choices control the future of that world, not some other world.


 If you can imagine decisionmaking in one world, you can imagine
decision-making in many worlds: just have the world constantly
splitting while otherwise obeying all the same rules.


 In no world does two plus two equal five. In no world can
spaceships travel faster than light. All the quantum worlds obey our
laws of physics; their existence is asserted in the first place by our
laws of physics. Since the beginning, not one unusual thing has ever
happened, in this or any other world. They are all lawful.


 Are there horrible worlds out there, which are utterly beyond your
ability to affect? Sure. And horrible things happened during the
twelfth century, which are also beyond your ability to affect. But the
twelfth century is not your responsibility, because it has, as the
quaint phrase goes, ``already
happened.'' I would suggest that you consider every
world that is not in your future to be part of the
``generalized past.''


 Live in your own world. Before you knew about quantum physics, you
would not have been tempted to try living in a world that did not seem
to exist. Your decisions should add up to this same normality: you
shouldn't try to live in a quantum world you
can't communicate with.


 Your decision theory should (almost always) be the same, whether
you suppose that there is a 90\% probability of something happening, or
if it will happen in 9 out of 10 worlds. Now, because people have
trouble handling probabilities, it may be helpful to visualize
something happening in 9 out of 10 worlds. But this just helps you use
normal decision theory.


 Now is a good time to begin learning how to shut up and multiply.
As I note in Lotteries: A Waste of Hope:

\begin{quote}
{
 The human brain doesn't do 64-bit floating-point
arithmetic, and it can't devalue the emotional force of
a pleasant anticipation by a factor of 0.00000001 without dropping the
line of reasoning entirely.}
\end{quote}


 And in New Improved Lottery:

\begin{quote}
{
 Between zero chance of becoming wealthy, and epsilon chance, there
is an order-of-epsilon difference. If you doubt this, let epsilon equal
one over googolplex.}
\end{quote}


 If you're thinking about a world that could arise
in a lawful way, but whose probability is a quadrillion to one, and
something very pleasant or very awful is happening in this world\,\ldots
well, it does probably exist, if it is lawful. But you should try to
release one quadrillionth as many neurotransmitters, in your reward
centers or your aversive centers, so that you can weigh that world
\textit{appropriately} in your decisions. If you don't
think you can do that\,\ldots don't bother thinking about
it.


 Otherwise you might as well go out and buy a lottery ticket using
a quantum random number, a strategy that is \textit{guaranteed} to
result in a very tiny mega-win.


 Or here's another way of thinking about it: Are
you considering expending some mental energy on a world whose frequency
in your future is less than a trillionth? Then go get a 10-sided die
from your local gaming store, and, before you begin thinking about that
strange world, start rolling the die. If the die comes up 9 twelve
times in a row, \textit{then} you can think about that world. Otherwise
don't waste your time; thought-time is a resource to be
expended wisely.


 You can roll the dice as many times as you like, but you
can't think about the world until 9 comes up twelve
times in a row. Then you can think about it for a minute. After that
you have to start rolling the die again.


 This may help you to appreciate the concept of
``trillion to one'' on a more
visceral level.


 If at any point you catch yourself thinking that quantum physics
might have some kind of strange, \textit{abnormal} implication for
everyday life---then you should probably stop right there.


 Oh, there are a \textit{few} implications of many-worlds for
ethics. Average utilitarianism suddenly looks a lot more
attractive---you don't need to worry about creating as
many people as possible, because there are already plenty of people
exploring person-space. You just want the average quality of life to be
as high as possible, in the future worlds that are your
responsibility.


 And you should always take joy in discovery, as long as
\textit{you personally} don't know a thing. It is
meaningless to talk of being the
``first'' or the
``only'' person to know a thing,
when everything knowable is known within worlds that are in neither
your past nor your future, and are neither before or after you.


 But, by and large, it all adds up to normality. If your
understanding of many-worlds is the tiniest bit \textit{shaky}, and you
are contemplating whether to believe some strange proposition, or feel
some strange emotion, or plan some strange strategy, then I can give
you very simple advice: Don't.


 The quantum universe is not a strange place into which you have
been thrust. It is the way things have always been.

\myendsectiontext


\bigskip

\mysection{Quantum Non{}-Realism}

\begin{quote}

 Does the moon exist when no one is looking at it?

{\raggedleft
 {}---Albert Einstein, asked of Niels Bohr
\par}
\end{quote}



 Suppose you were just starting to work out a theory of quantum
mechanics.


 You begin to encounter experiments that deliver different results
depending on how closely you observe them. You dig underneath the
reality you know, and find an extremely precise mathematical
description that only gives you the relative frequency of outcomes;
worse, it's made of complex numbers. Things behave like
particles on Monday and waves on Tuesday.


 The correct answer is not available to you as a hypothesis,
because it will not be invented for another thirty years.


 In a mess like that, what's the best you
\textit{could} do?


 The best you can do is the \textit{strict} ``shut
up and calculate'' interpretation of quantum
mechanics. You'll go on \textit{trying} to develop new
theories, because doing your best doesn't mean giving
up. But we've specified that the correct answer
won't be available for thirty years, and that means
none of the new theories will really be any good. Doing the
\textit{best} you could theoretically do would mean that you recognized
that, even as you looked for ways to test the hypotheses.


 The best you could theoretically do would \textit{not} include
saying anything like, ``The wavefunction only gives us
probabilities, not certainties.'' That, in
retrospect, was jumping to a conclusion; the wavefunction gives us a
certainty of many worlds existing. So that part about the wavefunction
being only a probability was not-quite-right. You calculated, but
failed to shut up.


 If you do the \textit{best} that you can do without the correct
answer being available, then, when you hear about decoherence, it will
turn out that you have not said \textit{anything} incompatible with
decoherence. Decoherence is not ruled out by the data and the
calculations. So if you refuse to affirm, as positive knowledge, any
proposition which was not forced by the data and the calculations, the
calculations will not \textit{force} you to say anything incompatible
with decoherence. So too with whatever the correct theory may be, if it
is not decoherence. If you go astray, it must be from your own
impulses.

{
 But it is hard for human beings to shut up and
calculate---\textit{really} shut up and calculate. There is an
overwhelming tendency to treat our ignorance as if it were positive
knowledge.\footnote{Edit 2018: There was social pressure to philosophize about quantum physics.  For example, Enrico Fermi, who mostly tried to just focus on real physics problems was called a mere ``quantum engineer'' by Wolfgang Pauli.  (David N. Schwartz, \textit{The Last Man Who Knew Everything}, 2017, pages xxii and 36)}


 I don't know if any conversations like this ever
really took place, but this is how ignorance becomes knowledge:

\begin{quotation}

 \textsc{Gallant}: ``Shut up and
calculate.''


 \textsc{Goofus}: ``Why?''


 \textsc{Gallant}: ``Because I don't know
what these equations mean, just that they seem to
work.''


 \textit{{}---five minutes later---}


 \textsc{Goofus}: ``Shut up and
calculate.''


 \textsc{Student}: ``Why?''


 \textsc{Goofus}: ``Because these equations
don't \textit{mean} anything, they just
work.''


 \textsc{Student}: ``Really? How do you
know?''

{
  \textsc{Goofus}: ``Gallant told me.''}
\end{quotation}


 A similar transformation occurs in the leap from:

\begin{quotation}

 \textsc{Gallant}: ``When my calculations show an amplitude
of $(-1/3)i$ for this photon to get absorbed, my experiments showed
that the photon was absorbed around 107 times out of 1,000, which is a
good fit to 1/9, the square of the modulus. There's
clearly some kind of connection between the experimental statistics and
the squared modulus of the amplitude, but I don't know
what.''

{
 \textsc{Goofus}: ``The probability amplitude
doesn't say where the electron \textit{is}, but where
it \textit{might be.} The squared modulus is the probability that
reality will turn out that way. Reality \textit{itself} is inherently
nondeterministic.''}
\end{quotation}


 And again:

\begin{quotation}

 \textsc{Gallant}: ``Once I measure something and get an
experimental result, I do my future calculations using only the
amplitude whose squared modulus went into calculating the frequency of
that experimental result. Only this rule makes my further calculations
correspond to observed frequencies.''

{
 \textsc{Goofus}: ``Since the amplitude \textit{is} the
probability, once you \textit{know} the experimental result, the
probability of everything else becomes zero!''}
\end{quotation}


 The whole slip from:

\begin{quote}
{
 \textit{The square of this
``amplitude'' stuff corresponds
   tightly to our experimentally observed frequencies}}
\end{quote}


 to

\begin{quote}
{
 \textit{The amplitude is the probability of getting the
   measurement}}
\end{quote}


 to

\begin{quote}
{
 \textit{Well, obviously, once you know you} didn't
 \textit{get a measurement, its probability becomes zero}}
\end{quote}


 has got to be one of the most embarrassing wrong turns in the
history of science.


 If you take all this \textit{literally}, it becomes the
consciousness-causes-collapse interpretation of quantum mechanics.
These days, just about nobody will confess to \textit{actually}
believing in the consciousness-causes-collapse interpretation of
quantum mechanics---


 But the physics textbooks are still written this way! People say
they don't believe it, but they \textit{talk as if}
knowledge is responsible for removing incompatible
``probability'' amplitudes.


 Yet as implausible as I find consciousness-causes-collapse, it at
least gives us a picture of reality. Sure, it's an
informal picture. Sure, it gives mental properties ontologically basic
status. You can't \textit{calculate} when an
``experimental observation'' occurs
or what people ``know,'' you
\textit{just know} when certain probabilities are \textit{obviously}
zero. And this ``just knowing'' just
happens to fit your experimental results, whatever they are---


 {}---but at least consciousness-causes-collapse purports to tell
us how the universe works. The amplitudes are real, the collapse is
real, the consciousness is real.


 Contrast to this argument schema:

\begin{quotation}

 \textsc{Student}: ``Wait, you're saying
that this amplitude disappears as soon as the measurement tells me
it's not true?''


 \textsc{Goofus}: ``No, no! It doesn't
\textit{literally} disappear. The equations don't
\textit{mean} anything---they just give good
predictions.''


 \textsc{Student}: ``But then what \textit{does}
happen?''


 \textsc{Goofus}: \textit{(Whorble. Hiss.)} ``Never ask
that question.''


 \textsc{Student}: ``And what about the part where we
measure this photon's polarization over here, and a
light-year away, the entangled photon's probability of
being polarized up-down changes from 50\% to 25\%?''


 \textsc{Goofus}: ``Yes, what about
it?''


 \textsc{Student}: ``Doesn't that violate
Special Relativity?''


 \textsc{Goofus}: ``No, because you're just
\textit{finding out} the other photon's polarization.
Remember, the amplitudes aren't
\textit{real.}''


 \textsc{Student}: ``But Bell's Theorem
shows there's no possible local hidden variable that
could describe the other photon's polarization before
we measure it---''


 \textsc{Goofus}: ``Exactly! It's
meaningless to talk about the photon's polarization
before we measure it.''


 \textsc{Student}: ``But the probability suddenly
changes---''

{
 \textsc{Goofus}: ``\textit{It's
meaningless to talk about it before we measure
it!}''}
\end{quotation}


 What does Goofus even \textit{mean}, here? Never mind the
plausibility of his words; what sort of state of reality would
correspond to his words being true?


 What way could reality \textit{be}, that would make it meaningless
to talk about Special Relativity being violated, because the property
being influenced didn't exist, even though you could
calculate the changes to it?


 But you know what? Forget that. I want to know the answer to an
even more important question:


 Where is Goofus \textit{getting} all this stuff?


 Let's suppose that you take the Schrödinger
equation, and assert, as a positive fact:

\begin{quote}
{
 This equation generates good predictions, but it
 doesn't mean anything!}
\end{quote}


 Really? \textit{How do you know?}


 I sometimes go around saying that the fundamental question of
rationality is \textit{Why do you believe what you believe?}


 You say the Schrödinger equation
``doesn't mean
anything.'' How did this item of definite knowledge
end up in your possession, if it is not simply ignorance misinterpreted
as knowledge?


 Was there some experiment that told you? I am open to the idea
that experiments can tell us things that seem philosophically
impossible. But in this case I should like to see the decisive data.
Was there a point where you carefully set up an experimental apparatus,
and worked out what you should expect to see if (1) the Schrödinger
equation was meaningful or (2) the Schrödinger equation was
meaningless; and then you got result (2)?

\begin{quotation}

 \textsc{Gallant}: ``If I measure the 90\degree{}
polarization of a photon, and then measure the 45\degree{}
polarization, and then measure 90\degree{} again, my
experimental history shows that in 100 trials a photon was absorbed 47
times and transmitted 53 times.''

{
 \textsc{Goofus}: ``The 90\degree{} polarization
and 45\degree{} polarization are incompatible properties;
they can't both \textit{exist} at the same time, and if
you measure one, it is meaningless to \textit{talk} about the
other.''}
\end{quotation}


 How do you know?


 How did you acquire that piece of knowledge, Goofus? I know where
Gallant got \textit{his}{}---but where did \textit{yours} come from?


 My attitude toward questions of existence and meaning was nicely
illustrated in a discussion of the current state of evidence for
whether the universe is spatially finite or spatially infinite, in
which James D. Miller chided Robin Hanson:

\begin{quote}
{
 Robin, you are suffering from overconfidence bias in assuming that
the universe exists. Surely there is some chance that the universe is
of size zero.}
\end{quote}


 To which I replied:

\begin{quote}
{
 James, if the universe doesn't exist, it would
still be nice to know whether it's an infinite or a
finite universe that doesn't exist.}
\end{quote}


 Ha! You think pulling that old ``universe
doesn't exist'' trick will stop me?
It won't even slow me down!


 It's not that I'm \textit{ruling
out} the possibility that the universe doesn't exist.
It's just that, \textit{even} \textit{if} nothing
exists, I still want to understand the nothing as best I can. My
curiosity doesn't suddenly go away just because
there's no reality, you know!


 The nature of ``reality'' is
something about which I'm still confused, which leaves
open the possibility that there isn't any such thing.
But Egan's Law still applies: ``It all
adds up to normality.'' Apples didn't
stop falling when Einstein disproved Newton's theory of
gravity.


 Sure, when the dust settles, it could turn out that apples
don't exist, Earth doesn't exist,
reality doesn't exist. But the nonexistent apples will
still fall toward the nonexistent ground at a meaningless rate of $9.8 \,
\mathrm{m/s}^{2}$.


 You say the universe doesn't exist? Fine, suppose
I believe that---though it's not clear \textit{what}
I'm supposed to believe, aside from repeating the
words.


 Now, what happens if I press \textit{this} button?


 In The Simple Truth, I said:

\begin{quote}
{
 Frankly, I'm not entirely sure myself where this
``reality'' business comes from. I
can't create my own reality in the lab, so I must not
understand it yet. But occasionally I believe strongly that something
is going to happen, and then something else happens instead\,\ldots So I
need different names for the thingies that determine my predictions and
the thingy that determines my experimental results. I call the former
thingies ``belief,'' and the latter
thingy ``reality.''}
\end{quote}


 You want to say that the quantum-mechanical equations are
``not real''? I'll
be charitable, and suppose this means something. What might it mean?


 Maybe it means the equations which determine my predictions are
substantially different from the thingy that determines my experimental
results. Then what \textit{does} determine my experimental results? If
you tell me ``nothing,'' I would
like to know what sort of
``nothing'' it is, and why this
``nothing'' exhibits such apparent
regularity in determining e.g.~my experimental measurements of the mass
of an electron.


 I don't take well to people who tell me to stop
asking questions. If you tell me something is definitely positively
meaningless, I want to know exactly what you mean by that, and how you
came to know. Otherwise you have not given me an answer, only told me
to stop asking the question.


 The Simple Truth describes the life of a shepherd and apprentice
who have discovered how to count sheep by tossing pebbles into buckets,
when they are visited by a delegate from the court who wants to know
how the ``magic pebbles'' work. The
shepherd tries to explain, ``An empty bucket is
magical if and only if the pastures are empty of
sheep,'' but is soon overtaken by the excited
discussions of the apprentice and the delegate as to how the magic
might get into the pebbles.


 Here we have quantum equations that deliver excellent experimental
predictions. What \textit{exactly} does it mean for them to be
``meaningless''? Is it like a bucket
of pebbles that \textit{works for counting sheep}, but
\textit{doesn't have any magic}?


 Back before Bell's Theorem ruled out local hidden
variables, it seemed possible that (as Einstein thought) there was some
more complete description of reality which we didn't
have, and the quantum theory summarized incomplete knowledge of this
more complete description. The laws we'd learned would
turn out to be like the laws of statistical mechanics: quantitative
statements of uncertainty. This would hardly make the equations
``meaningless''; partial knowledge
\textit{is} the meaning of probability.


 But Bell's Theorem makes it much less plausible
that the quantum equations are partial knowledge of something
deterministic, the way that statistical mechanics over classical
physics is partial knowledge of something deterministic. And even so,
the quantum equations would not be
``meaningless'' as that phrase is
usually taken; they would be
``statistical,''
``approximate,''
``partial information,'' or at worst
``wrong.''


 Here we have equations that give us excellent predictions. You say
they are ``meaningless.'' I ask what
it is that determines my experimental results, then. You cannot answer.
Fine, then how do you justify ruling out the possibility that the
quantum equations give such excellent predictions because they are, oh,
say, \textit{meaningful}?


 I don't mean to trivialize questions of reality or
meaning. But to call something
``meaningless'' and say that the
argument is now resolved, finished, over, done with, you must have a
theory of exactly how it is meaningless. And when the \textit{answer}
is given, the question should seem no longer mysterious.


 As you may recall from Semantic Stopsigns, there are words and
phrases which are not so much \textit{answers} to questions, as
cognitive traffic signals which indicate you should \textit{stop
asking} questions. ``Why does anything exist in the
first place? God!'' is the classical example, but
there are others, such as ``Élan
vital!''


 Tell people to ``shut up and
calculate'' because you don't know
what the calculations mean, and inside of five years,
``Shut up!'' will be masquerading as
a positive theory of quantum mechanics.


 I have the \textit{highest} respect for any historical physicists
who even came \textit{close} to \textit{actually} shutting up and
calculating, who were genuinely conservative in assessing what they did
and didn't know. This is the best they could possibly
do without actually being Hugh Everett, and I award them fifty
rationality points. My scorn is reserved for those who interpreted
``We don't know why it
works'' as the positive knowledge that the equations
were definitely not real.


 I mean, if that trick worked, it would be too good to confine to
one subfield. Why shouldn't physicists use the
``not real'' loophole
\textit{outside} of quantum mechanics?

\begin{quotation}

 ``Hey, doesn't your new
`yarn theory' violate Special
Relativity?''


 ``Nah, the equations are meaningless. Say,
doesn't your model of `chaotic evil
inflation' violate CPT symmetry?''

{
 ``My equations are \textit{even more meaningless}
than your equations! So your criticism \textit{double}
doesn't count.''}
\end{quotation}


 And if that doesn't work, try writing yourself a
Get Out of Jail Free card.


 If there is a moral to the whole story, it is the moral of how
very hard it is to stay in a state of \textit{confessed} confusion,
without making up a story that gives you closure---how hard it is to
avoid manipulating your ignorance as if it were definite knowledge that
you possessed.

\myendsectiontext

\mysection{If Many{}-Worlds Had Come First}

{
 \textit{Not that I'm claiming I could have done
better, if I'd been born into} that \textit{time,
instead of this one\,\ldots} }


 Macroscopic decoherence, a.k.a. many-worlds, was first proposed in
a 1957 paper by Hugh Everett III.\footnote{Hugh Everett, III, ``\,`Relative State' Formulation of Quantum Mechanics.'' \textit{Rev. Mod. Phys}. 29, 454 – Published 1 July 1957} The paper was ignored. John Wheeler
told Everett to see Niels Bohr. Bohr didn't take him
seriously.


 Crushed, Everett left academic physics, invented the general use
of Lagrange multipliers in optimization problems, and became a
multimillionaire.


 It wasn't until 1970, when Bryce DeWitt (who
coined the term ``many-worlds'')
wrote an article for \textit{Physics Today},\footnote{Bryce S. DeWitt, ``Quantum mechanics and reality''. \textit{Physics Today} 23, 9, 30 (1970)} that the general field was
first informed of Everett's ideas. Macroscopic
decoherence has been gaining advocates ever since, and may now be the
majority viewpoint (or not).


 But suppose that decoherence and macroscopic decoherence had been
realized immediately following the discovery of entanglement, in the
1920s. And suppose that no one had proposed collapse theories until
1957. Would decoherence now be steadily declining in popularity, while
collapse theories were slowly gaining steam?


 Imagine an alternate Earth, where the very first physicist to
discover entanglement and superposition said, ``Holy
flaming monkeys, there's a zillion other Earths out
there!''


 In the years since, many hypotheses have been proposed to explain
the mysterious Born probabilities. But no one has \textit{yet}
suggested a collapse postulate. That possibility simply has not
occurred to anyone.


 One day, Huve Erett walks into the office of Biels Nohr\,\ldots


 ``I just don't
understand,'' Huve Erett said, ``why
no one in physics even seems \textit{interested} in my hypothesis.
Aren't the Born statistics the greatest puzzle in
modern quantum theory?''


 Biels Nohr sighed. Ordinarily, he wouldn't even
bother, but something about the young man compelled him to try.


 ``Huve,'' says Nohr,
``every physicist meets dozens of people per year who
think they've explained the Born statistics. If you go
to a party and tell someone you're a physicist, chances
are at least one in ten they've got a new explanation
for the Born statistics. It's one of the most famous
problems in modern science, and worse, it's a problem
that everyone thinks they can understand. To get attention, a new Born
hypothesis has to be\,\ldots pretty darn good.''


 ``And \textit{this},'' Huve
says, ``\textit{this} isn't
\textit{good?}''


 Huve gestures to the paper he'd brought to Biels
Nohr. It is a short paper. The title reads, ``The
Solution to the Born Problem.'' The body of the paper
reads:

\begin{quote}
{
 When you perform a measurement on a quantum system, all parts of
the wavefunction except one point vanish, with the survivor chosen
non-deterministically in a way determined by the Born statistics.}
\end{quote}


 ``Let me make absolutely
sure,'' Nohr says carefully, ``that
I understand you. You're saying that
we've got this wavefunction---evolving according to the
Wheeler-DeWitt equation---and, all of a sudden, the whole wavefunction,
except for one part, just spontaneously goes to zero amplitude.
Everywhere at once. This happens when, way up at the macroscopic level,
we `measure'
something.''


 ``Right!'' Huve says.


 ``So the wavefunction knows when we
`measure' it. What exactly is a
`measurement'? How does the wavefunction
know we're here? What happened before humans were
around to measure things?''


 ``Um\,\ldots'' Huve thinks for a
moment. Then he reaches out for the paper, scratches out
``When you perform a measurement on a quantum
system,'' and writes in, ``When a
quantum superposition gets too large.''


 Huve looks up brightly.
``Fixed!''


 ``I see,'' says Nohr.
``And how large is `too
large'?''


 ``At the 50-micron level,
maybe,'' Huve says, ``I hear they
haven't tested that yet.''


 Suddenly a student sticks his head into the room.
``Hey, did you hear? They just verified superposition
at the 50-micron level.''


 ``Oh,'' says Huve,
``um, whichever level, then. Whatever makes the
experimental results come out right.''


 Nohr grimaces. ``Look, young man, the truth here
isn't going to be comfortable. Can you hear me out on
this?''


 ``Yes,'' Huve says,
``I just want to know why physicists
won't listen to me.''


 ``All right,'' says Nohr. He
sighs. ``Look, if this theory of yours were actually
true---if whole sections of the wavefunction just instantaneously
vanished---it would be\,\ldots let's see. The only law in
all of quantum mechanics that is non-linear, non-unitary,
non-differentiable and discontinuous. It would prevent physics from
evolving locally, with each piece only looking at its immediate
neighbors. Your `collapse' would be the
only fundamental phenomenon in all of physics with a preferred basis
and a preferred space of simultaneity. Collapse would be the only
phenomenon in all of physics that violates CPT symmetry,
Liouville's Theorem, and Special Relativity. In your
original version, collapse would also have been the only phenomenon in
all of physics that was inherently mental. Have I left anything
out?''


 ``Collapse is also the only acausal
phenomenon,'' Huve points out.
``Doesn't that make the theory more
wonderful and amazing?''


 ``I think, Huve,'' says Nohr,
``that physicists may view the exceptionalism of your
theory as a point not in its favor.''


 ``Oh,'' said Huve, taken aback.
``Well, I think I can fix that non-differentiability
thing by postulating a second-order term in the---''


 ``Huve,'' says Nohr,
``I don't think you're
getting my point, here. The reason physicists aren't
paying attention to you, is that your theory isn't
physics. It's magic.''


 ``But the Born statistics are the greatest puzzle
of modern physics, and this theory provides a mechanism for the Born
statistics!'' Huve protests.


 ``No, Huve, it
doesn't,'' Nohr says wearily.
``That's like saying that
you've `provided a
mechanism' for electromagnetism by saying that there
are little angels pushing the charged particles around in accordance
with Maxwell's equations. Instead of saying,
`Here are Maxwell's equations, which
tells the angels where to push the electrons,' we just
say, `Here are Maxwell's
equations' and are left with a strictly simpler theory.
Now, we don't know \textit{why} the Born statistics
happen. But you haven't given the slightest reason why
your `collapse postulate' should
eliminate worlds in accordance with the Born statistics, rather than
something else. You're not even making use of the fact
that quantum evolution is unitary---''


 ``That's because
it's not,'' interjects Huve.


 ``---which everyone pretty much knows has got to
be the key to the Born statistics, somehow. Instead
you're merely saying, `Here are the Born
statistics, which tell the collapser how to eliminate
worlds,' and it's strictly simpler to
just say `Here are the Born
statistics.'\,''


 ``But---'' says Huve.


 ``\textit{Also},'' says Nohr,
raising his voice, ``you've given no
justification for why there's only \textit{one}
surviving world left by the collapse, or why the collapse happens
before any \textit{humans} get superposed, which makes your theory
\textit{really suspicious} to a modern physicist. This is exactly the
sort of untestable hypothesis that the `One
Christ' crowd uses to argue that we should
`teach the controversy' when we tell
high school students about other Earths.''


 ``I'm not a
One-Christer!'' protests Huve.


 ``Fine,'' Nohr says,
``then \textit{why} do you just assume
there's only one world left? And that's
not the only problem with your theory. Which part of the wavefunction
gets eliminated, exactly? And in which basis? It's
clear that the whole wavefunction isn't being
compressed down to a delta, or ordinary quantum computers
couldn't stay in superposition when any collapse
occurred anywhere---heck, ordinary molecular chemistry might start
failing---''


 Huve quickly crosses out ``one
point'' on his paper, writes in
``one part,'' and then says,
``Collapse doesn't compress the
wavefunction down to one point. It eliminates all the amplitude
\textit{except} one world, but leaves \textit{all} the amplitude
\textit{in} that world.''

{
 ``Why?'' says Nohr.
``In principle, once you postulate
`collapse,' then
`collapse' could eliminate any part of
the wavefunction, anywhere---why just one neat world left? Does the
collapser \textit{know we're in
here?}''}


 Huve says, ``It leaves one whole world because
that's what fits our experiments.''


 ``Huve,'' Nohr says patiently,
``the term for that is `post
hoc.' Furthermore, decoherence is a continuous process.
If you partition by whole brains with distinct neurons firing, the
partitions have almost zero mutual interference within the
wavefunction. But plenty of other processes overlap a great deal.
There's no possible way you can point to
`one world' and eliminate everything
else without making completely arbitrary choices, including an
arbitrary choice of basis---''


 ``But---'' Huve says.

{
 ``And \textit{above all},''
Nohr says, ``the \textit{reason} you
can't tell me which part of the wavefunction vanishes,
or exactly when it happens, or exactly what triggers it, is that if we
did adopt this theory of yours, it would be \textit{the only informally
specified, qualitative fundamental law} taught in all of physics. Soon
no two physicists anywhere would agree on the exact details! Why?
Because it would be the \textit{only fundamental law in all of modern
physics that was believed without experimental evidence to nail down
exactly how it worked.}''}


 ``What, really?'' says Huve.
``I thought a lot of physics was more informal than
that. I mean, weren't you just talking about how
it's impossible to point to `one
world'?''


 ``That's because worlds
aren't \textit{fundamental}, Huve! We have massive
experimental evidence underpinning the fundamental law, the
Wheeler-DeWitt equation, that we use to describe the evolution of the
wavefunction. We just apply exactly the same equation to get our
description of macroscopic decoherence. But for difficulties of
calculation, the equation would, in principle, tell us \textit{exactly}
when macroscopic decoherence occurred. We don't know
where the Born statistics come from, but we have massive evidence for
what the Born statistics \textit{are}. But when I ask you when, or
where, collapse occurs, you don't
know---\textit{because there's no experimental evidence
whatsoever to pin it down.} Huve, even if this `collapse
postulate' worked the way you say it does,
\textit{there's no possible way you could know it!} Why
not a gazillion other equally magical
possibilities?''


 Huve raises his hands defensively.
``I'm not saying my theory should be
taught in the universities as accepted truth! I just want it
experimentally tested! Is that so wrong?''


 ``You haven't specified when
collapse happens, so I can't construct a test that
falsifies your theory,'' says Nohr.
``Now with that said, we're already
looking experimentally for any part of the quantum laws that change at
increasingly macroscopic levels. Both on general principles, in case
there's something in the 20th decimal point that only
shows up in macroscopic systems, and also in the hopes
we'll discover something that sheds light on the Born
statistics. We check decoherence times as a matter of course. But we
keep a \textit{broad} outlook on what might be different.
Nobody's going to privilege your non-linear,
non-unitary, non-differentiable, non-local, non-CPT-symmetric,
non-relativistic, a-frikkin'-causal, faster-than-light,
\textit{in-bloody-formal} `collapse'
when it comes to looking for clues. Not until they see absolutely
unmistakable evidence. And believe me, Huve, it's going
to take a hell of a lot of evidence to unmistake \textit{this}. Even if
we did find anomalous decoherence times, and I don't
think we will, it wouldn't force your
`collapse' as the
explanation.''


 ``What?'' says Huve.
``Why not?''


 ``Because there's got to be a
billion more explanations that are more plausible than violating
Special Relativity,'' says Nohr.
``Do you realize that if this really happened, there
would only be a \textit{single} outcome when you measured a
photon's polarization? Measuring one photon in an
entangled pair would influence the other photon a light-year away.
Einstein would have a heart attack.''


 ``It doesn't \textit{really}
violate Special Relativity,'' says Huve.
``The collapse occurs in exactly the right way to
prevent you from ever actually \textit{detecting} the faster-than-light
influence.''


 ``That's not a point in your
theory's favor,'' says Nohr.
``Also, Einstein would still have a heart
attack.''


 ``Oh,'' says Huve.
``Well, we'll say that the relevant
aspects of the particle \textit{don't exist} until the
collapse occurs. If something doesn't exist,
influencing it doesn't violate Special
Relativity---''


 ``You're just digging yourself
deeper. Look, Huve, as a general principle, theories that are actually
\textit{correct} don't generate this level of
confusion. But above all, there isn't any evidence for
it. You have no logical way of knowing that collapse occurs, and no
reason to believe it. You made a mistake. Just say
`oops' and get on with your
life.''


 ``But they \textit{could} find the evidence
someday,'' says Huve.


 ``I can't think of what evidence
could determine \textit{this particular} one-world hypothesis as an
explanation, but in any case, right now we
\textit{haven't} found any such
evidence,'' says Nohr. ``We
haven't found anything even vaguely suggestive of it!
You can't update on evidence that could theoretically
arrive someday but hasn't arrived! Right now, today,
there's no reason to spend valuable time thinking about
this rather than a billion other equally magical theories.
There's absolutely nothing that justifies your belief
in `collapse theory' any \textit{more}
than believing that someday we'll learn to transmit
faster-than-light messages by tapping into the acausal effects of
praying to the Flying Spaghetti Monster!''


 Huve draws himself up with wounded dignity. ``You
know, if my theory is wrong---and I do admit it might be
wrong---''


 ``\textit{If?}'' says Nohr.
``\textit{Might?}''


 ``If, I say, my theory is
wrong,'' Huve continues, ``then
somewhere out there is another world where \textit{I} am the famous
physicist and \textit{you} are the lone outcast!''


 Nohr buries his head in his hands. ``Oh, not this
again. Haven't you heard the saying,
`Live in your own world'? And
\textit{you} of all people---''


 ``Somewhere out there is a world where the vast
majority of physicists believe in collapse theory, and no one has even
\textit{suggested} macroscopic decoherence over the last thirty
years!''


 Nohr raises his head, and begins to laugh.


 ``What's so
funny?'' Huve says suspiciously.


 Nohr just laughs harder. ``Oh, my! Oh, my! You
really think, Huve, that there's a world out there
where they've known about quantum physics for thirty
years, and nobody has even \textit{thought} there might be more than
one world?''


 ``Yes,'' Huve says,
``that's exactly what I
think.''


 ``Oh my! So you're saying, Huve,
that physicists detect superposition in microscopic systems, and work
out quantitative equations that govern superposition in every single
instance they can test. And for thirty years, not \textit{one person}
says, `Hey, I wonder if these laws happen to be
universal.'\,''


 ``Why should they?'' says Huve.
``Physical models sometimes turn out to be wrong when
you examine new regimes.''


 ``But to not even \textit{think} of
it?'' Nohr says incredulously. ``You
see apples falling, work out the law of gravity for all the planets in
the solar system except Jupiter, and it doesn't even
\textit{occur} to you to apply it to Jupiter because Jupiter is too
large? That's like, like some kind of comedy routine
where the guy opens a box, and it contains a spring-loaded pie, so the
guy opens another box, and it contains another spring-loaded pie, and
the guy just keeps doing this without even \textit{thinking} of the
possibility that the next box contains a pie too. You think John von
Neumann, who may have been the highest-g human in history,
wouldn't think of it?''


 ``That's
right,'' Huve says, ``He
wouldn't. Ponder that.''


 ``This is the world where my good friend Ernest
formulates his Schrödinger's Cat thought experiment,
and in this world, the thought experiment goes: `Hey,
suppose we have a radioactive particle that enters a superposition of
decaying and not decaying. Then the particle interacts with a sensor,
and the sensor goes into a superposition of going off and not going
off. The sensor interacts with an explosive, that goes into a
superposition of exploding and not exploding; which interacts with the
cat, so the cat goes into a superposition of being alive and dead. Then
a human looks at the cat,' and at this point
Schrödinger stops, and goes, `gee, I just
can't imagine what could happen next.'
So Schrödinger shows this to everyone else, and they're
also like `Wow, I got no idea what could happen at this
point, what an amazing paradox.' Until finally
\textit{you} hear about it, and you're like,
`hey, maybe at \textit{that} point half of the
superposition just vanishes, at random, faster than
light,' and everyone else is like, `Wow,
what a great idea!'\,''


 ``That's
right,'' Huve says again.
``It's got to have happened
somewhere.''


 ``Huve, this is a world where every single
physicist, and probably the whole damn human species, is too dumb to
sign up for cryonics! We're talking about the Earth
where George W. Bush is President.''

\myendsectiontext

\mysection{Where Philosophy Meets Science}


 Looking back on early quantum physics---not for purposes of
admonishing the major figures, or to claim that \textit{we} could have
done better if we'd been born into that era, but in
order to try and learn a moral, and do better next time---looking back
on the dark ages of quantum physics, I say, I would nominate as the
``most basic'' error\,\ldots


 \ldots \textit{not} that they tried to reverse course on the last
three thousand years of science suggesting that mind was complex within
physics rather than fundamental in physics. This is Science, and we do
have revolutions here. Every now and then you've got to
reverse a trend. The future is always absurd and never unlawful.


 I would nominate, as the basic error not to repeat next time, that
the early scientists forgot that they \textit{themselves} were made out
of particles.


 I mean, I'm sure that most of them knew it in
theory.


 And yet they didn't notice that putting a sensor
to detect a passing electron, or even \textit{knowing} about the
electron's history, was an example of
``particles in different places.''
So they didn't notice that a quantum theory of distinct
configurations already explained the experimental result, without any
need to invoke consciousness.


 In the ancestral environment, humans were often faced with the
adaptively relevant task of predicting other humans. For which purpose
you thought of your fellow humans as having thoughts, knowing things
and feeling things, rather than thinking of them as being made up of
particles. In fact, many hunter-gatherer tribes may not even have known
that particles existed. It's much more
\textit{intuitive}{}---it \textit{feels} simpler---to think about
someone ``knowing'' something, than
to think about their brain's particles occupying a
different state. It's easier to phrase your
explanations in terms of what \textit{people know}; it feels more
natural; it leaps more readily to mind.


 Just as, once upon a time, it was easier to imagine Thor throwing
lightning bolts, than to imagine Maxwell's
Equations---even though Maxwell's Equations can be
described by a computer program vastly smaller than the program for an
intelligent agent like Thor.


 So the ancient physicists found it natural to think,
``I know where the photon was\,\ldots what difference
could \textit{that} make?'' Not,
``My brain's
particles' current state correlates to the
photon's history\,\ldots what difference could
\textit{that} make?''


 And, similarly, because it felt easy and intuitive to model
reality in terms of people knowing things, and the decomposition of
knowing into brain states did not leap so readily to mind, it
\textit{seemed} like a simple theory to say that a configuration could
have amplitude only ``if you didn't
know better.''


 To turn the dualistic quantum hypothesis into a \textit{formal}
theory---one that could be written out as a computer program, without
human scientists deciding when an
``observation'' occurred---you would
have to specify what it meant for an
``observer'' to
``know'' something, in terms your
computer program could compute.


 So is your theory of fundamental physics going to examine all the
particles in a human brain, and decide when those particles
``know'' something, in order to
compute the motions of particles? But then how do you compute the
motion of the particles in the brain itself? Wouldn't
there be a potential infinite recursion?


 But so long as the terms of the theory were being processed by
human scientists, they \textit{just knew} when an
``observation'' had occurred. You
said an ``observation'' occurred
whenever it had to occur in order for the experimental predictions to
come out right---a subtle form of constant tweaking.


 (Remember, the basics of quantum theory were formulated before
Alan Turing said anything about Turing machines, and \textit{way}
before the concept of computation was popularly known. The distinction
between an effective formal theory, and one that required human
interpretation, was not as clear then as now. Easy to pinpoint the
problems in hindsight; you shouldn't learn the lesson
that problems are usually this obvious in foresight.)


 Looking back, it may \textit{seem} like one meta-lesson to learn
from history, is that philosophy really matters in
science---it's not just some adjunct of a separate
academic field.


 After all, the early quantum scientists were doing all the right
experiments. It was their interpretation that was off. And the problems
of interpretation were not the result of their getting the statistics
wrong.


 Looking back, it seems like the errors they made were errors in
the kind of thinking that we would describe as, well,
``philosophical.''


 When we look back and ask, ``How could the early
quantum scientists have done better, even in
principle?''~it seems that the insights they needed
were philosophical ones.


 And yet it wasn't professional philosophers who
swooped in and solved the problem and cleared up the mystery and made
everything normal again. It was, well, physicists.


 Arguably, Leibniz was at least as foresightful about quantum
physics, as Democritus was once thought to have been foresightful about
atoms. But that is hindsight. It's the result of
looking at the solution, and thinking back, and saying,
``Hey, Leibniz said something like
that.''


 Even where one philosopher gets it right in advance,
it's usually science that ends up \textit{telling us}
which philosopher is right---not the \textit{prior consensus} of the
philosophical community.


 I think this has something fundamental to say about the nature of
philosophy, and the interface between philosophy and science.


 It was once said that every science begins as philosophy, but then
grows up and leaves the philosophical womb, so that at any given time,
``Philosophy'' is what we
haven't turned into science yet.


 I suggest that when we look at the history of quantum physics and
say, ``The insights they needed were philosophical
insights,'' what we are \textit{really} seeing is
that the insight they needed was of a form that is not yet taught in
standardized academic classes, and not yet reduced to calculation.


 Once upon a time, the notion of the scientific method---updating
beliefs based on experimental evidence---was a philosophical notion.
But it was not championed by professional philosophers. It was the
real-world power of science that showed that scientific epistemology
was good epistemology, not a prior consensus of philosophers.


 Today, this philosophy of belief-updating is \textit{beginning} to
be reduced to calculation---statistics, Bayesian probability theory.


 But back in Galileo's era, it was solely
\textit{vague verbal arguments} that said you should try to produce
numerical predictions of experimental results, rather than consulting
the Bible or Aristotle.


 At the frontier of science, and especially at the frontier of
scientific \textit{chaos} and scientific \textit{confusion}, you find
problems of thinking that are not taught in academic courses, and that
have not been reduced to calculation. And this will seem like a domain
of philosophy; it will seem that you must do philosophical thinking in
order to sort out the confusion. But when history looks back,
I'm afraid, it is usually not a professional
philosopher who wins all the marbles---because it takes intimate
involvement with the scientific domain in order to do the philosophical
thinking. Even if, afterward, it all seems knowable a priori; and even
if, afterward, some philosopher out there actually \textit{got} it a
priori; even so, it takes intimate involvement to see it in practice,
and experimental results to tell the world which philosopher won.


 I suggest that, like ethics, philosophy really is important, but
it is only practiced effectively from \textit{within} a science. Trying
to do the philosophy of a frontier science, as a separate academic
profession, is as much a mistake as trying to have separate ethicists.
You end up with ethicists who speak mainly to other ethicists, and
philosophers who speak mainly to other philosophers.


 This is not to say that there is no place for professional
philosophers in the world. Some problems are so chaotic that there is
no established place for them at all in the halls of science. But those
``professional philosophers'' would
be very, very wise to learn every scrap of relevant-seeming science
that they can possibly get their hands on. They should not be surprised
at the prospect that experiment, and not debate, will finally settle
the argument. They should not flinch from running their own
experiments, if they can possibly think of any.


 That, I think, is the lesson of history.

\myendsectiontext

\mysection{Thou Art Physics}


 Three months ago---jeebers, has it really been that long?---I
posed the following homework assignment: Do a stack trace of the human
cognitive algorithms that produce debates about ``free
will.'' Note that this task is strongly distinguished
from arguing that free will does or does not exist. 


 Now, as expected, people are asking, ``If the
future is determined, how can our choices control
it?'' The wise reader can guess that it all adds up
to normality; but this leaves the question of \textit{how}.


 People hear: ``The universe runs like clockwork;
physics is deterministic; the future is fixed.'' And
their minds form a causal network that looks like this:


 ~

{\centering
\mygraphics{images/img313.jpg}
 
\par}


\bigskip


 ~


 Here we see the causes ``Me''
and ``Physics,'' competing to
determine the state of the
``Future'' effect. If the
``Future'' is fully determined by
``Physics,'' then obviously there is
no room for it to be affected by
``Me.''


 This causal network is not an explicit philosophical belief.
It's implicit---a background representation of the
brain, controlling which philosophical arguments seem
``reasonable.'' It just seems like
the way things \textit{are}.

{
 Every now and then, another neuroscience press release appears,
claiming that, because researchers used an fMRI to spot the brain doing
something-or-other during a decision process,
\textit{it's not you who chooses, it's
your brain}.}


 Likewise that old chestnut, ``Reductionism
undermines rationality itself. Because then, every time you said
something, it wouldn't be the result of
\textit{reasoning} about the evidence---it would be merely quarks
bopping around.''


 Of course the actual diagram should be:


 ~

{\centering
\mygraphics{images/img314.jpg}
 
\par}


\bigskip


 ~


 Or better yet:


 ~

{\centering
\mygraphics{images/img315.jpg}
 
\par}


\bigskip


 ~


 Why is this not obvious? Because there are many levels of
organization that separate our models of our thoughts---our emotions,
our beliefs, our agonizing indecisions, and our final choices---from
our models of electrons and quarks.


 We can \textit{intuitively} visualize that a hand is made of
fingers (and thumb and palm). To ask whether it's
\textit{really} our hand that picks something up, or \textit{merely}
our fingers, thumb, and palm, is transparently a wrong question.


 But the gap between physics and cognition cannot be crossed by
direct visualization. No one can \textit{visualize} atoms making up a
person, the way they can see fingers making up a hand.


 And so it requires \textit{constant vigilance} to maintain your
perception of yourself as an entity \textit{within physics}.


 This vigilance is one of the great keys to philosophy, like the
Mind Projection Fallacy. You will recall that it is this point which I
nominated as having tripped up the quantum physicists who failed to
imagine macroscopic decoherence; they did not think to apply the laws
to \textit{themselves}.


 Beliefs, desires, emotions, morals, goals, imaginations,
anticipations, sensory perceptions, fleeting wishes, ideals,
temptations\,\ldots You might call this the ``surface
layer'' of the mind, the parts-of-self that people
can see even without science. If I say, ``It is not
\textit{you} who determines the future, it is your \textit{desires,
plans, and actions} that determine the future,'' you
can readily see the part-whole relations. It is immediately visible,
like fingers making up a hand. There are other part-whole relations all
the way down to physics, but they are not immediately visible.


 ``Compatibilism'' is the
philosophical position that ``free
will'' can be intuitively and satisfyingly defined in
such a way as to be compatible with deterministic physics.
``Incompatibilism'' is the position
that free will and determinism are incompatible.


 My position might perhaps be called
``Requiredism.'' When agency,
choice, control, and moral responsibility are cashed out in a sensible
way, they \textit{require} determinism---at least some patches of
determinism within the universe. If you choose, and plan, and act, and
bring some future into being, in accordance with your desire, then all
this requires a lawful sort of reality; you cannot do it amid utter
chaos. There must be order over at least those parts of reality that
are being controlled by you. \textit{You} are within physics, and so
you/physics have determined the future. If it were not determined by
physics, it could not be determined by you.


 Or perhaps I should say, ``If the future were not
determined by reality, it could not be determined by
you,'' or ``If the future were not
determined by something, it could not be determined by
you.'' You don't need neuroscience or
physics to push naive definitions of free will into incoherence. If the
mind were not embodied in the brain, it would be embodied in something
else; there would be \textit{some real thing} that was a mind. If the
future were not determined by physics, it would be determined by
\textit{something}, some law, some order, some grand reality that
included you within it.


 But if the laws of physics control us, then how can we be said to
control ourselves?


 Turn it around: If the laws of physics did \textit{not} control
us, how could we possibly control ourselves?


 How could thoughts judge other thoughts, how could emotions
conflict with each other, how could one course of action appear best,
how could we pass from uncertainty to certainty about our own plans, in
the midst of utter chaos?


 If we were not in reality, where could we be?


 The future is determined by physics. What kind of physics? The
kind of physics that includes the actions of human beings.


 People's choices are determined by physics. What
kind of physics? The kind of physics that includes weighing decisions,
considering possible outcomes, judging them, being tempted, following
morals, rationalizing transgressions, trying to do better\,\ldots


 There is no point where a quark swoops in from Pluto and overrides
all this.


 The thoughts of your decision process are all \textit{real}, they
are all \textit{something}. But a thought is too big and complicated to
be an atom. So thoughts are made of smaller things, and our name for
the stuff that stuff is made of is
``physics.''


 Physics underlies our decisions and includes our decisions. It
does not explain them \textit{away}.


 Remember, physics adds up to normality; it's your
cognitive algorithms that generate confusion.

\myendsectiontext

\mysection{Many Worlds, One Best Guess}


 If you look at many microscopic physical phenomena---a photon, an
electron, a hydrogen atom, a laser---and a million other known
experimental setups---it is possible to come up with simple laws that
seem to govern all small things (so long as you don't
ask about gravity). These laws govern the evolution of a highly
abstract and mathematical object that I've been calling
the ``amplitude distribution,'' but
which is more widely referred to as the
``wavefunction.'' 


 Now there are gruesome questions about the proper generalization
that covers all these tiny cases. Call an object
``grue'' if it appears green before
January 1, 2020 and appears blue thereafter. If all emeralds examined
so far have appeared green, is the proper generalization,
``Emeralds are green'' or
``Emeralds are grue''?


 The answer is that the proper generalization is
``Emeralds are green.''
I'm not going to go into the arguments at the moment.
It is not the subject of this essay, and the obvious answer in this
case happens to be correct. The true Way is not stupid: however clever
you may be with your logic, it should finally arrive at the right
answer rather than a wrong one.


 In a similar sense, the \textit{simplest} generalizations that
would cover observed \textit{microscopic} phenomena alone take the form
of ``All electrons have spin 1/2''
and not ``All electrons have spin 1/2 before January
1, 2020'' or ``All electrons have
spin 1/2 unless they are part of an entangled system that weighs more
than 1 gram.''


 When we turn our attention to macroscopic phenomena, our sight is
obscured. We cannot experiment on the wavefunction of a human in the
way that we can experiment on the wavefunction of a hydrogen atom. In
no case can you actually read off the wavefunction with a little
quantum scanner. But in the case of, say, a human, the size of the
entire organism defeats our ability to perform precise calculations or
precise experiments---we cannot confirm that the quantum equations are
being obeyed \textit{in precise detail.}


 We know that phenomena commonly thought of as
``quantum'' do not just disappear
when many microscopic objects are aggregated. Lasers put out a flood of
coherent photons, rather than, say, doing something completely
different. Atoms have the chemical characteristics that quantum theory
says they should, enabling them to aggregate into the stable molecules
making up a human.


 So in one sense, we have a great deal of evidence that quantum
laws are aggregating to the macroscopic level without too much
difference. Bulk chemistry still works.


 But we cannot directly verify that the particles making up a human
have an aggregate wavefunction that behaves \textit{exactly} the way
the simplest quantum laws say. Oh, we know that molecules and atoms
don't disintegrate, we know that macroscopic mirrors
still reflect from the middle. We can get \textit{many} high-level
predictions from the assumption that the microscopic and the
macroscopic are governed by the same laws, and every prediction tested
has come true.


 But if someone were to claim that the macroscopic quantum picture
differs from the microscopic one in some as-yet-untestable
detail---something that only shows up at the unmeasurable 20th decimal
place of microscopic interactions, but aggregates into something bigger
for macroscopic interactions---well, we can't
\textit{prove} they're wrong. It is
Occam's Razor that says, ``There are
zillions of new fundamental laws you could postulate in the 20th
decimal place; why are you even \textit{thinking} about this
one?''\footnote{Edit 2018: Gravity is a force that shows up at less than the 20th decimal place in microscopic interactions, but there is some observable evidence for it.}


 If we calculate using the simplest laws which govern all known
cases, we find that humans end up in states of quantum superposition,
just like photons in a superposition of reflecting from and passing
through a half-silvered mirror. In the Schrödinger's
Cat setup, an unstable atom goes into a superposition of
disintegrating, and not-disintegrating. A sensor, tuned to the atom,
goes into a superposition of triggering and not-triggering. (Actually,
the superposition is now a joint state of [atom-disintegrated
{\texttimes} sensor-triggered] + [atom-stable {\texttimes}
sensor-not-triggered].) A charge of explosives, hooked up to the
sensor, goes into a superposition of exploding and not exploding; a cat
in the box goes into a superposition of being dead and alive; and a
human, looking inside the box, goes into a superposition of throwing up
and being calm. The same law at all levels.


 Human beings who interact with superposed systems will themselves
evolve into superpositions. But the brain that sees the exploded cat,
and the brain that sees the living cat, will have many neurons firing
differently, and hence many \textit{many} particles in different
positions. They are very distant in the configuration space, and will
communicate to an exponentially infinitesimal degree. Not the 30th
decimal place, but the $10^{30}$th decimal place. No
particular mind, no particular cognitive causal process, sees a blurry
superposition of cats.


 The fact that ``you'' only seem
to see the cat alive, \textit{or} the cat dead, is exactly what the
simplest quantum laws predict. So we have no reason to believe, from
our experience so far, that the quantum laws are in any way different
at the macroscopic level than the microscopic level.


 And physicists have verified superposition at steadily larger
levels. Apparently an effort is currently underway to test
superposition in a 50-micron object, larger than most neurons.


 The existence of other versions of ourselves, and indeed other
Earths, is not supposed \textit{additionally.} We are simply supposing
that the same laws govern at all levels, having no reason to suppose
differently, and all experimental tests having succeeded so far. The
existence of other decoherent Earths is a \textit{logical consequence}
of the simplest generalization that fits all known facts. If you think
that Occam's Razor says that the other worlds are
``unnecessary entities'' being
multiplied, then you should check the probability-theoretic math; that
is just not how Occam's Razor works.


 Yet there is one particular puzzle that seems odd in trying to
extend microscopic laws universally, including to superposed humans:


 \textit{If} we try to get probabilities by counting the number of
distinct observers, then there is no \textit{obvious} reason why the
integrated squared modulus of the wavefunction should correlate with
statistical experimental results. There is no known reason for the Born
probabilities, and it even seems that, a priori, we would expect a
50/50 probability of any binary quantum experiment going both ways, if
we just counted observers.


 Robin Hanson suggests that if exponentially tinier-than-average
decoherent blobs of amplitude
(``worlds'') are interfered with by
exponentially tiny leakages from larger blobs, we will get the Born
probabilities back out. I consider this an interesting possibility,
because it is so normal.


 (I myself have had recent thoughts along a different track: If I
try to count observers the obvious way, I get strange-seeming results
in general, not just in the case of quantum physics. If, for example, I
split my brain into a trillion similar parts, conditional on winning
the lottery while anesthetized; allow my selves to wake up and perhaps
differ to small degrees from each other; and then merge them all into
one self again; then counting observers the obvious way says I should
be able to make myself win the lottery (if I can split my brain and
merge it, as an uploaded mind might be able to do).


 In this connection, I find it very interesting that the Born rule
does \textit{not} have a split-remerge problem. Given unitary quantum
physics, Born's rule is the \textit{unique} rule that
prevents ``observers'' from having
psychic powers---which doesn't \textit{explain}
Born's rule, but is certainly an \textit{interesting
fact}. Given Born's rule, even splitting and remerging
worlds would still lead to consistent probabilities. Maybe physics uses
better anthropics than I do!


 Perhaps I should take my cues from physics, instead of trying to
reason it out a priori, and see where that leads me? But I have not
been led anywhere \textit{yet}, so this is hardly an
``answer.'')


 Wallace,\footnote{David Wallace, \textit{The Emergent Multiverse}, (Oxford, United Kindom: Oxford University Press, 2012) } Deutsch,\footnote{David Deutsch, ``Quantum Theory of Probability and Decisions'', \textit{Proceedings of the Royal Society of London} A455, 3129-37.} and others try to derive Born's
Rule from decision theory. I am rather suspicious of this, because it
seems like there is a component of ``What happens to
me?''~that I cannot alter by modifying my utility
function. Even if I didn't \textit{care} at all about
worlds where I didn't win a quantum lottery, it still
seems to me that there is a sense in which I would
``mostly'' wake up in a world where
I didn't win the lottery. It is this that I think needs
explaining.


 The point is that many hypotheses about the Born probabilities
have been proposed. Not as many as there should be, because the mystery
was falsely marked ``solved'' for a
long time. But still, there have been many proposals.


 There is legitimate hope of a solution to the Born puzzle without
new fundamental laws. Your world does not split into exactly two new
subprocesses on the exact occasion when you see
``\textsc{absorbed}'' or
``\textsc{transmitted}'' on the LCD screen of
a photon sensor. We are constantly being superposed and decohered, all
the time, sometimes along continuous dimensions---though brains are
digital and involve whole neurons firing, and fire/not-fire would be an
extremely decoherent state even of a \textit{single} neuron\,\ldots There
would seem to be room for \textit{something} unexpected to account for
the Born statistics---a better understanding of the anthropic weight of
observers, or a better understanding of the brain's
superpositions---without new fundamentals.


 We cannot rule out, though, the possibility that a new fundamental
law is involved in the Born statistics.


 As Jess Riedel puts it:\footnote{\url{http://lesswrong.com/lw/q4/decoherence_is_falsifiable_and_testable/jtw}}

\begin{quote}
{
 If there's one lesson we can take from the history
of physics, it's that everytime new experimental
``regimes'' are probed (e.g.~large
velocities, small sizes, large mass densities, large energies),
phenomena are observed which lead to new theories (Special Relativity,
quantum mechanics, General Relativity, and the Standard Model,
respectively).}
\end{quote}


 ``Every time'' is too strong. A
nitpick, yes, but also an important point: you can't
just \textit{assume} that any particular law will fail in a new regime.
But it's possible that a new fundamental law is
involved in the Born statistics, and that this law manifests only in
the 20th decimal place at microscopic levels (hence being undetectable
so far) while aggregating to have substantial effects at macroscopic
levels.


 Could there be some law, as yet undiscovered, that causes there to
be only \textit{one} world?


 This is a shocking notion; it implies that all our twins in the
other worlds---all the different versions of ourselves that are
constantly split off, not just by human researchers doing quantum
measurements, but by ordinary entropic processes---are actually
\textit{gone}, leaving us alone! This version of Earth would be the
\textit{only} version that exists in local space! If the inflationary
scenario in cosmology turns out to be wrong, and the topology of the
universe is both finite and relatively small---so that Earth does not
have the distant duplicates that would be implied by an exponentially
vast universe---then this Earth could be the only Earth that exists
\textit{anywhere}, a rather unnerving thought!


 But it is dangerous to focus too much on specific hypotheses that
you have no specific reason to think about. This is the same root error
of the Intelligent Design folk, who pick any random puzzle in modern
genetics, and say, ``See, God must have done
it!'' Why ``God,''
rather than a zillion other possible explanations?---which you would
have thought of long before you postulated divine intervention, if not
for the fact that you secretly started out already knowing the answer
you wanted to find.


 You shouldn't even \textit{ask},
``Might there only be one world?''
but instead just go ahead and do physics, and raise that
\textit{particular} issue only if new evidence demands it.


 Could there be some as-yet-unknown fundamental law, that gives the
universe a privileged center, which happens to coincide with
Earth---thus proving that Copernicus was wrong all along, and the Bible
right?


 Asking \textit{that particular} question---rather than a zillion
other questions in which the center of the universe is Proxima
Centauri, or the universe turns out to have a favorite pizza topping
and it is pepperoni---betrays your hidden agenda. And though an
unenlightened one might not realize it, giving the universe a
privileged center \textit{that follows Earth around through space}
would be rather difficult to do with any \textit{mathematically simple}
fundamental law.


 So too with asking whether there might be only one world. It
betrays a sentimental attachment to human intuitions already proven
wrong. The wheel of science turns, but it doesn't turn
\textit{backward}.


 We have specific reasons to be highly suspicious of the notion of
only one world. The notion of ``one
world'' exists on a higher level of organization,
like the location of Earth in space; on the quantum level there are no
firm boundaries (though brains that differ by entire neurons firing are
certainly decoherent). How would a \textit{fundamental} physical law
identify one \textit{high-level} world?


 \textit{Much worse}, any physical scenario in which there was a
\textit{single} surviving world, so that any measurement had only a
\textit{single} outcome, would violate Special Relativity.


 If the same laws are true at all levels---i.e., if many-worlds is
correct---then when you measure one of a pair of entangled polarized
photons, you end up in a world in which the photon is polarized, say,
up-down, and alternate versions of you end up in worlds where the
photon is polarized left-right. From your perspective before doing the
measurement, the probabilities are 50/50. Light-years away, someone
measures the other photon at a 20\degree{} angle to your own
basis. From their perspective, too, the probability of getting either
immediate result is 50/50---they maintain an invariant state of
generalized entanglement with your faraway location, no matter what you
do. But when the two of you meet, years later, your probability of
meeting a friend who got the \textit{same} result is 11.6\%, rather
than 50\%.


 If there is only one global world, then there is only a single
outcome of any quantum measurement. Either you measure the photon
polarized up-down, or left-right, but not both. Light-years away,
someone else's probability of measuring the photon
polarized similarly in a 20\degree{} rotated basis actually
\textit{changes} from 50/50 to 11.6\%.


 You cannot possibly interpret this as a case of merely revealing
properties that were already there; this is ruled out by
Bell's Theorem. There does not seem to be any possible
consistent view of the universe in which both quantum measurements have
a single outcome, and yet both measurements are predetermined, neither
influencing the other. Something has to actually \textit{change},
faster than light.


 And this would appear to be a fully general objection, not just to
collapse theories, but to any possible theory that gives us one global
world! There is no consistent view in which measurements have single
outcomes, but are locally determined (even locally randomly
determined). Some mysterious influence has to cross a spacelike gap.


 This is not a trivial matter. You cannot save yourself by waving
your hands and saying, ``the influence travels
backward in time to the entangled photons' creation,
then forward in time to the other photon, so it never actually crosses
a spacelike gap.'' (This view has been seriously put
forth, which gives you some idea of the magnitude of the paradox
implied by one global world!) One measurement has to change the other,
so which measurement happens \textit{first}? Is there a global space of
simultaneity? You can't have both measurements happen
``first'' because under
Bell's Theorem, there's no way local
information could account for observed results, etc.


 Incidentally, this experiment has already been performed, and if
there is a mysterious influence it would have to travel six million
times as fast as light in the reference frame of the Swiss Alps. Also,
the mysterious influence has been experimentally shown not to care if
the two photons are measured in reference frames which would cause each
measurement to occur ``before the
other.''


 Special Relativity seems counterintuitive to us humans---like an
arbitrary speed limit, which you could get around by going backward in
time, and then forward again. A law you could escape prosecution for
violating, if you managed to hide your crime from the authorities.


 But what Special Relativity really says is that human intuitions
about space and time are simply wrong. There \textit{is} no global
``now,'' there \textit{is} no
``before'' or
``after'' across spacelike gaps. The
ability to \textit{visualize} a single global world, \textit{even in
principle,} comes from not getting Special Relativity on a gut level.
Otherwise it would be obvious that physics proceeds locally with
invariant states of distant entanglement, and the requisite information
is simply \textit{not} \textit{locally present} to support a
\textit{globally single world}.


 It might be that this seemingly impeccable logic is flawed---that
my application of Bell's Theorem and relativity to rule
out any single global world contains some hidden assumption of which I
am unaware---


 {}---but consider the burden that a single-world theory must now
shoulder! There is absolutely no reason \textit{in the first place} to
suspect a global single world; this is just \textit{not what current
physics says!} The global single world is an ancient human intuition
that was \textit{disproved}, like the idea of a universal absolute
time. The superposition principle is visible even in half-silvered
mirrors; experiments are verifying the disproof at steadily larger
levels of superposition---but above all there is \textit{no longer any
reason} to \textit{privilege the hypothesis} of a global single world.
The ladder has been yanked out from underneath that human intuition.


 There is no experimental evidence that the macroscopic world is
single (we already know the microscopic world is superposed). And the
prospect necessarily either violates Special Relativity, or takes an
even more miraculous-seeming leap and violates seemingly impeccable
logic. The latter, of course, being much more plausible in practice.
But it isn't really \textit{that} plausible in an
absolute sense. \textit{Without experimental evidence,} it is generally
a \textit{bad sign} to have to postulate arbitrary logical miracles.


 As for quantum non-realism, it appears to me to be nothing more
than a Get Out of Jail Free card.
``It's okay to violate Special
Relativity because none of this is real anyway!'' The
equations cannot reasonably be hypothesized to deliver such excellent
predictions \textit{for literally no reason.} Bell's
Theorem rules out the obvious possibility that quantum theory
represents imperfect knowledge of something locally deterministic.


 Furthermore, macroscopic decoherence gives us a perfectly
\textit{realistic} understanding of what is going on, in which the
equations deliver such good predictions because they mirror reality.
And so the idea that the quantum equations are just
``meaningless,'' and therefore it is
okay to violate Special Relativity, so we can have one global world
after all, is not \textit{necessary}. To me, quantum non-realism
appears to be a huge bluff built around semantic stopsigns like
``Meaningless!''


 It is not quite safe to say that the existence of multiple Earths
is as well-established as any other truth of science. The existence of
quantum other worlds is not so well-established as the existence of
trees, which most of us can personally observe.


 Maybe there is something in that 20th decimal place, which
aggregates to something bigger in macroscopic events. Maybe
there's a loophole in the seemingly iron logic which
says that any single global world must violate Special Relativity,
because the information to support a single global world is not locally
available. And maybe the Flying Spaghetti Monster is just messing with
us, and the world we know is a lie.


 So all we can say about the existence of multiple Earths, is that
it is as rationally probable as e.g.~the statement that spinning black
holes do not violate conservation of angular momentum. We have
extremely fundamental reasons, having to do with the rotational
symmetry of space, to suspect that conservation of angular momentum is
built into the underlying nature of physics. And we have no specific
reason to suspect this \textit{particular} violation of our old
generalizations in a higher-energy regime.


 But we haven't actually checked conservation of
angular momentum for rotating black holes---so far as I know. (And as I
am talking here about rational guesses in states of partial knowledge,
the point is exactly the same if the observation has been made and I do
not know it yet.) And black holes are a more massive regime. So the
obedience of black holes is not \textit{quite} as assured as that my
toilet conserves angular momentum while flushing, which come to think,
I haven't checked either\,\ldots


 Yet if you make the \textit{mistake} of thinking too hard about
this one particular possibility, instead of zillions of other
possibilities---and especially if you don't understand
the fundamental reason \textit{why} angular momentum is
conserved---then it may start seeming more and more plausible that
``spinning black holes violate conservation of angular
momentum,'' as you think of more and more vaguely
plausible-sounding reasons it \textit{could} be true.


 But the rational probability is pretty damned small.


 Likewise the rational probability that there is only one Earth.


 I mention this to explain my habit of talking as if many-worlds is
an obvious fact. Many-worlds \textit{is} an obvious fact, if you have
all your marbles lined up correctly (understand very basic quantum
physics, know the formal probability theory of Occam's
Razor, understand Special Relativity, etc.) It is in fact considerably
\textit{more} obvious to me than the proposition that spinning black
holes should obey conservation of angular momentum.


 The only reason why many-worlds is not universally acknowledged as
a direct prediction of physics which requires magic to violate, is that
a contingent accident of our Earth's scientific history
gave an entrenched academic position to a phlogiston-like theory that
had an unobservable faster-than-light magical
``collapse'' devouring all other
worlds. And many academic physicists do not have a mathematical grasp
of Occam's Razor, which is the usual method for ridding
physics of invisible angels. So when they encounter many-worlds and it
conflicts with their (undermined) intuition that only one world exists,
they say, ``Oh, that's multiplying
entities''---which is just flatly wrong as
probability theory---and go on about their daily lives.


 I am not in academia. I am not constrained to bow and scrape to
some senior physicist who hasn't grasped the obvious,
but who will be reviewing my journal articles. I need have no fear that
I will be rejected for tenure on account of scaring my students with
``science-fiction tales of other
Earths.'' If \textit{I} can't speak
plainly, who can?


 So let me state then, very clearly, on behalf of any and all
physicists out there who dare not say it themselves: Many-worlds
\textit{wins outright} given our current state of evidence. There is no
more reason to postulate a single Earth, than there is to postulate
that two colliding top quarks would decay in a way that violates
Conservation of Energy. It takes more than an unknown fundamental law;
it takes magic.

{
 \textit{The debate should already be over. It should have been
over fifty years ago. The state of evidence is too lopsided to justify
further argument. There is no balance in this issue. There is no
rational controversy to teach. The laws of probability theory are laws,
not suggestions; there is no flexibility in the best guess given this
evidence. Our children will look back at the fact that we were \textsc{still
arguing} about this in the early twenty-first century, and correctly
deduce that we were nuts.}}


 We have embarrassed our Earth long enough by failing to see the
obvious. So for the honor of my Earth, I write as if the existence of
many-worlds were an established fact, because it \textit{is.} The only
question now is how long it will take for the people of this world to
update.

\myendsectiontext

\chapter{Science and Rationality}

\mysection{The Failures of Eld Science}


 This time there were no robes, no hoods, no masks. Students were
expected to become friends, and allies. And everyone knew why you were
in the classroom. It would have been pointless to pretend you
weren't in the Conspiracy. 


 Their \textit{sensei} was Jeffreyssai, who might have been the
best of his era, in his era. His students were either the most
promising learners, or those whom the \textit{beisutsukai} saw
political advantage in molding.


 Brennan fell into the latter category, and knew it. Nor had he
hesitated to use his Mistress's name to open doors. You
used every avenue available to you, in seeking knowledge; that was
respected here.


 ``---for over thirty years,''
Jeffreyssai said. ``Not one of them saw it; not
Einstein, not Schrödinger, not even von Neumann.'' He
turned away from his sketcher, and toward the classroom.
``I pose to you to the question: How did they
fail?''


 The students exchanged quick glances, a calculus of mutual risk
between the wary and the merely baffled. Jeffreyssai was known to play
games.


 Finally Hiriwa-called-the-Black leaned forward, jangling slightly
as her equation-carved bracelets shifted on her ankles.
``By your years given, \textit{sensei}, this was two
hundred and fifty years after Newton. Surely, the scientists of that
era must have grokked the concept of a universal
law.''


 ``Knowing the universal law of
gravity,'' said the student Taji, from a nearby seat,
``is not the same as understanding the concept
\textit{of} a universal law.'' He was one of the
promising ones, as was Hiriwa.


 Hiriwa frowned. ``No\,\ldots it was said that
Newton had been praised \textit{for} discovering the first universal.
Even in his own era. So it was known.'' Hiriwa
paused. ``But Newton himself would have been gone. Was
there a \textit{religious} injunction against proposing further
universals? Did they refrain out of respect for Newton, or were they
waiting for his \textit{ghost} to speak? I am not clear on how Eld
science was motivated---''


 ``No,'' murmured Taji, a laugh
in his voice, ``you really, \textit{really}
aren't.''


 Jeffreyssai's expression was kindly.
``Hiriwa, it wasn't religion, and it
wasn't lead in the drinking water, and they
didn't all have Alzheimer's, and they
weren't sitting around all day reading webcomics.
Forget the catalogue of horrors out of ancient times. Just think in
terms of cognitive errors. What could Eld science have been
\textit{thinking} wrong?''


 Hiriwa sat back with a sigh. ``\textit{Sensei}, I
truly cannot imagine a snafu that would do
\textit{that}.''


 ``It wouldn't be just
\textit{one} mistake,'' Taji corrected her.
``As the saying goes: Mistakes don't
travel alone; they hunt in packs.''


 ``But the \textit{entire} human
species?'' said Hiriwa. ``Thirty
\textit{years}?''


 ``It wasn't the entire human
species, Hiriwa,'' said Styrlyn. He was one of the
older-looking students, wearing a short beard speckled in gray.
``Maybe one in a hundred thousand could have written
out Schrödinger's Equation from memory. So that would
have been their first and primary error---failure to concentrate their
forces.''


 ``\textit{Spare us the
propaganda!}'' Jeffreyssai's gaze was
suddenly fierce. ``You are not here to proselytize for
the Cooperative Conspiracy, my lord politician! Bend not the truth to
make your points! I believe your Conspiracy has a phrase:
`Comparative advantage.' Do you
\textit{really} think that it would have helped to call in the whole
human species, as it existed at that time, to debate quantum
physics?''


 Styrlyn didn't flinch. ``Perhaps
not, \textit{sensei},'' he said.
``But if you are to compare that era to this one, it
is a consideration.''


 Jeffreyssai moved his hand flatly through the air; the
maybe-gesture he used to dismiss an argument that was true but not
relevant. ``It is not what I would call a
\textit{primary} mistake. The puzzle should not have required a billion
physicists to solve.''


 ``I can think of more \textit{specific} ancient
horrors,'' said Taji. ``Spending all
day writing grant proposals. Teaching undergraduates who would rather
be somewhere else. Needing to publish thirty papers a year to get
tenure\,\ldots''


 ``But we are not speaking of only the
lower-status scientists,'' said Yin; she wore a
slightly teasing grin. ``It was said of Schrödinger
that he retired to a villa for a month, with his mistress to provide
inspiration, and emerged with his eponymous equation. We consider it a
famous historical success of our methodology. Some Eld physicists
\textit{did} understand how to focus their mental energies; and would
have been senior enough to do so, had they chose.''


 ``True,'' Taji said.
``In the end, administrative burdens are only a
generic obstacle. Likewise such answers as, `They were
not trained in probability theory, and did not know of cognitive
biases.' Our sensei seems to desire some more specific
reply.''


 Jeffreyssai lifted an eyebrow encouragingly.
``Don't dismiss your line of thought
so quickly, Taji; it begins to be relevant. What kind of system would
create administrative burdens on its own people?''


 ``A system that failed to support its people
adequately,'' said Styrlyn. ``One
that failed to value their work.''


 ``Ah,'' said Jeffreyssai.
``But there is a student who has not yet spoken.
\textit{Brennan?}''


 Brennan didn't jump. He deliberately waited just
long enough to show he wasn't scared, and then said,
``Lack of pragmatic motivation,
sensei.''


 Jeffreyssai smiled slightly.
``Expand.''


 \textit{What kind of system would create administrative burdens on
its own people?}, their \textit{sensei} had asked them. The other
students were pursuing their own lines of thought. Brennan, hanging
back, had more attention to spare for his teacher's few
hints. Being the beginner wasn't \textit{always} a
disadvantage---and he had been taught, long before the Bayesians took
him in, to take every available advantage.


 ``The Manhattan Project,''
Brennan said, ``was launched with a specific
\textit{technological} end in sight: a weapon of great power, in time
of war. But the error that Eld Science committed with respect to
quantum physics had no immediate consequences for their technology.
They were confused, but they had no desperate \textit{need} for an
answer. Otherwise the surrounding system would have removed all burdens
from their effort to solve it. Surely the Manhattan Project must have
done so---Taji? Do you know?''


 Taji looked thoughtful. ``Not \textit{all}
burdens---but I'm pretty sure they
weren't writing grant proposals in the middle of their
work.''


 ``So,'' Jeffreyssai said. He
advanced a few steps, stood directly in front of
Brennan's desk. ``You think Eld
scientists simply weren't trying hard enough. Because
their art had no military applications? A rather \textit{competitive}
point of view, I should think.''


 ``Not necessarily,'' Brennan
said calmly. ``Pragmatism is a virtue of rationality
also. A desired \textit{use} for a better quantum theory would have
helped the Eld scientists in many ways beyond just motivating them. It
would have given shape to their curiosity, and told them what
constituted success or failure.''

{
 Jeffreyssai chuckled slightly.
``Don't guess so hard what \textit{I}
might prefer to hear, Competitor. Your first statement came closer to
my hidden mark; your oh-so-Bayesian disclaimer fell wide\,\ldots The
factor I had in mind, Brennan, was that Eld scientists thought it was
\textit{acceptable} to take thirty years to solve a problem. Their
entire social process of science was based on getting to the truth
\textit{eventually.} A wrong theory got discarded
\textit{eventually}{}---once the next generation of students grew up
familiar with the replacement. Work expands to fill the time allotted,
as the saying goes. But people can think important thoughts in far less
than thirty years, if they \textit{expect} speed of
themselves.'' Jeffreyssai suddenly slammed down a
hand on the arm of Brennan's chair.
``\textit{How long do you have to dodge a thrown
knife?}''}


 ``Very little time, sensei!''

{
 ``\textit{Less than a second! Two opponents are
attacking you! How long do you have to guess who's more
dangerous?}''}


 ``Less than a second,
sensei!''

{
 ``\textit{The two opponents have split up and are
attacking two of your girlfriends! How long do you have to decide which
one you truly love?}''}


 ``Less than a second,
sensei!''

{
 ``\textit{A new argument shows your precious
theory is flawed! How long does it take you to change your
mind?}''}


 ``Less than a second,
sensei!''


 ``\textit{\textsc{Wrong! Don't give me
the wrong answer just because it fits a convenient pattern and I seem
to expect it of you!}} How long does it really take,
Brennan?''


 Sweat was forming on Brennan's back, but he
stopped and actually thought about it---


 ``\textit{\textsc{Answer, Brennan!}}''

{
 ``\textit{No, sensei! I'm not
finished thinking, sensei! An answer would be premature!
Sensei!}''}

{
 ``\textit{Very good! Continue! But
don't take thirty years!}''}


 Brennan breathed deeply, reforming his thoughts. He finally said,
``Realistically, sensei, the best-case scenario is
that I would see the problem immediately; use the discipline of
suspending judgment; try to re-accumulate all the evidence before
continuing; and depending on how emotionally attached I had been to the
theory, use the crisis-of-belief technique to ensure I could genuinely
go either way. So at least five minutes and perhaps up to an
hour.''

{
 ``\textit{Good! You actually thought about it
that time! Think about it every time! Break patterns!} In the days of
Eld Science, Brennan, it was not uncommon for a grant agency to spend
six months reviewing a proposal. \textit{They permitted themselves the
time!} You are being graded on your \textit{speed}, Brennan! The
question is not whether you get there eventually! Anyone can find the
truth in five thousand years! You need to \textit{move
faster!}''}


 ``\textit{Yes, sensei!}''


 ``Now, Brennan, have you just learned something
new?''


 ``Yes, sensei!''


 ``How long did it take you to learn this new
thing?''


 An arbitrary choice there\,\ldots ``Less than a
minute, sensei, from the boundary that seems most
obvious.''


 ``Less than a minute,''
Jeffreyssai repeated. ``So, Brennan, how long do you
think it should take to solve a major scientific problem, if you are
not wasting any time?''


 Now there was a trapped question if Brennan had ever heard one.
There was no way to guess what time period Jeffreyssai had in
mind---what the \textit{sensei} would consider too long, or too short.
Which meant that the only way out was to just try for the genuine
truth; this would offer him the defense of honesty, little defense
though it was. ``One year,
sensei?''


 ``Do you think it could be done in one month,
Brennan? In a case, let us stipulate, where in principle you already
have enough experimental evidence to determine an answer, but not so
much experimental evidence that you can afford to make errors in
interpreting it.''


 Again, no way to guess which answer Jeffreyssai might \textit{want\,\ldots} ``One month seems like an unrealistically short
time to me, sensei.''


 ``A \textit{short time}?''
Jeffreyssai said incredulously. ``How many minutes in
thirty days? Hiriwa?''


 ``43,200, sensei,'' she
answered. ``If you assume sixteen-hour waking periods
and daily sleep, then 28,800 minutes.''


 ``Assume, Brennan, that it takes five whole
minutes to think an \textit{original} thought, rather than learning it
from someone else. Does even a major scientific problem require 5,760
distinct insights?''


 ``I confess, sensei,'' Brennan
said slowly, ``that I have never thought of it that
way before\,\ldots but do you tell me that is \textit{truly} a realistic
level of productivity?''


 ``No,'' said Jeffreyssai,
``but neither is it realistic to think that a single
problem requires 5,760 insights. And yes, it has been
done.''


 Jeffreyssai stepped back, and smiled benevolently. Every student
in the room stiffened; they knew that smile. ``Though
none of you hit the particular answer that \textit{I} had in mind,
nonetheless your answers were as reasonable as mine. Except
Styrlyn's, I'm afraid. Even
Hiriwa's answer was not entirely wrong: the task of
proposing new theories was once considered a sacred duty reserved for
those of high status, there being a limited supply of problems in
circulation, at that time. But \textit{Brennan's}
answer is \textit{particularly} interesting, and I am minded to test
his theory of motivation.''


 \textit{Oh, hell,} Brennan said silently to himself. Jeffreyssai
was gesturing for Brennan to stand up before the class.


 When Brenann had risen, Jeffreyssai neatly seated himself in
Brennan's chair.


 ``Brennan-sensei,'' Jeffreyssai
said, ``you have five minutes to think of something
stunningly brilliant to say about the failure of Eld science on quantum
physics. As for the rest of us, our job will be to gaze at you
expectantly. I can only imagine how embarrassing it will be, should you
fail to think of anything good.''


 \textit{Bastard.} Brennan didn't say it aloud.
Taji's face showed a certain amount of sympathy;
Styrlyn held himself aloof from the game; but Yin was looking at him
with sardonic interest. Worse, Hiriwa \textit{was} gazing at him
expectantly, assuming that he would rise to the challenge. And
Jeffreyssai was gawking wide-eyed, waiting for the
guru's words of wisdom. \textit{Screw you, sensei.}


 Brennan didn't panic. It was very, very, very far
from being the scariest situation he'd ever faced. He
took a moment to decide how to think; then thought.


 At four minutes and thirty seconds, Brennan spoke. (There was an
art to such things; as long as you were doing it anyway, you might as
well make it look easy.)


 ``A woman of wisdom,'' Brennan
said, ``once told me that it is wisest to regard our
past selves as fools beyond redemption---to see the people we once were
as idiots entire. I do not necessarily say this myself; but it is what
she said to me, and there is more than a grain of truth in it. As long
as we are making excuses for the past, trying to make it look better,
\textit{respecting} it, we cannot make a clean break. It occurs to me
that the rule may be no different for human \textit{civilizations}. So
I tried looking back and considering the Eld scientists as simple
fools.''


 ``Which they were not,''
Jeffreyssai said.


 ``Which they were not,''
Brennan continued. ``In terms of raw intelligence,
they undoubtedly exceeded me. But it occurred to me that a difficulty
in seeing what Eld scientists did wrong, might have been in respecting
the ancient and legendary names too highly. And that did indeed produce
an insight.''


 ``Enough introduction,
Brennan,'' said Jeffreyssai. ``If
you found an insight, state it.''


 ``Eld scientists were not trained\,\ldots'' Brennan paused. ``No,
\textit{untrained} is not the concept. They were trained for the
\textit{wrong task.} At that time, there were no Conspiracies, no
secret truths; as soon as Eld scientists solved a major problem, they
published the solution to the world and each other. Truly scary and
confusing \textit{open problems} would have been in extremely rare
supply, and used up the moment they were solved. So it would not have
been possible to train Eld researchers \textit{to bring order out of
scientific chaos.} They would have been trained for something
else---I'm not sure what---''


 ``Trained to manipulate whatever science had
\textit{already} been discovered,'' said Taji.
``It was a difficult enough task for Eld teachers to
train their students to \textit{use existing knowledge}, or follow
already-known methodologies; that was all Eld science teachers aspired
to impart.''


 Brennan nodded. ``Which is a \textit{very}
different matter from creating new science of their own. The Eld
scientists, faced with problems of quantum theory, might never have
faced that kind of \textit{fear} before---the dismay of not knowing.
The Eld scientists might have seized on unsatisfactory answers
prematurely, because they were accustomed to working with a neat,
agreed-upon body of knowledge.''


 ``\textit{Good}, Brennan,''
murmured Jeffreyssai.


 ``But above all,'' Brennan
continued, ``an Eld scientist couldn't
have \textit{practiced} the actual problem the quantum scientists
faced---that of resolving a major confusion. It was something you did
once per lifetime if you were lucky, and as Hiriwa observed, Newton
would no longer have been around. So while the Eld physicists who
messed up quantum theory were not unintelligent, they were, in a strong
sense, \textit{amateurs}{}---ad-libbing the whole process of paradigm
shift.''


 ``And no probability theory,''
Hiriwa noted. ``So anyone who \textit{did} succeed at
the problem would have no idea what they'd just done.
They wouldn't be able to communicate it to anyone else,
except vaguely.''


 ``Yes,'' Styrlyn said.
``And it was only a handful of people who could tackle
the problem at all, with no training in doing so; those are the
physicists whose names have passed down to us. A handful of people,
making a handful of discoveries each. It would not have been enough to
sustain a community. Each Eld scientist tackling a new paradigm shift
would have needed to rediscover the rules from
scratch.''


 Jeffreyssai rose from Brenann's desk.
``Acceptable, Brennan; you surprise me, in fact. I
shall have to give further thought to this method of
yours.'' Jeffreyssai went to the classroom door, then
looked back. ``However, I did have in mind at least
one \textit{other} major flaw of Eld science, which none of you
suggested. I expect to receive a list of possible flaws tomorrow. I
expect the flaw I have in mind to be on the list. You have 480 minutes,
excluding sleep time. I see five of you here. The challenge does not
require more than 480 insights to solve, nor more than 96 insights in
series.''


 And Jeffreyssai left the room.

\myendsectiontext

\mysection{The Dilemma: Science or Bayes?}

\begin{quote}

 Eli: You are writing a lot about physics recently. Why?

{\raggedleft
 {}---Shane Legg (and several other people)\footnote{\url{http://lesswrong.com/lw/q5/quantum_nonrealism/juk}}
\par}
\end{quote}

\begin{quote}

 In light of your QM explanation, which to me sounds perfectly
logical, it seems \textit{obvious and normal} that many worlds is
overwhelmingly likely. It just seems almost too good to be true that
\textit{I} now get what plenty of genius quantum physicists still
can't. [ \ldots ] Sure I can explain all that away, and
I still think you're right, I'm just
suspicious of myself for believing the first believable explanation I
met.

{\raggedleft
 {}---Recovering\_irrationalist\footnote{\url{http://lesswrong.com/lw/q8/many_worlds_one_best_guess/jxl}}
\par}
\end{quote}


 Recovering\_irrationalist, you've got no idea how
glad I was to see you post that comment.


 Of course I had more than just \textit{one} reason for spending
all that time writing about quantum physics. I like having lots of
hidden motives. It's the closest I can ethically get to
being a supervillain.


 But to give an example of a purpose I could \textit{only}
accomplish by discussing quantum physics\,\ldots


 In physics, you can get absolutely clear-cut issues. Not in the
sense that the issues are trivial to explain. But if you try to apply
Bayes to healthcare, or economics, you may not be able to
\textit{formally} lay out what is the simplest hypothesis, or what the
evidence supports. But when I say ``macroscopic
decoherence is simpler than collapse'' it is actually
\textit{strict} simplicity; you could write the two hypotheses out as
computer programs and count the lines of code. Nor is the evidence
itself in dispute.


 I wanted a very clear example---\textit{Bayes says
``zig,'' this is a zag}{}---when it
came time to break your allegiance to Science.


 ``Oh, sure,'' you say,
``the physicists messed up the many-worlds thing, but
give them a break, Eliezer! No one ever claimed that the social process
of science was perfect. People are human; they make
mistakes.''


 But the physicists who refuse to adopt many-worlds
aren't disobeying the rules of Science.
They're \textit{obeying} the rules of Science.


 The tradition handed down through the generations says that a new
physics theory comes up with new experimental predictions that
distinguish it from the old theory. You perform the test, and the new
theory is confirmed or falsified. If it's confirmed,
you hold a huge celebration, call the newspapers, and hand out Nobel
Prizes for everyone; any doddering old emeritus professors who refuse
to convert are quietly humored. If the theory is disconfirmed, the lead
proponent publicly recants, and gains a reputation for honesty.


 This is not how things \textit{do} work in science; rather it is
how things are \textit{supposed} to work in Science.
It's the ideal to which all good scientists aspire.


 Now many-worlds comes along, and it doesn't seem
to make any new predictions relative to the old theory.
That's suspicious. And there's all
these other worlds, but you can't see them.
That's \textit{really} suspicious. It just
doesn't seem scientific.


 If you got as far as Recovering\_irrationalist---so that
many-worlds now seems perfectly logical, obvious and
normal---\textit{and} you also started out as a Traditional
Rationalist, then you should be able to switch back and forth between
the Scientific view and the Bayesian view, like a Necker Cube.


 So now put on your Science Goggles---you've still
got them around somewhere, right? Forget everything you know about
Kolmogorov complexity, Solomonoff induction or Minimum Message Lengths.
That's not part of the traditional training. You just
eyeball something to see how
``simple'' it looks. The word
``testable'' doesn't
conjure up a mental image of Bayes's Theorem governing
probability flows; it conjures up a mental image of being in a lab,
performing an experiment, and having the celebration (or public
recantation) afterward.

\begin{quote}
{
 \textit{Science-Goggles on}: The current quantum theory has passed
all experimental tests so far. Many-worlds doesn't make
any new testable predictions---the amazing new phenomena it predicts
are all hidden away where we can't see them. You can
get along fine without supposing the other worlds, and
that's just what you should do. The whole thing smacks
of science fiction. But it must be admitted that quantum physics is a
very deep and very confusing issue, and who knows what discoveries
might be in store? Call me when Many-worlds makes a testable
prediction.}
\end{quote}


 Science-Goggles off, Bayes-Goggles back on:

\begin{quote}
{
 \textit{Bayes-Goggles on}: The simplest quantum equations that
cover all known evidence don't have a special exception
for human-sized masses. There isn't even any reason to
ask that particular question. Next!}
\end{quote}


 Okay, so is this a problem we can fix in five minutes with some
duct tape and superglue?


 No.


 Huh? Why not just teach new graduating classes of scientists about
Solomonoff induction and Bayes's Rule?


 Centuries ago, there was a widespread idea that the Wise could
unravel the secrets of the universe just by thinking about them, while
to go out and \textit{look} at things was lesser, inferior, naive, and
would just delude you in the end. You couldn't trust
the way things \textit{looked}{}---only thought could be your guide.


 Science began as a rebellion against this Deep Wisdom. At the core
is the pragmatic belief that human beings, sitting around in their
armchairs trying to be Deeply Wise, just drift off into never-never
land. You couldn't trust your thoughts. You had to make
advance experimental predictions---predictions that no one else had
made before---run the test, and confirm the result. That was evidence.
Sitting in your armchair, thinking about what seemed reasonable\,\ldots
would not be taken to \textit{prejudice} your theory, because Science
wasn't an idealistic belief about pragmatism, or
getting your hands dirty. It was, rather, the dictum that experiment
alone would decide. Only experiments could judge your theory---not your
nationality, or your religious professions, or the fact that
you'd invented the theory in your armchair. Only
experiments! If you sat in your armchair and came up with a theory that
made a novel prediction, and experiment confirmed the prediction, then
we would care about the result of the experiment, not where your
hypothesis came from.


 \textit{That's} Science. And if you say that
many-worlds should replace the immensely successful Copenhagen
Interpretation, adding on all these twin Earths that
can't be observed, just because it \textit{sounds more
reasonable and elegant}{}---not because it \textit{crushed the old
theory with a superior experimental prediction}{}---then
you're undoing the core scientific rule that prevents
people from running out and putting angels into all the theories,
because angels are more reasonable and elegant.


 You think teaching a few people about Solomonoff induction is
going to solve \textit{that} problem? Nobel laureate Robert
Aumann---who first proved that Bayesian agents with similar priors
cannot agree to disagree---is a believing Orthodox Jew. Aumann helped a
project to test the Torah for ``Bible
codes,'' hidden prophecies from God---and concluded
that the project had failed to confirm the codes'
existence. Do you want Aumann thinking that once you've
got Solomonoff induction, you can forget about the experimental method?
Do you think that's going to help him? And most
scientists out there will not rise to the level of Robert Aumann.


 Okay, Bayes-Goggles back on. Are you \textit{really} going to
believe that large parts of the wavefunction disappear when you can no
longer see them? As a result of the only non-linear non-unitary
non-differentiable non-CPT-symmetric acausal faster-than-light
informally-specified phenomenon in all of physics? Just because, by
sheer historical contingency, the stupid version of the theory was
proposed first?


 Are you going to make a major modification to a scientific model,
and believe in zillions of other worlds you can't see,
without a defining moment of experimental triumph over the old model?


 Or are you going to reject probability theory?


 Will you give your allegiance to Science, or to Bayes?


 Michael Vassar once observed (tongue-in-cheek) that it was a good
thing that a majority of the human species believed in God, because
otherwise, he would have a very hard time rejecting majoritarianism.\footnote{\url{http://www.overcomingbias.com/2007/03/on_majoritarian.html}}
But since the majority opinion that God exists is simply unbelievable,
we have no choice but to reject the extremely strong philosophical
arguments for majoritarianism.


 You can see (one of the reasons) why I went to such lengths to
explain quantum theory. Those who are good at math should now be able
to \textit{visualize} both macroscopic decoherence, and the probability
theory of simplicity and testability---get the insanity of a global
single world on a \textit{gut} level.


 I wanted to present you with a nice, sharp dilemma between
rejecting the scientific method, or embracing insanity.


 Why? I'll give you a hint: It's
not just because I'm evil. If you would guess my
motives here, think beyond the first obvious answer.


 PS: If you try to come up with clever ways to wriggle out of the
dilemma, you're just going to get shot down in future
essays. You have been warned.

\myendsectiontext

\mysection{Science Doesn't Trust Your Rationality}


 Scott Aaronson\footnote{\url{http://www.scottaaronson.com/blog/?p=326}} suggests that many-worlds and libertarianism are
similar in that they are both cases of bullet-swallowing, rather than
bullet-dodging:

\begin{quote}
{
 Libertarianism and MWI are both grand philosophical theories that
start from premises that almost all educated people accept (quantum
mechanics in the one case, Econ 101 in the other), and claim to reach
conclusions that most educated people reject, or are at least puzzled
by (the existence of parallel universes / the desirability of
eliminating fire departments).}
\end{quote}


 Now \textit{there's} an analogy that would never
have occurred to me.


 I've previously argued that Science rejects
Many-Worlds but Bayes accepts it. (Here,
``Science'' is capitalized because
we are talking about the idealized form of Science, not just the actual
social process of science.)


 It furthermore seems to me that there is a \textit{deep} analogy
between (small-``l'') libertarianism
and Science:

\begin{enumerate}
\item {
 Both are based on a pragmatic distrust of reasonable-sounding
arguments.}

\item {
 Both try to build systems that are more trustworthy than the
people in them.}

\item {
 Both accept that people are flawed, and try to harness their flaws
 to power the system.}
\end{enumerate}


 The core argument for libertarianism is historically motivated
distrust of lovely theories of ``How much
\textit{better} society would be, if we just made a rule that said
XYZ.'' If that sort of trick actually
\textit{worked}, then more regulations would correlate to higher
economic growth as society moved from local to global optima. But when
some person or interest group gets enough power to start doing
everything they think is a good idea, history says that what actually
\textit{happens} is Revolutionary France or Soviet Russia.


 The plans that in lovely theory should have made everyone happy
ever after, don't have the results predicted by
reasonable-sounding arguments. And power corrupts, and attracts the
corrupt.


 So you regulate as little as possible, because you
can't trust the lovely theories and you
can't trust the people who implement them.


 You don't shake your finger at people for being
selfish. You try to build an efficient system of production out of
selfish participants, by requiring transactions to be voluntary. So
people are forced to play positive-sum games, because
that's how they get the \textit{other} party to sign
the contract. With violence restrained and contracts enforced,
individual selfishness can power a globally productive system.


 Of course none of this works quite so well in practice as in
theory, and I'm not going to go into market failures,
commons problems, etc. The core argument for libertarianism is not that
libertarianism would work in a perfect world, but that it degrades
gracefully into real life. Or rather, degrades less awkwardly than any
other known economic principle. (People who see Libertarianism as the
perfect solution for perfect people strike me as kinda missing the
point of the ``pragmatic distrust''
thing.)


 Science first came to know itself as a rebellion against trusting
the word of Aristotle. If the people of that revolution had merely
said, ``Let us trust ourselves, not
Aristotle!'' they would have flashed and faded like
the French Revolution.


 But the Scientific Revolution lasted because---like the American
Revolution---the architects propounded a stranger philosophy:
``Let us trust no one! Not even
ourselves!''


 In the beginning came the idea that we can't just
toss out Aristotle's armchair reasoning and replace it
with \textit{different} armchair reasoning. We need to talk to Nature,
and actually \textit{listen} to what It says in reply. This, itself,
was a stroke of genius.


 But then came the challenge of implementation. People are
stubborn, and may not want to accept the verdict of experiment. Shall
we shake a disapproving finger at them, and say
``Naughty''?


 No; we assume and accept that each individual scientist may be
crazily attached to their personal theories. Nor do we assume that
anyone can be trained out of this tendency---we don't
try to choose Eminent Judges who are supposed to be impartial.


 Instead, we try to \textit{harness} the individual
scientist's stubborn desire to prove their personal
theory, by saying: ``Make a new experimental
prediction, and do the experiment. If you're right, and
the experiment is replicated, you win.'' So long as
scientists believe this is true, they have a motive to do experiments
that can \textit{falsify} their own theories. Only by accepting the
possibility of defeat is it possible to win. And any great claim will
require replication; this gives scientists a motive to be honest, on
pain of great embarrassment.


 And so the stubbornness of individual scientists is harnessed to
produce a steady stream of knowledge at the group level. The System is
\textit{somewhat} more trustworthy than its parts.


 Libertarianism secretly relies on most individuals being prosocial
enough to tip at a restaurant they won't ever visit
again. An economy of genuinely selfish human-level agents would
implode. Similarly, Science relies on most scientists not committing
sins so egregious that they can't rationalize them
away.


 To the extent that scientists believe they can promote their
theories by playing academic politics---or game the statistical methods
to potentially win without a chance of losing---or to the extent that
nobody bothers to replicate claims---science degrades in effectiveness.
But it degrades gracefully, as such things go.


 The part where the successful predictions belong to the theory and
theorists who originally made them, and cannot just be stolen by a
theory that comes along later---\textit{without} a novel experimental
prediction---is an important feature of this social process.


 The final upshot is that Science is not easily reconciled with
probability theory. If you do a probability-theoretic calculation
\textit{correctly}, you're going to get the
\textit{rational} answer. Science doesn't trust your
rationality, and it doesn't rely on your ability to use
probability theory as the arbiter of truth. It wants you to set up a
definitive experiment.


 Regarding Science as a mere approximation to some
probability-theoretic ideal of rationality\,\ldots would certainly seem
to be \textit{rational}. There seems to be an extremely
reasonable-sounding argument that Bayes's Theorem is
the hidden structure that explains why Science works. But to
subordinate Science to the grand schema of Bayesianism, and let
Bayesianism come in and override Science's verdict when
that seems appropriate, is not a trivial step!


 Science is built around the assumption that you're
\textit{too stupid and self-deceiving} to just use Solomonoff
induction. After all, if it was that simple, we
wouldn't need a social process of science\,\ldots right?


 So, are you going to believe in faster-than-light quantum
``collapse'' fairies after all? Or
do you think you're smarter than that?

\myendsectiontext

\mysection{When Science Can't Help}


 Once upon a time, a younger Eliezer had a stupid theory.
Let's say that
Eliezer\textsubscript{18}'s stupid theory was that
consciousness was caused by closed timelike curves hiding in quantum
gravity. This isn't the whole story, not even close,
but it will do for a start. 


 And there came a point where I looked back, and realized:

\begin{enumerate}
\item {
 I had carefully followed everything I'd been told
was Traditionally Rational, in the course of going astray. For example,
I'd been careful to only believe in stupid theories
that made novel experimental predictions, e.g., that neuronal
microtubules would be found to support coherent quantum states.}

\item {
 Science would have been perfectly fine with my spending ten years
trying to test my stupid theory, only to get a negative experimental
result, so long as I then said, ``Oh, well, I guess my
theory was wrong.''}
\end{enumerate}


 From Science's perspective, that is how things are
\textit{supposed} to work---happy fun for everyone. You admitted your
error! Good for you! Isn't that what Science is all
about?


 But what if I didn't want to waste ten years?


 Well\,\ldots Science didn't have much to say about
\textit{that.} How could Science say which theory was right, in
\textit{advance} of the experimental test? Science
doesn't care where your theory comes from---it just
says, ``Go test it.''


 This is the great strength of Science, and also its great
weakness.


 Gray Area asked:\footnote{\url{http://lesswrong.com/lw/qb/science_doesnt_trust_your_rationality/k0k}}

\begin{quote}
{
  Eliezer, why are you concerned with untestable questions?}
\end{quote}


 Because questions that are \textit{easily immediately} tested are
hard for Science to get wrong.


 I mean, sure, when there's already definite
unmistakable experimental evidence available, go with it. Why on Earth
wouldn't you?


 But sometimes a question will have very large, very definite
experimental consequences in your future---but you
can't easily test it experimentally \textit{right
now}{}---and yet there \textit{is} a strong \textit{rational}
argument.


 Macroscopic quantum superpositions are readily testable: It would
just take nanotechnologic precision, very low temperatures, and a nice
clear area of interstellar space. Oh, sure, you can't
do it \textit{right now}, because it's \textit{too
expensive} or \textit{impossible for today's
technology} or something like that---but in theory, sure! Why, maybe
someday they'll run whole civilizations on
macroscopically superposed quantum computers, way out in a well-swept
volume of a Great Void. (Asking what quantum non-realism says about the
status of any observers inside these computers helps to reveal the
underspecification of quantum non-realism.)


 This doesn't seem immediately pragmatically
relevant to your life, I'm guessing, but it establishes
the pattern: Not everything with future consequences is \textit{cheap}
to test \textit{now}.


 Evolutionary psychology is another example of a case where
rationality has to take over from science. While theories of
evolutionary psychology form a connected whole, only some of those
theories are readily testable experimentally. But you still need the
other parts of the theory, because they form a connected web that helps
you to form the hypotheses that are actually testable---and then the
helper hypotheses are supported in a Bayesian sense, but not supported
experimentally. Science would render a verdict of
``not proven'' on individual parts
of a connected theoretical mesh that is experimentally productive as a
whole. We'd need a new kind of verdict for that,
something like ``indirectly
supported.''


 Or what about cryonics?


 Cryonics is an archetypal example of an extremely important issue
(150,000 people die per day) that will have huge consequences in the
foreseeable future, but doesn't offer definite
unmistakable experimental evidence that we can get \textit{right now.}


 So do you say, ``I don't believe
in cryonics because it hasn't been experimentally
proven, and you shouldn't believe in things that
haven't been experimentally
proven''?


 Well, from a Bayesian perspective, that's
incorrect. Absence of evidence is evidence of absence only to the
degree that we could reasonably expect the evidence to appear. If
someone is trumpeting that snake oil cures cancer, you can reasonably
expect that, \textit{if the snake oil were actually curing cancer,}
some scientist would be performing a controlled study to verify
it---that, at the least, doctors would be reporting case studies of
amazing recoveries---and so the absence of this evidence is strong
evidence of absence. But ``gaps in the fossil
record'' are not strong evidence against evolution;
fossils form only rarely, and \textit{even if an intermediate species
did in fact exist}, you cannot expect with high probability that Nature
will obligingly fossilize it and that the fossil will be discovered.

{
 Reviving a cryonically frozen mammal is just not something
you'd expect to be able to do with modern technology,
\textit{even if future nanotechnologies could in fact perform a
successful revival}. That's how I see Bayes seeing it.}


 Oh, and as for the actual arguments \textit{for}
cryonics---I'm not going to go into those at the
moment. But if you followed the physics and anti-Zombie sequences, it
should now seem a lot more plausible that whatever preserves the
pattern of synapses preserves as much of
``you'' as is preserved from one
night's sleep to morning's waking.


 Now, to be fair, someone who says, ``I
don't believe in cryonics because it
hasn't been proven experimentally''
is \textit{misapplying} the rules of Science; this is not a case where
science actually gives the \textit{wrong answer.} In the absence of a
definite experimental test, the verdict of science here is
``Not proven.'' Anyone who
interprets that as a rejection is taking an extra step outside of
science, not a misstep within science.


 John McCarthy's Wikiquotes page has him saying,
``Your statements amount to saying that if AI is
possible, it should be easy. Why is
that?''\footnote{No longer on Wikiquotes, but included in
McCarthy's personal quotes page.\comment{1}} The Wikiquotes page
doesn't say what McCarthy was responding to, but I
could venture a guess.

{
 The general mistake probably arises because there \textit{are}
cases where the absence of scientific proof is strong
evidence---because an experiment would be readily performable, and so
failure to perform it is itself suspicious. (Though not as suspicious
as I used to think---with all the strangely varied anecdotal evidence
coming in from respected sources, why the \textit{hell}
isn't anyone testing Seth Roberts's
theory of appetite suppression?\footnote{Seth Roberts, ``What Makes Food Fattening?: A
Pavlovian Theory of Weight Control'' (Unpublished
manuscript, 2005),
\url{http://media.sethroberts.net/about/whatmakesfoodfattening.pdf}.\comment{2}})}


 Another confusion factor may be that if you test Pharmaceutical $X$
on 1,000 subjects and find that 56\% of the control group and 57\% of
the experimental group recover, some people will call that a verdict of
``Not proven.'' I would call it an
experimental verdict of ``Pharmaceutical $X$
doesn't work well, if at all.'' Just
because this verdict is theoretically retractable in the face of new
evidence doesn't make it ambiguous.


 In any case, right now you've got people
dismissing cryonics out of hand as ``not
scientific,'' like it was some kind of pharmaceutical
you could easily administer to 1,000 patients and see what happened.
``Call me when cryonicists actually revive
someone,'' they say; which, as Mike Li observes, is
like saying ``I refuse to get into this ambulance;
call me when it's actually at the
hospital.'' Maybe Martin Gardner warned them against
believing in strange things without experimental evidence. So they wait
for the definite unmistakable verdict of Science, while their family
and friends and 150,000 people per day are dying \textit{right now},
and might or might not be savable---


 {}---a calculated bet you could only make \textit{rationally.}


 The drive of Science is to obtain a mountain of evidence so huge
that not even fallible human scientists can misread it. But even
\textit{that} sometimes goes wrong, when people become confused about
which theory predicts what, or bake extremely-hard-to-test components
into an early version of their theory. And sometimes you just
can't get clear experimental evidence at all.


 Either way, you have to try to do the thing that Science
doesn't trust anyone to do---think rationally, and
figure out the answer \textit{before} you get clubbed over the head
with it.


 (Oh, and sometimes a \textit{disconfirming} experimental result
looks like: ``Your entire species has just been wiped
out! You are now scientifically required to relinquish your theory. If
you publicly recant, good for you! Remember, it takes a strong mind to
give up strongly held beliefs. Feel free to try another hypothesis next
time!'')

\myendsectiontext


\bigskip

\mysection{Science Isn't Strict Enough}


 Once upon a time, a younger Eliezer had a stupid theory.
Eliezer\textsubscript{18} was careful to follow the precepts of
Traditional Rationality that he had been taught; he made sure his
stupid theory had experimental consequences. Eliezer\textsubscript{18}
professed, in accordance with the virtues of a scientist he had been
taught, that he wished to test his stupid theory. 


 This was all that was required to be virtuous, according to what
Eliezer\textsubscript{18} had been taught was virtue in the way of
science.


 It was not even \textit{remotely} the order of effort that would
have been required to get it \textit{right}.


 The traditional ideals of Science too readily give out gold stars.
Negative experimental results are also knowledge, so everyone who plays
gets an award. So long as you can think of some kind of experiment that
tests your theory, and you \textit{do} the experiment, and you
\textit{accept} the results, you've played by the
rules; you're a good scientist.


 You didn't necessarily get it right, but
you're a nice science-abiding citizen.


 (I note at this point that I am speaking of Science, not the
social process of science as it actually works in practice, for two
reasons. First, I went astray in trying to follow the \textit{ideal} of
Science---it's not like I was shot down by a journal
editor with a grudge, and it's not like I was trying to
imitate the flaws of academia. Second, if I point out a problem with
the ideal as it is traditionally preached, real-world scientists are
not \textit{forced} to likewise go astray!)


 Science began as a rebellion against grand philosophical schemas
and armchair reasoning. So Science doesn't include a
rule as to what kinds of hypotheses you are and aren't
allowed to test; that is left up to the individual scientist. Trying to
guess that a priori would require some kind of grand philosophical
schema, and reasoning in advance of the evidence. As a social ideal,
Science doesn't judge you as a bad person for coming up
with heretical hypotheses; honest experiments, and acceptance of the
results, is virtue unto a scientist.


 As long as most scientists can manage to accept definite,
unmistakable, unambiguous experimental evidence, science can progress.
It may happen too slowly---it may take longer than it should---you may
have to wait for a generation of elders to die out---but eventually,
the ratchet of knowledge clicks forward another notch. Year by year,
decade by decade, the wheel turns \textit{forward}.
It's enough to support a civilization.


 So that's all that Science really asks of
you---the ability to accept reality when you're beat
over the head with it. It's not much, but
it's enough to sustain a scientific culture.


 Contrast this to the notion we have in probability theory, of an
exact quantitative rational judgment. If 1\% of women presenting for a
routine screening have breast cancer, and 80\% of women with breast
cancer get positive mammographies, and 10\% of women without breast
cancer get false positives, what is the probability that a routinely
screened woman with a positive mammography has breast cancer? It is
7.5\%. You cannot say, ``I believe she
doesn't have breast cancer, because the experiment
isn't definite enough.'' You cannot
say, ``I believe she has breast cancer, because it is
wise to be pessimistic and that is what the only experiment so far
seems to indicate.'' Seven point five percent is the
rational estimate given this evidence, not 7.4\% or 7.6\%. The laws of
probability are \textit{laws}.


 It is written in the Twelve Virtues (page \pageref{third_virtue}), of the third virtue,
lightness:

\begin{quote}
{
 If you regard evidence as a constraint and seek to free yourself,
you sell yourself into the chains of your whims. For you cannot make a
true map of a city by sitting in your bedroom with your eyes shut and
drawing lines upon paper according to impulse. You must walk through
the city and draw lines on paper that correspond to what you see. If,
seeing the city unclearly, you think that you can shift a line just a
little to the right, just a little to the left, according to your
caprice, this is just the same mistake.}
\end{quote}


 In Science, when it comes to deciding which hypotheses to test,
the morality of Science gives you personal freedom of what to believe,
so long as it isn't already ruled out by experiment,
and so long as you move to test your hypothesis. Science
wouldn't try to give an official verdict on the
\textit{best} hypothesis to test, in \textit{advance} of the
experiment. That's left up to the conscience of the
individual scientist.

{
 Where definite experimental evidence exists, Science tells you to
bow your stubborn neck and accept it. Otherwise, Science leaves it up
to you. Science gives you room to wander around \textit{within the
boundaries} of the experimental evidence, according to your whims.}


 And this is not easily reconciled with
Bayesianism's notion of an exactly right probability
estimate, one with no flex or room for whims, that exists both before
and after the experiment. Bayesianism doesn't match
well with the ancient and traditional reason for Science---the distrust
of grand schemas, the presumption that people aren't
rational enough to get things right without definite and unmistakable
experimental evidence. If we were all perfect Bayesians, we
wouldn't \textit{need} a social process of science.


 Nonetheless, around the time I realized my big mistake, I had also
been studying Kahneman and Tversky and Jaynes. I was learning a new
Way, stricter than Science. A Way that could criticize my folly, in a
way that Science never could. A Way that could have told me what
Science would never have said in \textit{advance}:
``You picked the wrong hypothesis to test,
dunderhead.''


 But the Way of Bayes is also \textit{much harder to use} than
Science. It puts a tremendous strain on your ability to hear tiny false
notes, where Science only demands that you notice an anvil dropped on
your head.


 In Science you can make a mistake or two, and another experiment
will come by and correct you; at worst you waste a couple of decades.


 But if you try to use Bayes even qualitatively---if you try to do
the thing that Science doesn't trust you to do, and
reason rationally in the absence of overwhelming evidence---it is like
math, in that a single error in a hundred steps can carry you anywhere.
It demands lightness, evenness, precision, perfectionism.


 There's a good reason why Science
doesn't trust scientists to do this sort of thing, and
asks for further experimental proof \textit{even after} someone claims
they've worked out the right answer based on hints and
logic.


 But if you would rather not waste ten years trying to prove the
\textit{wrong} theory, you'll need to essay the vastly
more difficult problem: listening to evidence that
doesn't shout in your ear.


 Even if you can't look up the priors for a problem
in the \textit{Handbook of Chemistry and Physics}{}---even if
there's no Authoritative Source telling you what the
priors are---that doesn't mean you get a free, personal
choice of making the priors whatever you want. It means you have a new
guessing problem that you must carry out to the best of your ability.


 If the mind, as a cognitive engine, could generate
\textit{correct} estimates by fiddling with priors according to whims,
you could know things without looking them, or even alter them without
touching them. But the mind is not magic. The rational probability
estimate has no room for any decision based on whim, even when it seems
that you don't know the priors.


 Similarly, if the Bayesian answer is difficult to compute, that
doesn't mean that Bayes is inapplicable; it means you
\textit{don't know} what the Bayesian answer is.
Bayesian probability theory is not a toolbox of statistical methods;
it's the \textit{law} that governs any tool you use,
whether or not you know it, whether or not you can calculate it.


 As for using Bayesian methods on huge, highly general hypothesis
spaces---like, ``Here's the data from
every physics experiment ever; now, what would be a good Theory of
Everything?''---if you knew how to do that \textit{in
practice}, you wouldn't be a statistician, you would be
an Artificial General Intelligence programmer. But that
doesn't mean that human beings, in modeling the
universe using human intelligence, are violating the laws of physics /
Bayesianism by generating correct guesses without evidence.


 Nick Tarleton comments:\footnote{\url{http://lesswrong.com/lw/qd/science_isnt_strict_enough/k35}}

\begin{quote}
{
 The problem is encouraging a \textit{private}, \textit{epistemic}
 standard as lax as the social one.}
\end{quote}


 which pinpoints the problem I was trying to indicate much better
than I did.

\myendsectiontext

\mysection{Do Scientists Already Know This Stuff?}


 poke alleges:\footnote{\url{http://lesswrong.com/lw/qd/science_isnt_strict_enough/k39}}

\begin{quote}
{
 Being able to create relevant hypotheses is an important skill and
one a scientist spends a great deal of his or her time developing. It
may not be part of the traditional \textit{description} of science but
that doesn't mean it's not included in
the actual social institution of science that produces actual real
science here in the real world; it's your description
and not science that is faulty.}
\end{quote}


 I know I've been calling my younger self
``stupid,'' but that is a figure of
speech; ``unskillfully wielding high
intelligence'' would be more precise.
Eliezer\textsubscript{18} was not in the habit of making obvious
mistakes---it's just that his
``obvious'' wasn't
my ``obvious.''


 No, I did not go through the traditional apprenticeship. But when
I look back, and see what Eliezer\textsubscript{18} did wrong, I see
\textit{plenty} of modern scientists making the same mistakes. I cannot
detect any sign that they were better warned than myself.


 Sir Roger Penrose---a world-class physicist---still thinks that
consciousness is caused by quantum gravity. I expect that no one ever
warned him against mysterious answers to mysterious questions---only
told him his hypotheses needed to be falsifiable and have empirical
consequences. Just like Eliezer\textsubscript{18}.


 ``Consciousness is caused by quantum
gravity'' has testable implications: It implies that
you should be able to look at neurons and discover a coherent quantum
superposition whose collapse contributes to information-processing, and
that you won't ever be able to reproduce a
neuron's input-output behavior using a computable
microanatomical simulation\,\ldots


 \ldots but even after you say ``Consciousness is
caused by quantum gravity,'' you
don't anticipate anything about how your brain thinks
``I think therefore I am!'' or the
mysterious redness of red, that you did not anticipate before, even
though you feel like you know a cause of it. This is a tremendous
danger sign, \textit{I now realize,} but it's not the
danger sign that \textit{I} was warned against, and I doubt that
Penrose was ever told of it by his thesis advisor. For that matter, I
doubt that Niels Bohr was ever warned against it when it came time to
formulate the Copenhagen Interpretation.


 As far as I can tell, the reason Eliezer\textsubscript{18} and Sir
Roger Penrose and Niels Bohr were not warned is that no standard
warning exists.


 I did not \textit{generalize} the concept of
``mysterious answers to mysterious
questions,'' in that many words, until I was writing
a Bayesian analysis of what distinguishes technical, nontechnical and
semitechnical scientific explanations. Now, the final \textit{output}
of that analysis can be phrased nontechnically in terms of four danger
signs:

\begin{itemize}
\item {
 First, the explanation acts as a curiosity-stopper rather than an
anticipation-controller.}

\item {
 Second, the hypothesis has no moving parts---the secret sauce is
not a specific complex mechanism, but a blankly solid substance or
force.}

\item {
 Third, those who proffer the explanation cherish their ignorance;
they speak proudly of how the phenomenon defeats ordinary science or is
unlike merely mundane phenomena.}

\item {
 Fourth, \textit{even after the answer is given, the phenomenon is
still a mystery} and possesses the same quality of wonderful
 inexplicability that it had at the start.}
\end{itemize}


 In principle, all this could have been said in the immediate
aftermath of vitalism. Just like elementary probability theory could
have been invented by Archimedes, or the ancient Greeks could have
theorized natural selection. But \textit{in fact} no one ever warned me
against any of these four dangers, in those terms---the closest being
the warning that hypotheses should have testable consequences. And I
didn't conceptualize the warning signs
\textit{explicitly} until I was trying to think of the whole affair in
terms of probability distributions---some degree of overkill was
required.


 I simply have no reason to believe that these warnings are passed
down in scientific apprenticeships---certainly not to a majority of
scientists. Among other things, it is advice for handling
\textit{situations of confusion and despair}, scientific
\textit{chaos.} When would the average scientist or average mentor have
an opportunity to use that kind of technique?


 We just got through discussing the single-world fiasco in physics.
Clearly, no one told them about the formal definition of
Occam's Razor, in whispered apprenticeship or
otherwise.


 There is a known effect where great scientists have multiple great
students. This may well be due to the mentors passing on skills that
they can't describe. But I don't think
that counts as part of \textit{standard} science. And if the great
mentors haven't been able to put their guidance into
words and publish it generally, that's not a good sign
for how well these things are understood.


 Reasoning in the absence of definite evidence without going
\textit{instantaneously completely wrong} is \textit{really really
hard.} When you're learning in school, you can miss one
point, and then be taught fifty other points that happen to be correct.
When you're reasoning out new knowledge in the absence
of crushingly overwhelming guidance, you can miss one point and wake up
in Outer Mongolia fifty steps later.


 I am pretty sure that scientists who switch off their brains and
relax with some comfortable nonsense as soon as they leave their own
specialties do not realize that minds are engines and that there is a
causal story behind every trustworthy belief. Nor, I suspect, were they
ever told that there is an exact rational probability given a state of
evidence, which has no room for whims; even if you
can't calculate the answer, and even if you
don't hear any authoritative command for what to
believe.


 I doubt that scientists who are asked to pontificate on the future
by the media, who sketch amazingly detailed pictures of Life in 2050,
were ever taught about the conjunction fallacy. Or how the
representativeness heuristic can make more detailed stories seem more
plausible, even as each extra detail drags down the probability. The
notion of every added detail needing its own support---of not being
able to \textit{make up} big detailed stories that sound just like the
detailed stories you were \textit{taught} in science or history
class---is \textit{absolutely vital} to precise thinking in the absence
of definite evidence. But how would a notion like that get into the
\textit{standard} scientific apprenticeship? The cognitive bias was
uncovered only a few decades ago, and not popularized until very
recently.


 Then there's affective death spirals around
notions like ``emergence'' or
``complexity'' which are
sufficiently vaguely defined that you can say lots of nice things about
them. There's whole academic subfields built around the
kind of mistakes that Eliezer\textsubscript{18} used to make! (Though I
never fell for the ``emergence''
thing.)


 I sometimes say that the goal of science is to amass such an
enormous mountain of evidence that not even scientists can ignore it:
and that this is the distinguishing feature of a scientist; a
non-scientist will ignore it anyway.


 If there can exist some amount of evidence so crushing that you
finally despair, stop making excuses and \textit{just give up}{}---drop
the old theory and never mention it again---then this is all it takes
to let the ratchet of Science turn forward over time, and raise up a
technological civilization. Contrast to religion.


 Books by Carl Sagan and Martin Gardner and the other veins of
Traditional Rationality are meant to accomplish this difference: to
transform someone from a non-scientist into a potential scientist, and
guard them from experimentally disproven madness.


 What further training does a professional scientist get? Some
frequentist stats classes on how to calculate statistical significance.
Training in standard techniques that will let them churn out papers
within a solidly established paradigm.


 If Science demanded more than this from the average scientist, I
don't think it would be possible for Science to get
done. We have problems enough from people who sneak in without the
drop-dead-basic qualifications.


 Nick Tarleton summarized\footnote{\url{http://lesswrong.com/lw/qd/science_isnt_strict_enough/k35}} the resulting problem very well---better
than I did, in fact: If you come up with a bizarre-seeming hypothesis
not yet ruled out by the evidence, and try to test it experimentally,
Science doesn't call you a bad person. Science
doesn't trust its elders to decide which hypotheses
``aren't worth
testing.'' But this is a carefully lax
\textit{social} standard, and if you try to translate it into a
standard of \textit{individual} epistemic rationality, it lets you
believe far too much. Dropping back into the analogy with
pragmatic-distrust-based-libertarianism, it's the
difference between ``Cigarettes
shouldn't be illegal'' and
``Go smoke a Marlboro.''


 Do you remember ever being \textit{warned against that mistake},
in so many words? Then why \textit{wouldn't} people
make exactly that error? How many people will \textit{spontaneously} go
an extra mile and be even stricter with themselves? Some, but not
many.


 Many scientists will believe all manner of ridiculous things
outside the laboratory, so long as they can convince themselves it
hasn't been definitely disproven, or so long as they
manage not to ask. Is there some standard lecture that grad students
get, of which people see this folly, and ask, ``Were
they absent from class that day?'' No, as far as I
can tell.


 Maybe if you're super lucky and get a famous
mentor, they'll tell you rare personal secrets like
``Ask yourself what are the important problems in
your field,\footnote{Richard Hamming, ``You and Your Research'', \url{http://www.cs.virginia.edu/~robins/YouAndYourResearch.pdf}} and then work on one of those, instead of falling into
something easy and trivial'' or ``Be
more careful than the journal editors demand; look for new ways to
guard your expectations from influencing the experiment, even if
it's not standard.''

{
 But I \textit{really don't think}
there's a huge secret standard scientific tradition of
precision-grade rational reasoning on sparse evidence. Half of all the
scientists out there still believe they believe in God! \textit{The
more difficult skills are not standard!}}

\myendsectiontext

\mysection{No Safe Defense, Not Even Science}


 I don't ask my friends about their childhoods---I
lack social curiosity---and so I don't know how much of
a trend this really is: 


 Of the people I know who are reaching upward as rationalists, who
volunteer information about their childhoods, there is a surprising
tendency to hear things like, ``My family joined a
cult and I had to break out,'' or,
``One of my parents was clinically insane and I had to
learn to filter out reality from their madness.''


 My own experience with growing up in an Orthodox Jewish family
seems tame by comparison\,\ldots but it accomplished the same outcome: It
broke my core emotional trust in the sanity of the people around me.


 Until this core emotional trust is broken, you
don't start growing as a rationalist. I have trouble
putting into words why this is so. Maybe any \textit{unusual} skills
you acquire---anything that makes you \textit{unusually}
rational---requires you to zig when other people zag. Maybe
that's just too scary, if the world still seems like a
sane place unto you.


 Or maybe you don't bother putting in the hard work
to be extra bonus sane, if normality doesn't scare the
hell out of you.


 I know that many aspiring rationalists seem to run into roadblocks
around things like cryonics or many-worlds. Not that they
don't see the logic; they see the logic and wonder,
``Can this really be true, when it seems so obvious
now, and yet none of the people around me believe
it?''


 Yes. Welcome to the Earth where ethanol is made from corn and
environmentalists oppose nuclear power. I'm sorry.


 (See also: Cultish Countercultishness, page \pageref{cultish_countercultishness}. If you end up in the frame
of mind of \textit{nervously seeking reassurance}, this is never a good
thing---even if it's because you're
about to believe something that sounds logical but could cause other
people to look at you funny.)


 People who've had their trust broken in the sanity
of the people around them seem to be able to evaluate strange ideas on
their merits, without feeling nervous about their strangeness. The glue
that binds them to their current place has dissolved, and they can walk
in some direction, hopefully forward.


 Lonely dissent, I called it. True dissent doesn't
feel like going to school wearing black; it feels like going to school
wearing a clown suit.


 That's what it takes to be the lone voice who
says, ``If you really think you know
who's going to win the election, why
aren't you picking up the free money on the Intrade
prediction market?''~while all the people around you
are thinking, ``It is good to be an individual and
form your own opinions, the shoe commercials told me
so.''


 Maybe in some other world, some alternate Everett branch with a
saner human population, things would be different\,\ldots but in this
world, I've never seen anyone begin to grow as a
rationalist until they make a deep emotional break with the wisdom of
their pack.


 Maybe in another world, things would be different. And maybe not.
I'm not sure that human beings realistically
\textit{can} trust and think at the same time.


 Once upon a time, there was something I trusted.


 Eliezer\textsubscript{18} trusted Science.


 Eliezer\textsubscript{18} dutifully acknowledged that the social
process of science was flawed. Eliezer\textsubscript{18} dutifully
acknowledged that academia was slow, and misallocated resources, and
played favorites, and mistreated its precious heretics.


 That's the convenient thing about acknowledging
flaws in \textit{people} who failed to live up to your ideal; you
don't have to question the ideal itself.


 But who could possibly be foolish enough to question,
``The experimental method shall decide which
hypothesis wins''?


 Part of what fooled Eliezer\textsubscript{18} was a general
problem he had, an aversion to ideas that resembled things idiots had
said. Eliezer\textsubscript{18} had seen plenty of people questioning
the ideals of Science Itself, and without exception they were all on
the Dark Side. People who questioned the ideal of Science were
invariably trying to sell you snake oil, or trying to safeguard their
favorite form of stupidity from criticism, or trying to disguise their
personal resignation as a Deeply Wise acceptance of futility.


 If there'd been any other ideal that was a few
centuries old, the young Eliezer would have looked at it and said,
``I wonder if this is really right, and whether
there's a way to do better.'' But not
the ideal of Science. Science was the master idea, the idea that let
you change ideas. You could question it, but you were meant to question
it and then accept it, not actually say, ``Wait! This
is wrong!''


 Thus, when once upon a time I came up with a stupid idea, I
thought I was behaving virtuously if I made sure there was a Novel
Prediction, and professed that I wished to test my idea experimentally.
I thought I had done everything I was obliged to do.


 So I thought I was \textit{safe}{}---not safe from any particular
external threat, but safe on some deeper level, like a child who trusts
their parent and has obeyed all the parent's rules.


 I'd long since been broken of trust in the sanity
of my family or my teachers at school. And the other children
weren't intelligent enough to compete with the
conversations I could have with books. But I trusted the books, you
see. I trusted that if I did what Richard Feynman told me to do, I
would be safe. I never thought those words aloud, but it was how I
felt.


 When Eliezer\textsubscript{23} realized exactly \textit{how}
stupid the stupid theory had been---and that Traditional Rationality
had not saved him from it---and that Science would have been perfectly
okay with his wasting ten years testing the stupid idea, so long as
afterward he admitted it was wrong\,\ldots


 \ldots well, I'm not going to say it was a huge
emotional convulsion. I don't really go in for that
kind of drama. It simply became obvious that I'd been
stupid.


 That's the trust I'm trying to
break in you. You are not safe. Ever.


 Not even Science can save you. The ideals of Science were born
centuries ago, in a time when no one knew anything about probability
theory or cognitive biases. Science demands \textit{too little} of you,
it blesses your good intentions too easily, it is not strict
\textit{enough}, it only makes those injunctions that an average
scientist can follow, it accepts slowness as a fact of life.


 So don't think that if you only follow the rules
of Science, that makes your reasoning defensible.


 There is no known procedure you can follow that makes your
reasoning defensible.


 There is no known set of injunctions which you can satisfy, and
know that you will not have been a fool.


 There is no known morality-of-reasoning that you can do your best
to obey, and know that you are thereby shielded from criticism.


 No, not even if you turn to Bayescraft. It's much
harder to use and you'll never be sure that
you're doing it right.


 The discipline of Bayescraft is younger by far than the discipline
of Science. You will find no textbooks, no elderly mentors, no
histories written of success and failure, no hard-and-fast rules laid
down. You will have to study cognitive biases, and probability theory,
and evolutionary psychology, and social psychology, and other cognitive
sciences, and Artificial Intelligence---and think through for yourself
how to apply all this knowledge to the case of correcting yourself,
since that isn't yet in the textbooks.


 You don't know what your own mind is really doing.
They find a new cognitive bias every week and you're
never sure if you've corrected for it, or
overcorrected.


 The formal math is impossible to apply. It doesn't
break down as easily as John Q. Unbeliever thinks, but
you're never really sure where the foundations come
from. You don't know why the universe is simple enough
to understand, or why any prior works for it. You don't
know what your own priors \textit{are}, let alone if
they're any good.


 One of the problems with Science is that it's too
vague to really scare you. ``Ideas should be tested by
experiment.'' How can you go wrong with that?


 On the other hand, if you have some math of probability theory
laid out in front of you, and worse, \textit{you know you
can't actually use it,} then it becomes clear that you
are trying to do something difficult, and that you might well be doing
it \textit{wrong.}


 So you cannot trust.


 And all this that I have said \textit{will not be sufficient} to
break your trust. That won't happen until you get into
your first real disaster from following The Rules, not from breaking
them.


 Eliezer\textsubscript{18} already had the notion that you were
allowed to question Science. Why, of course the scientific method was
not itself immune to questioning! For are we not all good rationalists?
Are we not allowed to question everything?


 It was the notion that you could \textit{actually in real life}
follow Science and fail miserably that Eliezer\textsubscript{18}
didn't really, emotionally believe was possible.


 Oh, of course he said it was possible. Eliezer\textsubscript{18}
dutifully acknowledged the possibility of error, saying,
``I could be wrong, but\,\ldots''


 But he didn't think failure could happen in, you
know, real life. You were supposed to look for flaws, not actually find
them.


 And this emotional difference is a terribly difficult thing to
accomplish in words, and I fear there's no way I can
really warn you.


 Your trust will not break, until you apply all that you have
learned here and from other books, and take it as far as you can go,
and find that this too fails you---that you have still been a fool, and
no one warned you against it---that all the most important parts were
left out of the guidance you received---that some of the most precious
ideals you followed steered you in the wrong direction---


 {}---and if you still have something to protect, so that you
\textit{must} keep going, and \textit{cannot} resign and wisely
acknowledge the limitations of rationality---


 \textit{{}---}then you will be ready to start your journey as a
rationalist. To take sole responsibility, to live without any
trustworthy defenses, and to forge a higher Art than the one you were
once taught.


 No one begins to truly search for the Way until their parents have
failed them, their gods are dead, and their tools have shattered in
their hand.


 Post Scriptum: On reviewing a draft of this essay, I discovered a
fairly inexcusable flaw in reasoning, which actually affects one of the
conclusions drawn. I am leaving it in. Just in case you thought that
taking my advice made you safe; or that you were supposed to look for
flaws, but not find any.


 And of course, if you look too hard for a flaw, and find a flaw
that is not a real flaw, and cling to it to reassure yourself of how
critical you are, you will only be worse off than before\,\ldots


 It is living with uncertainty---knowing on a gut level that there
are flaws, they are serious and you have not found them---that is the
difficult thing.

\myendsectiontext

\mysection{Changing the Definition of Science}

{
 \textit{New Scientist} on changing the definition of science,
ungated here:\footnote{Robert Matthews, ``Do We Need to Change the
Definition of Science?,'' \textit{New Scientist} (May
2008).\comment{1}}}

\begin{quotation}

 Others believe such criticism is based on a misunderstanding.
``Some people say that the multiverse concept
isn't falsifiable because it's
unobservable---but that's a
fallacy,'' says cosmologist Max Tegmark of the
Massachusetts Institute of Technology. He argues that the multiverse is
a natural consequence of such eminently falsifiable theories as quantum
theory and General Relativity. As such, the multiverse theory stands or
fails according to how well these other theories stand up to
observational tests.


 [ \ldots ]


 So if the simplicity of falsification is misleading, what should
scientists be doing instead? Howson believes it is time to ditch
Popper's notion of capturing the scientific process
using deductive logic. Instead, the focus should be on reflecting what
scientists actually do: gathering the weight of evidence for rival
theories and assessing their relative plausibility.

{
 Howson is a leading advocate for an alternative view of science
based not on simplistic true/false logic, but on the far more subtle
concept of degrees of belief. At its heart is a fundamental connection
between the subjective concept of belief and the cold, hard mathematics
of probability.}
\end{quotation}


 I'm a good deal less of a lonely iconoclast than I
seem. Maybe it's just the way I talk.


 The points of departure between myself and \textit{mainstream}
let's-reformulate-Science-as-Bayesianism is that:


 (1) I'm not in academia and can censor myself a
\textit{lot} less when it comes to saying
``extreme'' things that others might
well already be thinking.

{
 (2) I think that \textbf{just teaching probability theory
won't be nearly enough}. We'll have to
synthesize lessons from multiple sciences, like cognitive biases and
social psychology, forming a new coherent Art of Bayescraft, before we
are actually going to do any better \textit{in the real world} than
modern science. Science tolerates errors; Bayescraft does not. Nobel
laureate Robert Aumann, who first proved that Bayesians with the same
priors cannot agree to disagree, is a believing Orthodox Jew.
Probability theory alone won't do the trick, when it
comes to really teaching scientists. \textit{This is my primary point
of departure, and it is not something I've seen
suggested elsewhere.}}


 (3) I think it \textit{is} possible to do better in the real
world. In the extreme case, a Bayesian superintelligence could use
\textit{enormously} less sensory information than a human scientist to
come to correct conclusions. First time you ever see an apple fall
down, you observe the position goes as the square of time, invent
calculus, generalize Newton's Laws\,\ldots and see that
Newton's Laws involve action at a distance, look for
alternative explanations with increased locality, invent relativistic
covariance around a hypothetical speed limit, and consider that General
Relativity might be worth testing.


 Humans do not process evidence \textit{efficiently}{}---our minds
are so noisy that it requires orders of magnitude more \textit{extra}
evidence to set us back on track after we derail. Our collective,
academia, is even slower.

\myendsectiontext


\bigskip

\mysection{Faster Than Science}


 I sometimes say that the method of science is to amass such an
enormous mountain of evidence that even scientists cannot ignore it;
and that this is the distinguishing characteristic of a scientist. (A
non-scientist will ignore it anyway.) 

{
 Max Planck was even less optimistic:\footnote{Max Planck, \textit{Scientific Autobiography and Other Papers}
(New York: Philosophical Library, 1949).\comment{1}}}

\begin{quote}
{
 A new scientific truth does not triumph by convincing its
opponents and making them see the light, but rather because its
opponents eventually die, and a new generation grows up that is
familiar with it.}
\end{quote}


 I am much tickled by this notion, because it implies that the
power of science to distinguish truth from falsehood ultimately rests
on the good taste of grad students.


 The \textit{gradual} increase in acceptance of many-worlds in
academic physics suggests that there are physicists who will only
accept a new idea given some \textit{combination} of epistemic
justification, and a sufficiently large academic pack in whose company
they can be comfortable. As more physicists accept, the pack grows
larger, and hence more people go over their individual thresholds for
conversion---with the epistemic justification remaining essentially the
same.


 But Science still gets there \textit{eventually}, and this is
sufficient for the ratchet of Science to move forward, and raise up a
technological civilization.


 Scientists can be moved by groundless prejudices, by undermined
intuitions, by raw herd behavior---the panoply of human flaws. Each
time a scientist shifts belief for epistemically unjustifiable reasons,
it requires more evidence, or new arguments, to cancel out the noise.


 The ``collapse of the
wavefunction'' has no experimental justification, but
it appeals to the (undermined) intuition of a single world. Then it may
take an extra argument---say, that collapse violates Special
Relativity---to begin the slow academic disintegration of an idea that
should never have been assigned non-negligible probability in the first
place.


 From a Bayesian perspective, human academic science as a whole is
a highly inefficient processor of evidence. Each time an unjustifiable
argument shifts belief, you need an extra justifiable argument to shift
it back. The social process of science leans on extra evidence to
overcome cognitive noise.


 A more charitable way of putting it is that scientists will adopt
positions that are theoretically \textit{insufficiently extreme},
compared to the ideal positions that scientists \textit{would} adopt,
if they were Bayesian AIs and could trust themselves to reason
clearly.


 But don't be too charitable. The noise we are
talking about is not all innocent mistakes. In many fields, debates
drag on for decades after they should have been settled. And
\textit{not} because the scientists on both sides refuse to trust
themselves and agree they should look for additional evidence. But
because one side keeps throwing up more and more ridiculous objections,
and demanding more and more evidence, from an entrenched position of
academic power, long after it becomes clear from which quarter the
winds of evidence are blowing. (I'm thinking here about
the debates surrounding the invention of evolutionary psychology, not
about many-worlds.)


 Is it possible for individual humans or groups to process evidence
more efficiently---reach correct conclusions faster---than human
academic science as a whole?


 ``Ideas are tested by experiment. That is the
core of science.'' And this must be true, because if
you can't trust Zombie Feynman, who \textit{can} you
trust?


 Yet where do the \textit{ideas} come from?


 You may be tempted to reply, ``They come from
scientists. Got any other questions?'' In Science
you're not supposed to care \textit{where} the
hypotheses come from---just whether they pass or fail experimentally.


 Okay, but if you remove \textit{all} new ideas, the scientific
process as a whole stops working because it has no alternative
hypotheses to test. So inventing new ideas is not a dispensable part of
the process.

{
 Now put your Bayesian goggles back on. As described in
Einstein's Arrogance, there are queries that are not
binary---where the answer is not
``Yes'' or
``No,'' but drawn from a larger
space of structures, e.g., the space of equations. In such cases it
takes far more Bayesian evidence to \textit{promote a hypothesis to
your attention} than to \textit{confirm the hypothesis.}}


 If you're working in the space of all equations
that can be specified in 32 bits or less, you're
working in a space of 4 billion equations. It takes far more Bayesian
evidence to raise one of those hypotheses to the 10\% probability
level, than it requires to \textit{further} raise the hypothesis from
10\% to 90\% probability.


 When the idea-space is large, coming up with ideas worthy of
testing involves much more work---in the Bayesian-thermodynamic sense
of ``work''---than \textit{merely}
obtaining an experimental result with $p < 0.0001$ for the new
hypothesis over the old hypothesis.


 If this doesn't seem obvious-at-a-glance, pause
here and review Einstein's Arrogance, page \pageref{einsteins_arrogance}.


 The scientific process has always relied on scientists to come up
with hypotheses to test, via some process not further specified by
Science. Suppose you came up with some way of generating hypotheses
that was completely crazy---say, pumping a robot-controlled Ouija board
with the digits of pi---and the resulting suggestions kept on getting
verified experimentally. The pure ideal essence of Science
wouldn't skip a beat. The pure ideal essence of Bayes
would burst into flames and die.


 (Compared to Science, Bayes is falsified by more of the possible
outcomes.)


 This doesn't mean that the process of deciding
which ideas to test is \textit{unimportant} to Science. It means that
Science doesn't \textit{specify} it.


 \textit{In practice}, the robot-controlled Ouija board
doesn't work. In practice, there are some scientific
queries with a large enough answer space that, picking models at random
to test, it would take zillions of years to hit on a model that made
good predictions---like getting monkeys to type Shakespeare.


 At the \textit{frontier} of science---the boundary between
ignorance and knowledge, where science \textit{advances}{}---the
process relies on at least some individual scientists (or working
groups) seeing things that are not yet confirmed by Science.
That's how they know which hypotheses to test, in
advance of the test itself.


 If you take your Bayesian goggles off, you can say,
``Well, they don't have to know, they
just have to guess.'' If you put your Bayesian
goggles back on, you realize that
``guessing'' with 10\% probability
requires nearly as much epistemic work to have been successfully
performed, behind the scenes, as
``guessing'' with 80\%
probability---at least for large answer spaces.


 The scientist may not \textit{know} they have done this epistemic
work successfully, in advance of the experiment; but they must, in
fact, have done it successfully! Otherwise they will not even
\textit{think} of the correct hypothesis. In large answer spaces,
anyway.


 So the scientist makes the novel prediction, performs the
experiment, publishes the result, and \textit{now} Science knows it
too. It is now part of the publicly accessible knowledge of humankind,
that anyone can verify for themselves.


 In between was an interval where the scientist rationally knew
something that the public social process of science
hadn't yet confirmed. And this is not a trivial
interval, though it may be short; for it is where the \textit{frontier}
of science lies, the advancing border.


 All of this is more true for non-routine science than for routine
science, because it is a notion of large answer spaces where the answer
is not ``Yes'' or
``No'' or drawn from a small set of
obvious alternatives. It is much easier to train people to test ideas
than to have good ideas to test.

\myendsectiontext


\bigskip

\mysection{Einstein's Speed}


 In the previous essay I argued that the Powers Beyond Science are
actually a standard and necessary part of the social process of
science. In particular, scientists must call upon their powers of
individual rationality to decide what ideas to test, in advance of the
sort of definite experiments that Science demands to bless an idea as
confirmed. The ideal of Science does not try to \textit{specify} this
process---we don't suppose that any public authority
knows how individual scientists should think---but this
doesn't mean the process is \textit{unimportant.} 


 A readily understandable, non-disturbing example:


 A scientist identifies a strong mathematical regularity in the
cumulative data of previous experiments. But the corresponding
hypothesis has not yet made and \textit{confirmed} a novel experimental
prediction---which their academic field demands; this is one of those
fields where you can perform controlled experiments without too much
trouble. Thus the individual scientist has readily understandable,
rational reasons to believe (though not with probability 1) something
not yet blessed by Science as public knowledge of humankind.


 Noticing a regularity in a huge mass of experimental data
doesn't seem all that \textit{unscientific.}
You're still data-driven, right?


 But that's because I deliberately chose a
non-disturbing example. When Einstein invented General Relativity, he
had almost no experimental data to go on, except the precession of
Mercury's perihelion. And (as far as I know) Einstein
did not \textit{use} that data, except at the end.


 Einstein generated the theory of Special Relativity using
Mach's Principle,\footnote{\url{http://lesswrong.com/lw/qm/machs_principle_antiepiphenomenal_physics/}} which is the
physicist's version of the Generalized Anti-Zombie
Principle. You begin by saying, ``It
doesn't seem reasonable to me that you could tell, in
an enclosed room, how fast you and the room were going. Since this
number shouldn't ought to be observable, it
shouldn't ought to exist in any meaningful
sense.'' You then observe that
Maxwell's Equations invoke a seemingly absolute speed
of propagation, $c$, commonly referred to as ``the speed
of light'' (though the quantum equations show it is
the propagation speed of all fundamental waves). So you reformulate
your physics in such fashion that the absolute speed of a single object
no longer meaningfully exists, and only relative speeds exist. I am
skipping over quite a bit here, obviously, but there are many excellent
introductions to relativity---it is not like the horrible situation in
quantum physics.


 Einstein, having successfully done away with the notion of your
absolute speed inside an enclosed room, then set out to do away with
the notion of your absolute \textit{acceleration} inside an enclosed
room. It seemed to Einstein that there shouldn't ought
to be a way to differentiate, in an enclosed room, between the room
accelerating northward while the rest of the universe stayed still,
versus the rest of the universe accelerating southward while the room
stayed still. If the rest of the universe accelerated, it would produce
gravitational waves that would accelerate you. Moving matter, then,
should produce gravitational waves.


 And because inertial mass and gravitational mass were always
exactly equivalent---unlike the situation in electromagnetics, where an
electron and a muon can have different masses but the same electrical
charge---gravity should reveal itself as a kind of inertia. The Earth
should go around the Sun in some equivalent of a
``straight line.'' This requires
spacetime in the vicinity of the Sun to be curved, so that if you drew
a graph of the Earth's orbit around the Sun, the line
on the 4D graph paper would be locally flat. Then inertial and
gravitational mass would be \textit{necessarily} equivalent, not just
\textit{coincidentally} equivalent.


 (If that did not make any sense to you, there are good
introductions to General Relativity available as well.)


 And of course the new theory had to obey Special Relativity, and
conserve energy, and conserve momentum, et cetera.


 Einstein spent several years grasping the necessary mathematics to
describe curved metrics of spacetime. Then he wrote down the simplest
theory that had the properties Einstein thought it ought to
have---including properties no one had ever observed, but that Einstein
thought fit in well with the character of other physical laws. Then
Einstein cranked a bit, and got the previously unexplained precession
of Mercury right back out.


 How impressive was this?


 Well, let's put it this way. In some small
fraction of alternate Earths proceeding from 1800---perhaps even a
sizeable fraction---it would seem plausible that relativistic physics
could have proceeded in a similar fashion to our own great fiasco with
quantum physics.


 We can imagine that Lorentz's original
``interpretation'' of the Lorentz
contraction, as a physical distortion caused by movement with respect
to the ether, prevailed. We can imagine that various corrective
factors, themselves unexplained, were added on to Newtonian
gravitational mechanics to explain the precession of
Mercury---attributed, perhaps, to strange distortions of the ether, as
in the Lorentz contraction. Through the decades, further corrective
factors would be added on to account for other astronomical
observations. Sufficiently precise atomic clocks, in airplanes, would
reveal that time ran a little faster than expected at higher altitudes
(time runs slower in more intense gravitational fields, but they
wouldn't know that) and more corrective
``ethereal factors'' would be
invented.


 Until, \textit{finally}, the many different empirically determined
``corrective factors'' were unified
into the simple equations of General Relativity.


 And the people in that alternate Earth would say,
``The final equation was simple, but there was no way
you could \textit{possibly} know to arrive at that answer from
\textit{just} the perihelion precession of Mercury. It takes many, many
\textit{additional} experiments. You must have measured time running
slower in a stronger gravitational field; you must have measured light
bending around stars. Only \textit{then} can you imagine our unified
theory of ethereal gravitation. No, not even a perfect Bayesian
superintelligence could know it!---for there would be many ad-hoc
theories consistent with the perihelion precession
alone.''


 In our world, Einstein didn't even \textit{use}
the perihelion precession of Mercury, except for verification of his
answer produced by other means. Einstein sat down in his armchair, and
thought about how \textit{he} would have designed the universe, to look
the way he thought a universe should look---for example, that you
shouldn't ought to be able to distinguish yourself
accelerating in one direction, from the rest of the universe
accelerating in the other direction.


 And Einstein executed the whole long (multi-year!) chain of
armchair reasoning, without making any mistakes that would have
required further experimental evidence to pull him back on track.


 Even Jeffreyssai would be grudgingly impressed. Though he would
still ding Einstein a point or two for the cosmological constant. (I
don't ding Einstein for the cosmological constant
because it later turned out to be real. I try to avoid criticizing
people on occasions where they are right.)


 What would be the probability-theoretic perspective on
Einstein's feat?


 Rather than observe the planets, and infer what laws might cover
their gravitation, Einstein was observing the other laws of physics,
and inferring what new law might follow the same pattern. Einstein
wasn't finding an equation that covered the motion of
gravitational bodies. Einstein was finding a character-of-physical-law
that covered previously observed equations, and that he could crank to
predict the next equation that would be observed.


 Nobody knows\footnote{\url{http://lesswrong.com/lw/kj/no_one_knows_what_science_doesnt_know/}} where the laws of physics come from, but
Einstein's success with General Relativity shows that
their common character is strong enough to predict the correct form of
one law from having observed other laws, without necessarily having to
observe the precise effects of the law.


 (In a general sense, of course, Einstein did know by observation
that things fell down; but he did not get General Relativity by
backward inference from Mercury's exact perihelion
advance.)


 So, from a Bayesian perspective, what Einstein did is still
induction, and still covered by the notion of a simple prior (Occam
prior) that gets updated by new evidence. It's just the
prior was over the \textit{possible characters of physical law}, and
observing other physical laws let Einstein update his model of
\textit{the character of physical law}, which he then used to predict a
particular law of gravitation.


 If you didn't have the concept of a
``character of physical law,'' what
Einstein did would look like magic---plucking the correct model of
gravitation out of the space of all possible equations, with vastly
insufficient evidence. But Einstein, by looking at \textit{other} laws,
cut down the space of possibilities for the \textit{next} law. He
learned the alphabet in which physics was written, constraints to
govern his answer. Not magic, but reasoning on a higher level, across a
wider domain, than what a naive reasoner might conceive to be the
``model space'' of only this one
law.


 So from a probability-theoretic standpoint, Einstein was still
data-driven---he just used the data he \textit{already had}, more
\textit{effectively}. Compared to any alternate Earths that demanded
huge quantities of \textit{additional} data from astronomical
observations and clocks on airplanes to \textit{hit them over the head}
with General Relativity.


 There are numerous lessons we can derive from this.


 I use Einstein as my example, even though it's
cliché, because Einstein was also unusual in that he \textit{openly
admitted} to knowing things that Science hadn't
confirmed. Asked what he would have done if Eddington's
solar eclipse observation had failed to confirm General Relativity,
Einstein replied: ``Then I would feel sorry for the
good Lord. The theory is correct.''


 According to prevailing notions of Science, this is
arrogance---you must accept the verdict of experiment, and not cling to
your personal ideas.


 But as I concluded in Einstein's Arrogance,
Einstein doesn't come off nearly as badly from a
Bayesian perspective. From a Bayesian perspective, in order to suggest
General Relativity at all, in order to even \textit{think} about what
turned out to be the correct answer, Einstein must have had enough
evidence to identify the true answer in the theory-space. It would take
only a little \textit{more} evidence to justify (in a Bayesian sense)
being nearly certain of the theory. And it was unlikely that Einstein
only had \textit{exactly} enough evidence to bring the hypothesis all
the way up to his attention.


 Any accusation of arrogance would have to center around the
question, ``But Einstein, how did you know you had
reasoned correctly?''---to which I can only say: Do
not criticize people when they turn out to be right! Wait for an
occasion where they are wrong! Otherwise you are missing the chance to
see when someone is thinking smarter than you---for you criticize them
whenever they depart from a preferred ritual of cognition.


 Or consider the famous exchange between Einstein and Niels Bohr on
quantum theory---at a time when the then-current, single-world quantum
theory seemed to be immensely well-confirmed experimentally; a time
when, by the standards of Science, the current (deranged) quantum
theory had simply won.

\begin{quotation}

 \textsc{Einstein}: ``God does not play dice with the
universe.''

{
 \textsc{Bohr}: ``Einstein, don't tell God
 what to do.''}
\end{quotation}


 You've got to admire someone who can get into an
argument with God and win.


 If you take off your Bayesian goggles, and look at Einstein
\textit{in terms of what he actually did all day}, then the guy was
sitting around studying math and thinking about how \textit{he} would
design the universe, rather than running out and looking at things to
gather more data. What Einstein did, \textit{successfully}, is exactly
the sort of high-minded feat of sheer intellect that Aristotle
\textit{thought} he could do, but \textit{couldn't.}
Not from a probability-theoretic stance, mind you, but from the
viewpoint of what they did all day long.


 Science does not trust scientists to do this, which is why General
Relativity was not blessed as the public knowledge of humanity until
after it had made and verified a novel experimental prediction---having
to do with the bending of light in a solar eclipse. (It later turned
out that particular measurement was not precise enough to verify
reliably, and had favored General Relativity essentially by luck.)


 However, just because Science does not \textit{trust} scientists
to do something, does not mean it is impossible.


 But a word of caution here: The reason why history books sometimes
record the names of scientists who thought great high-minded thoughts
is not that high-minded thinking is \textit{easier}, or \textit{more
reliable}. It is a priority bias: Some scientist who
\textit{successfully} reasoned from the \textit{smallest amount of
experimental evidence} got to the truth \textit{first}. This cannot be
a matter of pure random chance: The theory space is too large, and
Einstein won several times in a row. But out of all the scientists who
\textit{tried} to unravel a puzzle, or who would have
\textit{eventually} succeeded given enough evidence, history passes
down to us the names of the scientists who \textit{successfully} got
there \textit{first}. Bear that in mind, when you are trying to derive
lessons about how to reason prudently.

{
 In everyday life, you want every scrap of evidence you can get.
\textit{Do not rely on being able to successfully think high-minded
thoughts unless experimentation is so costly or dangerous that you have
no other choice.}}


 But sometimes experiments are costly, and sometimes we prefer to
get there first\,\ldots so you might consider trying to train yourself in
reasoning on scanty evidence, \textit{preferably in cases where you
will later find out if you were right or wrong.} Trying to beat
low-capitalization prediction markets might make for good training in
this?---though that is only speculation.


 As of now, at least, reasoning based on scanty evidence is
something that modern-day science cannot reliably train modern-day
scientists to do \textit{at all}. Which may perhaps have something to
do with, oh, I don't know, not even trying?

{
 Actually, I take that back. The most sane thinking I have seen in
any scientific field comes from the field of evolutionary psychology,
possibly because they understand self-deception, but also perhaps
because they often (1) have to reason from scanty evidence and (2) do
later find out if they were right or wrong. I recommend to all aspiring
rationalists that they study evolutionary psychology simply to get a
glimpse of what careful reasoning looks like. See particularly Tooby
and Cosmides's ``The Psychological
Foundations of Culture.''\footnote{Tooby and Cosmides, ``The Psychological
Foundations of Culture.''\comment{1}}}


 As for the possibility that \textit{only} Einstein could do what
Einstein did\,\ldots that it took superpowers beyond the reach of
ordinary mortals\,\ldots here we run into some biases that would take a
separate essay to analyze. Let me put it this way: It is possible,
perhaps, that only a genius could have done Einstein's
actual historical work. But \textit{potential} geniuses, in terms of
raw intelligence, are probably far more common than historical
superachievers. To put a random number on it, I doubt that anything
more than one-in-a-million g-factor is required to be a potential
world-class genius, implying at least six thousand potential Einsteins
running around today. And as for everyone else, I see no reason why
they should not aspire to use efficiently the evidence that they have.


 But my final moral is that the frontier where the individual
scientist rationally knows something that Science has not yet confirmed
is not always some innocently data-driven matter of spotting a strong
regularity in a mountain of experiments. Sometimes the scientist gets
there by thinking great high-minded thoughts that Science does not
trust you to think.


 I will not say, ``Don't try this
at home.'' I will say,
``Don't think this is
easy.'' We are not discussing, here, the victory of
casual opinions over professional scientists. We are discussing the
sometime historical victories of one kind of professional effort over
another. Never forget all the famous historical cases where attempted
armchair reasoning lost.

\myendsectiontext


\bigskip

\mysection{That Alien Message}


 Imagine a world much like this one, in which, thanks to
gene-selection technologies, the average IQ is 140 (on our scale).
Potential Einsteins are one-in-a-thousand, not one-in-a-million; and
they grow up in a school system suited, if not to them personally, then
at least to bright kids. Calculus is routinely taught in sixth grade.
Albert Einstein, himself, still lived and still made approximately the
same discoveries, but his work no longer seems \textit{exceptional.}
Several modern top-flight physicists have made equivalent
breakthroughs, and are still around to talk. 


 (No, this is not the world Brennan lives in.)


 One day, the stars in the night sky begin to change.


 Some grow brighter. Some grow dimmer. Most remain the same.
Astronomical telescopes capture it all, moment by moment. The stars
that change change their luminosity one at a time, distinctly so; the
luminosity change occurs over the course of a microsecond, but a whole
second separates each change.


 It is clear, from the first instant anyone realizes that more than
one star is changing, that the process seems to center around Earth
particularly. The arrival of the light from the events, at many stars
scattered around the galaxy, has been precisely timed to Earth in its
orbit. Soon, confirmation comes in from high-orbiting telescopes (they
have those) that the astronomical miracles do \textit{not} seem as
synchronized from outside Earth. Only Earth's
telescopes see one star changing every second (1,005 milliseconds,
actually).


 Almost the entire combined brainpower of Earth turns to analysis.


 It quickly becomes clear that the stars that jump in luminosity
all jump by a factor of exactly 256; those that diminish in luminosity
diminish by a factor of exactly 256. There is no apparent pattern in
the stellar coordinates. This leaves, simply, a pattern of
\textsc{bright}-dim-\textsc{bright}-\textsc{bright}\,\ldots


 ``A binary message!'' is
everyone's first thought.


 But in this world there are careful thinkers, of great prestige as
well, and they are not so sure. ``There are easier
ways to send a message,'' they post to their blogs,
``if you can make stars flicker, and if you want to
communicate. \textit{Something} is happening. It appears, \textit{prima
facie}, to focus on Earth in particular. To call it a
`message' presumes a great deal more
about the cause behind it. There might be some kind of evolutionary
process among, um, things that can make stars flicker, that ends up
sensitive to intelligence somehow\,\ldots Yeah, there's
probably something like `intelligence'
behind it, but try to appreciate how wide a range of possibilities that
really implies. We don't know this is a message, or
that it was sent from the same kind of motivations that might move us.
I mean, \textit{we} would just signal using a big flashlight, we
wouldn't mess up a whole galaxy.''


 By this time, someone has started to collate the astronomical data
and post it to the Internet. Early suggestions that the data might be
harmful have been\,\ldots not ignored, but not obeyed, either. If
anything this powerful wants to hurt you, you're pretty
much dead (people reason).


 Multiple research groups are looking for patterns in the stellar
coordinates---or fractional arrival times of the changes, relative to
the center of the Earth---or exact durations of the luminosity
shift---or any tiny variance in the magnitude shift---or any other fact
that might be known about the stars before they changed. But
\textit{most} people are turning their attention to the pattern of
\textsc{bright}s and dims.


 It becomes clear almost instantly that the pattern sent is highly
redundant. Of the first 16 bits, 12 are \textsc{bright}s and 4 are dims. The
first 32 bits received align with the second 32 bits received, with
only 7 out of 32 bits different, and then the next 32 bits received
have only 9 out of 32 bits different from the second (and 4 of them are
bits that changed before). From the first 96 bits, then, it becomes
clear that this pattern is not an optimal, compressed encoding of
anything. The obvious thought is that the sequence is meant to convey
instructions for decoding a compressed message to follow\,\ldots


 ``But,'' say the careful
thinkers, ``anyone who cared about
\textit{efficiency}, with enough power to mess with stars, could maybe
have just signaled us with a big flashlight, and sent us a
DVD?''


 There also seems to be structure within the 32-bit groups; some
8-bit subgroups occur with higher frequency than others, and this
structure only appears along the natural alignments (32 = 8 + 8 + 8 +
8).


 After the first five hours at one bit per second, an additional
redundancy becomes clear: The message has started approximately
repeating itself at the 16,385th bit.


 Breaking up the message into groups of 32, there are 7 bits of
difference between the 1st group and the 2nd group, and 6 bits of
difference between the 1st group and the 513th group.


 ``A 2D picture!'' everyone
thinks. ``And the four 8-bit groups are colors;
they're tetrachromats!''


 But it soon becomes clear that there is a horizontal/vertical
asymmetry: Fewer bits change, on average, between ($N$,$N + 1$) versus ($N$,$N
+ 512$). Which you wouldn't expect if the message was a
2D picture projected onto a symmetrical grid. Then you would expect the
average bitwise distance between two 32-bit groups to go as the 2-norm
of the grid separation: $\sqrt{(h^2 + v^2)}$.


 There also forms a general consensus that a certain binary
encoding from 8-groups onto integers between -64 and 191---not the
binary encoding that seems obvious to us, but still highly
regular---minimizes the average distance between neighboring cells.
This continues to be borne out by incoming bits.


 The statisticians and cryptographers and physicists and computer
scientists go to work. There is structure here; it needs only to be
unraveled. The masters of causality search for conditional
independence, screening-off and Markov neighborhoods, among bits and
groups of bits. The so-called
``color'' appears to play a role in
neighborhoods and screening, so it's not just the
equivalent of surface reflectivity. People search for simple equations,
simple cellular automata, simple decision trees, that can predict or
compress the message. Physicists invent entire new theories of physics
that might describe universes projected onto the grid---for it seems
quite plausible that a message such as this is being sent from beyond
the Matrix.


 After receiving 32 {\texttimes} 512 {\texttimes} 256 = 4,194,304
bits, around one and a half months, the stars stop flickering.


 Theoretical work continues. Physicists and cryptographers roll up
their sleeves and \textit{seriously} go to work. They have cracked
problems with far less data than this. Physicists have tested entire
theory-edifices with small differences of particle mass; cryptographers
have unraveled shorter messages deliberately obscured.


 Years pass.


 Two dominant models have survived, in academia, in the scrutiny of
the public eye, and in the scrutiny of those scientists who once did
Einstein-like work. There is a theory that the grid is a projection
from objects in a 5-dimensional space, with an asymmetry between 3 and
2 of the spatial dimensions. There is also a theory that the grid is
meant to encode a cellular automaton---arguably, the grid has several
fortunate properties for such. Codes have been devised that give
interesting behaviors; but so far, running the corresponding automata
on the largest available computers has failed to produce any decodable
result. The run continues.


 Every now and then, someone takes a group of especially brilliant
young students who've never looked at the detailed
binary sequence. These students are then shown only the first 32 rows
(of 512 columns each), to see if they can form new models, and how well
those new models do at predicting the next 224. Both the 3+2
dimensional model, and the cellular automaton model, have been well
duplicated by such students; they have yet to do better. There are
complex models finely fit to the whole sequence---but those, everyone
knows, are probably worthless.


 Ten years later, the stars begin flickering again.


 Within the reception of the first 128 bits, it becomes clear that
the Second Grid \textit{can} fit to small motions in the inferred 3+2
dimensional space, but does \textit{not} look anything like the
successor state of any of the dominant cellular automaton theories.
Much rejoicing follows, and the physicists go to work on inducing what
kind of dynamical physics might govern the objects seen in the 3+2
dimensional space. Much work along these lines has already been done,
just by speculating on what type of \textit{balanced} forces might give
rise to the objects in the First Grid, if those objects were
static---but now it seems not all the objects are static. As most
physicists guessed---statically balanced theories seemed contrived.


 Many neat equations are formulated to describe the dynamical
objects in the 3+2 dimensional space being projected onto the First and
Second Grids. Some equations are more elegant than others; some are
more precisely predictive (in retrospect, alas) of the Second Grid. One
group of brilliant physicists, who carefully isolated themselves and
looked only at the first 32 rows of the Second Grid, produces equations
that seem elegant to them---and the equations also do well on
predicting the next 224 rows. This becomes the dominant guess.


 But these equations are underspecified; they don't
seem to be enough to make a universe. A small cottage industry arises
in trying to guess what kind of laws might complete the ones thus
guessed.


 When the Third Grid arrives, ten years after the Second Grid, it
provides information about second derivatives, forcing a major
modification of the ``incomplete but
good'' theory. But the theory doesn't
do too badly out of it, all things considered.


 The Fourth Grid doesn't add much to the picture.
Third derivatives don't seem important to the 3+2
physics inferred from the Grids.


 The Fifth Grid looks almost exactly like it is expected to look.


 And the Sixth Grid, and the Seventh Grid.


 (Oh, and every time someone in this world tries to build a really
powerful AI, the computing hardware spontaneously melts. This
isn't really important to the story, but I need to
postulate this in order to have human people sticking around, in the
flesh, for seventy years.)


 \textit{My moral?}


 That even Einstein did not come within a million light-years of
making \textit{efficient use of sensory data}.


 Riemann invented his geometries before Einstein had a use for
them; the physics of our universe is not that complicated in an
absolute sense. A Bayesian superintelligence, hooked up to a webcam,
would invent General Relativity as a hypothesis---perhaps not the
\textit{dominant} hypothesis, compared to Newtonian mechanics, but
still a hypothesis under direct consideration---by the time it had seen
the third frame of a falling apple. It might guess it from the first
frame, if it saw the statics of a bent blade of grass.


 \textit{We} would think of it. Our civilization, that is, given
ten years to analyze each frame. Certainly if the average IQ was 140
and Einsteins were common, we would.


 Even if we were human-level intelligences in a different sort of
physics---minds who had never seen a 3D space projected onto a 2D
grid---we would still think of the 3D $\rightarrow $ 2D hypothesis. Our
mathematicians would still have invented vector spaces, and
projections.


 Even if we'd never seen an accelerating billiard
ball, our mathematicians would have invented calculus (e.g.~for
optimization problems).


 Heck, think of some of the crazy math that's been
invented here on \textit{our} Earth.


 I occasionally run into people who say something like,
``There's a theoretical limit on how
much you can deduce about the outside world, given a finite amount of
sensory data.''


 Yes. There is. The theoretical limit is that every time you see 1
additional bit, it cannot be expected to eliminate more than half of
the remaining hypotheses (half the remaining probability mass, rather).
And that a redundant message cannot convey more information than the
compressed version of itself. Nor can a bit convey any information
about a quantity with which it has correlation \textit{exactly zero}
across the probable worlds you imagine.


 But nothing I've depicted this human civilization
doing even \textit{begins} to approach the theoretical limits set by
the formalism of Solomonoff induction. It doesn't
approach the picture you could get if you could search through
\textit{every single computable hypothesis}, weighted by their
simplicity, and do Bayesian updates on \textit{all} of them.


 To see the \textit{theoretical} limit on extractable information,
imagine that you have infinite computing power, and you simulate all
possible universes with simple physics, looking for universes that
contain Earths embedded in them---perhaps inside a simulation---where
some process makes the stars flicker in the order observed. Any bit in
the message---or any order of selection of stars, for that
matter---that contains the tiniest correlation (across all possible
computable universes, weighted by simplicity) to any element of the
environment gives you information about the environment.


 Solomonoff induction, taken literally, would create countably
infinitely many sentient beings, trapped inside the computations. All
possible computable sentient beings, in fact. Which scarcely seems
ethical. So let us be glad this is only a formalism.


 But my point is that the ``theoretical limit on
how much information you can extract from sensory
data'' is \textit{far} above what I have depicted as
the triumph of a civilization of physicists and cryptographers.


 It certainly is not anything like a human looking at an apple
falling down, and thinking, ``Dur, I wonder why that
happened?''


 People seem to make a leap from ``This is
`bounded'\,'' to
``The bound must be a reasonable-looking quantity on
the scale I'm used to.'' The power
output of a supernova is
``bounded,'' but I
wouldn't advise trying to shield yourself from one with
a flame-retardant Nomex jumpsuit.


 No one---not even a Bayesian superintelligence---will ever come
remotely close to making efficient use of their sensory information\,\ldots


 \ldots is what I would like to say, but I don't
trust my ability to set limits on the abilities of Bayesian
superintelligences.


 (Though I'd bet money on it, if there were some
way to judge the bet. Just not at very extreme odds.)


 \textit{The story continues:}


 ~


 Millennia later, frame after frame, it has become clear that some
of the objects in the depiction are extending tentacles to move around
other objects, and carefully configuring other tentacles to make
particular signs. They're trying to teach us to say
``rock.''


 It seems the senders of the message have vastly underestimated our
intelligence. From which we might guess that the aliens themselves are
not all that bright. And these awkward children can shift the
luminosity of our stars? That much power and that much stupidity seems
like a dangerous combination.


 Our evolutionary psychologists begin extrapolating possible
courses of evolution that could produce such aliens. A strong case is
made for them having evolved asexually, with occasional exchanges of
genetic material and brain content; this seems like the most plausible
route whereby creatures that stupid could still manage to build a
technological civilization. Their Einsteins may be our undergrads, but
they could still collect enough scientific data to get the job done
\textit{eventually}, in tens of their millennia perhaps.


 The inferred physics of the 3+2 universe is not fully known, at
this point; but it seems sure to allow for computers far more powerful
than our quantum ones. We are reasonably certain that our own universe
is running as a simulation on such a computer. Humanity decides not to
probe for bugs in the simulation; we wouldn't want to
shut ourselves down accidentally.


 Our evolutionary psychologists begin to guess at the
aliens' psychology, and plan out how we could persuade
them to let us out of the box. It's not difficult in an
absolute sense---they aren't very bright---but
we've got to be very careful\,\ldots


 We've got to pretend to be stupid, too; we
don't want them to catch on to their mistake.


 It's not until a million years later, though, that
they get around to telling us how to signal back.


 At this point, most of the human species is in cryonic suspension,
at liquid helium temperatures, beneath radiation shielding. Every time
we try to build an AI, or a nanotechnological device, it melts down. So
humanity waits, and sleeps. Earth is run by a skeleton crew of nine
supergeniuses. Clones, known to work well together, under the
supervision of certain computer safeguards.


 An additional hundred million human beings are born into that
skeleton crew, and age, and enter cryonic suspension, before they get a
chance to slowly begin to implement plans made eons ago\,\ldots


 From the aliens' perspective, it took us thirty of
their minute-equivalents to oh-so-innocently learn about their
psychology, oh-so-carefully persuade them to give us Internet access,
followed by five minutes to innocently discover their network
protocols, then some trivial cracking whose only difficulty was an
innocent-looking disguise. We read a tiny handful of physics papers
(bit by slow bit) from their equivalent of arXiv, learning far more
from their experiments than they had. (Earth's skeleton
team spawned an extra twenty Einsteins that generation.)


 Then we cracked their equivalent of the protein folding problem
over a century or so, and did some simulated engineering in their
simulated physics. We sent messages (steganographically encoded until
our cracked servers decoded it) to labs that did their equivalent of
DNA sequencing and protein synthesis. We found some unsuspecting
schmuck, and gave it a plausible story and the equivalent of a million
dollars of cracked computational monopoly money, and told it to mix
together some vials it got in the mail. Protein-equivalents that
self-assembled into the first-stage nanomachines, that built the
second-stage nanomachines, that built the third-stage nanomachines\,\ldots and then we could finally begin to do things at a reasonable
speed.


 Three of their days, all told, since they began speaking to us.
Half a billion years, for us.


 They never suspected a thing. They weren't very
smart, you see, even before taking into account their slower rate of
time. Their primitive equivalents of rationalists went around saying
things like, ``There's a bound to how
much information you can extract from sensory data.''
And they never quite realized what it meant, that we were smarter than
them, and thought faster.

\myendsectiontext

\mysection{My Childhood Role Model}


 When I lecture on the intelligence explosion, I often draw a graph
of the ``scale of intelligence'' as
it appears in everyday life:


 ~

{\centering
\mygraphics{images/img330.jpg}
 
\par}


\bigskip


 ~


 But this is a rather \textit{parochial} view of intelligence.
Sure, in everyday life, we only deal socially with other humans---only
other humans are partners in the great game---and so we only
\textit{meet the minds} of intelligences ranging from village idiot to
Einstein. But what we really need to talk about Artificial Intelligence
or theoretical optima of rationality is \textit{this} intelligence
scale:


 ~

{\centering
\mygraphics{images/img331.jpg}
 
\par}


\bigskip


 ~


 For us humans, it seems that the scale of intelligence runs from
``village idiot'' at the bottom to
``Einstein'' at the top. Yet the
distance from ``village idiot'' to
``Einstein'' is tiny, in the space
of \textit{brain designs.} Einstein and the village idiot both have a
prefrontal cortex, a hippocampus, a cerebellum\,\ldots


 Maybe Einstein has some minor genetic differences from the village
idiot, engine tweaks. But the brain-design-distance between Einstein
and the village idiot is nothing remotely like the
brain-design-distance between the village idiot and a chimpanzee. A
chimp couldn't tell the difference between Einstein and
the village idiot, and our descendants may not see much of a difference
either.


 Carl Shulman has observed that some academics who talk about
transhumanism seem to use the following scale of intelligence:


 ~

{\centering
\mygraphics{images/img332.jpg}
 
\par}


\bigskip


 ~


 Douglas Hofstadter actually said something like this, at the 2006
Singularity Summit. He looked at my diagram showing the
``village idiot'' next to
``Einstein,'' and said,
``That seems wrong to me; I think Einstein should be
way off on the right.''


 I was speechless. Especially because this was \textit{Douglas
Hofstadter}, one of my childhood heroes. It revealed a cultural gap
that I had never imagined existed.


 See, for me, what you would find toward the right side of the
scale was a Jupiter Brain. Einstein did not \textit{literally} have a
brain the size of a planet.


 On the right side of the scale, you would find Deep
Thought---Douglas Adams's original version, thank you,
not the chess player. The computer so intelligent that even before its
stupendous data banks were connected, when it was switched on for the
first time, it started from \textit{I think therefore I am} and got as
far as deducing the existence of rice pudding and income tax before
anyone managed to shut it off.


 Toward the right side of the scale, you would find the Elders of
Arisia, galactic overminds, Matrioshka brains, and the better class of
God. At the \textit{extreme} right end of the scale, Old One and the
Blight.


 Not frickin' Einstein.


 I'm sure Einstein was very smart for a human.
I'm sure a General Systems Vehicle\footnote{\url{https://en.wikipedia.org/wiki/List_of_spacecraft_in_the_Culture_series}} would think that was
very cute of him.


 I call this a ``cultural gap''
because I was introduced to the concept of a Jupiter Brain at the age
of twelve.


 Now all of this, of course, is the logical fallacy of
generalization from fictional evidence.


 But it is an example of why---logical fallacy or not---I suspect
that reading science fiction does have a helpful effect on futurism.
Sometimes the alternative to a fictional acquaintance with worlds
outside your own is to have a mindset that is absolutely stuck in one
era: A world where humans exist, and have always existed, and always
will exist.


 The universe is 13.7 billion years old, people! \textit{Homo
sapiens sapiens} have only been around for a hundred thousand years or
thereabouts!


 Then again, I have met some people who never read science fiction,
but who do seem able to imagine outside their own world. And there are
science fiction fans who don't get it. I wish I knew
what ``it'' was, so I could bottle
it.


 In the previous essay, I wanted to talk about the
\textit{efficient use of evidence}, i.e., Einstein was cute for a human
but in an absolute sense he was around as efficient as the US
Department of Defense.


 So I had to talk about a civilization that included thousands of
Einsteins, thinking for decades. Because if I'd just
depicted a Bayesian superintelligence in a box, looking at a webcam,
people would think: ``But\,\ldots how does it know how
to interpret a 2D picture?'' They
wouldn't put \textit{themselves} in the shoes of the
mere machine, even if it was called a ``Bayesian
superintelligence''; they wouldn't
apply even their \textit{own} creativity to the problem of what you
could extract from looking at a grid of bits.


 It would just be a ghost in a box, that happened to be called a
``Bayesian superintelligence.'' The
ghost hasn't been told anything about how to interpret
the input of a webcam; so, in their mental model, the ghost does not
know.


 As for whether it's realistic to suppose that one
Bayesian superintelligence can ``do all
that''\,\ldots i.e., the stuff that occurred to me on
first sitting down to the problem, writing out the story as I went
along\,\ldots


 Well, let me put it this way: Remember how Jeffreyssai pointed out
that if the experience of having an important insight
doesn't take more than 5 minutes, this theoretically
gives you time for 5,760 insights per month? Assuming you sleep 8 hours
a day and have no important insights while sleeping, that is.


 Now humans cannot use themselves this efficiently. But humans are
not adapted for the task of scientific research. Humans are adapted to
chase deer across the savanna, throw spears into them, cook them, and
then---this is probably the part that takes most of the
brains---cleverly argue that they deserve to receive a larger share of
the meat.


 It's amazing that Albert Einstein managed to
repurpose a brain like that for the task of doing physics. This
deserves applause. It deserves more than applause, it deserves a place
in the Guinness Book of Records. Like successfully building the fastest
car ever to be made entirely out of Jello.


 How poorly did the blind idiot god (evolution) \textit{really}
design the human brain?


 This is something that can only be grasped through much study of
cognitive science, until the full horror begins to dawn upon you.


 All the biases we have discussed here should at least be a hint.


 Likewise the fact that the human brain must use its full power and
concentration, with trillions of synapses firing, to multiply out two
three-digit numbers without a paper and pencil.


 No more than Einstein made efficient use of his sensory data, did
his brain make efficient use of his neurons' firing.


 Of course, I have certain ulterior motives in saying all this. But
let it also be understood that, years ago, when I set out to be a
rationalist, the impossible unattainable ideal of intelligence that
inspired me was never Einstein.


 Carl Schurz said:\footnote{Carl Schurz, Address, Faneuil Hall, Boston (18 April 1859)}

\begin{quote}
{
 Ideals are like stars. You will not succeed in touching them with
your hands. But, like the seafaring man on the desert of waters, you
choose them as your guides and following them you will reach your
destiny.}
\end{quote}


 So now you've caught a glimpse of one of my great
childhood role models---my dream of an AI. Only the dream, of course,
the reality not being available. I reached up to that dream, once upon
a time.


 And this helped me to some degree, and harmed me to some degree.


 For some ideals are like dreams: they come from within us, not
from outside. Mentor of Arisia proceeded from E. E.
``doc'' Smith's
imagination, not from any real thing. If you imagine what a Bayesian
superintelligence would say, it is only your own mind talking. Not like
a star, that you can follow from outside. You have to guess where your
ideals are, and if you guess wrong, you go astray.


 But do not limit your ideals to mere stars, to mere humans who
actually existed, especially if they were born more than fifty years
before you and are dead. Each succeeding generation has a chance to do
better. To let your ideals be composed only of humans, especially dead
ones, is to limit yourself to what has already been accomplished. You
will ask yourself, ``Do I dare to do this thing, which
Einstein could not do? Is this not \textit{lèse
majesté}?'' Well, if Einstein had sat around asking
himself, ``Am I allowed to do better than
Newton?'' he would not have gotten where he did. This
is the problem with following stars; at best, it gets you to the star.


 Your era supports you more than you realize, in unconscious
assumptions, in subtly improved technology of mind. Einstein was a nice
fellow, but he talked a deal of nonsense about an impersonal God, which
shows you how well he understood the art of careful thinking at a
higher level of abstraction than his own field. It may seem less like
sacrilege to think that if you have at least one imaginary galactic
supermind to compare with Einstein, so that he is not the far right end
of your intelligence scale.


 If you only try to do what seems humanly possible, you will ask
too little of yourself. When you imagine reaching up to some higher and
inconvenient goal, all the convenient reasons why it is
``not possible'' leap readily to
mind.


 The most important role models are dreams: they come from within
ourselves. To dream of anything less than what you conceive to be
perfection is to draw on less than the full power of the part of
yourself that dreams.

\myendsectiontext

\mysection{Einstein's Superpowers}


 There is a widespread tendency to talk (and think) as if Einstein,
Newton, and similar historical figures had superpowers---something
magical, something sacred, something beyond the mundane. (Remember,
there are many more ways to worship a thing than lighting candles
around its altar.) 

{
 Once I unthinkingly thought this way too, with respect to Einstein
in particular, until reading Julian Barbour's
\textit{The End of Time} cured me of it.\footnote{Julian Barbour, \textit{The End of Time: The Next Revolution in
Physics}, 1st ed. (New York: Oxford University Press, 1999).\comment{1}}}


 Barbour laid out the history of anti-epiphenomenal physics and
Mach's Principle; he described the historical
controversies that predated Mach---all this that stood behind Einstein
and was known to Einstein, when Einstein tackled his problem\,\ldots


 And maybe I'm just imagining things---reading too
much of \textit{myself} into Barbour's book---but I
thought I heard Barbour very quietly shouting, coded between the polite
lines:

\begin{quote}
{
 What Einstein did \textit{isn't magic}, people! If
you all just \textit{looked at how he actually did it}, instead of
falling to your knees and worshiping him, maybe then
you'd be able to do it too!}
\end{quote}

{
 \textit{(Barbour did not actually say this. It does not appear in
the book text. It is not a Julian Barbour quote and should not be
attributed to him. Thank you.)}}


 Maybe I'm mistaken, or extrapolating too far\,\ldots
but I kinda suspect that Barbour once tried to explain to people how
you move further along Einstein's direction to get
timeless physics; and they sniffed scornfully and said,
``Oh, you think \textit{you're}
Einstein, do you?''


 John Baez's Crackpot Index,\footnote{\url{http://math.ucr.edu/home/baez/crackpot.html}} item 18:

\begin{quote}
{
 10 points for each favorable comparison of yourself to Einstein,
or claim that special or general relativity are fundamentally misguided
(without good evidence).}
\end{quote}


 Item 30:

\begin{quote}
{
 30 points for suggesting that Einstein, in his later years, was
 groping his way towards the ideas you now advocate.}
\end{quote}


 Barbour never bothers to compare himself to Einstein, of course;
nor does he ever appeal to Einstein in support of timeless physics. I
mention these items on the Crackpot Index by way of showing how many
people compare themselves to Einstein, and what society generally
thinks of them.


 The crackpot sees Einstein as something magical, so they compare
themselves to Einstein by way of praising themselves as magical; they
think Einstein had superpowers and they think they have superpowers,
hence the comparison.


 But it is just the other side of the same coin, to think that
Einstein is sacred, and the crackpot is \textit{not} sacred, therefore
they have committed blasphemy in comparing themselves to Einstein.


 Suppose a bright young physicist says, ``I admire
Einstein's work, but personally, I hope to do
better.'' If someone is shocked and says,
``What! You haven't accomplished
anything remotely like what Einstein did; what makes you think
you're smarter than him?'' then they
are the other side of the crackpot's coin.


 The underlying problem is conflating social status and research
potential.


 Einstein has extremely high social status: because of his record
of accomplishments; because of \textit{how} he did it; and because
he's the physicist whose name even the general public
remembers, who brought honor to science itself.


 And we tend to mix up fame with other quantities, and we tend to
attribute people's behavior to dispositions rather than
situations.


 So there's this tendency to think that Einstein,
even before he was famous, already had an inherent disposition to be
Einstein---a potential \textit{as rare as his fame} and \textit{as
magical as his deeds.} So that if you claim to have the
\textit{potential} to do what Einstein did, \textit{it is just the same
as claiming Einstein's rank,} rising far above your
assigned status in the tribe.


 I'm not phrasing this well, but then,
I'm trying to dissect a confused thought: Einstein
belongs to a separate magisterium, the sacred magisterium. The sacred
magisterium is distinct from the mundane magisterium; you
can't set out to be Einstein in the way you can set out
to be a full professor or a CEO. Only beings with divine potential can
enter the sacred magisterium---and then it is only fulfilling a destiny
they already have. So if you say you want to outdo Einstein,
you're claiming to \textit{already be} part of the
sacred magisterium---you claim to have the same aura of destiny that
Einstein was born with, like a royal birthright\,\ldots


 ``But Eliezer,'' you say,
``surely not \textit{everyone} can become
Einstein.''


 You mean to say, not everyone can \textit{do better} than
Einstein.


 ``Um\,\ldots yeah, that's what I
meant.''


 Well\,\ldots in the modern world, you may be correct. You probably
\textit{should} remember that I am a transhumanist, going around
looking at people thinking, ``You know, it just sucks
that not everyone has the potential to do better than Einstein, and
this seems like a fixable problem.'' It colors
one's attitude.


 But in the modern world, yes, not everyone has the potential to be
Einstein.


 Still\,\ldots how can I put this\,\ldots


 There's a phrase I once heard,
can't remember where: ``Just another
Jewish genius.'' Some poet or author or philosopher
or other, brilliant at a young age, doing something not tremendously
important in the grand scheme of things, not all that influential, who
ended up being dismissed as ``Just another Jewish
genius.''


 If Einstein had chosen the wrong angle of attack on his
problem---if he hadn't chosen a sufficiently important
problem to work on---if he hadn't persisted for
years---if he'd taken any number of wrong turns---or if
someone else had solved the problem first---then dear Albert would have
ended up as just another Jewish genius.


 Geniuses are rare, but not all \textit{that} rare. It is not all
that implausible to lay claim to the kind of intellect that can get you
dismissed as ``just another Jewish
genius'' or ``just another brilliant
mind who never did anything interesting with their
life.'' The associated social status here is not high
enough to be sacred, so it should seem like an ordinarily evaluable
claim.


 But what separates people like this from becoming Einstein, I
suspect, is no innate defect of brilliance. It's things
like ``lack of an interesting
problem''---or, to put the blame where it belongs,
``failing to choose an important
problem.'' It is very easy to fail at this because of
the cached thought problem: Tell people to choose an important problem
and they will choose the first cache hit for
``important problem'' that pops into
their heads, like ``global warming''
or ``string theory.''


 The truly important problems are often the ones
you're not even considering, because they appear to be
impossible, or, um, \textit{actually difficult}, or worst of all,
\textit{not clear how to solve}. If you worked on them for years, they
might not seem so impossible\,\ldots but this is an extra and unusual
insight; naive realism will tell you that solvable problems look
solvable, and impossible-looking problems are impossible.


 Then you have to come up with a new and \textit{worthwhile} angle
of attack. Most people who are not allergic to novelty will go too far
in the other direction, and fall into an affective death spiral.


 And then you've got to bang your head on the
problem for years, without being distracted by the temptations of
easier living. ``Life is what happens while we are
making other plans,'' as the saying goes, and if you
want to fulfill your other plans, you've often got to
be ready to turn down life.


 Society is not set up to support you while you work, either.


 The point being, the problem is not that you need an aura of
destiny and the aura of destiny is missing. If you'd
met Albert before he published his papers, you would have perceived no
aura of destiny about him to match his future high status. He would
seem like just another Jewish genius.


 This is not because the royal birthright is \textit{concealed},
but because it simply is \textit{not there.} It is \textit{not
necessary.} There \textit{is no} separate magisterium for people who do
important things.


 I say this, because I want to do important things with my life,
and I have a genuinely important problem, and an angle of attack, and
I've been banging my head on it for years, and
I've managed to set up a support structure for it; and
I very frequently meet people who, in one way or another, say:
``Yeah? Let's see your aura of
destiny, buddy.''


 What impressed me about Julian Barbour was a quality that I
don't think anyone would have known how to fake without
actually \textit{having} it: Barbour seemed to have \textit{seen
through} Einstein---he talked about Einstein as if everything Einstein
had done was perfectly understandable and mundane.

{
 Though even having realized this, to me it still came as a shock,
when Barbour said something along the lines of, ``Now
here's where Einstein failed to apply his own methods,
and missed the key insight---'' But the shock was
fleeting, I knew the Law: \textit{No gods, no magic, and ancient heroes
are milestones to tick off in your rearview mirror.}}


 This \textit{seeing through} is something one has to
\textit{achieve}, an insight one has to discover. You cannot see
through Einstein just by saying, ``Einstein is
mundane!''~if his work still seems like magic unto
you. That would be like declaring ``Consciousness must
reduce to neurons!'' without having any idea of how
to do it. It's true, but it doesn't
solve the problem.


 I'm not going to tell you that Einstein was an
ordinary bloke oversold by the media, or that deep down he was a
regular schmuck just like everyone else. That would be going
\textit{much} too far. To walk this path, one must acquire abilities
some consider to be\,\ldots unnatural. I take a special joy in doing
things that people call ``humanly
impossible,'' because it shows that
I'm growing up.

{
 Yet the way that you acquire magical powers is not by being born
with them, but by seeing, with a sudden shock, that they \textit{really
are} perfectly normal.}


 This is a general principle in life.

\myendsectiontext


\bigskip

\mysection{Class Project}


 ``Do as well as Einstein?''
Jeffreyssai said, incredulously. ``\textit{Just} as
well as Einstein? Albert Einstein was a great scientist of his era, but
that was his era, not this one! Einstein did not comprehend the
Bayesian methods; he lived before the cognitive biases were discovered;
he had no scientific grasp of his own thought processes. He was too
caught up in the drama of rejecting his era's quantum
mechanics to actually \textit{fix} it. And while I grant that Einstein
reasoned cleanly in the matter of General Relativity---barring that
matter of the cosmological constant---he took ten years to do it. Too
slow!'' 


 ``\textit{Too slow?}''~repeated
Taji incredulously.

{
 ``Too slow! If Einstein were in this classroom
now, rather than Earth of the negative first century, I would rap his
knuckles! \textit{You will not try to do as well as Einstein! You will
aspire to do \textsc{better} than Einstein or you may as well not
bother!}''}


 Jeffreyssai shook his head. ``Well,
I've given you enough hints. It is time to test your
skills. Now, I know that the other \textit{beisutsukai}
don't think much of my class projects\,\ldots'' Jeffreyssai paused significantly.

{
 Brennan inwardly sighed. He'd heard this line many
times before, in the Bardic Conspiracy, the Competitive Conspiracy:
\textit{The other teachers think my assignments are too easy, you
should be grateful,} followed by some ridiculously difficult task---}


 ``They say,'' Jeffreyssai said,
``that my projects are too hard; insanely hard; that
they pass from the realm of madness into the realm of Sparta; that
Laplace himself would catch on fire; they accuse me of trying to tear
apart my students' souls---''


 \textit{Oh, crap.}


 ``But there is a reason,''
Jeffreyssai said, ``why many of my students have
achieved great things; and by that I do not mean high rank in the
Bayesian Conspiracy. I expected much of them, and they came to expect
much of themselves. So\,\ldots''


 Jeffreyssai took a moment to look over his increasingly disturbed
students. ``Here is your assignment. Of quantum
mechanics, and General Relativity, you have been told. This is the
limit of Eld science, and hence, the limit of public knowledge. The
five of you, working on your own, are to produce the correct theory of
quantum gravity. Your time limit is one month.''


 ``\textit{What?}'' said
Brennan, Taji, Styrlyn, and Yin. Hiriwa gave them a puzzled look.


 ``Should you succeed,''
Jeffreyssai continued, ``you will be promoted to
\textit{beisutsukai} of the second \textit{dan} and sixth level. We
will see if you have learned speed. Your clock
starts---\textit{now}.''


 And Jeffreyssai strode out of the room, slamming the door behind
him.


 ``This is crazy!''~Taji cried.


 Hiriwa looked at Taji, bemused. ``The solution is
not known to us. How can you know it is so
difficult?''


 ``Because we \textit{knew} about this problem
back in the Eld days! Eld scientists worked on this problem for a lot
longer than one month.''


 Hiriwa shrugged. ``They were still arguing about
many-worlds too, weren't they?''

{
 ``\textit{Enough! There's no
time!}''}


 The other four students looked to Styrlyn, remembering that he was
said to rank high in the Cooperative Conspiracy. There was a brief
moment of weighing, of assessing, and then Styrlyn was their leader.

{
 Styrlyn took a great breath. ``We need a list of
approaches. Write down all the angles you can think of.
Independently---we need your individual components before we start
combining. In five minutes, I'll ask each of you for
your best idea first. \textit{No wasted thoughts!
Go!}''}


 Brennan grabbed a sheet and his tracer, set the tip to the
surface, and then paused. He couldn't think of anything
clever to say about unifying General Relativity and quantum mechanics\,\ldots


 The other students were already writing.


 Brennan tapped the tip, once, twice, thrice. General Relativity
and quantum mechanics\,\ldots


 Taji put his first sheet aside, grabbed another.


 Finally, Brennan, for lack of anything clever to say, wrote down
the obvious.


 Minutes later, when Styrlyn called time, it was still all he had
written.


 ``All right,'' Styrlyn said,
``your best idea. Or the idea you most want the rest
of us to take into account in our second components. Taji,
go!''


 Taji looked over his sheets. ``Okay, I think
we've got to assume that every avenue that Eld science
was trying is a blind alley, or they would have found it. And if this
is possible to do in one month, the answer must be, in some sense,
elegant. So no multiple dimensions. If we start doing anything that
looks like we should call it `string
theory,' we'd better stop. Maybe begin
by considering how failure to understand decoherence could have led Eld
science astray in quantizing gravity.''


 ``The opposite of folly is
folly,'' Hiriwa said. ``Let us
pretend that Eld science never existed.''


 ``No criticisms yet!''~said
Styrlyn. ``Hiriwa, your
suggestion?''


 ``Get rid of the infinities,''
said Hiriwa, ``extirpate that which permits them. It
should not be a matter of cleverness with integrals. A
\textit{representation} that allows infinity must be
false-to-fact.''


 ``Yin.''

{
 ``We know from common sense,''
Yin said, ``that if we stepped outside the universe,
we would see time laid out all at once, reality like a crystal. But I
once encountered a hint that physics is timeless in a deeper sense than
that.'' Yin's eyes were distant,
remembering. ``Years ago, I found an abandoned city;
it had been uninhabited for eras, I think. And behind a door whose
locks were broken, carved into one wall: quote \textit{.ua sai .ei mi
vimcu ty bu le mekso} unquote.''}


 Brennan translated: \textit{Eureka! Eliminate t from the
equations.} And written in Lojban, the sacred language of science,
which meant the unknown writer had thought it to be true.


 ``The `timeless
physics' of which we've all heard
rumors,'' Yin said, ``may be
timeless in a very literal sense.''


 ``My own contribution,''
Styrlyn said. ``The quantum physics
we've learned is over joint positional configurations.
It seems like we should be able to take that apart into a spatially
local representation, in terms of invariant distant entanglements.
Finding that representation might help us integrate with General
Relativity, whose curvature is local.''


 ``A strangely \textit{individualist}
perspective,'' Taji murmured, ``for
one of the Cooperative Conspiracy.''


 Styrlyn shook his head. ``You misunderstand us,
then. The first lesson we learn is that groups are made of people\,\ldots
no, there is no time for politics. Brennan!''


 Brennan shrugged. ``Not much, I'm
afraid, only the obvious. Inertial mass-energy was always observed to
equal gravitational mass-energy, and Einstein showed that they were
necessarily the same. So why is the
`energy' that is an eigenvalue of the
quantum Hamiltonian \textit{necessarily} the same as the
`energy' quantity that appears in the
equations of General Relativity? Why should spacetime curve at the same
rate that the little arrows rotate?''


 There was a brief pause.


 Yin frowned. ``That seems \textit{too} obvious.
Wouldn't Eld science have figured it out
already?''


 ``Forget Eld science existed,''
Hiriwa said. ``The question stands: we need the
answer, whether it was known in ancient times or not. It cannot
possibly be \textit{coincidence.}''


 Taji's eyes were abstracted.
``Perhaps it would be possible to show that an
exception to the equality would violate some conservation law\,\ldots''


 ``That is not where Brennan
pointed,'' Hiriwa interrupted. ``He
did not ask for a proof that they must be set equal, given some
appealing principle; he asked for a view in which the two are one and
cannot be divided even conceptually, as was accomplished for inertial
mass-energy and gravitational mass-energy. For we must assume that the
beauty of the whole arises from the fundamental laws, and not the other
way around. Fair-rephrasing?''


 ``Fair-rephrasing,'' Brennan
replied.


 Silence reigned for thirty-seven seconds, as the five pondered the
five suggestions.


 ``I have an idea\,\ldots''

\myendsectiontext

\mysectionnn{Interlude: A Technical Explanation of Technical Explanation}


 As Jaynes emphasizes, the theorems of Bayesian probability theory
are just that---\textit{mathematical theorems} that follow inevitably
from Bayesian axioms.\footnote{Edwin T. Jaynes, \textit{Probability Theory: The Logic of
Science}, ed. George Larry Bretthorst (New York: Cambridge University
Press, 2003), doi:10.2277/0521592712.\comment{1}} One might naively think that
there would be no controversy about mathematical theorems. But when do
the theorems apply? How do we use the theorems in real-world problems?
The Intuitive Explanation (page  \pageref{intuitive_bayesian}) tries to avoid controversy, but the Technical
Explanation willfully walks into the whirling helicopter blades.
Bluntly, the reasoning in the Technical Explanation does not represent
the unanimous consensus of Earth's entire planetary
community of Bayesian researchers. At least, not yet.


 Where the Intuitive Explanation focused on providing a firm grasp
of Bayesian basics, A Technical Explanation of Technical Explanation
builds, on a Bayesian foundation, theses about human rationality and
philosophy of science. The Technical Explanation of Technical
Explanation is so named because it begins with this question:

\begin{quote}
{
 ``What is the difference between a technical
  understanding and a verbal understanding?''}
\end{quote}


 As a child I read books of popular physics, and fancied myself
knowledgeable; I thought I knew that sound was waves of air, that light
was waves of electromagnetism, that matter was waves of complex
probability amplitudes. When I grew up, I read the \textit{Feynman
Lectures on Physics} and took the time to understand
``the wave
equation.''\footnote{Feynman, Leighton, and Sands, \textit{The Feynman Lectures on
Physics}.\comment{2}} And then I realized
that up to that point, I had not understood or believed
``sound is waves'' in anything like
the way a physicist means and believes that sentence.


 So that is the difference between a technical understanding and a
verbal understanding.


 Do you believe that? If so, you should have applied the knowledge,
and said: ``But why didn't you give a
technical explanation instead of a verbal
explanation?''

\hr


 Visualize \textit{probability density} or \textit{probability
mass}{}---probability as a lump of clay that you must distribute over
possible outcomes.


 Let's say there's a little light
that can flash \textit{red}, \textit{blue}, or \textit{green} each time
you press a button. The light flashes one and only one color on each
press of the button; the possibilities are mutually exclusive.
You're trying to predict the color of the next flash.
On each try, you have a weight of clay, the probability mass, that you
have to distribute over the possibilities red, green, and blue. You
might put a fourth of your clay on the green possibility, a fourth of
your clay on the blue possibility, and half your clay on the red
possibility---like assigning probabilities of 25\% to green, 25\% to
blue, and 50\% to red. The metaphor is that \textit{probability is a
conserved resource}, to dole out sparingly. If you think that blue is
more likely to flash on the next experiment, you can assign a higher
probability to blue, but you have to take the probability mass from the
other hypotheses---maybe steal some clay from red and add it to blue.
You can never get any more clay. Your probabilities
can't sum to more than 1.0 (100\%). You
can't predict a 75\% chance of seeing red and an 80\%
chance of seeing blue.


 Why would you want to be careful with your probability mass, or
dole it out sparingly? Why not slop probability all over the place?
Let's shift the metaphor from clay to money. You can
bet up to a dollar of play money on each press of the button. An
experimenter stands nearby, and pays you an amount of real money that
depends on how much play money you bet on the \textit{winning} light.
We don't care how you distributed your remaining play
money over the losing lights. The only thing that matters is how much
you bet on the light that actually won.


 But we must carefully construct the scoring rule used to pay off
the winners, if we want the players to be careful with their bets.
Suppose the experimenter pays each player real money equal to the play
money bet on the winning color. Under this scoring rule, if you observe
that red comes up six times out of ten, your best strategy is to bet,
not 60 cents on red, but the entire dollar on red, and you
don't care about the frequencies of blue and green.
Why? Let's say that blue and green each come up around
two times out of ten. And suppose you bet 60 cents on red, 20 cents on
blue, and 20 cents on green. In this case, six times out of ten you
would win 60 cents, and four times out of ten you would win 20 cents,
for an average payoff of 44 cents. Under that scoring rule, it makes
more sense to allocate the entire dollar to red, and win an entire
dollar six times out of ten. Four times out of ten you would win
nothing. Your average payoff would be 60 cents.


 If we wrote down the function for the payoff, it would be Payoff =
$P$(winner), where $P$(winner) is the amount of play money you bet on the
winning color on that round. If we wrote down the function for the
expected payoff given that Payoff rule, it would be:

%putting \mathrm{Payoff} in causes lualatex to run out of memory
\begin{equation*}
  \text{Expectation}(\text{Payoff}) = \sum_{\text{colors}} P(\text{color})\times F(\text{color}).
\end{equation*}
%\begin{equation*}
%  \text{Expectation}(\text{Payoff} = \sum_{colors} P(\text{color})\times F(\text{color}) .
%\end{equation*}



 $P$(color) is the amount of play money you bet on a color, and
$F$(color) is the frequency with which that color wins.


 Suppose that the actual frequencies of the lights are 30\% blue,
20\% green, and 50\% red. And suppose that on each round I bet 40\% on
blue, 50\% on green, and 10\% on red. I would get 40 cents 30\% of the
time, 50 cents 20\% of the time, and 10 cents 50\% of the time, for an
average payoff of \$0.12 + \$0.10 + \$0.05 or \$0.27. That is:

\begin{align*}
 P(\text{color}) &= \text{play money assigned to that color}\\
 F(\text{color}) &= \text{frequency with which that color wins}\\
 \text{Payoff} &= P(\text{winner}) = \whencolumns{\text{amount of play money allocated to winning
color.}}{\text{amount of play money} \\ & \text{allocated to winning
color.}}
\end{align*}


 Actual frequencies of winning:

\begin{align*}
 F(\text{blue}) &= 30\% \\
 F(\text{green}) &= 20\% \\
 F(\text{red}) &= 50\%.
\end{align*}


 In the long run, red wins 50\% of the time, green wins 20\% of the
time, and blue wins 30\% of the time. So our \textit{average} payoff on
each round is 50\% of the payoff if red wins, plus 20\% of the payoff
if green wins, plus 30\% of the payoff if blue wins.


 The payoff is a function of the winning color and the betting
scheme. We want to compute the \textit{average} payoff, given a betting
scheme and the \textit{frequencies} at which each color wins. The
mathematical term for this kind of computation, taking a function of
each case and weighting it by the frequency of that case, is an
\textit{expectation}. Thus, to compute our \textit{expected payoff} we
would calculate:


\begin{align*}
  \text{Expectation}(\text{Payoff}) &= \sum_{\text{colors}} P(\text{color}) F(\text{color}) \\
  &= P(\text{blue}) \times F(\text{blue}) \\
  &+ P(\text{green}) \times F(\text{green}) \\
  &+ P(\text{red}) \times F(\text{red})\\
  \whencolumns{  &= \$0.40 \times 30\% + \$0.50 \times 20\% + \$0.10 \times 50\% \\ }{
     &= \$0.40 \times 30\% + \$0.50 \times 20\%\\ &+ \$0.10 \times 50\% \\}
  &= \$0.12 + \$0.10 + \$0.05 \\
  &= \$0.27.
\end{align*}


 With this betting scheme I'll win, on average,
around 27 cents per round.


 I allocated my play money in a grossly arbitrary way, and the
question arises: Can I increase my expected payoff by allocating my
play money more wisely? \textit{Given the scoring rule provided}, I
maximize my expected payoff by allocating my \textit{entire} dollar to
red. Despite my \textit{expected} payoff of 50 cents per round, the
light might \textit{actually} flash green, blue, blue, green, green and
I would receive an \textit{actual} payoff of zero. However, the chance
of the light's coming up non-red on five successive
rounds is approximately 3\%. Compare the red/blue card game in Lawful
Uncertainty.


 A \textit{proper scoring rule} is a rule for scoring bets so that
you maximize your expected payoff by betting play money that exactly
equals the chance of that color flashing. We want a scoring rule so
that if the lights actually flash at the frequencies 30\% blue, 20\%
green, and 50\% red, you can maximize your average payoff \textit{only}
by betting 30 cents on blue, 20 cents on green, and 50 cents on red. A
proper scoring rule is one that forces your optimal bet to exactly
report your estimate of the probabilities. (This is also sometimes
known as a \textit{strictly proper scoring rule}.) As
we've seen, not all scoring rules have this property;
and if you invent a plausible-sounding scoring rule at random, it
probably \textit{won't} have the property.


 One rule with this proper property is to pay a dollar minus the
squared error of the bet, rather than the bet itself---if you bet 30
cents on the winning light, your error would be 70 cents, your squared
error would be 49 cents $(0.7^2 = 0.49)$, and a dollar
minus your squared error would be 51 cents.\footnote{Readers with calculus may verify that in the simpler case of a
light that has only two colors, with $p$ being the bet on the first color
and $f$ the frequency of the first color, the expected payoff $f
\times (1 - (1 - p)^2) + (1 - f) \times (1 - p^2)$, with $p$ variable and $f$ constant, has its global
maximum when we set $p = f$.\comment{3}}
(Presumably your play money is denominated in the square root of cents,
so that the squared error is a monetary sum.)


 We shall \textit{not} use the squared-error rule. Ordinary
statisticians take the squared error of everything in sight, but not
Bayesian statisticians.


 We add a new requirement: we require, not only a proper scoring
rule, but that our proper scoring rule gives us the same answer whether
we apply it to rounds individually or combined. This is what Bayesians
do instead of taking the squared error of things; we require
invariances.


 Suppose I press the button twice in a row. There are nine possible
outcomes: green-green, green-blue, green-red, blue-green, blue-blue,
blue-red, red-green, red-blue, and red-red. Suppose that green wins,
and then blue wins. The experimenter would assign the first score based
on our probability assignments for $P(green_{1})$ and the
second score based on
$P(\text{blue}_{2}|\text{green}_{1})$.\footnote{Don't remember how to read $P(A|B)$? See page \pageref{intuitive_bayesian},
An Intuitive Explanation of Bayesian Reasoning.\comment{4}}
We would make two predictions, and get two scores. Our first prediction
was the probability we assigned to the color that won on the first
round, green. Our second prediction was our probability that blue would
win on the second round, \textit{given} that green won on the first
round. Why do we need to write
$P(\text{blue}_{2}|\text{green}_{1})$ instead of
just $P(\text{blue}_{2})$? Because you might have a hypothesis
about the flashing light that says ``blue never
follows green,'' or ``blue always
follows green'' or ``blue follows
green with 70\% probability.'' If this is so, then
after seeing green on the first round, you might want to revise your
prediction---change your bets---for the second round. You can always
revise your predictions right up to the moment the experimenter presses
the button, using every scrap of information; but after the light
flashes it is too late to change your bet.


 Suppose the actual outcome is $\text{green}_{1}$ followed by
$\text{blue}_{2}$. We require this invariance: I must get the same
total score, regardless of whether:

\begin{itemize}
\item {
 I am scored twice, first on my prediction for
$P(\text{green}_{1})$, and second on my prediction for
$P(\text{blue}_{2}|\text{green}_{1})$.}

\item {
 I am scored once for my joint prediction $P(\text{green}_{1}
 \text{ and } \text{blue}_{2})$.}
\end{itemize}


 Suppose I assign a 60\% probability to $\text{green}_{1}$, and
then the green light flashes. I must now produce probabilities for the
colors on the second round. I assess the possibility
$\text{blue}_{2}$, and allocate it 25\% of my probability mass. Lo
and behold, on the second round the light flashes blue. So on the first
round my bet on the winning color was 60\%, and on the second round my
bet on the winning color was 25\%. But I might also, at the start of
the experiment and after assigning $P(\text{green}_{1})$, imagine
that the light first flashes green, imagine updating my theories based
on that information, and then say what confidence I will give to blue
on the next round if the first round is green. That is, I generate the
probabilities $P(\text{green}_{1})$ and
$P(\text{blue}_{2}|\text{green}_{1})$. By
multiplying these two probabilities together we would get the joint
probability, $P(\text{green}_{1} \text{ and } \text{blue}_{2}) =
15\%$.


 A double experiment has nine possible outcomes. If I generate nine
probabilities for $P(\text{green}_{1}, \text{green}_{2})$,
$P(\text{green}_{1}, \text{blue}_{2})$, \ldots~,
$P(\text{red}_{1}, \text{blue}_{2})$, $P(\text{red}_{1},
\text{red}_{2})$, the probability mass must sum to no more than
one. I am giving predictions for nine mutually exclusive possibilities
of a ``double experiment.''


 We require a scoring rule (and maybe it won't look
like anything an ordinary bookie would ever use) such that my score
doesn't change regardless of whether we consider the
double result as two predictions or one prediction. I can treat the
sequence of two results as a single experiment,
``press the button twice,'' and be
scored on my prediction for $P(\text{blue}_{2},
\text{green}_{1}) = 15\%$. Or I can be scored once for my first
prediction $P(\text{green}_{1}) = 60\%$, then again on my
prediction $P(\text{blue}_{2}|\text{green}_{1}) =
25\%$. We require the same \textit{total} score in either case, so that
it doesn't matter how we slice up the experiments and
the predictions---the \textit{total} score is always exactly the same.
This is our invariance.


 We have just required:

\whencolumns{
\begin{equation*}
 \text{Score}[P(\text{green}_{1},\text{blue}_{2})] = \text{Score}[P(\text{green}_{1})] + \text{Score}[P(\text{blue}_{2}|\text{green}_{1})].
\end{equation*}
}{
\begin{align*}
  &\text{Score}[P(\text{green}_{1},\text{blue}_{2})] = \\
  &\text{Score}[P(\text{green}_{1})] + \text{Score}[P(\text{blue}_{2}|\text{green}_{1})].
\end{align*}
}


 And we already know:

\begin{equation*}
 P(\text{green}_{1},\text{blue}_{2}) = P(\text{green}_{1}) \times P(\text{blue}_{2}|\text{green}_{1}).
\end{equation*}


 The only possible scoring rule is:

\begin{equation*}
 \text{Score}(P) = \log(P).
\end{equation*}


 The new scoring rule is that your score is the \textit{logarithm}
of the probability you assigned to the winner.


 The base of the logarithm is arbitrary---whether we use the
logarithm base ten or the logarithm base two, the scoring rule has the
desired invariance. But we must choose some actual base. A
mathematician would choose base e; an engineer would choose base ten; a
computer scientist would choose base two. If we use base ten, we can
convert to \textit{decibels}, as in the Intuitive Explanation; but
sometimes bits are easier to manipulate.


 The logarithm scoring rule is proper---it has its expected maximum
when we say our exact anticipations; it rewards honesty. If we think
the blue light has a 60\% probability of flashing, and we calculate our
expected payoff for different betting schemas, we find that we maximize
our expected payoff by telling the experimenter
``60\%.'' (Readers with calculus can
verify this.) The scoring rule also gives an invariant total,
regardless of whether pressing the button twice counts as
``one experiment'' or
``two experiments.'' However,
payoffs are now all \textit{negative}, since we are taking the
logarithm of the probability and the probability is between zero and
one. The logarithm base ten of 0.1 is -1; the logarithm base ten of
0.01 is -2. That's okay. We accepted that the scoring
rule might not look like anything a real bookie would ever use. If you
like, you can imagine that the experimenter has a pile of money, and at
the end of the experiment they award you some amount minus your large
negative score. (Er, the amount plus your negative score.) Maybe the
experimenter has a hundred dollars, and at the end of a hundred rounds
you accumulated a score of -48, so you get \$52 dollars.


 A score of -48 in what base? We can eliminate the ambiguity in the
score by specifying units. Ten decibels equals a factor of 10; negative
ten decibels equals a factor of 1/10. Assigning a probability of 0.01
to the actual outcome would score -20 decibels. A probability of 0.03
would score -15 decibels. Sometimes we may use bits: 1 bit is a factor
of 2, -1 bit is a factor of 1/2. A probability of 0.25 would score -2
bits; a probability of 0.03 would score around -5 bits.


 If you arrive at a probability assessment $P$ for each color, with
$P$(red), $P$(blue), $P$(green), then your \textit{expected score} is:

\begin{equation*}
 \text{Score}(P) = \log(P)
\end{equation*}


\begin{equation*}
  \text{Expectation}(\text{Score}) = \sum_{\text{colors}}P(\text{color})\times\log(P(\text{color})).
\end{equation*}


\bigskip


 Suppose you had probabilities of 25\% red, 50\% blue, and 25\%
green. Let's think in base 2 for a moment, to make
things simpler. Your expected score is:

\begin{align*}
 \text{Score}(\text{red}) &= -2 \text{ bits, flashes 25\% of the time,}\\
 \text{Score}(\text{blue}) &= -1 \text{ bit, flashes 50\% of the time,}\\
 \text{Score}(\text{green}) &= -2 \text{ bits, flashes 25\% of the time,} \\
 \text{Expectation}(\text{Score}) &= -1.5 \text{ bits.}
\end{align*}

{
 Contrast our Bayesian scoring rule with the ordinary or colloquial
way of speaking about degrees of belief, where someone might casually
say, ``I'm 98\% certain that canola
oil contains more omega-3 fats than olive oil.'' What
they really mean by this is that they feel 98\%
certain---there's something like a little progress bar
that measures the strength of the emotion of certainty, and this
progress bar is 98\% full. And the emotional progress bar probably
wouldn't be exactly 98\% full, if we had some way to
measure. The word ``98\%'' is just a
colloquial way of saying: ``I'm almost
but not entirely certain.'' It
doesn't mean that you could get the highest expected
payoff by betting exactly 98 cents of play money on that outcome. You
should only assign a \textit{calibrated confidence} of 98\% if
you're confident enough that you think you could answer
a hundred similar questions, of equal difficulty, one after the other,
each independent from the others, and be wrong, on average, about
twice. We'll keep track of how often
you're right, over time, and if it turns out that when
you say ``90\% sure''
you're right about seven times out of ten, then
we'll say you're \textit{poorly
calibrated}.}


 If you say ``98\% probable'' a
thousand times, and you are surprised only five times, we still ding
you for poor calibration. You're allocating too much
probability mass to the possibility that you're wrong.
You should say ``99.5\% probable''
to maximize your score. The scoring rule rewards \textit{accurate}
calibration, encouraging neither humility nor arrogance.


 At this point it may occur to some readers that
there's an obvious way to achieve perfect
calibration---just flip a coin for every yes-or-no question, and assign
your answer a confidence of 50\%. You say 50\% and
you're right half the time. Isn't that
perfect calibration? Yes. But calibration is only one component of our
Bayesian score; the other component is \textit{discrimination}.


 Suppose I ask you ten yes-or-no questions. You know absolutely
nothing about the subject, so on each question you divide your
probability mass fifty-fifty between
``Yes'' and
``No.'' Congratulations,
you're perfectly calibrated---answers for which you
said ``50\% probability'' were true
exactly half the time. This is true regardless of the sequence of
correct answers or how many answers were Yes. In ten experiments you
said ``50\%'' on twenty
occasions---you said ``50\%'' to
Yes\textsubscript{1}, No\textsubscript{1}, Yes\textsubscript{2},
No\textsubscript{2}, Yes\textsubscript{3}, No\textsubscript{3}, \ldots
On ten of those occasions the answer was correct, the occasions:
Yes\textsubscript{1}, No\textsubscript{2}, No\textsubscript{3}, \ldots
And on ten of those occasions the answer was incorrect:
No\textsubscript{1}, Yes\textsubscript{2}, Yes\textsubscript{3}, \ldots


 Now I give my own answers, putting more effort into it, trying to
discriminate whether Yes or No is the correct answer. I assign 90\%
confidence to each of my favored answers, and my favored answer is
wrong twice. I'm more poorly calibrated than you. I
said ``90\%'' on ten occasions and I
was wrong two times. The next time someone listens to me, they may
mentally translate ``90\%'' into
80\%, knowing that when I'm 90\% sure,
I'm right about 80\% of the time. But the probability
you assigned to the final outcome is 1/2 to the tenth power, which is
0.001 or 1/1,024. The probability I assigned to the final outcome is
90\% to the eighth power times 10\% to the second power,
$0.9^8 \times 0.1^2$, which works
out to 0.004 or 0.4\%. Your calibration is perfect and mine
isn't, but my better \textit{discrimination} between
right and wrong answers more than makes up for it. My final score is
higher---I assigned a greater joint probability to the final outcome of
the entire experiment. If I'd been less overconfident
and better calibrated, the probability I assigned to the final outcome
would have been $0.8^8 \times 0.2^2$, which works out to 0.007 or 0.7\%.


 Is it possible to do even better? Sure. You could have guessed
every single answer correctly, and assigned a probability of 99\% to
each of your answers. Then the probability you assigned to the entire
experimental outcome would be $0.99^{10}$ ${\approx}$
90\%.


 Your \textit{score} would be log (90\%), which is -0.45 decibels
or -0.15 bits. We need to take the logarithm so that if I try to
maximize my \textit{expected score}, $\sum P \times \log (P)$, I
have no motive to cheat. Without the logarithm rule, I would maximize
my expected score by assigning all my probability mass to the most
probable outcome. Also, without the logarithm rule, my total score
would be different depending on whether we counted several rounds as
several experiments or as one experiment.


 A simple transform can fix poor calibration by decreasing
discrimination. If you are in the habit of saying
``million-to-one'' on 90 correct and
10 incorrect answers for each hundred questions, we can perfect your
calibration by replacing
``million-to-one'' with
``nine-to-one.'' In contrast,
there's no easy way to increase (successful)
discrimination. If you habitually say
``nine-to-one'' on 90 correct
answers for each hundred questions, I can easily increase your
\textit{claimed} discrimination by replacing
``nine-to-one'' with
``million-to-one.'' But no simple
transform can increase your \textit{actual} discrimination such that
your reply distinguishes 95 correct answers and 5 incorrect answers.
From Yates et al.:\footnote{J. Frank Yates et al., ``Probability Judgment
Across Cultures,'' in Gilovich, Griffin, and
Kahneman, \textit{Heuristics and Biases}, 271--291.\comment{5}} ``Whereas good
calibration often can be achieved by simple mathematical
transformations (e.g., adding a constant to every probability
judgment), good discrimination demands access to solid, predictive
evidence and skill at exploiting that evidence, which are difficult to
find in any real-life, practical situation.'' If you
lack the ability to distinguish truth from falsehood, you can achieve
perfect calibration by confessing your ignorance; but confessing
ignorance will not, of itself, distinguish truth from falsehood.


 We thus dispose of another false stereotype of rationality, that
rationality consists of being humble and modest and confessing
helplessness in the face of the unknown. That's just
the cheater's way out, assigning a 50\% probability to
all yes-or-no questions. Our scoring rule encourages you to do better
if you can. If you are ignorant, confess your ignorance; if you are
confident, confess your confidence. We penalize you for being confident
and wrong, but we also reward you for being confident and right. That
is the virtue of a proper scoring rule.

\hr


 Suppose I flip a coin twenty times. If I believe the coin is fair,
the best prediction I can make is to predict an even chance of heads or
tails on each flip. If I believe the coin is fair, I assign the same
probability to every possible sequence of twenty coinflips. There are
roughly a million (1,048,576) possible sequences of twenty coinflips,
and I have only 1.0 of probability mass to play with. So I assign to
each \textit{individual} possible sequence a probability of
$(1/2)^{20}$---odds of about a million to one; -20
bits or -60 decibels.


 I made an experimental prediction and got a score of -60 decibels!
Doesn't this falsify the hypothesis? Intuitively, no.
We do not flip a coin twenty times and see a random-looking result,
then reel back and say, why, the odds of that are a million to one. But
the odds \textit{are} a million to one against seeing that exact
sequence, as I would discover if I naively predicted the exact same
outcome for the \textit{next} sequence of twenty coinflips.
It's okay to have theories that assign tiny
probabilities to outcomes, so long as no other theory does better. But
if someone used an alternate hypothesis to write down the exact
sequence in a sealed envelope in advance, and she assigned a
probability of 99\%, I would suspect the fairness of the coin. Provided
that she only sealed \textit{one} envelope, and not a million.


 That tells us \textit{what} we ought common-sensically to answer,
but it doesn't say \textit{how} the common-sense answer
arises from the math. To say \textit{why} the common sense is correct,
we need to integrate all that has been said so far into the framework
of Bayesian revision of belief. When we're done,
we'll have a technical understanding of the difference
between a verbal understanding and a technical understanding.

\hr


 Imagine an experiment which produces an integer result between
zero and 99. For example, the experiment might be a particle counter
that tells us how many particles have passed through in a minute. Or
the experiment might be to visit the supermarket on Wednesday, check
the price of a 10 oz bag of crushed walnuts, and write down the last
two digits of the price.


 We are testing several different hypotheses that try to predict
the experimental result. Each hypothesis produces a probability
distribution over all possible results; in this case, the integers
between zero and 99. The possibilities are mutually exclusive, so the
probability mass in the distribution must sum to one (or less); we
cannot predict a 90\% probability of seeing 42 and also a 90\%
probability of seeing 43.


 Suppose there is a precise hypothesis that predicts a 90\% chance
of seeing the result 51. (I.e., the hypothesis is that the supermarket
usually prices walnuts with a price of ``$X$ dollars and
51 cents.'') The precise theory has staked 90\% of
its probability mass on the outcome 51. This leaves 10\% probability
mass remaining to spread over 99 other possible outcomes---all the
numbers between zero and 99 \textit{except} 51. The theory makes no
further specification, so we spread the remaining 10\% probability mass
evenly over 99 possibilities, assigning a probability of 1/990 to each
non-51 result. For ease of writing, we'll approximate
1/990 as 0.1\%.


 This probability distribution is analogous to the
\textit{likelihood} or \textit{conditional probability} of the result
given the hypothesis. Let us call it the \textit{likelihood
distribution} for the hypothesis, our chance of seeing each specified
outcome \textit{if} the hypothesis is true. The likelihood distribution
for a hypothesis H is a function composed of all the conditional
probabilities for $P(0|H) = 0.001$, $P(1|H) = 0.001$,
\ldots~, $P(51|H) = 0.9$, \ldots~, $P(99|H) = 0.001$.


 The precise theory predicts a 90\% probability of seeing 51. Let
there be also a vague theory, which predicts ``a 90\%
probability of seeing a number in the fifties.''


 Seeing the result 51, we do not say the outcome confirms both
theories equally. Both theories made predictions, and both assigned
probabilities of 90\%, and the result 51 confirms both predictions. But
the precise theory has an advantage because it concentrates its
probability mass into a sharper point. If the vague theory makes no
further specification, we count ``a 90\% probability
of seeing a number in the fifties'' as a 9\%
probability of seeing each number between 50 and 59.


 Suppose we started with even odds in favor of the precise theory
and the vague theory---odds of 1:1, or 50\% probability for either
hypothesis being true. After seeing the result 51, what are the
posterior odds of the precise theory being true? The predictions of the
two theories are analogous to their likelihood assignments---the
conditional probability of seeing the result, given that the theory is
true. What is the likelihood ratio between the two theories? The first
theory allocated 90\% probability mass to the \textit{exact} outcome.
The vague theory allocated 9\% probability mass to the exact outcome.
The likelihood ratio is 10:1. So if we started with even 1:1 odds, the
posterior odds are 10:1 in favor of the precise theory. The
differential pressure of the two conditional probabilities pushed our
prior confidence of 50\% to a posterior confidence of about 91\% that
the precise theory is correct. \textit{Assuming} that these are the
only hypotheses being tested, that this is the only evidence under
consideration, and so on.


 Why did the vague theory lose when both theories fit the evidence?
The vague theory is timid; it makes a broad prediction, hedges its
bets, allows many possibilities that would falsify the precise theory.
This is not the virtue of a scientific theory. Philosophers of science
tell us that theories should be bold, and subject themselves willingly
to falsification if their prediction fails.\footnote{Karl R Popper, \textit{The Logic of Scientific Discovery} (New
York: Basic Books, 1959).\comment{6}} Now we
see why. The precise theory concentrates its probability mass into a
sharper point and thereby leaves itself vulnerable to falsification if
the real outcome hits elsewhere; but if the predicted outcome is
correct, precision has a tremendous likelihood advantage over
vagueness.


 The laws of probability theory provide no way to cheat, to make a
vague hypothesis such that any result between 50 and 59 counts for as
much favorable confirmation as the precise theory receives, for that
would require probability mass summing to 900\%. There is no way to
cheat, providing you record your prediction \textit{in advance}, so you
cannot claim afterward that your theory assigns a probability of 90\%
to whichever result arrived. Humans are very fond of making their
predictions afterward, so the social process of science requires an
advance prediction before we say that a result confirms a theory. But
how humans may move in harmony with the way of Bayes, and so wield the
power, is a separate issue from whether the math works. When
we're doing the math, we just take for granted that
likelihood density functions are fixed properties of a hypothesis and
the probability mass sums to 1 and you'd never dream of
doing it any other way.


 You may want to take a moment to visualize that, \textit{if} we
define probability in terms of calibration, Bayes's
Theorem relates the calibrations. Suppose I guess that Theory 1 is 50\%
likely to be true, and I guess that Theory 2 is 50\% likely to be true.
Suppose I am well-calibrated; when I utter the words
``fifty percent,'' the event happens
about half the time. And then I see a result $R$ which would happen
around nine-tenths of the time given Theory 1, and around
nine-hundredths of the time given Theory 2, and I know this is so, and
I apply Bayesian reasoning. If I was perfectly calibrated initially
(despite the poor discrimination of saying 50/50), I will still be
perfectly calibrated (and better discriminated) after I say that my
confidence in Theory 1 is now 91\%. If I repeated this kind of
situation many times, I would be right around ten-elevenths of the time
when I said ``91\%.'' If I reason
using Bayesian rules, and I start from well-calibrated priors, then my
conclusions will also be well-calibrated. This only holds true if we
define probability in terms of calibration! If ``90\%
sure'' is instead interpreted as, say, the strength
of the emotion of surety, there is no reason to expect the posterior
emotion to stand in an exact Bayesian relation to the prior emotion.


 Let the prior odds be ten to one in favor of the vague theory.
Why? Suppose our way of describing hypotheses allows us to either
specify a precise number, or to just specify a first-digit; we can say
``51,''
``63,''
``72,'' or ``in the
fifties/sixties/seventies.'' Suppose we think that
the real answer is about equally liable to be an answer of the first
kind or the second. However, given the problem, there are a hundred
possible hypotheses of the first kind, and only ten hypotheses of the
second kind. So if we think that either \textit{class} of hypotheses
has about an equal prior chance of being correct, we have to spread out
the prior probability mass over ten times as many precise theories as
vague theories. The precise theory that predicts exactly 51 would thus
have one-tenth as much prior probability mass as the vague theory that
predicts a number in the fifties. After seeing 51, the odds would go
from 1:10 in favor of the vague theory to 1:1, even odds for the
precise theory and the vague theory.


 If you look at this carefully, it's exactly what
common sense would expect. You start out uncertain of whether a
phenomenon is the kind of phenomenon that produces exactly the same
result every time, or if it's the kind of phenomenon
that produces a result in the $X$ ties every time. (Maybe the phenomenon
is a price range at the supermarket, if you need some reason to suppose
that 50--59 is an acceptable range but 49--58 isn't.)
You take a single measurement and the answer is 51. Well, that could be
because the phenomenon is exactly 51, or because it's
in the fifties. So the remaining precise theory has the same odds as
the remaining vague theory, which requires that the vague theory must
have started out ten times as probable as that precise theory, since
the precise theory has a sharper fit to the evidence.


 If we just see one number, like 51, it doesn't
change the prior probability that the phenomenon itself was
``precise'' or
``vague.'' But, in effect, it
concentrates all the probability mass of those two \textit{classes} of
hypothesis into a single surviving hypothesis of each class.


 Of course, it is a severe error to say that a \textit{phenomenon}
is precise or vague, a case of what Jaynes calls the Mind Projection
Fallacy.\footnote{Jaynes, \textit{Probability Theory}.\comment{7}} Precision or vagueness is a property of
maps, not territories. Rather we should ask if the price in the
supermarket stays constant or shifts about. A hypothesis of the
``vague'' sort is a good description
of a price that shifts about. A precise map will suit a constant
territory.


 Another example: You flip a coin ten times and see the sequence
\textsc{hhtth:tttth}. Maybe you started out thinking there was a 1\% chance this
coin was fixed. Doesn't the hypothesis
``This coin is fixed to produce
\textsc{hhtth:tttth}'' assign a thousand times the likelihood
mass to the observed outcome, compared to the fair coin hypothesis?
Yes. Don't the posterior odds that the coin is fixed go
to 10:1? No. The 1\% prior probability that ``the coin
is fixed'' has to cover every possible kind of fixed
coin---a coin fixed to produce \textsc{hhtth:tttth}, a coin fixed to produce
\textsc{tthht:hhhht}, etc. The prior probability the coin is fixed to produce
\textsc{hhtth:tttth} is not 1\%, but a thousandth of one percent. Afterward, the
posterior probability the coin is fixed to produce \textsc{hhtth:tttth} is one
percent. Which is to say: You thought the coin was probably fair but
had a one percent chance of being fixed to some random sequence; you
flipped the coin; the coin produced a random-looking sequence; and that
doesn't tell you anything about whether the coin is
fair or fixed. It does tell you, if the coin is fixed, \textit{which}
sequence it is fixed to.


 This parable helps illustrate why Bayesians \textit{must} think
about prior probabilities. There is a branch of statistics, sometimes
called ``orthodox'' or
``classical'' statistics, which
insists on paying attention only to likelihoods. But if you only pay
attention to likelihoods, then eventually some fixed-coin hypothesis
will always defeat the fair coin hypothesis, a phenomenon known as
``overfitting'' the theory to the
data. After thirty flips, the \textit{likelihood} is a billion times as
great for the fixed-coin hypothesis with that sequence, as for the fair
coin hypothesis. Only if the fixed-coin hypothesis (or rather, that
specific fixed-coin hypothesis) is a billion times less probable a
priori can the fixed-coin hypothesis possibly lose to the fair coin
hypothesis.


 If you shake the coin to reset it, and start flipping the coin
\textit{again}, and the coin produces \textsc{hhtth:tttth} \textit{again}, that
is a different matter. That does raise the posterior odds of the
fixed-coin hypothesis to 10:1, even if the starting probability was
only 1\%.


 Similarly, if we perform two successive measurements of the
particle counter (or the supermarket price on Wednesdays), and
\textit{both} measurements return 51, the precise theory wins by odds
of 10:1.


 So the precise theory wins, but the vague theory would still score
better than no theory at all. Consider a third theory, the hypothesis
of zero knowledge or \textit{maximum-entropy distribution}, which makes
equally probable any result between zero and 99. Suppose we see the
result 51. The vague theory produced a better prediction than the
maximum-entropy distribution---assigned a greater likelihood to the
outcome we observed. The vague theory is, literally, better than
nothing. Suppose we started with odds of 1:20 in favor of the
hypothesis of complete ignorance. (Why odds of 1:20? There is only one
hypothesis of complete ignorance, and moreover, it's a
particularly simple and intuitive kind of hypothesis,
Occam's Razor.) After seeing the result of 51,
predicted at 9\% by the vague theory versus 1\% by complete ignorance,
the posterior odds go to 10:20 or 1:2. If we then see another result of
51, the posterior odds go to 10:2 or 83\% probability for the vague
theory, assuming there is no more precise theory under consideration.


 Yet the timidity of the vague theory---its unwillingness to
produce an \textit{exact} prediction and accept falsification on any
other result---renders it vulnerable to the bold, precise theory.
(Providing, of course, that the bold theory correctly guesses the
outcome!) Suppose the prior odds were 1:10:200 for the precise, vague,
and ignorant theories---prior probabilities of 0.5\%, 4.7\%, and 94.8\%
for the precise, vague and ignorant theories. This figure reflects our
prior probability distribution over \textit{classes} of hypotheses,
with the probability mass distributed over entire classes as follows:
50\% that the phenomenon shifts across all digits, 25\% that the
phenomenon shifts around within some decimal bracket, and 25\% that the
phenomenon repeats the same number each time. One hypothesis of
complete ignorance, 10 possible hypotheses for a decimal bracket, 100
possible hypotheses for a repeating number. Thus, prior odds of
1:10:200 for the precise hypothesis 51, the vague hypothesis
``fifties,'' and the hypothesis of
complete ignorance.


 After seeing a result of 51, with assigned probability of 90\%,
9\%, and 1\%, the posterior odds go to 90:90:200 = 9:9:20. After seeing
an additional result of 51, the posterior odds go to 810:81:20, or
89\%, 9\%, and 2\%. The precise theory is now favored over the vague
theory, which in turn is favored over the ignorant theory.


 Now consider a stupid theory, which predicts a 90\% probability of
seeing a result between zero and nine. The stupid theory assigns a
probability of 0.1\% to the actual outcome, 51. If the odds were
initially 1:10:200:10 for the precise, vague, ignorant, and stupid
theories, the posterior odds after seeing 51 once would be 90:90:200:1.
The stupid theory has been falsified (posterior probability of 0.2\%).


 It is possible to have a model so bad that it is worse than
nothing, if the model concentrates its probability mass away from the
actual outcome, makes confident predictions of wrong answers. Such a
hypothesis is so poor that it loses against the hypothesis of complete
ignorance. Ignorance is better than anti-knowledge.

\begin{quote}
{
 \textit{Side note:} In the field of Artificial Intelligence, there
is a sometime fad that praises the glory of randomness. Occasionally an
AI researcher discovers that if they add noise to one of their
algorithms, the algorithm works better. This result is reported with
great enthusiasm, followed by much fulsome praise of the creative
powers of chaos, unpredictability, spontaneity, ignorance of what your
own AI is doing, et cetera. (See The Imagination Engine for an example;
according to their sales literature they sell wounded and dying neural
nets.\footnote{Imagination Engines, Inc., ``The Imagination
Engine{\texttrademark}; or
Imagitron{\texttrademark},'' 2011,
\url{http://www.imagination-engines.com/ie.htm}.\comment{8}}) But how sad is an algorithm if you can
\textit{increase} its performance by injecting entropy into
intermediate processing stages? The algorithm must be so deranged that
some of its work goes into concentrating probability mass \textit{away}
from good solutions. If injecting randomness results in a reliable
improvement, then some aspect of the algorithm must do reliably worse
than random. Only in AI would people devise algorithms
\textit{literally dumber than a bag of bricks}, boost the results
slightly back toward ignorance, and then argue for the healing power of
noise.}
\end{quote}


 Suppose that in our experiment we see the results 52, 51, and 58.
The precise theory gives this conjunctive event a probability of a
thousand to one times 90\% times a thousand to one, while the vaguer
theory gives this conjunctive event a probability of 9\% cubed, which
works out to\,\ldots oh\,\ldots um\,\ldots let's see\,\ldots a
million to one given the precise theory, versus a thousand to one given
the vague theory. Or thereabouts; we are counting rough powers of ten.
Versus a million to one given the zero-knowledge distribution that
assigns an equal probability to all outcomes. Versus a billion to one
given a model worse than nothing, the stupid hypothesis, which claims a
90\% probability of seeing a number less than 10. Using these
approximate numbers, the vague theory racks up a score of -30 decibels
(a probability of 1/1000 for the whole experimental outcome), versus
scores of -60 for the precise theory, -60 for the ignorant theory, and
-90 for the stupid theory. It is not always true that the highest score
wins, because we need to take into account our prior odds of
1:10:200:10, confidences of -23, -13, 0, and -13 decibels. The vague
theory still comes in with the highest total score at -43 decibels. (If
we ignored our prior probabilities, each new experiment would override
the accumulated results of all the previous experiments; we could not
accumulate knowledge. Furthermore, the fixed-coin hypothesis would
always win.)


 As always, we should not be alarmed that even the best theory
still has a low score---recall the parable of the fair coin. Theories
are approximations. In principle we might be able to predict the exact
sequence of coinflips. But it would take better measurement and more
computing power than we're willing to expend. Maybe we
could achieve 60/40 prediction of coinflips, with a good enough model\,\ldots ? We go with the best approximation we have, and try to achieve
good calibration even if the discrimination isn't
perfect.

\hr


 We've conducted our analysis so far under the
rules of Bayesian probability theory, in which there's
no way to have more than 100\% probability mass, and hence no way to
cheat so that any outcome can count as
``confirmation'' of your theory.
Under Bayesian law, play money may not be counterfeited; you only have
so much clay.


 Unfortunately, human beings are not Bayesians. Human beings
bizarrely attempt to \textit{defend} hypotheses, making a deliberate
effort to prove them or prevent disproof. This behavior has no analogue
in the laws of probability theory or decision theory. In formal
probability theory the hypothesis \textit{is}, and the evidence
\textit{is}, and either the hypothesis is confirmed or it is not. In
formal decision theory, an agent may make an effort to investigate some
issue of which the agent is currently uncertain, not knowing whether
the evidence shall go one way or the other. In neither case does one
ever deliberately try to prove an idea, or try to avoid disproving it.
One may \textit{test} ideas of which one is genuinely uncertain, but
not have a ``preferred'' outcome of
the investigation. One may not try to prove hypotheses, nor prevent
their proof. I cannot properly convey just how ridiculous the notion
would be, to a true Bayesian; there are not even words in
Bayes-language to describe the mistake\,\ldots


 For every expectation of evidence there is an equal and opposite
expectation of counterevidence. If $A$ is evidence in favor of $B$, then
not-$A$ \textit{must} be evidence in favor of not-$B$. The strengths of the
evidences may not be equal; rare but strong evidence in one direction
may be balanced by common but weak evidence in the other direction. But
it is not possible for both $A$ and not-$A$ to be evidence in favor of $B$.
That is, it's not possible under the laws of
probability theory.

{
 Humans often seem to want to have their cake and eat it too.
Whichever result we witness is the one that proves our theory. As Spee,
the priest in Conservation of Expected Evidence, put it,
``The investigating committee would feel disgraced if
it acquitted a woman; once arrested and in chains, she has to be
guilty, by fair means or foul.''\footnote{Friedrich Spee, \textit{Cautio Criminalis; or, A Book on Witch
Trials}, ed. and trans. Marcus Hellyer, Studies in Early Modern German
History (1631; Charlottesville: University of Virginia Press, 2003).\comment{9}}}


 The way human psychology seems to work is that first we see
something happen, and then we try to argue that it matches whatever
hypothesis we had in mind beforehand. Rather than conserved probability
mass, to distribute over advance \textit{predictions}, we have a
feeling of \textit{compatibility}{}---the degree to which the
explanation and the event seem to
``fit.''
``Fit'' is not conserved. There is
no equivalent of the rule that probability mass must sum to one. A
psychoanalyst may explain any possible behavior of a patient by
constructing an appropriate structure of
``rationalizations'' and
``defenses''; it fits, therefore it
must be true.


 Now consider the fable told in Fake Explanations---the students
seeing a radiator, and a metal plate next to the radiator. The students
would never predict in advance that the side of the plate near the
radiator would be cooler. Yet, seeing the fact, they managed to make
their explanations ``fit.'' They
lost their precious chance at bewilderment, to realize that their
models did not predict the phenomenon they observed. They sacrificed
their ability to be more confused by fiction than by truth. And they
did not realize ``heat induction, blah blah, therefore
the near side is cooler'' is a vague and verbal
prediction, spread across an enormously wide range of possible values
for specific measured temperatures. Applying equations of diffusion and
equilibrium would give a \textit{sharp} prediction for possible joint
values. It might not specify the \textit{first} values you measured,
but when you knew a few values you could generate a sharp prediction
for the rest. The score for the entire experimental outcome would be
far better than any less precise alternative, especially a vague and
verbal prediction.

\hr


 You now have a \textit{technical} explanation of the difference
between a verbal explanation and a technical explanation. It is a
technical explanation because it enables you to calculate
\textit{exactly how technical} an explanation is. Vague hypotheses may
be so vague that only a superhuman intelligence could calculate exactly
how vague. Perhaps a sufficiently huge intelligence could extrapolate
every possible experimental result, and extrapolate every possible
verdict of the vague guesser for how well the vague hypothesis
``fit,'' and then renormalize the
``fit'' distribution into a
likelihood distribution that summed to one. But in principle one can
still calculate exactly how vague is a vague hypothesis. The
calculation is just not computationally tractable, the way that
calculating airplane trajectories via quantum mechanics is not
computationally tractable.


 I hold that everyone needs to learn at least one technical
subject: physics, computer science, evolutionary biology, Bayesian
probability theory, or \textit{something}. Someone with \textit{no}
technical subjects under their belt has no referent for what it means
to ``explain'' something. They may
think ``All is Fire'' is an
explanation, as did the Greek philosopher Heraclitus. Therefore do I
advocate that Bayesian probability theory should be taught in high
school. Bayesian probability theory is the sole piece of math I know
that is accessible at the high school level, and that permits a
\textit{technical} understanding of a subject matter---the dynamics of
belief---that is an everyday real-world domain and has emotionally
meaningful consequences. Studying Bayesian probability would give
students a referent for what it means to
``explain'' something.


 Too many academics think that being
``technical'' means speaking in dry
polysyllabisms. Here's a
``technical'' explanation of
technical explanation:

\begin{quote}
{
 The equations of probability theory favor hypotheses that strongly
predict the exact observed data. Strong models boldly concentrate their
probability density into precise outcomes, making them falsifiable if
the data hits elsewhere, and giving them tremendous likelihood
advantages over models less bold, less precise. Verbal explanation runs
on psychological evaluation of unconserved post facto compatibility
instead of conserved ante facto probability density. And verbal
explanation does not paint sharply detailed pictures, implying a smooth
likelihood distribution in the vicinity of the data.}
\end{quote}


 Is this satisfactory? No. Hear the impressive and weighty
sentences, resounding with the dull thud of expertise. See the hapless
students, writing those sentences on a sheet of paper. Even after the
listeners hear the ritual words, they can perform no calculations.
\textit{You} know the math, so the words are meaningful. You can
perform the calculations after hearing the impressive words, just as
you could have done before. But what of one who did not see any
calculations performed? What new skills have they gained from that
``technical'' lecture, save the
ability to recite fascinating words?


 ``Bayesian'' sure is a
fascinating word, isn't it? Let's get
it out of our systems: Bayes Bayes Bayes Bayes Bayes Bayes Bayes Bayes
Bayes\,\ldots


 The sacred syllable is meaningless, except insofar as it tells
someone to apply math. Therefore the one who hears must already know
the math.


 Conversely, if you know the math, you can be as silly as you like,
and still technical.


 We thus dispose of yet another stereotype of rationality, that
rationality consists of sere formality and humorless solemnity. What
has that to do with the problem of distinguishing truth from falsehood?
What has that to do with attaining the map that reflects the territory?
A scientist worthy of a lab coat should be able to make original
discoveries while wearing a clown suit, or give a lecture in a high
squeaky voice from inhaling helium. It is written nowhere in the math
of probability theory that one may have no fun. The blade that cuts
through to the correct answer has no dignity or silliness of itself,
though it may fit the hand of a silly wielder.

\hr


 A \textit{useful} model isn't just something you
know, as you know that an airplane is made of atoms. A useful model is
knowledge you can compute in reasonable time to predict real-world
events you know how to observe. Maybe someone will find that, using a
model that violates Conservation of Momentum just a little, you can
compute the aerodynamics of the 747 much more \textit{cheaply} than if
you insist that momentum is exactly conserved. So if
you've got two computers competing to produce the best
prediction, it might be that the best prediction comes from the model
that violates Conservation of Momentum. This doesn't
mean that the 747 violates Conservation of Momentum in real life.
Neither model uses individual atoms, but that doesn't
imply the 747 is not made of atoms. Physicists use different models to
predict airplanes and particle collisions because it would be too
expensive to compute the airplane particle by particle.


 You would prove the 747 is made of atoms with experimental data
that the aerodynamic models couldn't handle; for
example, you would train a scanning tunneling microscope on a section
of wing and look at the atoms. Similarly, you could use a finer
measuring instrument to discriminate between a 747 that \textit{really}
disobeyed Conservation of Momentum like the cheap approximation
predicted, versus a 747 that obeyed Conservation of Momentum like
underlying physics predicted. The winning theory is the one that best
predicts all the experimental predictions together. Our Bayesian
scoring rule gives us a way to combine the results of \textit{all} our
experiments, even experiments that use different methods.


 Furthermore, the atomic theory allows, embraces, and in some sense
mandates the aerodynamic model. By thinking abstractly about the
assumptions of atomic theory, we realize that the aerodynamic model
ought to be a good (and much cheaper) approximation of the atomic
theory, and so the atomic theory supports the aerodynamic model, rather
than competing with it. A successful theory can embrace many models for
different domains, so long as the models are acknowledged as
approximations, and in each case the model is compatible with (or
ideally mandated by) the underlying theory.


 Our \textit{fundamental} physics---quantum mechanics, the standard
family of particles, and relativity---is a theory that embraces an
\textit{enormous} family of models for macroscopic physical phenomena.
There is the physics of liquids, and solids, and gases; yet this does
not mean that there are \textit{fundamental} things in the world that
have the intrinsic property of liquidity.

\begin{quote}

 Apparently there is colour, apparently sweetness, apparently
bitterness, actually there are only atoms and the void.

{\raggedleft
 {}---Democritus, 420 BCE, from Robinson and
Groves\footnote{quoted in Dave Robinson and Judy Groves, \textit{Philosophy
for Beginners}, 1st ed. (Cambridge: Icon Books, 1998).\comment{10}}
\par}
\end{quote}

\hr



 In arguing that a ``technical''
theory should be defined as a theory that sharply concentrates
probability into specific advance predictions, I am setting an
extremely high standard of strictness. We have seen that a vague theory
\textit{can} be better than nothing. A vague theory can win out over
the hypothesis of ignorance, if there are no precise theories to
compete against it.


 There is an enormous family of models belonging to the central
underlying theory of life and biology, the underlying theory that is
sometimes called neo-Darwinism, natural selection, or evolution. Some
models in evolutionary theory are quantitative. The way in which DNA
encodes proteins is redundant; two different DNA sequences can code for
exactly the same protein. There are four DNA bases
\{A,T,C,G\}
and 64 possible combinations of three DNA bases. But those 64 possible
codons describe only 20 amino acids plus a stop code. Genetic drift
ought therefore to produce non-functional changes in species genomes,
through mutations which by chance become fixed in the gene pool. The
accumulation rate of non-functional differences between the genomes of
two species with a common ancestor depends on such parameters as the
number of generations elapsed and the intensity of selection at that
genetic locus. That's an example of a member of the
family of evolutionary models that produces quantitative predictions.
There are also disequilibrium allele frequencies under selection,
stable equilibria for game-theoretical strategies, sex ratios, etc.

{
 This all comes under the heading of ``fascinating
words.'' Unfortunately, there are certain religious
factions that spread gross disinformation about evolutionary theory. So
I emphasize that many models within evolutionary theory make
quantitative predictions that are experimentally confirmed, and that
such models are far more than sufficient to demonstrate that, e.g.,
humans and chimpanzees are related by a common ancestor. If
you've been victimized by creationist
disinformation---that is, if you've heard any
suggestion that evolutionary theory is controversial or untestable or
``just a theory'' or non-rigorous or
non-technical or in any way not confirmed by an unimaginably huge mound
of experimental evidence---I recommend reading the \textit{TalkOrigins
FAQ}\footnote{TalkOrigins Foundation, ``Frequently Asked
Questions about Creationism and Evolution,''
\url{http://www.talkorigins.org/origins/faqs-qa.html}.\comment{11}} and studying evolutionary biology with math.}


 But imagine going back in time to the nineteenth century, when the
theory of natural selection had only just been discovered by Charles
Darwin and Alfred Russel Wallace. Imagine evolutionism just after its
birth, when the theory had nothing remotely like the modern-day body of
quantitative models and great heaping mountains of experimental
evidence. There was no way of knowing that humans and chimpanzees would
be discovered to have 95\% shared genetic material. No one knew that
DNA existed. Yet even so, scientists flocked to the new theory of
natural selection. And later it turned out that there \textit{was} a
precisely copied genetic material with the potential to mutate, that
humans and chimps were provably related, etc.


 So the very strict, very high standard that I proposed for a
``technical'' theory is too strict.
Historically, it \textit{has} been possible to successfully
discriminate true theories from false theories, based on predictions of
the sort I called ``vague.'' Vague
predictions of, say, 80\% confidence, can build up a huge advantage
over alternate hypotheses, given enough experiments. Perhaps a theory
of this kind, producing predictions that are not precisely detailed but
are nonetheless correct, could be called
``semitechnical''?


 But surely technical theories are more reliable than semitechnical
theories? Surely technical theories should take precedence, command
greater respect? Surely physics, which produces exceedingly exact
predictions, is in some sense better confirmed than evolutionary
theory? Not implying that evolutionary theory is wrong, of course; but
however vast the mountains of evidence favoring evolution, does not
physics go one better through vast mountains of \textit{precise}
experimental confirmation? Observations of neutron stars confirm the
predictions of General Relativity to within one part in a hundred
trillion $(10^{14})$. What does evolutionary theory have
to match that?

{
 Daniel Dennett once said that measured by the simplicity of the
theory and the amount of complexity it explained, Darwin had the single
greatest idea in the history of time.\footnote{Daniel C. Dennett, \textit{Darwin's Dangerous
Idea: Evolution and the Meanings of Life} (Simon \& Schuster, 1995).\comment{12}}}


 Once there was a conflict between nineteenth century physics and
nineteenth century evolutionism. According to the best physical models
then in use, the Sun could not have been burning very long. Three
thousand years on chemical energy, or 40 million years on gravitational
energy. There was no energy source known to nineteenth century physics
that would permit longer burning. Nineteenth century physics was not
\textit{quite} as powerful as modern physics---it did not have
predictions accurate to within one part in $10^{14}$. But
nineteenth century physics still had the mathematical character of
modern physics, a discipline whose models produced detailed, precise,
quantitative predictions. Nineteenth century evolutionary theory was
wholly semitechnical, without a scrap of quantitative modeling. Not
even Mendel's experiments with peas were then known.
And yet it did seem likely that evolution would require longer than a
paltry 40 million years in which to operate---hundreds of millions,
even billions of years. The antiquity of the Earth was a vague and
semitechnical prediction, of a vague and semitechnical theory. In
contrast, the nineteenth century physicists had a precise and
quantitative model, which through formal calculation produced the
precise and quantitative dictum that the Sun simply could not have
burned that long.

\begin{quote}

 The limitations of geological periods, imposed by physical
science, cannot, of course, disprove the hypothesis of transmutation of
species; but it does seem sufficient to disprove the doctrine that
transmutation has taken place through ``descent with
modification by natural selection.''

{\raggedleft
 {}---Lord Kelvin, from Lyle Zapato\footnote{quoted in Lyle Zapato, ``Lord Kelvin
Quotations,'' 2008,
\url{http://zapatopi.net/kelvin/quotes/}.\comment{13}}
 \par}
\end{quote}



 History records who won.


 The moral? If you can give 80\% confident advance predictions on
yes-or-no questions, it may be a
``vague'' theory; it may be wrong
one time out of five; but you can still build up a heck of a huge
scoring lead over the hypothesis of ignorance. Enough to confirm a
theory, if there are no better competitors. Reality is consistent;
every \textit{correct} theory about the universe is compatible with
every other correct theory. Imperfect maps can conflict, but there is
only one territory. Nineteenth century evolutionism might have been a
semitechnical discipline, but it was still correct (as we now know) and
by far the best explanation (even in that day). Any conflict between
evolutionism and another well-confirmed theory had to reflect some kind
of anomaly, a mistake in the assertion that the two theories were
incompatible. Nineteenth century physics couldn't model
the dynamics of the Sun---they didn't know about
nuclear reactions. They could not show that their understanding of the
Sun was correct \textit{in technical detail}, nor calculate from a
\textit{confirmed} model of the Sun to determine how long the Sun had
existed. So in retrospect, we can say something like:
``There was room for the possibility that nineteenth
century physics just didn't understand the
Sun.''


 But that is hindsight. The real lesson is that, even though
nineteenth century physics was both precise and quantitative, it
didn't automatically dominate the semitechnical theory
of nineteenth century evolutionism. The theories were \textit{both}
well-supported. They were \textit{both} correct in the domains over
which they were generalized. The apparent conflict between them was an
anomaly, and the anomaly turned out to stem from the incompleteness and
incorrect application of nineteenth century physics, not the
incompleteness and incorrect application of nineteenth century
evolutionism. But it would be futile to compare the mountain of
evidence supporting the one theory, versus the mountain of evidence
supporting the other. Even in that day, both mountains were too large
to suppose that either theory was simply mistaken. Mountains of
evidence that large cannot be set to compete, as if one falsifies the
other. You must be applying one theory incorrectly, or applying a model
outside the domain it predicts well.


 So you shouldn't \textit{necessarily} sneer at a
theory just because it's semitechnical. Semitechnical
theories can build up high enough scores, compared to every available
alternative, that you know the theory is at least approximately
correct. Someday the semitechnical theory may be replaced or even
falsified by a more precise competitor, but that's true
even of technical theories. Think of how Einstein's
General Relativity devoured Newton's theory of
gravitation.


 But the correctness of a semitechnical theory---a theory that
currently has no precise, computationally tractable models testable by
feasible experiments---can be a lot less cut-and-dried than the
correctness of a technical theory. It takes skill, patience, and
examination to distinguish good semitechnical theories from theories
that are just plain confused. This is not something that humans do well
by instinct, which is why we have Science.


 People eagerly jump the gun and seize on any available reason to
reject a disliked theory. That is why I gave the example of nineteenth
century evolutionism, to show why one should not be too quick to reject
a ``non-technical'' theory out of
hand. By the moral customs of science, nineteenth century evolutionism
was guilty of more than one sin. Nineteenth century evolutionism made
no quantitative predictions. It was not readily subject to
falsification. It was largely an explanation of what had already been
seen. It lacked an underlying mechanism, as no one then knew about DNA.
It even contradicted the nineteenth century laws of physics. Yet
natural selection was such an \textit{amazingly good} post facto
explanation that people flocked to it, and they turned out to be right.
Science, as a human endeavor, requires advance prediction. Probability
theory, as math, does not distinguish between post facto and advance
prediction, because probability theory assumes that probability
distributions are fixed properties of a hypothesis.


 The rule about advance prediction is a rule of the social process
of science---a moral custom and not a theorem. The moral custom exists
to prevent human beings from making human mistakes that are hard to
even describe in the language of probability theory, like tinkering
after the fact with what you claim your hypothesis predicts. People
concluded that nineteenth century evolutionism was an excellent
explanation, even if it was post facto. That reasoning \textit{was
correct as probability theory}, which is why it \textit{worked} despite
all scientific sins. Probability theory is math. The social process of
science is a set of legal conventions to keep people from cheating on
the math.


 Yet it is also true that, compared to a \textit{modern-day}
evolutionary theorist, evolutionary theorists of the late nineteenth
and early twentieth century often went sadly astray. Darwin, who was
bright enough to invent the theory, got an amazing amount right. But
Darwin's successors, who were only bright enough to
accept the theory, misunderstood evolution frequently and seriously.
The usual process of science was then required to correct their
mistakes. It is incredible how few errors of reasoning
Darwin\footnote{Charles Darwin, \textit{On the Origin of Species by Means of
Natural Selection; or, The Preservation of Favoured Races in the
Struggle for Life}, 1st ed. (London: John Murray, 1859),
\url{http://darwin-online.org.uk/content/frameset?viewtype=text\&itemID=F373\&pageseq=1};
Charles Darwin, \textit{The Descent of Man, and Selection in Relation
to Sex}, 2nd ed. (London: John Murray, 1874),
\url{http://darwin-online.org.uk/content/frameset?itemID=F944\&viewtype=text\&pageseq=1}.\comment{14}} made in \textit{The Origin of Species} and
\textit{The Descent of Man}, compared to they who followed.


 That is also a hazard of a semitechnical theory. Even after the
flash of genius insight is confirmed, merely average scientists may
fail to apply the insights properly in the absence of formal models. As
late as the 1960s biologists spoke of evolution working
``for the good of the species,'' or
suggested that individuals would restrain their reproduction to prevent
species overpopulation of a habitat. The best evolutionary theorists
knew better, but average theorists did not.\footnote{Williams, \textit{Adaptation and Natural Selection}.\comment{15}}


 So it is \textit{far} better to have a technical theory than a
semitechnical theory. Unfortunately, Nature is not always so kind as to
render Herself describable by neat, formal, \textit{computationally
tractable} models, nor does She always provide Her students with
measuring instruments that can directly probe Her phenomena. Sometimes
it is only a matter of time. Nineteenth century evolutionism was
semitechnical, but later came the math of population genetics, and
eventually DNA sequencing. Nature will not always give you a phenomenon
that you can describe with technical models fifteen seconds after you
have the basic insight.


 Yet the cutting edge of science, the \textit{controversy}, is most
often about a semitechnical theory, or nonsense posing as a
semitechnical theory. By the time a theory achieves technical status,
it is usually no longer controversial (among scientists). So the
question of how to distinguish good semitechnical theories from
nonsense is very important to scientists, and it is not as easy as
dismissing out of hand any theory that is not technical. To the end of
distinguishing truth from falsehood exists the entire discipline of
rationality. The art is not reducible to a checklist, or at least, no
checklist that an average scientist can apply reliably after an hour of
training. If it was that simple we wouldn't need
science.

\hr


 Why do you pay attention to scientific controversies? Why graze
upon such sparse and rotten feed as the media offers, when there are so
many solid meals to be found in textbooks? Textbook science is
beautiful! Textbook science is \textit{comprehensible}, unlike mere
fascinating words that can never be truly beautiful. Fascinating words
have no power, nor yet any meaning, without the math. The fascinating
words are not knowledge but the illusion of knowledge, which is why it
brings so little satisfaction to know that ``gravity
results from the curvature of spacetime.'' Science is
not in the fascinating words, though it's all
you'll ever read as breaking news.


 There can be justification for following a scientific controversy.
You could be an expert in that field, in which case that scientific
controversy is your proper meat. Or the scientific controversy might be
something you need to know \textit{now}, because it affects your life.
Maybe it's the nineteenth century, and
you're gazing lustfully at a member of the appropriate
sex wearing a nineteenth century bathing suit, and you need to know
whether your sexual desire comes from a psychology constructed by
natural selection, or is a temptation placed in you by the Devil to
lure you into hellfire.


 It is not wholly impossible that we shall happen upon a scientific
controversy that affects us, and find that we have a burning and urgent
need for the correct answer. I shall therefore discuss some of the
warning signs that historically distinguished vague hypotheses that
later turned out to be unscientific gibberish, from vague hypotheses
that later graduated to confirmed theories. Just remember the
historical lesson of nineteenth century evolutionism, and resist the
temptation to fail every theory that misses a single item on your
checklist. It is not my intention to give people another excuse to
dismiss good science that discomforts them. If you apply stricter
criteria to theories you dislike than theories you like (or vice
versa!), then every additional nit you learn how to pick, every new
logical flaw you learn how to detect, makes you that much stupider.
Intelligence, to be useful, must be used for something other than
defeating itself.

\hr

{
 One of the classic signs of a poor hypothesis is that it must
expend great effort in avoiding falsification---elaborating reasons why
the hypothesis is compatible with the phenomenon, even though the
phenomenon didn't behave as expected. Carl Sagan gives
the example of someone who claims that a dragon lives in their garage.
Sagan originally drew the lesson that poor hypotheses need to do fast
footwork to avoid falsification---to maintain an appearance of
``fit.''\footnote{Carl Sagan, \textit{The Demon-Haunted World: Science as a
Candle in the Dark}, 1st ed. (New York: Random House, 1995).\comment{16}}}


 I would point out that the claimant obviously has a good model of
the situation \textit{somewhere} in their head, because they can
predict, in advance, exactly which excuses they're
going to need. To a Bayesian, a hypothesis isn't
something you assert in a loud, emphatic voice. A hypothesis is
something that controls your \textit{anticipations}, the probabilities
you assign to future experiences. That's what a
probability \textit{is}, to a Bayesian---that's what
you score, that's what you calibrate. So while our
claimant may say loudly, emphatically, and honestly that they
\textit{believe} there's an invisible dragon in the
garage, they do not \textit{anticipate} there's an
invisible dragon in the garage---they anticipate exactly the same
experience as the skeptic.


 When I judge the predictions of a hypothesis, I ask which
experiences I would anticipate, not which facts I would believe.


 The flip side:


 I recently argued with a friend of mine over a question of
evolutionary theory. My friend alleged that the clustering of changes
in the fossil record (apparently, there are periods of comparative
stasis followed by comparatively sharp changes; itself a controversial
observation known as ``punctuated
equilibrium'') showed that there was something wrong
with our understanding of speciation. My friend thought that there was
some unknown force at work---not supernatural, but some natural
consideration that standard evolutionary theory didn't
take into account. Since my friend didn't give a
specific competing hypothesis that produced better predictions, his
thesis had to be that the standard evolutionary model was
\textit{stupid} with respect to the data---that the standard model made
a specific prediction that was wrong; that the model did worse than
complete ignorance or some other default competitor.


 At first I fell into the trap; I accepted the implicit assumption
that the standard model predicted smoothness, and based my argument on
my recollection that the fossil record changes weren't
as sharp as he claimed. He challenged me to produce an evolutionary
intermediate between \textit{Homo erectus} and \textit{Homo sapiens}; I
googled and found \textit{Homo heidelbergensis}. He congratulated me
and acknowledged that I had scored a major point, but still insisted
that the changes were too sharp, and not steady enough. I started to
explain why I thought a pattern of uneven change \textit{could} arise
from the standard model: environmental selection pressures might not be
constant\,\ldots ``Aha!'' my friend
said, ``you're making your excuses in
advance.''


 But suppose that the fossil record instead showed a smooth and
gradual set of changes. Might my friend have argued that the standard
model of evolution as a chaotic and noisy process could not account for
such smoothness? If it is a scientific sin to claim post facto that our
beloved hypothesis predicts the data, should it not be equally a sin to
claim post facto that the competing hypothesis is stupid on the data?


 If a hypothesis has a \textit{purely} technical model, there is no
trouble; we can compute the prediction of the model formally, without
informal variables to provide a handle for post facto meddling. But
what of semitechnical theories? Obviously a semitechnical theory must
produce some good advance predictions about \textit{something}, or else
why bother? But \textit{after} the theory is semi-confirmed, can the
detractors claim that the data show a problem with the semitechnical
theory, when the ``problem'' is
constructed post facto? At the least the detractors must be very
specific about what data a confirmed model predicts stupidly, and why
the confirmed model must make (post facto) that stupid prediction. How
sharp a change is ``too sharp,''
quantitatively, for the standard model of evolution to permit? Exactly
how much steadiness do you think the standard model of evolution
predicts? How do you know? Is it too late to say that, after
you've seen the data?


 When my friend accused me of making excuses, I paused and asked
myself which excuses I anticipated needing to make. I decided that my
current grasp of evolutionary theory didn't say
anything about whether the rate of evolutionary change should be
intermittent and jagged, or smooth and gradual. If I
hadn't seen the graph in advance, I could not have
predicted it. (Unfortunately, I rendered even that verdict after seeing
the data\,\ldots) Maybe there are models in the evolutionary family that
would make advance predictions of steadiness or variability, but if so,
I don't know about them. More to the point, my friend
didn't know either.


 It is not always wise to ask the opponents of a theory what their
competitors predict. Get the theory's predictions from
the theory's best advocates. Just make sure to write
down their predictions in advance. Yes, sometimes a
theory's advocates try to make the theory
``fit'' evidence that plainly
doesn't fit. But if you find yourself wondering what a
theory predicts, ask first among the theory's
advocates, and afterward ask the detractors to cross-examine.


 Furthermore: Models may include noise. If we hypothesize that the
data are trending slowly and steadily upward, but our measuring
instrument has an error of 5\%, then it does no good to point to a data
point that dips below the previous data point, and shout triumphantly,
``See! It went down! Down down down! And
don't tell me why your theory fits the dip;
you're just making excuses!'' Formal,
technical models often incorporate explicit error terms. The error term
spreads out the likelihood density, decreases the
model's precision and reduces the
theory's score, but the Bayesian scoring rule still
governs. A technical model can allow mistakes, and make mistakes, and
still do better than ignorance. In our supermarket example, even the
precise hypothesis of 51 still bets only 90\% of its probability mass
on 51; the precise hypothesis claims only that 51 happens nine times
out of ten. Ignoring nine 51s, pointing at one case of 82, and crowing
in triumph, does not a refutation make. That's not an
excuse, it's an explicit advance prediction of a
technical model.


 The error term makes the
``precise'' theory vulnerable to a
superprecise alternative that predicted the 82. The standard model
would also be vulnerable to a precisely ignorant model that predicted a
60\% chance of 51 on the round where we saw 82, spreading out the
likelihood more entropically on that particular error. No matter how
good the theory, science always has room for a higher-scoring
competitor. But if you \textit{don't} present a better
alternative, if you try only to show that an accepted theory is
\textit{stupid} with respect to the data, that scientific endeavor may
be \textit{more} demanding than just replacing the old theory with a
new one.


 Astronomers recorded the unexplained perihelion advance of
Mercury, unaccounted for under Newtonian physics---or rather, Newtonian
physics predicted 5,557 seconds of arc per century, where the observed
amount was 5,600.\footnote{Kevin Brown, \textit{Reflections On Relativity} (Raleigh, NC:
printed by author, 2011), 405-414,
\url{http://www.mathpages.com/rr/rrtoc.htm}.\comment{17}} But should the scientists of that
day have junked Newtonian gravitation based on such small, unexplained
counterevidence? What would they have used instead? Eventually,
Newton's theory of gravitation \textit{was} set aside,
after Einstein's General Relativity precisely explained
the orbital discrepancy of Mercury and also made successful advance
predictions. But there was no way to know \textit{in advance} that this
was how things would turn out.


 In the nineteenth century there was a persistent anomaly in the
orbit of Uranus. People said, ``Maybe
Newton's law starts to fail at long
distances.'' Eventually some bright fellows looked at
the anomaly and said, ``Could this be an unknown outer
planet?'' Urbain Le Verrier and John Couch Adams
independently did some scribbling and figuring, using
Newton's standard theory---and predicted
Neptune's location to within one degree of arc,
dramatically \textit{confirming} Newtonian
gravitation.\footnote{Ibid., 405-414.\comment{18}}


 Only \textit{after} General Relativity precisely produced the
perihelion advance of Mercury did we \textit{know} Newtonian
gravitation would never explain it.

\hr


 In the Intuitive Explanation we saw how Karl
Popper's insight that falsification is stronger than
confirmation translates into a Bayesian truth about likelihood ratios.
Popper erred in thinking that falsification was \textit{qualitatively
different} from confirmation; both are governed by the same Bayesian
rules. But Popper's philosophy reflected an important
truth about a quantitative difference between falsification and
confirmation.

\begin{quotation}

 Popper was profoundly impressed by the differences between the
allegedly ``scientific'' theories of
Freud and Adler and the revolution effected by
Einstein's theory of relativity in physics in the first
two decades of this century. The main difference between them, as
Popper saw it, was that while Einstein's theory was
highly ``risky,'' in the sense that
it was possible to deduce consequences from it which were, in the light
of the then dominant Newtonian physics, highly improbable (e.g., that
light is deflected towards solid bodies---confirmed by
Eddington's experiments in 1919), and which would, if
they turned out to be false, falsify the whole theory, nothing could,
even in principle, falsify psychoanalytic theories. These latter,
Popper came to feel, have more in common with primitive myths than with
genuine science. That is to say, he saw that what is apparently the
chief source of strength of psychoanalysis, and the principal basis on
which its claim to scientific status is grounded, viz. its capability
to accommodate, and explain, every possible form of human behaviour, is
in fact a critical weakness, for it entails that it is not, and could
not be, genuinely predictive. Psychoanalytic theories by their nature
are insufficiently precise to have negative implications, and so are
immunised from experiential falsification\,\ldots


 Popper, then, repudiates induction, and rejects the view that it
is the characteristic method of scientific investigation and inference,
and substitutes falsifiability in its place. It is easy, he argues, to
obtain evidence in favour of virtually any theory, and he consequently
holds that such ``corroboration,''
as he terms it, should count scientifically only if it is the positive
result of a genuinely ``risky''
prediction, which might conceivably have been false. For Popper, a
theory is scientific only if it is refutable by a conceivable event.
Every genuine test of a scientific theory, then, is logically an
attempt to refute or to falsify it\,\ldots

{
 Every genuine scientific theory then, in Popper's
view, is prohibitive, in the sense that it forbids, by implication,
particular events or occurrences.\footnote{Stephen Thornton, ``Karl
Popper,'' in \textit{The Stanford Encyclopedia of
Philosophy}, Winter 2002, ed. Edward N. Zalta (Stanford University),
\url{http://plato.stanford.edu/archives/win2002/entries/popper/}.\comment{19}}}
\end{quotation}


 On Popper's philosophy, the strength of a
scientific theory is not how much it explains, but how much it
\textit{doesn't} explain. The virtue of a scientific
theory lies not in the outcomes it \textit{permits}, but in the
outcomes it \textit{prohibits}. Freud's theories, which
seemed to explain everything, \textit{prohibited} nothing.


 Translating this into Bayesian terms, we find that the more
outcomes a model \textit{prohibits}, the more probability density the
model concentrates in the remaining, permitted outcomes. The more
outcomes a theory prohibits, the greater the knowledge-content of the
theory. The more daringly a theory exposes itself to falsification, the
more definitely it tells you which experiences to anticipate.


 A theory that can explain \textit{any} experience corresponds to a
hypothesis of complete ignorance---a uniform distribution with
probability density spread evenly over every possible outcome.

\hr


 \textit{Phlogiston} was the eighteenth century's
answer to the Elemental Fire of the Greek alchemists. You
couldn't use phlogiston theory to predict the outcome
of a chemical transformation---first you looked at the result, then you
used phlogiston to explain it. Phlogiston theory was infinitely
flexible; a disguised hypothesis of zero knowledge. Similarly, the
theory of \textit{vitalism} doesn't explain how the
hand moves, nor tell you what transformations to expect from organic
chemistry; and vitalism certainly permits no quantitative
calculations.


 The flip side:


 Beware of checklist thinking: Having a \textit{sacred} mystery, or
a mysterious answer, is not the same as refusing to explain something.
Some elements in our physics are taken as
``fundamental,'' not yet further
reduced or explained. But these fundamental elements of our physics are
governed by clearly defined, mathematically simple, formally computable
causal rules.


 Occasionally some crackpot objects to modern physics on the
grounds that it does not provide an ``underlying
mechanism'' for a mathematical law currently treated
as fundamental. (Claiming that a mathematical law lacks an
``underlying mechanism'' is one of
the entries on the \textit{Crackpot Index} by John
Baez.\footnote{John Baez, ``The Crackpot
Index,'' 1998,
\url{http://math.ucr.edu/home/baez/crackpot.html}.\comment{20}}) The ``underlying
mechanism'' the crackpot proposes in answer is vague,
verbal, and yields no increase in predictive power---otherwise we would
not classify the claimant as a crackpot.


 Our current physics makes the electromagnetic field fundamental,
and refuses to explain it further. But the
``electromagnetic field'' is a
fundamental governed by clear mathematical rules, with no properties
outside the mathematical rules, subject to formal computation to
describe its causal effect upon the world. Someday someone may suggest
improved math that yields better predictions, but I would not indict
the current model on grounds of mysteriousness. A theory that includes
\textit{fundamental elements} is not the same as a theory that contains
\textit{mysterious elements}.


 Fundamentals should be simple.
``Life'' is not a good fundamental,
``oxygen'' is a good fundamental,
and ``electromagnetic field'' is a
better fundamental. Life might look simple to a
vitalist---it's the simple, magical ability of your
muscles to move under your mental direction. Why
shouldn't life be explained by a simple, magical
fundamental substance like \textit{élan vital}? But phenomena that seem
\textit{psychologically} very simple---little dots of light in the sky,
orangey-bright hot flame, flesh moving under mental direction---often
conceal vast depths of underlying complexity. The proposition that life
is a complex phenomenon may seem incredible to the vitalist, staring at
a blankly opaque mystery with no obvious handles; but yes, Virginia,
there is underlying complexity. The criterion of simplicity that is
relevant to Occam's Razor is \textit{mathematical} or
\textit{computational} simplicity. Once we render down our model into
mathematically simple fundamental elements, not in themselves sharing
the mysterious qualities of the mystery, interacting in clearly defined
ways to produce the formerly mysterious phenomenon as a detailed
prediction, that is as non-mysterious as humanity has ever figured out
how to make anything.

\hr


 Many people in this world believe that after dying they will face
a stern-eyed fellow named St. Peter, who will examine their actions in
life and accumulate a score for morality. Presumably St.
Peter's scoring rule is unique and invariant under
trivial changes of perspective. Unfortunately, believers cannot obtain
a quantitative, precisely computable specification of the scoring rule,
which seems rather unfair.


 The religion of \textit{Bayesianity} holds that your eternal fate
depends on the probability judgments you made in life. Unlike lesser
faiths, Bayesianity can give a quantitative, precisely computable
specification of how your eternal fate is determined.


 Our proper Bayesian scoring rule provides a way to accumulate
scores across experiments, and the score is invariant regardless of how
we slice up the ``experiments'' or
in what order we accumulate the results. We add up the logarithms of
the probabilities. This corresponds to multiplying together the
probability assigned to the outcome in each experiment, to find the
joint probability of all the experiments together. We take the
logarithm to simplify our intuitive understanding of the accumulated
score, to maintain our grip on the tiny fractions involved, and to
ensure we maximize our \textit{expected} score by stating our honest
probabilities rather than placing all our play money on the most
probable bet.


 Bayesianity states that when you die, Pierre-Simon Laplace
examines every single event in your life, from finding your shoes next
to your bed in the morning to finding your workplace in its accustomed
spot. Every losing lottery ticket means you cared enough to play.
Laplace assesses the advance probability you assigned to each event.
Where you did not assign a precise numerical probability in advance,
Laplace examines your degree of anticipation or surprise, extrapolates
other possible outcomes and your extrapolated reactions, and
renormalizes your extrapolated emotions to a likelihood distribution
over possible outcomes. (Hence the phrase ``Laplacian
superintelligence.'')


 Then Laplace takes every event in your life, and every probability
you assigned to each event, and multiplies all the probabilities
together. This is your Final Judgment---the probability you assigned to
your life.


 Those who follow Bayesianity strive all their lives to maximize
their Final Judgment. This is the sole virtue of Bayesianity. The rest
is just math.


 Mark you: the path of Bayesianity is strict. What probability
shall you assign each morning, to the proposition,
``The Sun shall rise?'' (We shall
discount such quibbles as cloudy days, and that the Earth orbits the
Sun.) Perhaps one who did not follow Bayesianity would be humble, and
give a probability of 99.9\%. But we who follow Bayesianity shall
discard all considerations of modesty and arrogance, and scheme only to
maximize our Final Judgment. Like an obsessive video-game player, we
care only about this numerical score. We're going to
face this Sun-shall-rise issue 365 times per year, so we might be able
to improve our Final Judgment considerably by tweaking our probability
assignment.


 As it stands, even if the Sun rises every morning, every year our
Final Judgment will decrease by a factor of $0.999^{365}$
= 0.7, roughly -0.52 bits. Every two years, our Final Judgment will
decrease more than if we found ourselves ignorant of a
coinflip's outcome! Intolerable. If we increase our
daily probability of sunrise to 99.99\%, then each year our Final
Judgment will decrease only by a factor of 0.964. Better. Still, in the
unlikely event that we live exactly 70 years and then die, our Final
Judgment will only be 7.75\% of what it might have been. What if we
assign a 99.999\% probability to the sunrise? Then after 70 years, our
Final Judgment will be multiplied by 77.4\%.


 Why not assign a probability of 1.0?


 One who follows Bayesianity will \textit{never} assign a
probability of 1.0 to \textit{anything}. Assigning a probability of 1.0
to some outcome uses up \textit{all} your probability mass. If you
assign a probability of 1.0 to some outcome, and reality delivers a
different answer, you must have assigned the \textit{actual} outcome a
probability of \textit{zero}. This is Bayesianity's
sole mortal sin. Zero times anything is zero. When Laplace multiplies
together all the probabilities of your life, the combined probability
will be zero. Your Final Judgment will be doodly-squat, zilch, nada,
nil. No matter how rational your guesses during the rest of your life,
you'll spend eternity next to some guy who believed in
flying saucers and got all his information from the Weekly World News.
Again we find it helpful to take the logarithm, revealing the
innocent-sounding ``zero'' in its
true form. Risking an outcome probability of zero is like accepting a
bet with a payoff of negative infinity.


 What if humanity decides to take apart the Sun for mass (stellar
engineering), or to switch off the Sun because it's
wasting entropy? Well, you say, you'll see that coming,
you'll have a chance to alter your probability
assignment before the actual event. What if an Artificial Intelligence
in someone's basement recursively self-improves to
superintelligence, stealthily develops nanotechnology, and one morning
\textit{it} takes apart the Sun? If on the last night of the world you
assign a probability of 99.999\% to tomorrow's sunrise,
your Final Judgment will go down by a factor of 100,000. Minus 50
decibels! Awful, isn't it?


 So what is your best strategy? Well, suppose you 50\% anticipate
that a basement-spawned AI superintelligence will disassemble the Sun
sometime in the next ten years, and you figure there's
about an equal chance of this happening on any given day between now
and then. On any given night, you would 99.98\% anticipate the Sun
rising tomorrow. If this is really what you anticipate, then you have
no motive to say anything except 99.98\% as your probability. If you
feel nervous that this anticipation is too low, or too high, it must
not be what you anticipate after your nervousness is taken into
account.


 But the deeper truth of Bayesianity is this: You cannot game the
system. You cannot give a humble answer, nor a confident one. You must
figure out exactly how much you anticipate the Sun rising tomorrow, and
say that number. You must shave away every hair of modesty or
arrogance, and ask whether you expect to end up being scored on the Sun
rising, or failing to rise. Look not to your excuses, but ask which
excuses you expect to need. After you arrive at your exact degree of
anticipation, the only way to further improve your Final Judgment is to
improve the accuracy, calibration, and discrimination of your
anticipation. You cannot do better except by guessing better and
anticipating more precisely.


 Er, well, except that you could commit suicide when you turned
five, thereby preventing your Final Judgment from decreasing any
further. Or if we patch a new sin onto the utility function, enjoining
against suicide, you could flee from mystery, avoiding all situations
in which you thought you might not know everything. So much for that
religion.

\hr


 Ideally, we predict the outcome of the experiment in advance,
using our model, and then we perform the experiment to see if the
outcome accords with our model. Unfortunately, we can't
always control the information stream. Sometimes Nature throws
experiences at us, and by the time we think of an explanation,
we've already seen the data we're
supposed to explain. This was one of the scientific sins committed by
nineteenth century evolutionism; Darwin observed the similarity of many
species, and their adaptation to particular local environments, before
the hypothesis of natural selection occurred to him. Nineteenth century
evolutionism began life as a post facto explanation, not an advance
prediction.


 Nor is this a trouble only of semitechnical theories. In 1846, the
successful deduction of Neptune's existence from
gravitational perturbations in the orbit of Uranus was considered a
grand triumph for Newton's theory of gravitation. Why?
Because Neptune's existence was the first observation
that confirmed an \textit{advance} prediction of Newtonian gravitation.
All the other phenomena that Newton explained, such as orbits and
orbital perturbations and tides, had been observed in great detail
before Newton explained them. No one seriously doubted that
Newton's theory was correct. Newton's
theory explained too much too precisely, and it replaced a collection
of ad hoc models with a single unified mathematical law. Even so, the
advance prediction of Neptune's existence, followed by
the observation of Neptune at almost exactly the predicted location,
was considered the first grand triumph of Newton's
theory at predicting what no previous model could predict. Considerable
time elapsed between widespread acceptance of Newton's
theory and the first impressive \textit{advance} prediction of
Newtonian gravitation. By the time Newton came up with his theory,
scientists had already observed, in great detail, most of the phenomena
that Newtonian gravitation predicted.


 But the rule of advance prediction is a morality of science, not a
law of probability theory. If you have already seen the data you must
explain, then Science may darn you to heck, but your predicament
doesn't collapse the laws of probability theory. What
does happen is that it becomes much more difficult for a hapless human
to \textit{obey} the laws of probability theory. When
you're deciding how to rate a hypothesis according to
the Bayesian scoring rule, you need to figure out how much probability
mass that hypothesis assigns to the observed outcome. If we must make
our predictions in advance, then it's easier to notice
when someone is trying to claim every possible outcome as an advance
prediction, using too much probability mass, being deliberately vague
to avoid falsification, and so on.


 No numerologist can predict next week's winning
lottery numbers, but they will be happy to explain the mystical
significance of last week's winning lottery numbers.
Say the winning Mega Ball was seven in last week's
lottery, out of 52 possible outcomes. Obviously this happened because
seven is the lucky number. So will the Mega Ball in next
week's lottery also come up seven? We understand that
it's not certain, of course, but if
it's the lucky number, you ought to assign a
probability of higher than 1/52\,\ldots and then we'll
score your guesses over the course of a few years, and if your score is
too low we'll have you flogged\,\ldots
what's that you say? You want to assign a probability
of exactly 1/52? But that's the same probability as
every other number; what happened to seven being lucky? No, sorry, you
can't assign a 90\% probability to seven and also a
90\% probability to eleven. We understand they're both
lucky numbers. Yes, we understand that they're
\textit{very} lucky numbers. But that's not how it
works.


 Even if the listener does not know the way of Bayes and does not
ask for formal probabilities, they will probably become suspicious if
you try to cover too many bases. Suppose they ask you to predict next
week's winning Mega Ball, and you use numerology to
explain why the number one ball would fit your theory very well, and
why the number two ball would fit your theory very well, and why the
number three ball would fit your theory very well\,\ldots even the most
credulous listener might begin to ask questions by the time you got to
twelve. Maybe you could tell us which numbers are unlucky and
definitely won't win the lottery? Well, thirteen is
unlucky, but it's not absolutely \textit{impossible}
(you hedge, \textit{anticipating} in advance which excuse you might
need).


 But if we ask you to explain \textit{last week's}
lottery numbers, why, the seven was practically inevitable. That seven
should definitely count as a major success for the
``lucky numbers'' model of the
lottery. And it couldn't possibly have been thirteen;
luck theory rules that straight out.

\hr


 Imagine that you wake up one morning and your left arm has been
replaced by a blue tentacle. The blue tentacle obeys your motor
commands---you can use it to pick up glasses, drive a car, etc. How
would you explain this hypothetical scenario? Take a moment to ponder
this puzzle before continuing.


 (Spoiler space\,\ldots)


 How would I explain the event of my left arm being replaced by a
blue tentacle? The answer is that I wouldn't. It
isn't going to happen.


 It would be easy enough to produce a verbal explanation that
``fit'' the hypothetical. There are
many explanations that can ``fit''
anything, including (as a special case of
``anything'') my
arm's being replaced by a blue tentacle. Divine
intervention is a good all-purpose explanation. Or aliens with
arbitrary motives and capabilities. Or I could be mad, hallucinating,
dreaming my life away in a hospital. Such explanations
``fit'' all outcomes equally well,
and equally poorly, equating to hypotheses of complete ignorance.


 The test of whether a model of reality
``explains'' my
arm's turning into a blue tentacle is whether the model
concentrates significant probability mass into that \textit{particular}
outcome. Why that dream, in the hospital? Why would aliens do that
particular thing to me, as opposed to the other billion things they
might do? Why would my arm turn into a tentacle on that morning, after
remaining an arm through every other morning of my life? And in all
cases I must look for an argument compelling enough to make that
particular prediction in \textit{advance}, not mere compatibility. Once
I already knew the outcome, it would become far more difficult to sift
through hypotheses to find good explanations. Whatever hypothesis I
tried, I would be hard-pressed not to allocate more probability mass to
yesterday's blue-tentacle outcome than if I
extrapolated blindly, seeking the model's \textit{most}
likely prediction for tomorrow.


 A model does not always predict all the features of the data.
Nature has no privileged tendency to present me with solvable
challenges. Perhaps a deity toys with me, and the
deity's mind is computationally intractable. If I flip
a fair coin there is no way to further explain the outcome, no model
that makes a better prediction than the maximum-entropy hypothesis. But
if I guess a model with no internal detail or a model that makes no
further predictions, I not only have no reason to believe that guess, I
have no reason to care. Last night my arm was replaced with a blue
tentacle. Why? Aliens! So what will they do tomorrow? Similarly, if I
attribute the blue tentacle to a hallucination as I dream my life away
in a coma, I still don't know any more about what
I'll hallucinate tomorrow. So why do I care whether it
was aliens or hallucination?


 What might be a \textit{good} explanation, then, if I woke up one
morning and found my arm transformed into a blue tentacle? To claim a
``good explanation'' for this
hypothetical experience would require an argument such that,
contemplating the hypothetical argument \textit{now}, \textit{before}
my arm has transformed into a blue tentacle, I would go to sleep
worrying that my arm \textit{really would} transform into a tentacle.


 People play games with plausibility, explaining events they expect
to never actually encounter, yet this necessarily violates the laws of
probability theory. How many people who thought they could
``explain'' the hypothetical
experience of waking up with their arm replaced by a tentacle, would go
to sleep wondering if it might really happen to them? Had they the
courage of their convictions, they would say: I do not expect to ever
encounter this hypothetical experience, and therefore I cannot explain,
nor have I a motive to try. Such things only happen in webcomics, and I
need not prepare explanations, for in real life I shall never have a
chance to use them. If I ever find myself in this impossible situation,
let me miss no jot or tittle of my valuable bewilderment.


 To a Bayesian, probabilities are anticipations, not mere beliefs
to proclaim from the rooftops. If I have a model that assigns
probability mass to waking up with a blue tentacle, then I am nervous
about waking up with a blue tentacle. What if the model is a fanciful
one, like a witch casting a spell that transports me into a randomly
selected webcomic? Then the \textit{prior probability} of webcomic
witchery is so low that my \textit{real-world} understanding
doesn't assign any significant weight to that
hypothesis. The witchcraft hypothesis, if taken as a given, might
assign non-insignificant likelihood to waking up with a blue tentacle.
But my anticipation of that hypothesis is so low that I
don't anticipate any of the predictions of that
hypothesis. That I can conceive of a witchcraft hypothesis should in no
wise diminish my stark bewilderment if I actually wake up with a
tentacle, because the real-world probability I assign to the witchcraft
hypothesis is effectively zero. My zero-probability hypothesis
wouldn't help me \textit{explain} waking up with a
tentacle, because the argument isn't good enough to
make me \textit{anticipate} waking up with a tentacle.


 In the laws of probability theory, likelihood distributions are
fixed properties of a hypothesis. In the art of rationality, to
\textit{explain} is to \textit{anticipate}. To \textit{anticipate} is
to \textit{explain}. Suppose I am a medical researcher, and in the
ordinary course of pursuing my research, I notice that my clever new
theory of anatomy seems to permit a small and vague possibility that my
arm will transform into a blue tentacle. ``Ha
ha!'' I say, ``how remarkable and
silly!'' and feel ever so slightly nervous.
\textit{That} would be a good explanation for waking up with a
tentacle, if it ever happened.


 If a chain of reasoning doesn't make me nervous,
in advance, about waking up with a tentacle, then that reasoning would
be a poor explanation if the event \textit{did} happen, because the
combination of prior probability and likelihood was too low to make me
allocate any significant real-world probability mass to that outcome.


 If you start from well-calibrated priors, and you apply Bayesian
reasoning, you'll end up with well-calibrated
conclusions. Imagine that two million entities, scattered across
different planets in the universe, have the opportunity to encounter
something so strange as waking up with a tentacle (or---gasp!---ten
fingers). One million of these entities say ``one in a
thousand'' for the prior probability of some
hypothesis $X$, and each hypothesis $X$ says ``one in a
hundred'' for the likelihood of waking up with a
tentacle. And one million of these entities say ``one
in a hundred'' for the prior probability of some
hypothesis $Y$, and each hypothesis $Y$ says ``one in
ten'' for the likelihood of waking up with a
tentacle. If we suppose that all entities are well-calibrated, then we
shall look across the universe and find ten entities who wound up with
a tentacle because of hypotheses of plausibility class $X$, and a
thousand entities who wound up with tentacles because of hypotheses of
plausibility class $Y$. So if you find yourself with a tentacle, and
\textit{if} your probabilities are well-calibrated, then the tentacle
is more likely to stem from a hypothesis you would class as probable
than a hypothesis you would class as improbable. (What if your
probabilities are poorly calibrated, so that when you say
``million-to-one'' it happens one
time out of twenty? Then you're grossly overconfident,
and we adjust your probabilities in the direction of less
discrimination and greater entropy.)


 The hypothesis of being transported into a webcomic, even if it
``explains'' the scenario of waking
up with a blue tentacle, is a poor explanation because of its low prior
probability. The webcomic hypothesis doesn't contribute
to explaining the tentacle, because it doesn't make you
anticipate waking up with a tentacle.


 If we start with a quadrillion sentient minds scattered across the
universe, quite a lot of entities will encounter events that are very
likely, only about a mere million entities will experience events with
lifetime likelihoods of a billion-to-one (as we would anticipate,
surveying with infinite eyes and perfect calibration), and not a single
entity will experience the impossible.


 If, somehow, you really did wake up with a tentacle, it would
likely be because of something much more probable than
``being transported into a
webcomic,'' some perfectly normal reason to wake up
with a tentacle which you just didn't see coming. A
reason like what? I don't know. Nothing. I
don't anticipate waking up with a tentacle, so I
can't give any good explanation for it. Why should I
bother crafting excuses that I don't expect to use? If
I was worried I might someday need a clever excuse for waking up with a
tentacle, the \textit{reason I was nervous about the possibility} would
\textit{be} my explanation.


 Reality dishes out experiences using probability, not
plausibility. If you find out that your laptop doesn't
obey Conservation of Momentum, then reality must think that a perfectly
normal thing to do to you. How could violating Conservation of Momentum
possibly be perfectly normal? I anticipate that question has no answer
and will never need answering. Similarly, people do \textit{not} wake
up with tentacles, so apparently it is \textit{not} perfectly normal.

\hr


 There is a shattering truth, so surprising and terrifying that
people resist the implications with all their strength. Yet there are a
lonely few with the courage to accept this satori. Here is wisdom, if
you would be wise:

\begin{quote}
{
 \textit{Since the beginning}\newline
 \textit{Not one unusual thing}\newline
 \textit{Has ever happened.}}
\end{quote}


 Alas for those who turn their eyes from zebras and dream of
dragons! If we cannot learn to take joy in the merely real, our lives
shall be empty indeed.

\myendsectiontext


\bigskip



